{
    "optim": "arXiv:2402.11656v1  [cs.IT]  18 Feb 2024\n1\nIntegrating Pre-Trained Language Model with Physical Layer Communications\nJu-Hyung Lee Dong-Ho Lee Joohan Lee Jay Pujara\nAbstract—The burgeoning ﬁeld of on-device AI communica-\ntion, where devices exchange information directly through embed-\nded foundation models, such as language models (LMs), requires\nrobust, efﬁcient, and generalizable communication frameworks.\nHowever, integrating these frameworks with existing wireless\nsystems and effectively managing noise and bit errors pose\nsigniﬁcant challenges. In this work, we introduce a practical on-\ndevice AI communication framework, integrated with physical\nlayer (PHY) communication functions, demonstrated through\nits performance on a link-level simulator. Our framework in-\ncorporates end-to-end training with channel noise to enhance\nresilience, incorporates vector quantized variational autoencoders\n(VQ-VAE) for efﬁcient and robust communication, and utilizes\npre-trained encoder-decoder transformers for improved general-\nization capabilities. Simulations, across various communication\nscenarios, reveal that our framework achieves a 50% reduction in\ntransmission size while demonstrating substantial generalization\nability and noise robustness under standardized 3GPP channel\nmodels.\nIndex Terms—Physical layer communications, language model,\nVQ-VAE, natural language processing (NLP), link-level simula-\ntion.\nI. INTRODUCTION\nThe increasing capabilities of mobile devices and the\nadvancements in large language model (LLM), particularly\nfoundation models, have paved the way for a new era of on-\ndevice artiﬁcial intelligence (AI).1 This paradigm shift allows\ndevices to possess their own AI capabilities, enabling tasks\nsuch as real-time translation, personalized recommendations,\nand even autonomous driving, all while ensuring privacy and\nefﬁciency [1]–[4].\nOn-device AI communication enables devices equipped\nwith advanced foundation models like LMs to directly ex-\nchange information, forming a network of distributed intel-\nligence. This distributed AI-to-AI communication requires\nefﬁcient and accurate transmission of information between de-\nvices. The ”encoded representation” generated by the AI/LLM\nat the TX side (called AI-Src-Enc) needs to be reliably trans-\nmitted and accurately interpreted as ”decoding input” by the\nAI/LLM at the RX side (called AI-Src-Dec) [5].\nHowever, seamlessly integrating this novel technology with\nexisting communication infrastructure presents a signiﬁcant\nchallenge. Maintaining backward compatibility is a crucial\nrequirement in wireless communication systems, allowing\nJ.-H. Lee and J. Lee are with Ming Hsieh Department of Electrical and\nComputer Engineering, University of Southern California, Los Angeles, USA\n(Emails: {juhyung.lee, joohanl}@usc.edu).\nD.-H. Lee and J. Pujara are with Information Science Institute, Uni-\nversity of Southern California, Marina Del Rey, USA (Emails: {dongho.lee,\njpujara}@usc.edu).\n1Throughout this paper, we will use the term “on-device AI” and “on-\ndevice AI/language model (LM)” interchangeably to refer to a foundation\nmodel or a language model deployed at both transmitter (TX) side and receiver\n(RX) side in a distributed manner.\ndevices designed for older networks (e.g., 4G and 5G) to\noperate seamlessly with newer technologies (e.g., 6G). This\ninteroperability ensures a smooth transition between networks,\nsuch as handover and roaming, enhancing user experience.\nFor on-device AI communication, ensuring backward com-\npatibility is still essential, enabling existing communication\ninfrastructure to support this new paradigm without requiring\nmajor modiﬁcations. Thus, it is required to integrate the on-\ndevice AI model application into wireless communication\nsystems, ensuring they adhere to existing legacy protocols for\nseamless interoperability [6].\nFurthermore, effective on-device AI communication de-\nmands several key qualities: (1) Robustness: The system must\nbe resilient to communication errors (e.g., bit error) and noise\n(e.g., channel fading) inherent in dynamic wireless environ-\nments; (2) Efﬁciency: The system must efﬁciently compress\nand transmit data while maintaining accuracy and ﬁdelity; and\n(3) Generalization Capability: The system should be able to\nhandle diverse inputs and adapt to various communication sce-\nnarios. Meeting these requirements presents another challenge,\nrequiring novel approaches in system design and optimization.\nA. Related Works\nSemantic\ncommunication.\nSemantic\ncommunication,\nwhich\nfocuses\non\neffectively\ntransmitting\nsemantic\n(meaningful)\ninformation\nrather\nthan\nmerely\nreceiving\nindividual symbols or bits [7], is the most relevant research\ndirection for distributed AI-to-AI communications. In order\nto accomplish this, semantic communication systems leverage\nneural network (NN) at both the TX and RX to extract and\ndecode the semantic information. Semantic communication\nresearch can be classiﬁed based on the types of data\nthey utilize, including image [8]–[10], video [11]–[13],\nand speech/text data [14]–[16]. These works pioneered\nthe inclusion of AI in source coding within transceivers,\noptimizing joint source-and-channel coding (JSCC) under\nspeciﬁc noisy channels and data distributions.\nHowever, such semantic communication framework poses\nsigniﬁcant challenges for practical application in on-device\nAI communication. Firstly, it demands major modiﬁcations\nto existing legacy communication protocols (e.g., 5G-NR\nprotocol), distinguishing it from practical distributed AI-to-AI\ncommunication systems. JSCC necessitates that both channel\ncoding and communication modules be modiﬁed and trainable,\nrequiring major modiﬁcations in existing legacy communica-\ntion protocols that are impractical in conventional wireless\ncommunication systems.\nSecondly, much of the existing research assumes ideal chan-\nnel conditions (e.g., additive white Gaussian noise (AWGN))\nand bases analysis on information theory and symbol-level\n2\ntransmission. This overlooks the complexities of non-ideal\n(realistic) channel conditions and the necessity for link (or\nsystem)-level analysis and practical bit-level transmission.\nAdvancing the pioneering efforts in semantic communica-\ntion towards practical application in on-device AI communi-\ncation necessitates two critical components: (1) Reliable com-\nmunication systems need to seamlessly operate with existing\ninfrastructure. This typically involves interacting with various\nphysical-layer communication function modules like mappers,\nforward error correction (FEC), and orthogonal frequency-\ndivision multiplexing (OFDM), each serving a distinct purpose.\nTherefore, it becomes necessary to integrate AI-Src-Enc and\nAI-Src-Dec within the transceiver system, with the operational\nparameters of modules compatible with, or analogous to, those\nin 5G-NR physical-layer modules. (2) Efﬁcient communication\nsystems should be able to compress the output of AI-Src-Enc\nand accurately decode the input of AI-Src-Dec. Developing\nan effective compression approach is crucial for reducing\nthe size of semantic messages while retaining their essential\ninformation.\nFig. 1 shows the difference between semantic communica-\ntion and on-device AI communication systems.\nPre-Trained Language Model.\nRecent studies on text\nsemantic communication exploit transformer architectures [17]\nto extract semantics at the TX and recover the original infor-\nmation at the RX [18], [19]. However, such frameworks may\nhave the following challenges: (i) training an end-to-end (E2E)\nsemantic communication pipeline requires a huge computa-\ntional effort due to the many randomly initialized parameters\nof semantic encoder/decoder to be trained on; (ii) difﬁculty in\nhandling out-of-vocabulary (OOV) since they only use a set\nof whitespace-separated tokens in the training data. General-\npurpose communication systems should be able to effectively\nhandle any data, including out-of-domain (OOD) data that lies\noutside the training data used to develop the framework. This\nnecessitates using pre-trained language models with superior\ngeneralizability, allowing them to perform well even when\nencountering unforeseen data variations.\nPre-trained language models, which have been extensively\ntrained on vast web datasets, are revolutionizing the ﬁeld of\nnatural language processing (NLP) [20], [21]. These models,\noften referred to as “foundation models”, possess the ability\nto effectively generalize even to data where they have not\nspeciﬁcally been trained for [2]. Their capabilities are a result\nof leveraging transfer learning and scaling techniques. Transfer\nlearning involves utilizing knowledge acquired from one task\nand applying it to another [22]. In the context of deep learning,\npre-training is the prevailing approach to transfer learning,\nwhere a model is initially trained on a surrogate task and\nsubsequently ﬁne-tuned to adapt to the downstream task of\ninterest.\nB. Contributions\nTo design and evaluate a practical and widely applicable\non-device AI communication framework, we focus on three\nkey questions:\nQ1: How can we integrate a pre-trained language model in\npractical physical layer (PHY) communication systems\nand evaluate its reliability in realistic network scenario?\nQ2: How can we efﬁciently compress the output of the AI-\nSrc-Enc and accurately decode the noisy input of the RX\nAI-Src-Dec?\nQ3: How can we leverage the knowledge gained from a large\ndataset to build a general-purpose encoder/decoder for\nsystem-wide application?\nOur main contributions, which address these challenges, are\nsummarized as follows:\n• We integrate a language model with the link-level simula-\ntor, NVIDIA Sionna [23], incorporating 5G-NR PHY\ncommunication functions (e.g., Polar channel coding and\nQAM mapper). We evaluate its performance on a channel\nthat contains not only noise but also delay dispersion\n(e.g., 3GPP CDL-family channel), seeing the efﬁcacy of\non-device AI communication. Furthermore, we propose\na noise-tuning method to optimize its reliability. This\naddresses Q1.\n• Converting on-device AI information (e.g., output of AI-\nSrc-Enc and input of AI-Src-Dec) into bit-level informa-\ntion often increases data load. Additionally, even minor\nbit errors, induced by channel noise, can greatly hinder\ncommunication. Addressing this, we propose a novel ap-\nproach that leverages vector quantization techniques [24]\nfor efﬁcient compression and decoding of on-device AI\ninformation. This approach transforms high-dimensional\nvectors into discrete data via a codebook, signiﬁcantly\nreducing transmission overhead even while mitigating\nthe impact of bit errors (i.e., robustness against channel\nnoise). This addresses Q2.\n• We incorporate encoder-decoder transformers into E2E\non-device AI communication systems, initializing them\nwith pre-trained weights. This approach reduces the re-\nliance on channel-speciﬁc and data distribution-speciﬁc\noptimization, thus enhancing the system’s generalizabil-\nity; This addresses Q3. In particular, we employ a\npre-trained encoder-decoder transformer (BART [25]) to\ninitialize the parameters of AI-Src-Enc/Dec so that the\npipeline itself requires little or no computational effort\nand use a pre-trained tokenizer to effectively handle OOV\nso that our pipeline can be generalized to any other text.\n• We release source code for the experiments to promote\nreproducible ML research in wireless communication.2\nC. Paper Organization and Notation\nThis paper is organized as follows: Sec.II provides the\nbackground information on two key concepts: on-device AI\ncommunication and vector quantised variational auto encoder\n(VQ-VAE) After presenting a detailed system model for the\non-device AI communication systems in Sec.III, Sec. IV\nprovides comparison results and ablation studies to assess\nthe contribution of each of our proposed approaches, with\na speciﬁc emphasis on the accuracy and efﬁciency of text\n2https://github.com/abman23/on-device-ai-comm\n3\n(a) Semantic communication system.\n(b) On-device AI/LM communication system.\nFig. 1: Overview of semantic communication systems and on-device AI/LM communication system.\ntransmission. Then, we also present an in-depth analysis of\nour proposed noise-tuning methods, followed by concluding\nremarks in Sec. VI.\nNotation.\nRandom variables are denoted by capital italic\nfont, e.g., X, Y , with realizations x, y, respectively. I(X; Y ),\np(y|x) and p(x, y) represent the mutual information, condi-\ntional probability, and joint probability distribution of the two\nrandom variables X and Y . Multivariate random variables are\nrepresented with capital bold font, e.g., Y = [Y0, Y1]T . Vectors\nare represented using a lowercase bold font, e.g., y. We use\nRD×1 to represent the D-dimensional space of real-valued\nvectors. We also use ∥ · ∥ to denote the L2-norm, which is\nan Euclidean norm.\nII. BACKGROUND\nA. On-device AI (Distributed AI-to-AI) Communication\nOn-device AI (distributed AI-to-AI) communication refers\nto a paradigm where AI models, e.g., LM, are embedded\nlocally within devices and communicate with each other\nover a network. This decentralized approach allows devices\nto exchange complex, context-rich information, leveraging\nthe capabilities of AI models to facilitate personalized and\nintelligent interactions without relying on centralized servers.\nIn the process of AI-to-AI communication using via LM, the\nTX side initially encodes the input sequence. This encoded\ndata is then sent across through the physical layer to the\nRX side, where it is decoded back into its original form. To\nenable this, several key components are required. Both AI-\nSrc-Enc at the TX and AI-Src-Dec at the RX must employ\na shared tokenizer and embedder. These tools play a pivotal\nrole in accurately encoding and decoding the data. Initially,\nthe tokenizer divides the input sequence into discrete tokens.\nSubsequently, each token is transformed into an embedding\nrepresentation through the embedder. This series of mapped\nembeddings is then input into the encoder to generate a\ntransmittable representation. At the RX end, to reconstruct the\noriginal sequence from this representation, the same embedder\nis used to deduce the token index, which is then converted back\nto the corresponding token using the tokenizer.\nThe transmittable representation itself is a high-dimensional\nvector made up of ﬂoating point numbers. For its transmission\nvia the physical layer, this vector needs to be converted into\na form of bit-level information, suitable for digital transmis-\nsion. However, these ﬂoating-point numbers are particularly\nsusceptible to bit-ﬂips, which can occur due to noise within\nthe physical layer as mentioned in Q2. For instance, a 32-bit\nﬂoating-point number representing 1.0 could change to inﬁnity\nwith just one bit-ﬂip (bit error) in the second position, leading\nto a signiﬁcant decline in transmission accuracy [26].\nB. Vector Quantized Variational Autoencoders (VQ-VAE)\nVQ-VAE are a version of variational autoencoders [27],\ndistinguished by their use of vector quantization techniques\nto effectively encode information into discrete latent represen-\ntations [24]. At the core, an autoencoder is a neural network\nthat identiﬁes latent spaces, which are complex and non-linear\nfunctions derived from the data. This neural network architec-\nture is divided into encoder and decoder. The encoder’s role\nis to process and transform the input data into a latent vector\nrepresentation. Following this, the decoder is tasked with the\naccurate reconstruction of the original data, using only the\nlatent vector representation provided by the encoder. Unlike\ntraditional approaches where this latent representation is con-\ntinuous [27], the VQ-VAE creates discrete latent representation\nby incorporating a discrete codebook. This codebook, forming\nan array of vector entries each assigned a speciﬁc index, is\nutilized to discretize the latent space within the autoencoder.\nBy implementing this strategy, the VQ-VAE facilitates the\nlearning of a discrete latent space that effectively captures key\nfeatures of the data. The resultant latent representation in this\nmodel is a sequence of integer indices corresponding to the\ncodebook entries, which not only allows for more efﬁcient\ndata compression but also maintains a level of reconstruction\nquality that is comparable to traditional methods.\n4\nFig. 2: Framework overview of on-device AI/LM PHY communication systems integrated with pre-trained language model.\nThis framework incorporates a link-level simulator to realistically emulate bit-level transmission within PHY communication\nsystems. At the transmission (TX) end, the symbol stream s undergoes AI-Src-Enc SE(·), vector quantization QE(·; Z), and\nchannel encoder CE(·) to produce x. Conversely, at the receiver (RX) end, the received signal y is channel-decoded, vector-\ndequantized, and semantically decoded to recover the symbol ˆs. We evaluate the system in three different criteria: lexical\nsimilarity, semantic similarity, and the compression rate.\nIII. ON-DEVICE AI COMMUNICATION SYSTEMS\nA. Problem Description\nConsider a sentence s that maps to symbol stream x:\nx = CE (QE (SE (s) ; Z)) ,\n(1)\nwhere CE(·), QE(·; Z), and SE(·) represent the channel\nencoder, vector quantization function which maps semantic\nfeatures into discrete indices with the codebook Z, and the\nAI-Src-Enc, respectively. This symbol stream passes through\na physical channel, h, with noise in the RF front end of a RX;\nwhich is expressed by the received signal, y:\ny = hx + n,\n(2)\nHere, the encoded signal by TX propagates over the channel;\nRX receives the attenuated signal with n ∼ CN\n\u00000, σ2\nn\n\u0001\n. Then,\ny is decoded at the RX to estimate the sentence ˆs:\nˆs = SD (QD (CD (y) ; Z)) ,\n(3)\nwhere SD(·) and CD(·) represent the AI-Src-Dec and the\nchannel decoder, respectively, and QD(·; Z) represents the vec-\ntor dequantization function which recovers received discrete\nindices into semantic features with the same codebook Z.\nOn-device AI/LM = (New) Lossy Source Coding.\nWhile\nconventional (lossy) source coding focuses on compressing\nthe source input by ensuring statistical similarity between the\noriginal and reconstructed signals (s and ˆs), AI-Src-Enc takes\na different approach. The system aims to minimize lexical\nerrors (i.e., lexical similarity) and semantic errors (i.e., seman-\ntic similarity) while also reducing the number of bits/symbols\nretrieved from AI-Src-Enc, thereby achieving compression. In\nparticular, it prioritizes compressing the embedding size (i.e.,\nthe dimensionality of r) while maintaining, or even enhancing,\nboth lexical and semantic similarities between the original and\nreconstructed data.\nWhile leveraging advanced traditional PHY communica-\ntion system’s techniques (e.g., multiple-input multiple-output\n(MIMO), OFDM, channel coding, etc.) which prioritize achiev-\ning low bit error rate (BER) (or symbol error rate (SER)), on-\ndevice AI/LM communication system focuses more on preserv-\ning the meaning between the original and reconstructed data to\nensure successful distributed AI-to-AI (inter-AI) transmission.\nTo this end, we design and evaluate our E2E on-device AI\ncommunication system within the context of bit-level PHY\ncommunication transmission to see its E2E performance in\nrealistic scenarios.3 Our rationale for this system is to preserve\nthe meaning and context of the data, even in the presence of\nrealistic channel noise and bit errors.\nB. System Model\nThe architecture of the communication system is illustrated\nin Fig. 2, where the TX consists of CE(·), QE(·; Z), and SE(·)\nand RX consists of CD(·), QD(·; Z), and SD(·), while both\nTX and RX share the codebook Z.\nOn the TX end, the symbol stream s is initially encoded\ninto a vector representation r that encapsulates its semantic\ninformation, using the AI-Src-Enc SE(·). This vector is then\nmapped to discrete indices t within the codebook Z through\na vector quantization technique QE(·; Z). Following this, this\ndiscrete indices t are processed by the channel encoder CE(·),\n3In this study, our primary focus is on PHY layer functions, and we do not\naddress MAC (or higher) layer functions, like automatic repeat request (ARQ)\nand hybrid automatic repeat request (HARQ), which aim to ensure error-free\ntransmission. It is important to note that in certain network scenarios—where\ntransmitted data are latency-sensitive and cannot afford the delay caused by\nHARQ, or in broadcast situations where HARQ is not applicable, such as in\nURLLC or LEO satellite networks—the retransmission process is bypassed.\n5\ntransforming them into x with added redundancy, this step\nensures reliable detection and correction of bit errors.\nInversely, on the RX side, a channel decoder CD(·) ﬁrst\ndecodes the received signal; vector dequantization technique\nQD(·; Z) recovers the discrete indices ˆt into vector represen-\ntation ˆr using the codebook Z; and then the AI-Src-Dec SD(·)\ndecodes the signal and recovers the symbol ˆs.\nAI-Source-Encoder and AI-Source-Decoder.\nBoth the AI-\nSrc-Enc SE(·) and AI-Src-Dec SD(·) are constructed from\na series of 6 transformer layers [17]. Each of these layers\nintegrates a self-attention mechanism, positional encoding, and\na densely connected layer, fortiﬁed by residual connections.\nNotably, while they share a similar foundational architecture,\nthe speciﬁc manner in which the self-attention operates di-\nverges between the encoder and decoder components. This\ndistinction in the self-attention mechanism ensures specialized\nprocessing tailored to the unique demands of both encoding\nand decoding tasks. The encoder employs a fully-visible self-\nattention strategy, granting the model the capability to focus\non any token of the input while the decoder leverages an\nauto-regressive self-attention mechanism, limiting the model’s\nattention solely to previous outputs, which is more appropriate\nfor the streaming paradigm in which the decoder operates.\nThese architectures can be pre-trained on a large scale corpus\nby corrupting documents and computing the cross entropy loss\nbetween the decoder’s output and the original document to\nlearn the model generalizable knowledge [25].\nHere,\nwe\nemploy\nsuch\npre-trained\ncheckpoints\n(BART-base [25])\nand\nuse\nthe\nencoder and\ndecoder\nweights\nto\ninitialize\nthe\nweights\nof\nSE(·)\nand\nSD(·)\nrespectively. For a more detailed understanding of the\nen/decoder’s operation, both SE(·) and SD(·) share the\npre-trained embedding E and the pre-trained tokenizer T .\nOnce the sentence s is given to SE(·), T\ntokenizes s\ninto tokens st = [st1, st2, ...stn] and maps each token to\nembedding se = [se1, se2, ...sen] by E. Then, SE(·) encodes\nse into hidden states r = [r1, r2, ...rn] ∈ Rn×dr through\nmultiple transformer layers, and passes it to channel encoder\nCE(·). In this context, n denotes the total number of tokens,\nwhile dr speciﬁes the dimension of the feature representation\nof each token.\nAfter transmission is complete and the hidden states ˆr are\nretrieved from the channel decoder CD(·) and provided to\nSD(·), the semantic decoder SD(ˆr) establishes the condi-\ntional distribution pθSD (ˆsi | ˆs0:i−1, ˆr) and auto-regressively\nsamples words from this distribution for each index.\nVector Quantization (VQ-VAE).\nOur framework employs\nvector quantization to transform continuous feature representa-\ntions into discrete indices, enabling efﬁcient data transmission.\nThe core of this process is a discrete codebook\nZ = {zk}K\nk=1 ∈ RK×dz,\n(4)\nwhere K denotes the codebook size and dz the dimension of\neach code vector.\nAt the TX end, the continuous feature vector r ∈ Rn×dr,\ngenerated by the AI-Src-Enc SE(·), is quantized into discrete\nindices t ∈ Rn×dz using Z. This quantization aims for dz <\ndr to ensure transmission efﬁciency. Speciﬁcally, each feature\nFig. 3: Architecture of AI-Source-Encoder (AI-Src-Enc) and\nQuantizer\nvector ri ∈ r is divided into segments rij, each with dimension\ndz. For instance, a feature vector ri with dimension 768 and a\ncodebook dimension of 256 can be segmented into three parts\n([ri1, ri2, ri3]), each of dimension 256. The quantizer QE(·; Z)\nmaps each segment rij to the closest codebook entry zk ∈ Z,\nforming the discrete representation ti ∈ t:\nti = QE(ri; Z) =\n\u0012\nargmin\nzk∈Z\n\r\rrij − zk\n\r\r2\n\u0013\n∈ Rζ×dz,\n(5)\nwhere ζ is the length of the encoded sequence. In the given\nexample, ζ equals 3.\nConversely, at the RX end, the dequantizer QD(·; Z) con-\nverts the received discrete indices ˆti back into continuous\nvectors ˆri by directly referencing Z, reconstructing the feature\nrepresentation ˆri from ˆti.\nChannel En/Decoder.\nThe channel encoder CE(·) and\ndecoder CD(·) incorporate various PHY communication func-\ntions, such as Polar code, QAM mapper, OFDM, MIMO,\nselected for their alignment with 5G-NR standards. This ap-\nproach ensures that our framework mirrors real-world commu-\nnication scenarios while acknowledging its partial compliance\nwith 5G-NR protocols.\nFirstly, the input bit for CE(·) is grouped with other bits\nto form a codeword. Polar codes, a form of linear block error\ncorrection codes, are considered one of the channel coding\nschemes in 5G-NR, where low complexity error correction\nis available [28]. It adds redundancy to the codeword with\na certain coderate ρ. This helps detect and correct bit errors\nintroduced during transmission. The codeword is then further\nprocessed and segmented for transmission.\nEach segmented codeword is mapped to a speciﬁc point on\na constellation diagram, such as our considered QAM. Higher\nQAM schemes offer more bits per symbol (better efﬁciency)\nbut are more susceptible to noise. The chosen QAM symbol\nis then represented by a combination of amplitude and phase\nvariations in a carrier signal. The number of bits per symbol\n6\nused is denoted by m and the mapper takes as input a message\nu ∈ {0, . . . , 2m − 1}\nThe modulated symbols are divided into subcarriers across\na wide spectrum. This distributes the signal energy, making\nit more resilient to frequency-selective fading channels. Each\nuser (or subframe) can be modulated independently, enabling\nadaptive bit rate and channel equalization by using the received\nmodulation and coding scheme (MCS) index. The MCS index\nis dynamically selected and can be adjusted on a per-subframe\nbasis, based on the latest channel quality information (CQI).\nData is transmitted simultaneously leveraging multiple an-\ntennas, i.e., MIMO, to exploit spatial diversity or multiplexing.\nThis creates multiple independent channels, increasing relia-\nbility, data rate, or both. The processed signal is transmitted\nover the air. At the receiver, the signal is received by multiple\nantennas. The received signal is then demodulated (QAM de-\ncoding) and demultiplexed (OFDM decoding). Channel coding\nalgorithms (Polar decoding) are applied to correct any errors\nintroduced during transmission. Finally, the decoded bits are\nreassembled into the original data.\nChannel.\nIn the on-device AI communication, the wireless\npropagation channel, henceforth simply referred to as channel,\nintroduces various types of noise and impairments, which\ncan signiﬁcantly affect the transmitted signal. These impacts\ninclude, but are not limited to, path loss, fading, Doppler shift,\nand AWGN.\n3GPP has deﬁned standardized models that are used for\nthe simulation and testing of various wireless system con-\ncepts. These channel models describe time variation, delay\ndispersion, angular dispersion (at both link ends) and ampli-\ntude characteristics. We particularly leverage the standardized\n3GPP clustered delay line (CDL)-family channel models, such\nas CDL-A, CDL-B, and CDL-C [29]. It is worth noting that\nwhile these CDL models are useful for testing, particularly\nfor link-level simulation, they often diverge signiﬁcantly from\nreal-world channels.\nC. Train Objectives\nOur framework is jointly trained using two loss functions:\nLCE and LVQVAE. The LCE minimizes the discrepancy\nbetween input sentence s at the TX end and its predicted\nsentence ˆs at the RX end, employing the cross entropy loss:\nLCE(ˆs, s) = −\nX\ni=1 p (sti) log (p (ˆsti)) +\n(1 − p (sti)) log (1 − p (ˆsti)) ,\n(6)\nwhere p (sti) is the true distribution in which the correct token\nat the i-th index has a probability of 1, and all other tokens\nhave a probability of 0. On the other hand, p (ˆsti) denotes the\npredicted probability distribution over all the possible tokens\nfor the i-th index. LVQVAE aims to jointly train codebook Z\nand the framework in end-to-end as follows:\nLVQVAE = ∥sg[r] − t∥2\n2 + β ∥sg[t] − r∥2\n2 .\n(7)\nwhere sg[·] represents the stop-gradient operation, ensuring no\ngradient is passed through and treating it as a constant that\ndoesn’t update. Our framework is trained by combining the\ntwo aforementioned loss functions as follows:\nL = LCE + LVQVAE.\n(8)\nIn this training process, the trainable parameters include AI-\nSrc-Enc SE(·), AI-Src-Dec SD(·), its embedding E, quantizer\nQE(·; Z), dequantizer QD(·; Z), and its codebook Z.\nD. Optimization Techniques\nOur system employs three key optimization techniques to\nenhance performance:\nNoise-Tuning.\nWe optimize robustness against communi-\ncation noise by adaptively tuning AI-Src-Enc and AI-Src-\nDec to bit (or symbol) errors or channel noise. During ﬁne-\ntuning, we expose them to simulated channel impairments\n(e.g., under the 3GPP CDL-A channel) alongside the channel\nencoder/decoder. This simple ﬁne-tuning, without modifying\nany PHY module, signiﬁcantly improves reliability across\ndiverse channel/communication conditions.\nCodebook.\nTo achieve efﬁcient data compression, we uti-\nlize a VQ-VAE. It learns a codebook of discrete vectors\ncapturing the essence of the AI-Src-Enc’s continuous repre-\nsentations. These codebook vectors, signiﬁcantly smaller than\nthe originals, are transmitted, reducing bandwidth demands.\nInterestingly, it also mitigates the impact of bit errors during\ntransmission as its representation learns the bit (or symbol)\nerror pattern - potentially due to it learning the bit (or symbol)\nerror pattern during pre-training. Upon reception, the VQ-VAE\ndecodes these indices back into high-dimensional vectors. This\ndecoding utilizes the shared latent space (i.e., Z) learned\nduring pre-training, ensuring effective recovery of the semantic\ncontent within the compressed representation. This method\nbalances accuracy, compression, and inference complexity\nthrough the adjustable compression rate (and embedding size).\nPre-Training.\nTo reduce the need for extensive application-\nspeciﬁc training data, we leverage pre-trained models like\nBART-base. This pre-training equips the system with a broad\nbase of generalizable knowledge, enhancing generalization\nperformance.\nIV. EXPERIMENTS\nA. Dataset\nTrain Dataset.\nTheoretically, for training purposes, any text\ncan be utilized. We can set both the input s and the output ˆs\nto be identical for each sentence. This approach aims to train\nthe framework to ensure the faithful transmission of sentences\nwithout any modiﬁcations, aligning with the primary objective\nof the system. However, following the precedent set by earlier\nstudies in text semantic communication [18], [19], we utilize\nthe European Parliament dataset [30] (called EuroParl) which\nis extracted from the proceedings of the European Parliament.\nTest Dataset.\nFor the evaluation, it is important to evaluate\nthe generalization efﬁcacy of framework on out-of-distribution\ndata, particularly on sentences or even tokens not encoun-\ntered during training. To evaluate the generalizability, we\nrandomly sample 1K sentences from the image-caption dataset\nFlickr [31]. The token distribution in this dataset differs\n7\nfrom our training data, a result of reporting bias. This bias\nemerges because people tend to report what interests them\n(e.g., parliamentary discussions) rather than typical and general\nfacts (e.g., describing an image).\nB. Implementation Details\nTABLE I: Type (or parameter) for channel en/decoder.\nType (or Parameter)\nValue\nChannel En/Decoder\nChannel coding\nPolar code\nCoderate (ρ)\n0.5\n# of coded bits\n960\n# of information bits\n480\nMapper\nQAM\n# of bits per symbol (m)\n4\n# of OFDM symbols\n14\n# of TX×RX antennas\n2×2, 1×1\nDirection\nDownlink\nCarrier frequency\n2.6 [GHz]\nSubcarrier spacing\n15 [kHz]\nFFT size (# of subcarrier)\n72\nChannel (train)\nCDL-A, Rayleigh\nChannel (test)\nCDL-{A∼D}, Rayleigh\nAI-Source-En/Decoder\nPre-trained LM (T , E, SE(·), SD(·))\nBART-base\nembedding dimension (dr)\n768\nCodebook\nDimension of each code (dz)\n2\nCodebook size (K)\n1024\nOur entire framework is built using the Keras frame-\nwork [32]. For modeling various channel structures, we uti-\nlize the Sionna library [33]. We employ the Huggingface\nlibrary [34] to load the pre-trained weights of the BART-base\nmodel, which serves as the foundation for initializing the\nembedding E, tokenizer T , AI-Src-Enc SE(·) and the AI-Src-\nDec SD(·), respectively. T , pre-trained embedding E In the\nﬁne-tuning phase, the Adam optimizer [35] is employed, with\nthe sequence length capped at 64 tokens, and the training has\nbeen done for 3 epochs. We conduct a grid search to ﬁnd the\nbest learning rate from the set [3e-4, 1e-4, 5e-5, 2e-5, 1e-5] and\nthe batch size from [2, 4, 8], using the development dataset to\ndetermine the optimal parameters. All of our experiments are\nrun on an RTX 2080-Ti using 32-bit ﬂoating-point precision.\nDetailed system parameters are summarized in Table I.\nC. Evaluation\nIn traditional communication systems, the performance of\ninformation transmission is evaluated by measuring the accu-\nracy of transmitting individual bits (0s and 1s), as reﬂected\nby the Bit Error Rate (BER), or by assessing the ﬁdelity of\nconveying symbols, which are collections of bits, denoted by\nthe Symbol Error Rate (SER).\nIn contrast, on-device AI communication prioritizes the\ntransmission of meaningful content4, focusing on the efﬁcient\nutilization of bandwidth for more effective data transfer. To\n4This objective aligns with those of other research in the ﬁeld of semantic\ncommunication.\naccurately evaluate the performance of on-device AI com-\nmunication systems, we utilize three speciﬁc metrics: lex-\nical similarity (e.g., BLEU [36]), semantic similarity (e.g.,\nSBERT [37]) between s and ˆs, and the compression rate of\nρ.\nBLEU.\nThe BLEU score [36], initially developed for\nevaluating machine translation, quantiﬁes the correspondence\nbetween the n-grams of a generated sentence ˆs and those\nin a reference sentence s [18], [19]. Here, n-grams mean a\ncollection of n successive words in a sentence. BLEU score\ninvolves two key factors: (1) n-gram-based precision of the\ngenerated sentence ˆs and the reference sentence s as follow:\npn =\nP\nn-gram∈ˆs Countclip(n-gram)\nP\nn-gram∈ˆs Count(n-gram) .\n(9)\nHere, Countclip(n-gram) represents the number of n-grams\nfrom the generated sentence ˆs that are found in a reference\nsentence s while Count(n-gram) represents the total number\nof n-grams in the generated sentence ˆs.\nHowever, simply counting identical n-grams can lead to an\noverestimation. Consider the case where the reference sentence\nis “I am a boy” and the generated sentence is “a a a a”. In\nthis scenario, the unigram precision p1 would erroneously be\ncomputed as 1, as each occurrence of the unigram “a” is found\nin the reference sentence.\nTo address this issue, Count clip(n-gram) is employed\nto cap the count at the highest frequency observed in the\nreference sentence s, thereby preventing overcounting. In the\ngiven example, Count clip(“a”) is adjusted to 1 instead of 4,\nreﬂecting the maximum occurrence of the unigram “a” in the\nreference sentence s; (2) A brevity penalty is used to mitigate\nthe inﬂuence of sentence length, preventing the overﬁtting to\nthe sentence length. This penalty comes into play when the\nlength of generated sentence ˆs is shorter than the sentence\nlength of the reference sentence s as follow:\nBP =\n(\n1,\nif |ˆs| > |s|\ne(1−|s|/|ˆs|).\nif |ˆs| ≤ |s|\n(10)\nThe BLEU score for n-grams, represented as BLEU-n,\nis calculated as the product of this brevity penalty and the\nexponential of the precision score for n-grams exp (log pn).\nThe overall BELU score is the brevity penalty multiplied by\nthe exponential of the weighted sum of the log precision scores\nfor different n-grams, represented as exp\n\u0010PN\nn=1 wn log pn\n\u0011\n,\nwhere wn denotes the weight of the n-gram. Here, BLEU-\nn refers to the BLEU score considering only n-grams, and\nthe general BLEU score is a weighted average of BLEU-1,\nBLEU-2, BLEU-3, and BLEU-4. Higher-order n-grams (i.e.,\nlonger n-grams) are indicative of the ﬂuency and grammatical\naccuracy of the generated sentence ˆs.\nSBERT.\nDespite a low lexical overlap between the sen-\ntences s and ˆs, their semantic content may be closely aligned.\nFor example, the words “child” and “children” bear a close\nsemantic relationship, yet a BLEU score based on lexical\nmatching would not recognize this and would rate the similar-\nity as zero. To compute such semantic similarity, sentences can\nbe represented into vector embeddings through an embedding\n8\nFramework\nPHY Comm.\nTransmission\nPre-Training\nNoise-Tuning\nEuroParl (In-dist.)\nFlickr (Out-dist.)\nBLEU-3\nBLEU-4\nSBERT\nBLEU-3\nBLEU-4\nSBERT\nDeepSC [14]\n✗ (symbol-level)\n✗\n✗\n✗\n0.6329\n0.5802\n0.7669\n0.1878\n0.1111\n0.3737\nSeq2Seq-SC [26]\n✓ (bit-level)\nTanh\n✓\n✗\n0.6428\n0.5732\n0.8142\n0.5522\n0.4795\n0.7910\nOurs (1 × 1)\n✓ (bit-level)\nVQ-VAE\n✓\n✓\n0.9959\n0.9946\n0.9959\n0.9714\n0.9682\n0.9998\nTABLE II: Performance comparison study. Each baseline is trained with EuroParl training set and evaluated using both\nthe EuroParl and Flickr test sets (Channel = Rayleigh, EbN0 = 7 [dB]). The EuroParl test set assesses the in-distribution\nperformance, whereas the Flickr test set evaluates the out-of-distribution performance.\nmodel denoted as M. The degree of semantic similarity can\nthen be quantiﬁed by computing the cosine similarity between\nthese vector representations as follow:\nmatch(ˆs, s) =\nM(s) · M(ˆs)T\n∥M(s)∥ ∥M(ˆs)∥.\n(11)\nExisting research in semantic communication often employs\nBERT [38] as the embedding model M to encode sentences.\nTo derive sentence embedding, they typically use methods\nlike average pooling or extract the embedding from the ﬁrst\ntoken (i.e., CLS pooling). These embeddings are then used to\ncalculate cosine similarity [18], [19]. Nonetheless, such pre-\ntrained models, when not ﬁne-tuned for the speciﬁc task of\nsemantic textual similarity, may not effectively capture the\ntrue semantic nuances of sentences. This is attributed to the\nanisotropic nature of the embedding space, which can lead\nto embeddings that do not properly represent the semantic\nvariance across sentences [39]. Here, we use SBERT [37],\nwhich is ﬁne-tuned on semantic textual similarity tasks, to\nencode the sentence embedding.\nCompression Efﬁciency.\nGeneral (lossy) source coding in\nconventional systems emphasizes compact representation of\ninformation to enhance transmission/spectral efﬁciency, often\nat the expense of minor data loss. This contrasts with on-\ndevice AI communication, where the exchange of efﬁcient\nrepresentations prioritizes semantic ﬁdelity over mere data\nvolume reduction. The aim here is to transmit the essence\nand context of messages with minimal semantic distortion.\nThe compression rate in on-device AI communication, there-\nfore, assesses how effectively AI-Src-Enc output is compacted.\nIt is quantiﬁed by the ratio of the sizes of AI-Src-Enc output\n(r) and channel encoder input (t), described as:\ncompress(r, t) = size(r)\nsize(t),\n(12)\nwhere size(x) denotes the size of vector x.\nTo evaluate how compression impacts the conveyance\nof a message’s meaning, we deﬁne compression efﬁciency\n(Ecompress) as a metric that examines the balance between the\ncompression rate and semantic similarity:\nEcompress ≜\nmatch(ˆs, s; ρ)\nlog2 (compress(r, t)),\n(13)\nwhere match(·, ·; ρ) assesses the SBERT for a given ρ com-\npress rate.\nV. EXPERIMENTAL RESULTS\nA. Setup/Baseline\nWe primarily evaluate our proposed on-device AI/LLM\ncommunication frameworks (“Ours”) from four distinct view-\npoints:\nPHY Communication.\nPHY communication conduct bit-\nlevel transmission by leveraging speciﬁc PHY functions, e.g.,\nPolar coding, QAM mapper, OFDM. On the other hand, exist-\ning semantic communication works, exempliﬁed by systems\nlike DeepSC [18]), conduct symbol-level transmission, not\nconsidering the practical PHY communication functions.\nPre-Training Utilization.\n(1) w/o pre-training uti-\nlizes a transformer architecture for the AI-Src-Enc and AI-\nSrc-Dec, starting with random initialization; while (2) w/\npre-training begins with pre-trained model weights to\ninitialize the AI-Src-Enc and AI-Src-Dec.\nNoise-Tuning Utilization.\n(1) w/o noise-tuning ﬁne-\ntunes the framework in the absence of any simulated channel\nnoise; while (2) w/ noise-tuning incorporates simulated\nchannel noise, inducing bit errors, into the ﬁne-tuning process.\nIn particular, the systems is noise-tuned (ﬁne-tuned) under the\nCDL family of channel models and bit-level PHY communi-\ncation setup (see details in Table I) and energy per-bit to noise\nratio (EbN0) = 5 ∼ 15 [dB].\nCodebook Utilization.\nIn PHY communication, it is neces-\nsary to transform the vector output of the AI-Src-Enc into a\ndiscrete bit-level representation. One straightforward method\nis to directly map each ﬂoating-point number in the vector to\nits bit-level equivalent (e.g., 768-dimensional vector results in\n768×32 bits). However, this method is highly susceptible to\nchannel noise, where even a single bit error can signiﬁcantly\ndistort the vector representation (e.g., ﬂoating-point arithmetic\nerror). To mitigate this issue, we explore and compare various\ntechniques that are more robust to noise. (1) Direct encodes\nthe ﬂoating-point numbers of r straight into bits for transmis-\nsion; (2) Tanh also transforms the ﬂoating-point numbers of r\ninto bits for sending but applies a hyperbolic tangent activation\nfunction to adjust for the cases when bit errors from channel\nnoise push the received representation ˆr beyond certain range\n(e.g., [−1, 1]). By doing so, it realigns the out-of-bound values\nback into the [−1, 1] range, and has been used in Seq2Seq-\nSC [26]; (3) VQ-VAE employs vector quantization along with\na codebook Z to encode vector representation r into a set of\ndiscrete codebook indices t for transmission.\n9\nTransmit s\nA man pushes a bicycle along the beach as the sun sets behind him.\nBaseline\nReceive ˆs\nDeepSC [14]\na man between a pity along the bureau as the danish sets behind him.\nSeq2Seq-SC [26]\nA man pushes a bicycle along the beach as sun sets behind him.\nOurs (1 × 1)\nA man pushes a bicycle along the beach as the sun sets behind him.\nTABLE III: Received output examples of baselines and ours (Channel = Rayleigh, EbN0 = 7 [dB]).\n0\n5\n10\n0\n0.5\n1\nTest (Dataset) = EuroParl\n(a) BLEU-4 (EuroParl)\n0\n5\n10\n0\n0.5\n1\nTest (Dataset) = EuroParl\n(b) SBERT (EuroParl)\n0\n5\n10\n0\n0.5\n1\nTest (Dataset) = FlicKr\n(c) BLEU-4 (Flickr)\n0\n5\n10\n0\n0.5\n1\nTest (Dataset) = FlicKr\n(d) SBERT (Flickr)\nFig. 4: Performance comparison with existing frameworks under different EbN0 [dB] (Channel = Rayleigh)\nB. Comparative Study\nWe begin by evaluating the overall efﬁcacy of our proposed\nframework against earlier works in semantic communication.\nEach baseline is trained using the EuroParl training set and\nevaluated on both the EuroParl and Flickr test sets. There\nis a signiﬁcant overlap in vocabulary between the EuroParl\ntraining and test sets, while the overlap is minimal between\nthe EuroParl training set and the Flickr test set. This setup\nallows for an assessment of the framework’s generalizability.\nFor a fair comparison, all baseline models, including the\nbaseline DeepSC which focuses on symbol-level transmission,\nare evaluated under identical conditions of 1 × 1 SISO and\nRayleigh channel throughout the comparative study.\nTable II illustrates the performance comparison under a\nRayleigh Channel with EbN0 = 7 [dB]. Meanwhile, Table III\noffers qualitative examples demonstrating the transmission\naccuracy of each methodology, and Fig. 4 highlights the\nrobustness of each approach.\nTables II and III demonstrate that our framework signiﬁ-\ncantly outperforms both DeepSC and Seq2Seq-SC. A key ob-\nservation from Table II is the substantial decline in DeepSC’s\nperformance on the Flickr dataset, whereas the performance\nreduction for Seq2Seq-SC on Flickr is less severe in com-\nparison. This difference can be mainly due to the use of\npre-training which exhibits generalization capability for\nOOV - that will be elaborated on a later section.\nFig. 4 also demonstrates the superior noise robustness of our\nframework compared to Seq2Seq-SC. An interesting point in\nFig. 4 is the gradual increase in DeepSC’s trend compared\nto the sharp rise in Seq2Seq-SC and our framework. This\nprimarily stems from whether the transmission takes place\nthrough bit-level transmission via practical PHY communica-\ntion. Transmitting through the PHY process information in bit-\nlevel, which requires converting the ﬂoating-point vector into\nbits, where bit errors caused by noise can lead to substantial\nchanges in the information (called ﬂoating-point arithmetic\nerror). Therefore, in conditions of substantial noise, such as\nwhen EbN0 < 5 [dB], transmitting vector representations\nthrough the PHY becomes challenging. Conversely, DeepSC\ntransmits representations based on symbol-level, where noise\nis directly added into the continuous vector representation,\nwhile not considering the practical issues in bit-level operation.\nThis results in such a gradual increase in its performance trend\nas it does not experience any ﬂoating-point error.\nC. Ablation Study\nIn this part of the discussion, we explore the impact of\neach component within our optimized E2E on-device AI\ncommunication framework and examine their respective roles.\nTable IV shows how performance varies with and without the\nuse of pre-training and noise-tuning. Additionally,\nTable VI shows the performance differences when using dif-\nferent transmission approaches including Naive, Tanh and\nVQ-VAE, showing the impact of the use of Codebook.\n1) Impact of Pre-Training: As shown in Table IV, w/o\npre-training leads to a considerable performance drop.\nAfter increasing the number of training epochs, the frame-\nwork shows improvement on in-distribution data that shares\na substantial vocabulary and distribution overlap with the\ntraining data. However, its performance on other datasets with\nminimal overlap with the training data remains close to zero.\nThis indicates that pre-training plays a crucial role in\nthe framework’s ability to generalize - which allows this\nframework to be usable across a wide range of applications.\n2) Impact of Noise-Tuning: As shown in Table IV, w/o\nnoise-tuning leads relatively small performance drop.\nHowever, it provides an intriguing insight that LM and\nVQ-VAE (i.e., AI-Scr-Enc and AI-Src-Dec) are somewhat able\nto learn how to handle bit (or symbol) errors during their\ncommunication with another end.\nTo assess the impact of noise-tuning in more detail, we\npresent Table V and Fig. 5. These results compare the per-\nformance of AI-Src-Enc and AI-Src-Dec trained with and\nwithout noise-tuning (speciﬁcally, the CDL-A channel at EbN0\n10\nCombination\nCodebook\nPre-Training\nNoise-Tuning\nEuroParl (In-dist.)\nFlickr (Out-dist.)\nBLEU-3\nBLEU-4\nSBERT\nBLEU-3\nBLEU-4\nSBERT\nOurs\nVQ-VAE\n✓\n✓\n0.9918\n0.9888\n0.9944\n0.9296\n0.9178\n0.9959\nw/o pre-training (3 epochs)\nVQ-VAE\n✗\n✓\n0.0690\n0.0393\n0.3571\n0.0002\n0.0000\n0.0080\nw/o pre-training (10 epochs)\nVQ-VAE\n✗\n✓\n0.6136\n0.5376\n0.7277\n0.0573\n0.0246\n0.0933\nw/o noise-tuning\nVQ-VAE\n✓\n✗\n0.9515\n0.9325\n0.9804\n0.9147\n0.8907\n0.9787\nTABLE IV: Performance variance w/ and w/o pre-training and noise-tuning (Channel = CDL-A, EbN0 = 4 [dB]).\n0\n2\n4\n6\n0\n0.2\n0.4\n0.6\n0.8\n1\nTest (Channel) = CDL-A\n(a) BLEU-4 (In-dist.)\n0\n2\n4\n6\n0\n0.2\n0.4\n0.6\n0.8\n1\nTest (Channel) = CDL-B\n(b) BLEU-4 (Out-dist.)\n0\n2\n4\n6\n0\n0.2\n0.4\n0.6\n0.8\n1\nTest (Channel) = CDL-C\n(c) BLEU-4 (Out-dist.)\n-3\n-1\n1\n3\n0\n0.2\n0.4\n0.6\n0.8\n1\nTest (Channel) = CDL-D\n(d) BLEU-4 (Out-dist.)\n0\n2\n4\n6\n0\n0.2\n0.4\n0.6\n0.8\n1\nTest (Channel) = CDL-A\n(e) SBERT (In-dist.)\n0\n2\n4\n6\n0\n0.2\n0.4\n0.6\n0.8\n1\nTest (Channel) = CDL-B\n(f) SBERT (Out-dist.)\n0\n2\n4\n6\n0\n0.2\n0.4\n0.6\n0.8\n1\nTest (Channel) = CDL-C\n(g) SBERT (Out-dist.)\n-3\n-1\n1\n3\n0\n0.2\n0.4\n0.6\n0.8\n1\nTest (Channel) = CDL-D\n(h) SBERT (Out-dist.)\nFig. 5: Impact of noise-tuning (w/o Noise-Tuning vs. w/ Noise-Tuning). The CDL-A channel assesses the in-distribution\nperformance, whereas the CDL-B, -C, and -D evaluate the out-of-distribution performance.\nEbNo [dB]\nNoise-Tuning\nTest\nBER\nBLEU\nSBERT\n(CDL-A)\n(Channel)\n2 [dB]\n✗\nCDL-A\n2.124 × 10−1\n0.5801\n0.8477\n✓\nCDL-A\n0.7278\n0.9147\n✗\nCDL-B\n2.332 × 10−1\n0.4588\n0.7734\n✓\nCDL-B\n0.6125\n0.8500\n✗\nCDL-C\n2.419 × 10−1\n0.4072\n0.7359\n✓\nCDL-C\n0.5394\n0.7988\n3 [dB]\n✗\nCDL-A\n1.641 × 10−1\n0.7931\n0.9481\n✓\nCDL-A\n0.8893\n0.9872\n✗\nCDL-B\n1.844 × 10−1\n0.7312\n0.9224\n✓\nCDL-B\n0.8441\n0.9691\n✗\nCDL-C\n1.934 × 10−1\n0.6858\n0.9023\n✓\nCDL-C\n0.8260\n0.9619\nTABLE V: Impact of noise-tuning (w/o Noise-Tuning vs. w/\nNoise-Tuning).\nof 5 ∼ 15 [dB]) in four different communication conditions\nby testing those in CDL-A, B, C, and D channels. The\nperformance difference showcases the impact of incorporating\nrealistic communication errors into the ﬁne-tuning process,\nindicating that AI-Src-Enc and AI-Src-Dec can learn and\npartially mitigate bit error patterns induced by noisy channel\nencountered during link-level PHY communication.5 However,\nhow the AI-Src-Enc and AI-Src-Dec learn and overcome\ncommunication errors is still an open question that we defer to\nour future work. Overall, the AI-Src-Enc/AI-Src-Dec archives\nEbN0 gain up to ∼ 1 [dB] by utilizing the noise-tuning.\nAn important challenge for on-device AI communication\nis their robustness to test-time distributional shifts that nat-\nurally occur when the test environment no longer matches\nthe conditions in a training environment. This is present\nin wireless communication systems, where the propagation\nconditions may change whenever the user is moving. Thus, an\nimportant question is whether the on-device AI communication\ncan retain its performance, both from the same communication\ncondition in training (in-distribution) and other communication\nconditions (out-of-distribution). To this end, we also test its\nperformance in CDL-B, -C, and -D channels, whose condition\nis not seen in training, in Table V and Figs. 5.6 CDL-B\nand CDL-C results indicate that noise-tuning enhances the\n5We conjecture that the AI-Src-Enc and AI-Src-Dec (e.g., LM and\nVQ-VAE) learn bit error pattern of a pre-determined constellation in map-\nper/demapper. When symbol error occurs, neighbor symbols likely are\ndetected, not far-distant symbols. During noise-tuning, such intelligent\nen/decoder adaptively modiﬁes its E and Z to be more robust to bit errors.\n6CDL-A channels encompass both line-of-sight (LoS) and non-LOS\n(NLoS) conditions, offering a more diverse representation of wireless channel\npropagation. In contrast, CDL-B and CDL-C channels are predominantly\nNLoS. CDL-D channels, on the other hand, are characterized by LoS.\n11\nCase\nCodebook\nPre-train\nNoise-tuning\nEuroParl (In-dist.)\nFlickr (Out-dist.)\nBLEU-3\nBLEU-4\nSBERT\nBLEU-3\nBLEU-4\nSBERT\nNaive Transmission\n✗ (Naive)\n✓\n✓\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\nTanh Transmission\n✗ (Tanh)\n✓\n✓\n0.3660\n0.2759\n0.6691\n0.1636\n0.0983\n0.5094\nVQ-VAE Transmission (Ours)\n✓ (VQ-VAE)\n✓\n✓\n0.9918\n0.9888\n0.9944\n0.9296\n0.9178\n0.9959\nTABLE VI: Performance variance with different transmission approaches (Channel = CDL-A, EbN0 = 4 [dB]).\nrobustness even in channels not seen in training, while the\nCDL-D (Figs. 5d and 5h) case highlights that there is still\nroom for improvement for the noise-tuning to be more channel-\nagnostic.\n3) Impact of Codebook: Table VI shows that the VQ-VAE\ntransmission signiﬁcantly outperforms other methods, achiev-\ning near-ﬂawless results under the CDL-A channel at an\nEbN0 = 4 [dB]. This demonstrates the effectiveness of using\na discrete codebook for vector representation quantization in\nenhancing both accuracy and transmission robustness.\nFigs. 6a and 6b further illustrate the impact of the codebook\n(VQ-VAE) over different EbN0 [dB]. In the scenario where a\ncodebook is not used, the shape for transmitting information\nis an n × dr, where each element is a ﬂoating point vector.\nThus, the total size of the transmitted information x becomes\nn × dr × 32 bits, considering that each ﬂoating-point vector is\n32 bits. Conversely, when a codebook is used when dz = 2,\nthe size of transmission is reduced to n × (dr/2). In this case,\neach point in the transmission is an integer index. The total\nsize of the transmitted information x becomes n×(dr/2)×32,\nwith the 32 bits now representing the size of each integer. It\nis worth noting that using integer datatype is notably robust\nagainst rounding errors and precision loss; additionally, it\nallows for using smaller data types, such as 16-bit integers.\nRemarkably, even with a 50% compression of the output of\nAI-Src-Enc, with-codebook consistently outperforms without-\ncodebook, achieving EbN0 gains up to ∼ 6 [dB]. This suggests\nthe potential of the encoded message from the AI-Src-Enc to\nbe effectively compressed without losing its accuracy.\nTradeoff: Compression (and Codebook size) vs. Accuracy.\nThe codebook dimensions (dz) and its size (K) in AI-Src-\nEnc/Dec impact the performance of the on-device AI commu-\nnication systems. Figs. 6c and 6d show how dz affects per-\nformance, examining increments through {2, 4, 8, 16, 32, 64}.\nIncreasing dz enhances compression but may reduce transmis-\nsion accuracy, as compressing a data vector of size dz into a\nsingle index increases vulnerability to transmission errors—a\nsingle index error can impact the entire dz.\nFig. 6e shows the relationship between K and the per-\nformance. Smaller K reduces computational demands, yet it\nmight cause an information loss during quantization, which\ncan adversely affect the ﬁdelity of the reconstructed repre-\nsentation. On the other hand, increasing K provides a more\nﬁne-grained resolution and greater accuracy. However, this\ncomes with increased computational cost due to the cost of\ntraining and inference overhead, and it may even hinder the\nconvergence of training.\nAdditionally, Fig. 7 the relationship between compression\nefﬁciency (Ecompress) and compression rate, identifying a Pareto\noptimal point between the two. Therefore, ﬁnding the right\nbalance and designing an appropriate compression rate and\ncodebook size is crucial for achieving a desirable balance\nbetween accuracy and efﬁciency. Thus, optimizing the com-\npression rate (and codebook size) for AI-Src-Enc/Dec is\ncrucial for striking an optimal balance between accuracy and\ncomputational efﬁciency.\nVI. CONCLUSIONS\nIn this study, we integrated the BART pre-trained LM with\nthe NVIDIA SIONNA link-level simulator to simulate on-\ndevice AI communication within a 5G-NR framework. The\nperformance of on-device communication was assessed in bit-\nlevel transmission across various PHY communication setups,\nincluding 3GPP CDL-family channels, MIMO, OFDM, and\nPolar code.\nOur analysis yielded several key insights from three opti-\nmization techniques: (1) Integration of pre-trained language\nmodels signiﬁcantly enhances the generalization capabilities\nof the on-device AI communication system; (2) Noise-tuning\nresults in an approximate EbN0 gain of around 1 [dB],\neffectively improving performance in both familiar (CDL-\nA channel) and new (CDL-B∼D channels) communication\nconditions; (3) Codebook utilization leads to an EbN0 gain of\nup to approximately 6 [dB], accompanied by a 50% reduction\nin AI-Src-Enc output size. Even with a compression rate of\n8 (utilizing only 12.5% of the compressed information), the\nsystem maintains reasonable performance levels.\nThe implementation strategy involves two stages:\n• Training Stage (Ofﬂine): The AI-Src-En/Dec embedding,\nalong with the codebook, are trained by minimizing the\nloss function described in Sec. III-C. This computation-\nally intensive stage occurs ofﬂine, leveraging powerful\nresources.\n• Execution Stage (On-Device): The on-device system em-\nploys the pre-trained AI-Src-Enc/Dec and codebooks,\nrequiring only inference-level computations.\nLimitations.\nWhile our proposed framework showcases\nthe performance of on-device AI communication under a\nbit-level transmission with a link-level PHY communication\nsetup, there are notable limitations that should be addressed to\nachieve full compliance with 5G-NR communication systems.\nSpeciﬁcally, beyond the PHY, the medium access control\n(MAC) or network layers typically employs automatic repeat\nrequest (ARQ) or hybrid ARQ (HARQ) protocols for packet\nerror correction. The absence of consideration for these higher-\nlayer protocols in our study limits the assessment of the prac-\ntical performance of our framework. Incorporating ARQ or\nHARQ mechanisms into our simulation setup would provide\n12\n0\n5\n10\n15\n0\n0.2\n0.4\n0.6\n0.8\n1\n(a) w/ vs. w/o VQ-VAE\n(BLEU)\n0\n5\n10\n15\n0\n0.2\n0.4\n0.6\n0.8\n1\n(b) w/ vs. w/o VQ-VAE\n(SBERT)\n2\n4\n8\n16\n32\n64\n0\n0.2\n0.4\n0.6\n0.8\n1\n(c) Compress vs. Accuracy\n(BLEU)\n2\n4\n8\n16\n32\n64\n0\n0.5\n1\n(d) Compress vs. Accuracy\n(SBERT)\n102\n103\n0.2\n0.4\n0.6\n0.8\n(e) Codebook size vs. Ac-\ncuracy (BLEU)\nFig. 6: Impact of codebook. Figs. 6a and 6b compares w/o Codebook and w/ Codebook. Fig. 6c and 6d show the tradeoff\nbetween compression and accuracy. Fig. 6e shows a tradeoff between codebook size and accuracy.\n20\n40\n60\n0\n1\n2\n3\n4\nFig. 7: Compression efﬁciency over compression rate\na more comprehensive evaluation of the on-device AI com-\nmunication framework’s efﬁcacy in real-world communication\nscenarios.\nOpen Questions.\nExperimental results in Sec. IV-C high-\nlight that on-device AI can improve communication perfor-\nmance through its predictive and contextual learning abilities.\nWhile integrating channel encoding/decoding with AI-Src-\nEnc/Dec, such as through JSCC or AI-native PHY/MAC,\ncould unlock the full potential, this faces challenges like\ncompatibility with 4G-LTE and 5G-NR, regulatory issues, and\ncost implications.\nTherefore, employing AI as a complementary tool while\nkeeping or carefully optimizing existing PHY or higher-layer\nfunctions presents a more feasible approach. Future research\ncould focus on: (1) ﬁnding the best noise-tuning conditions\nwithout altering PHY functions; (2) exploring how language\nmodels can effectively counteract noisy conditions; (3) improv-\ning speciﬁc PHY functions to boost AI communication; (4)\ndetermining if AI/LM can also learn packet error patterns to\nease the HARQ (or ARQ) process.\nAcknowledgements: This research was partly funded by\nthe National Science Foundation (NSF).\nWe express our deep gratitude to Prof. Andreas F. Molisch for\nhis invaluable feedback and multifaceted support throughout\nthis work. We also thank Thomas Choi for his insightful\ndiscussions during the initial stages of our research.\nREFERENCES\n[1] S. Dhar, J. Guo, J. J. Liu, S. Tripathi, U. Kurup, and M. Shah, “A\nsurvey of on-device machine learning: An algorithms and learning theory\nperspective,” ACM Trans. Internet Things, vol. 2, no. 3, Jul. 2021.\n[2] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von\nArx, M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill et al., “On\nthe opportunities and risks of foundation models,” arXiv preprint\narXiv:2108.07258, 2022.\n[3] S. Geng, S. Liu, and et al., “Recommendation as language processing\n(RLP): A uniﬁed pretrain, personalized prompt & predict paradigm (P5),”\nin Proc. ACM Conf. on Recommender Systems, New York, NY, USA,\n2022, p. 299–315.\n[4] C. Cui, Y. Ma, and et al., “A survey on multimodal large language mod-\nels for autonomous driving,” arXiv preprint arXiv:2311.12320, 2023.\n[5] G. Del´etang, A. Ruoss, P.-A. Duquenne, E. Catt, T. Genewein, C. Mat-\ntern, J. Grau-Moya, L. K. Wenliang, M. Aitchison, L. Orseau, M. Hutter,\nand J. Veness, “Language modeling is compression,” arXiv preprint\narXiv:2309.10668, 2023.\n[6] X. Lin, “An overview of 5G advanced evolution in 3GPP release 18,”\nIEEE Commun. Standards Mag., vol. 6, no. 3, pp. 77–83, 2022.\n[7] Z. Qin, X. Tao, J. Lu, W. Tong, and G. Y. Li, “Semantic communications:\nPrinciples and challenges,” arXiv preprint arXiv:2201.01389, 2021.\n[8] E. Bourtsoulatze, D. B. Kurka, and D. G¨und¨uz, “Deep joint source-\nchannel coding for wireless image transmission,” IEEE Trans. on\nCognitive Communications and Networking, vol. 5, no. 3, pp. 567–579,\n2019.\n[9] J. Shao, Y. Mao, and J. Zhang, “Learning task-oriented communication\nfor edge inference: An information bottleneck approach,” IEEE J. Sel.\nAreas Commun., vol. 40, no. 1, pp. 197–211, 2021.\n[10] D. Huang, F. Gao, X. Tao, Q. Du, and J. Lu, “Toward semantic\ncommunications: Deep learning-based image semantic coding,” IEEE\nJ. Sel. Areas Commun., vol. 41, no. 1, pp. 55–71, 2022.\n[11] T.-Y. Tung and D. G¨und¨uz, “DeepWiVe: Deep-learning-aided wireless\nvideo transmission,” IEEE J. Sel. Areas Commun., vol. 40, no. 9, pp.\n2570–2583, 2022.\n[12] S. Wang, J. Dai, Z. Liang, K. Niu, Z. Si, C. Dong, X. Qin, and\nP. Zhang, “Wireless deep video semantic transmission,” IEEE J. Sel.\nAreas Commun., vol. 41, no. 1, pp. 214–229, 2022.\n[13] P. Jiang, C.-K. Wen, S. Jin, and G. Y. Li, “Wireless semantic communi-\ncations for video conferencing,” IEEE J. Sel. Areas Commun., vol. 41,\nno. 1, pp. 230–244, 2022.\n[14] H. Xie, Z. Qin, G. Y. Li, and B.-H. Juang, “Deep learning enabled\nsemantic communication systems,” IEEE Trans. on Signal Processing,\nvol. 69, pp. 2663–2675, 2021.\n[15] T. Han, Q. Yang, Z. Shi, S. He, and Z. Zhang, “Semantic-preserved\ncommunication system for highly efﬁcient speech transmission,” IEEE\nJ. Sel. Areas Commun., vol. 41, no. 1, pp. 245–259, 2022.\n[16] Z. Weng, Z. Qin, X. Tao, C. Pan, G. Liu, and G. Y. Li, “Deep\nlearning enabled semantic communications with speech recognition and\nsynthesis,” IEEE Trans. on Wireless Communications, 2023.\n[17] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nŁ. Kaiser, and I. Polosukhin, “Attention is all you need,” Advances in\nneural information processing systems (NIPS), vol. 30, 2017.\n[18] H. Xie, Z. Qin, G. Y. Li, and B.-H. Juang, “Deep learning enabled\nsemantic communication systems,” IEEE Trans. on Signal Process.,\nvol. 69, pp. 2663–2675, 2021.\n[19] H. Hu, X. Zhu, F. Zhou, W. Wu, R. Q. Hu, and H. Zhu, “One-to-many\nsemantic communication systems: Design, implementation, performance\nevaluation,” IEEE Commun. Lett., 2022.\n13\n[20] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal,\nA. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., “Language mod-\nels are few-shot learners,” Advances in neural information processing\nsystems (NIPS), vol. 33, pp. 1877–1901, 2020.\n[21] A. Srivastava, A. Rastogi, A. Rao, A. A. M. Shoeb, A. Abid, A. Fisch,\nA. R. Brown, A. Santoro, A. Gupta, A. Garriga-Alonso et al., “Beyond\nthe imitation game: Quantifying and extrapolating the capabilities of\nlanguage models,” arXiv preprint arXiv:2206.04615, 2022.\n[22] S. Thrun, “Lifelong learning algorithms,” in Learning to learn. Springer,\n1998, pp. 181–209.\n[23] J. Hoydis, S. Cammerer, F. A. Aoudia, A. Vem, N. Binder, G. Marcus,\nand A. Keller, “Sionna: An open-source library for next-generation\nphysical layer research,” arXiv preprint arXiv:2203.11854, 2022.\n[24] A. Van Den Oord, O. Vinyals et al., “Neural discrete representation\nlearning,” Advances in neural information processing systems (NIPS),\nvol. 30, 2017.\n[25] M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy,\nV. Stoyanov, and L. Zettlemoyer, “BART: Denoising sequence-to-\nsequence pre-training for natural language generation, translation, and\ncomprehension,” in Proc. the Association for Computational Linguistics,\nOnline, Jul. 2020, pp. 7871–7880.\n[26] J.-H. Lee, D.-H. Lee, E. Sheen, T. Choi, and J. Pujara, “Seq2seq-sc:\nEnd-to-end semantic communication systems with pre-trained language\nmodel,” Asilomar Conference on Signals, Systems, and Computers, 2023.\n[27] D. P. Kingma and M. Welling, “Auto-encoding variational bayes,” arXiv\npreprint arXiv:1312.6114, 2013.\n[28] 3GPP TS 38.212 v17.3.0, “NR; multiplexing and channel coding,” Sep.\n2022.\n[29] 3GPP, “Study on channel model for frequencies from 0.5 to 100 GHz,”\nTech. Rep. 38.901 (V17.0.0), Mar. 2022.\n[30] P. Koehn, “Europarl: A parallel corpus for statistical machine transla-\ntion,” in Proc. Machine Translation Summit X: Papers, Phuket, Thailand,\nSep. 2005, pp. 79–86.\n[31] P. Young, A. Lai, M. Hodosh, and J. Hockenmaier, “From image descrip-\ntions to visual denotations: New similarity metrics for semantic inference\nover event descriptions,” Trans. of the Association for Computational\nLinguistics, vol. 2, pp. 67–78, 2014.\n[32] F. Chollet et al., “Keras,” https://keras.io, 2015.\n[33] J. Hoydis, S. Cammerer, F. Ait Aoudia, A. Vem, N. Binder, G. Marcus,\nand A. Keller, “Sionna: An open-source library for next-generation\nphysical layer research,” arXiv:2203.11854 [cs.IT], Mar. 2022.\n[34] T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac,\nT. Rault, R. Louf, M. Funtowicz et al., “Transformers: State-of-the-art\nnatural language processing,” in Proc. Empirical Methods in Natural\nLanguage Processing, 2020, pp. 38–45.\n[35] D. Kingma and J. Ba, “Adam: A method for stochastic optimization,”\nin International Conference on Learning Representations (ICLR), San\nDiega, CA, USA, 2015.\n[36] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, “BLEU: a method\nfor automatic evaluation of machine translation,” in Proc. the Annual\nMeeting of the Association for Computational Linguistics, Philadelphia,\nPennsylvania, USA, 2002, pp. 311–318.\n[37] N. Reimers and I. Gurevych, “Sentence-BERT: Sentence embeddings\nusing Siamese BERT-networks,” in Proc. Empirical Methods in Natural\nLanguage Processing, Hong Kong, China, Nov. 2019, pp. 3982–3992.\n[38] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training\nof deep bidirectional transformers for language understanding,” in Proc.\nAssociation for Computational Linguistics, Minneapolis, Minnesota,\n2019, pp. 4171–4186.\n[39] B. Li, H. Zhou, J. He, M. Wang, Y. Yang, and L. Li, “On the sentence\nembeddings from pre-trained language models,” in Proc. the 2020 Conf.\non Empirical Methods in Natural Language Processing, Online, Nov.\n2020, pp. 9119–9130.\n"
}