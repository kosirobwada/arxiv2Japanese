{
    "optim": "RETHINKING TEST-TIME LIKELIHOOD: THE LIKELI-\nHOOD PATH PRINCIPLE AND ITS APPLICATION TO OOD\nDETECTION\nSicong Huang\nUniversity of Toronto, Vector Institute & Borealis AI\nJiawei He\nBorealis AI\nKry Yik Chau Lui\nBorealis AI\nABSTRACT\nWhile likelihood is attractive in theory, its estimates by deep generative models\n(DGMs) are often broken in practice, and perform poorly for out of distribution\n(OOD) Detection. Various recent works started to consider alternative scores and\nachieved better performances. However, such recipes do not come with provable\nguarantees, nor is it clear that their choices extract sufficient information.\nWe attempt to change this by conducting a case study on variational autoencoders\n(VAEs). First, we introduce the likelihood path (LPath) principle, generalizing the\nlikelihood principle. This narrows the search for informative summary statistics\ndown to the minimal sufficient statistics of VAEs’ conditional likelihoods. Second,\nintroducing new theoretic tools such as nearly essential support, essential distance\nand co-Lipschitzness, we obtain non-asymptotic provable OOD detection guaran-\ntees for certain distillation of the minimal sufficient statistics. The corresponding\nLPath algorithm demonstrates SOTA performances, even using simple and small\nVAEs 1 with poor likelihood estimates. To our best knowledge, this is the first\nprovable unsupervised OOD method that delivers excellent empirical results, better\nthan any other VAEs based techniques.\n1\nINTRODUCTION\nIndependent and identically distributed (IID) samples in training and test times is the key to much of\nmachine learning (ML)’s success. For example, this experimentally validated modern neural nets\nbefore tight learning theoretic bounds are established. However, as ML systems are deployed in\nthe real world, out of distribution (OOD) data are apriori unknown and pose serious threats. This is\nparticularly so in the most general setting where labels are absent, and test input arrives in a streaming\nfashion. While attractive in theory, naive approaches, such as using the likelihood of deep generative\nmodels (DGMs), are proved to be ineffective, often assigning high likelihood to OOD data (Nalisnick\net al., 2018). Even with access to perfect density, likelihood alone is still insufficient to detect OOD\ndata Le Lan & Dinh (2021); Zhang et al. (2021) when the IID and OOD distributions overlap.\nIn response to likelihood’s weakness, most works have focused on either improving density mod-\nels Havtorn et al. (2021); Kirichenko et al. (2020) or taking some form of likelihood ratios with a\nbaseline model chosen with prior knowledge about image data (Ren et al., 2019; Serrà et al., 2019;\nXiao et al., 2020). Recent theoretical works (Behrmann et al., 2021; Dai et al.) show that perfect\ndensity estimation may be infeasible for many DGMs. It is thus logical to consider OOD screening\nscores that are more robust to density estimation, following Vapnik’s principle de Mello & Ponti\n(2018): When solving a problem of interest (OOD detection), do not solve a more general problem\n(perfect density estimation) as an intermediate step. Some recent works on OOD detection Ahmadian\n& Lindsten (2021); Bergamin et al. (2022); Morningstar et al. (2021); Graham et al. (2023); Liu\net al. (2023) indeed start to consider other information contained in the entire neural activation path\n1We use the same model as Xiao et al. (2020), open sourced from:\nhttps://github.com/\nXavierXiao/Likelihood-Regret.\n1\narXiv:2401.04933v1  [cs.LG]  10 Jan 2024\nFigure 1: Main idea illustration. Left, we have xIID distribution (blue) and xOOD distribution\n(yellow) in the visible space. xOOD is classified into four cases. Middle, we have prior (turquoise),\nposterior after observing xIID (blue), posterior divided into four cases after observing xOOD (yellow),\nin the latent space. Right, we have the reconstructed bxIID (red) on top of real xIID distribution (blue),\nand bxOOD again divided into four cases. Cases (1) and (2)’s graphs means bxOOD is well reconstructed,\nwhile the fried egg alike shapes for Cases (3) and (4) indicate bxOOD are poorly reconstructed. The\ngrey area indicates some pathological OOD regions where VAE assigns high density but not a lot of\nvolume. When integrated, these regions give nearly zero probabilities, and hence the data therein\ncannot be sampled in polynomial times. These are atypical sets.\n(a)\n(b)\n(c)\nFigure 2: Example histograms of (a): Z Norm ∥z∥2, corresponding to the prior p\n\u0000zk\u0001\nin equation\n1. (b): MSE, ∥x − bx∥2, corresponding to the conditional likelihood pθ\n\u0000x | zk\u0001\nin equation 1. (c):\nELBO, corresponding to log pθ(x) in equation 1. The four cases in Figure 1 can be mapped to\ncombinations of Zoverlap, Zseparable in (a) and Xoverlap, Xseparable in (b). Case (1): Zoverlap+Xoverlap; Case\n(2): Zseparable + Xoverlap; Case (3): Zoverlap + Xseparable; Case (4): Zseparable + Xseparable. The separation\nis less pronounced in ELBO. IID data is CIFAR10, OOD data is SVHN. z is 100 dimensional. All\nvalues are normalized, for details on normalization, see Appendix C.\nleading to the likelihood. Examples include entropy, KL divergence, and Jacobian in the likelihood\nMorningstar et al. (2021). See Section A.1 for more discussions on related works. However, it is not\nobvious what kind of statistical inferences these statistics perform, nor do they come with provable\nguarantees. To sum, while the entire neural activation path contains all the information, it is hard to\nchoose which statistics for test time inferences, with theoretical guarantees.\nUnderstanding OOD detection’s theoretical limitation is arguably more important than the IID settings,\nbecause OOD data are unknown in advance which makes the experimental validation less reliable than\nthe IID cases. However, very few works (except Fang et al. (2022)) explore the theory of the OOD\ndetection, especially in the general unsupervised case. This paper makes a theoretical step towards\nchanging this. We develop a principled and provable method, and show state-of-the-art (SOTA) OOD\ndetection performance can be achieved using simple and small VAEs with poor likelihood estimates.\nTo clearly demonstrate the multi-fold contribution of this paper, we discuss the contributions from\nthree perspectives: empirical, methodological, and theoretical ones.\nEmpirical contribution. We contribute a recipe (Section 4) for selecting OOD screening statistics,\nexploiting VAEs’ structure (Figure 1). The recipe starts from this counter-intuitive question: for OOD\n2\ndetection, since practical VAEs are broken (Behrmann et al., 2021; Dai et al.), can we identify VAEs\nthat are sub-optimal in the right way (instead of aiming for perfect density estimation) to achieve good\nperformance? We give one positive answer. Our algorithm broadly follows DoSE Morningstar et al.\n(2021)’s framework, but differs in two important aspects. First, our statistics perform explicit instance\ndependent inferences, allowing neural latent models (e.g. VAEs) to access rich literature in parametric\nstatistical inferences (Section 2, Appendix B.5). Second, our choice, the minimal sufficient statistics\nof the encoder and decoder’s conditional likelihoods, can provably detect OOD samples, even under\nimperfect estimation (Theorem 3.8). Our simple method delivers SOTA peformances (Table 1). We\nachieve so with DC-VAEs from Xiao et al. (2020)’s repository, which is much less powerful (in terms\nof parameter count) and much less well estimated (with regards to its generative sample quality). We\nbelieve this “achieving more with less” phenomenon proves our method’s potential.\nMethodological contribution. The aforementioned recipe follows our newly proposed likelihood\npath principle (LPath) which generalizes the classical likelihood principle 2: when performing\ninstance dependent inference (e.g. OOD detection) under imperfect density estimation, more informa-\ntion can be obtained from the neural activation path that estimates pθ(x). Note that the search space\nis much smaller, by not considering arbitrary functions of activation. We only consider the activation\nthat propagate to pθ(x). We believe this principle is of independent interests to representation learning.\nIf it is possible to extend it to more powerful models (e.g. Glow Kingma & Dhariwal (2018) or\ndiffusion models Rombach et al. (2022)), we anticipate better results. This is left to future works.\nTheoretical contribution. In the general unsupervised OOD detection literature, ours is the first\nwork that quantifies how well VAEs can screen OOD (Theorem 3.8) to our best knowledge. To\nprove such results, we introduce nearly essential support, essential separation and essential distance\n(Definitions 3.1, 3.2, 3.3, 3.4) for distributions, capturing both near-OOD and far-OOD cases (Fang\net al., 2022). We also generalize Lipschtiz continuity and injectivity (Definitions 3.6, B.6, B.7) to\ndescribe how VAEs detect OOD samples. These new concepts that describe the encoder and decoder’s\nfunction analytic properties, the essential distance between PIID and POOD, as well as VAEs’ test time\nreconstruction error characterize our method. Our argument is combinatorial and geometric in nature,\nwhich complements the traditional statistical and information theoretic tools.\nThe rest of the paper is organized as follows. Section 2 bases our method on well established statistical\nprinciples. Section 3 details our theory. Section 4 describes our algorithm and 5 presents an empirical\nevaluation of our algorithm and shows that our proposed LPath method achieves SOTA in the widely\naccepted unsupervised OOD detection benchmarks.\n2\nFROM THE LIKELIHOOD PRINCIPLE TO THE LIKELIHOOD PATH PRINCIPLE\nThis section discusses the statistical foundation of our likelihood path principle. We begin with\nsuboptimality in existing methods (problem I and problem II), followed by proposing the minimal\nsufficient statistics of VAEs’ conditional likelihoods as a solution.\nProblem I: VAEs’ encoder and decoder contain complementary information for OOD detection,\nbut they can be cancelled out in log pθ(x). Recall VAEs’ likelihood estimation:\nlog pθ(x) ≈ log\n\"\n1\nK\nK\nX\nk=1\npθ\n\u0000x | zk\u0001\np\n\u0000zk\u0001\nqϕ (zk | x)\n#\n,\n(1)\nwhich aggregates both lower and higher level information. The decoder pθ\n\u0000x | zk\u0001\n’s reconstruction\nfocuses on the pixel textures, while encoder qϕ\n\u0000zk | x\n\u0001\n’s samples evaluated at the prior, p\n\u0000zk\u0001\n,\ndescribe semantics. Consider xOOD, whose lower level features are similar to IID data, but is\nsemantically different. We can imagine pθ\n\u0000x | zk\u0001\nis large while p\n\u0000zk\u0001\nis small. However, (Havtorn\net al., 2021) demonstrates pθ(x) is dominated by lower level information. Even if p\n\u0000zk\u0001\nwants to\nreveal xOOD’s OOD nature, we cannot decipher it through pθ(xOOD). The converse: pθ\n\u0000x | zk\u0001\ncan\nflag xOOD when the reconstruction error is big. But if p\n\u0000zk\u0001\nis unusually high compared to typical\nxIID, pθ(x) may appear less OOD. We illustrate the main idea with Fig. 1 and demonstrate the four\ncases with histograms from real data in Fig. 2. See Section 3.2 for an in-depth analysis and Table 1\nfor some empirical evidence. To conclude, useful information for screening xOOD is diluted in either\ncase, due to the arithmetical cancellation in multiplication (experimentally verified in Table 3).\n2The marginal likelihood pθ(x) is a special case, because it only uses the end point in the likelihood path.\n3\nProblem II: Too much overwhelms, too little is insufficient. On the other spectrum, one may\npropose to track all neural activations. Since this is not tractable, Morningstar et al. (2021) carefully\nselects various summary statistics. But it is unclear whether they contain sufficient information.\nMoreover, these approaches require fitting a second stage classical statistical algorithm on the chosen\nstatistics, which typically work less well in higher dimensions (Maciejewski et al., 2022). Without a\nprincipled selection, including too many can cripple the second stage algorithm; having too few loses\ncritical information. Neither extreme (tracking too many or too few) seems ideal.\nProposed Solution: The Likelihood Path Principle. We propose and apply our likelihood path prin-\nciple to VAEs. This entails applying the likelihood principle twice in VAEs’ encoder and decoder dis-\ntributions, and track their minimal sufficient statistics: T(x, zk) = (µx(zk), σx(zk), µz(x), σz(x)).\nWe then fit a second stage statistical algorithm on them, akin to Morningstar et al. (2021). We refer to\nsuch sufficient statistics as VAEs’ likelihood paths and name our method the LPath method. Our work\ndiffers from others in two major ways. First, our choices are based on the well established likelihood\nand sufficiency principles, instead of less clear criteria. Second, our method can remain robust to\nimperfect pθ(x) estimation, provably (Theorem 3.8).\nInstance-dependent parametric inference opens door for neural nets to rich methods from\nclassical statistics. When pθ(x | µx(zk), σx(zk)) and qϕ\n\u0000zk | µz(x), σz(x)\n\u0001\nare Gaussian param-\neterized, the inferred instance dependent parameters T(x, zk) allow us to perform statistical tests\nin both latent and visible spaces. By the no-free-lunch principle in statistics3, this model-specific\ninformation can be advantageous versus generic tests 4 based on pθ(x) alone. By the likelihood\nprinciple, which states that in the inference about model parameters, after data is observed, all relevant\ninformation is contained in the likelihood function. Thus T(x, zk) is sufficiently informative for\nOOD inferences. Unlike classical statistical counterparts, which are often static, T(x, zk) is dynamic\ndepending on neural activation. However, they still inherit the inferential properties, capturing all\ninformation in the sense of the well established likelihood and sufficiency principles. In the VAEs’\ncase, LPath is built by qϕ(z | x), p(z), and pθ(x | z), which depends on T(x, zk). This LPath\ncan surprisingly benefit when VAEs break in the right way (Appendix B.4.3). Our likelihood path\nprinciple generalizes the likelihood principle, by considering the neural activation path that leads to\npθ(x). Greater details are discussed in Section B.5.\nModern DGMs are very powerful, but their complexity prevents them from having closed form\nsufficient statistics in the pθ(x). As such, it is unclear how to apply the likelihood and sufficiency\nprinciples. While VAEs don’t even compute pθ(x) exactly, its encoder-decoder LPath infers instance-\ndependent parameters which are minimal sufficient statistics. For this reason, it is an ideal candidate\nto test the likelihood path principle. Our analysis centers around it in this paper.\n3\nFROM THE LIKELIHOOD PATH PRINCIPLE TO OOD DETECTION\nIn Section 2, we narrowed the search of a good OOD detection recipe, from all possible activation\npaths down to VAEs’ minimal sufficient statistics: T(x, zk) = µx(zk), σx(zk), µz(x), σz(x). How-\never, two issues remain. First, they remain high dimensional. This not only costs computational\ntime, but can also cause trouble to the second stage statistical algorithm (Maciejewski et al., 2022).\nSecond, while they are based on statistical theories, they don’t come with OOD detection performance\nguarantee, ideally depending on datasets, VAEs’ functional and statistical generalization properties.\nThis section complements our statistical principles with rigorous non-asymptotic bounds. Generaliz-\ning point-wise injectivity and Lipschitz continuity, Section 3.1 develops new tools to establish data\nand model dependent bounds on VAEs OOD detection (Theorem 3.8). Aided by these inequalities,\nSection 3.2 finalizes the OOD detection algorithm by combining statistical and geometric theories.\n3.1\nPROVABLE DATA AND MODEL DEPENDENT OOD DETECTION PERFORMANCES\nIn Section 3.1.1, we introduce essential separation and distances (Definition 3.1, 3.2 3.3). Section\n3.1.2 generalizes injectivity and Lipschitz continuity. These are relevant for OOD detection as\nthey can describe how VAEs can mix PIID and POOD together in both the visible and latent spaces.\nThese new tools are not VAEs specific and can be of independent interests for general representation\nlearning. Using such concepts, Section 3.1.3 proves how well VAEs’ minimal sufficient statistics\n3Tests which strive to have high power against all alternatives (model agnostic) can have low power in many\nimportant situations (model specific), see Simon & Tibshirani (2014) for another concrete example.\n4For example, typicality test in Nalisnick et al. (2019) and likelihood regret in Xiao et al. (2020)\n4\nFigure 3: Left: Supt(PIID) is the red solid line, which is decomposed to one nearly essential support\n(purple solid line), and less likely events (two green solid lines). Right: Supt(PIID) and Supt(POOD)\nare the purple solid line. ESupt(PIID) is the blue solid line and ESupt(POOD) is the red solid line.\nThe green solid line depicts the corresponding essential distance, so they are essentially separable.\nThe key idea is that for many overlapped distributions, most of their samples are separable.\ncan detect OOD depending on: 1. how separable PIID and POOD are in the visible space; 2. how well\nthe decoder reconstructs PIID; 3. how badly encoder qϕ confuse between PIID and POOD in the latent\nspace; 4. how Lipscchitz continuous the decoder pθ is.\n3.1.1\nESSENTIAL SEPARATION AND ESSENTIAL DISTANCE\nWe introduce a class of essential separation concepts below. They are applicable to both the far-OOD\nand near-OOD cases (Fang et al., 2022; Hendrycks & Gimpel, 2016; Fort et al., 2021). The high level\nidea is that, many PIID and POOD pairs are separable if we consider the more likely samples.\nDefinition 3.1 (Nearly essential support of a Distribution). Let P be a probability distribution with\nsupport Supt(P) (See Appendix B.1 for a definition.) and 0 ≤ ϵ < 1 be given. We say a subset\nESupt(P; −ϵ) ⊂ Supt(P) is an ϵ nearly essential support5 of P, if P(ESupt(P; −ϵ)) ≥ 1 − ϵ.\nWe omit ϵ when the context is clear. Intuitively, when ϵ is small, the subset ESupt(P; −ϵ) contains\nmost events except those occurring with probability less than ϵ. A pictorial illustration is shown on\nthe left in Figure 3 and examples are in Section B.1. Among such nearly essential supports between\nPIID and POOD, we are interested in the ones that are maximally separable.\nDefinition 3.2 (Essential Distance). Let PIID and POOD be two probability distributions with supports\nin a metric space (X, dX), ϵIID ≥ 0 and ϵOOD ≥ 0 be given. We define the (ϵIID, ϵOOD) essential\ndistance between the two distributions as:\nDX|ϵIID,ϵOOD(PIID, POOD)\n(2)\n:=\nsup\nESupt(PIID;−ϵIID)⊂PIID\nESupt(POOD;−ϵOOD)⊂POOD\ndX(ESupt(PIID; −ϵIID), ESupt(POOD; −ϵOOD))\n(3)\nWe believe this captures many practical cases much better. See also the right of Figure 3 for a graphical\ndemonstration and Appendix B.1 for more examples. We can now define essential separability:\nDefinition 3.3 (Essentially Separable between IID and OOD). Let PIID and POOD be two probability\ndistributions and minter > 0 6 be given. We say PIID and POOD are (ϵIID, ϵOOD) essentially separable\nby minter, if there exist ϵIID > 0 and ϵOOD > 0 such that:\nDX|ϵIID,ϵOOD(PIID, POOD) ≥ minter\n(4)\nDX|ϵIID,ϵOOD(PIID, POOD) depends on where and how much we remove certain events. Therefore, it\ncan still provide a meaningful separation even when Supt(PIID) = Supt(POOD). In turn, (ϵIID, ϵOOD)\ndepends on the intrinsic level of separation between PIID and POOD. See Appendix B.1 for a measure\ntheoretic view on our construction. We next relate (ϵIID, ϵOOD) to the essential distance/margin:\nDefinition 3.4 (Margin Essential Distance). Under the setting in Definition 3.3, we define the margin\nminter minimal support probabilities as the arg min 7 for the following minimization problem:\nϵ∗\nIID, ϵ∗\nOOD = arg\ninf\nϵIID,ϵOOD≥0\nsuch that\nDX|ϵIID,ϵOOD(PIID,POOD)≥minter\nϵIID + ϵOOD\n(5)\nThe corresponding distance is called minter margin mini-max essential distance:\nDX|minter(PIID, POOD) = DX|ϵ∗\nIID,ϵ∗\nOOD(PIID, POOD)\n(6)\n5We add the term nearly to avoid collision with the closely related essential support in real analysis.\n6This margin is interpreted as the desired level of essential inter-distribution separation.\n7Without loss of generality, if the arg min does not exist, we consider ϵ∗\nIID, ϵ∗\nOOD up to a desired level of\nprecision. Among them, we choose one as an approximate minimum. The construction remains well-posed.\n5\nFigure 4: Left: If f is L-Lipschitz, it cannot\n(forward) push one small region BR(x) to\na big one (diameter no more than 2LR) - f\nis not “one-to-many”. Right: If f is (K, k)\nco-Lipschitz, its preimage f −1 cannot (back-\nward) pull one small region BR(y) to a big\none (diameter no more than 2KR + k) - f is\n“one-to-one”.\nBy construction, DX|minter(PIID, POOD) ≥ minter. Because of the union bound, we also say with\nprobability at least 1 − (ϵ∗\nIID + ϵ∗\nOOD), PIID and POOD are separated by margin minter.\n3.1.2\nGENERALIZING LIPSCHITZNESS\nNext, we review classical point-wise injectivity and Lipschitz continuity, and then extend them into\nnew ones. These geometric function analytic properties describe how encoder qϕ can confuse POOD\nto be PIID in the latent space, and how well decoder pθ can reconstruct POOD undesirably.\nDefinition 3.5 (L-Lipschitz: region-wise not “one-to-many”). Let (X, dX, µ) and (Y, dY , ν) be two\nmetric-measure spaces, with equal (probability) measures µ(X) = ν(Y ). Let L > 0 be fixed. A\nfunction f : X → Y is L-Lipschitz, if for any R ≥ 0, any x ∈ X:\nDiameter(f(BR(x))) ≤ L · Diameter(BR(x))\n(7)\nThe equivalence between the geometric version and the standard L-Lipscthiz definition, along with\nmore discussions, are in Appendix B.2. It is relevant for OOD detection, since how well decoder\npθ can reconstruct POOD depends on pθ’s Lipschiz constant, demonstrated by Case 1 in Figure 1\nand Section 3.2. Point-wise injectivity (one-to-one), which dictates that f −1(y) is singleton, is\na counterpart to continuity in the sense of invariance of dimension Müger (2015). However, this\ndefinition does not measure how “one-to-one”, nor does it apply to a region. We quantitatively extend\nit to regions with positive probabilities, which may better suit probabilistic applications.\nDefinition 3.6 (Co-Lipschitz: region-wise “one-to-one”). Let K > 0, k ≥ 0 be given. Under the\nsame settings as Definition 3.5, a function f : X → Y is co-Lipschitz with degrees (K, k), if for\nany y ∈ Y , any R ≥ 0:\nDiameter(f −1(BR(y))) ≤ K · Diameter(BR(y)) + k\n(8)\nWe call it co-Lipschitz, because it is reminiscent of Definition 3.5, with f(BR(y)) (forward mapping)\nreplaced by f −1(BR(y)) (backward inverse image). Its relation to OOD detection is illustrated\nin Case 1 and 3 in Figure 1 and and Section 3.2. See Figure 4 for a graphical illustration and\nAppendix B.2 for intuitions. Of equal importance to us is the negations: anti-Lipscthizness and\nanti-co-Lipschitzness (Definition B.6, B.7) in Appendix B.2. See also Appendix B.2 for the relation\nbetween co-Lipschitzness and quasi-isometry in geometric group theory. These concepts are used in\nTheorem 3.8 and their relations to OOD detection are discussed in Section 3.2.\n3.1.3\nPROVABLE OOD DETECTION PERFORMANCE GUARANTEE FOR VAES\nOur main theoretical result quantifies how well VAEs’ minimal sufficient statistics can detect POOD.\nIts significance is that POOD is not knowable in practice, so no experiments can fully validate OOD\ndetection performances. Nonetheless, we can describe what factors affect our method’s performances.\nArguably, this interpretability makes our method desired for safety and security critical situations,\nwhere all other comparable methods lack similar guarantees.\nAt a high level, three major factors capture the hardness of an OOD detection problem. The first is the\ndataset property, such as minter (Definition 3.4). The second class is the function analytic properties\nincluding Lipschitzness and co-Lipschitzness in Section 3.1.2. We introduce the last one, statistical\ngeneralization properties, which is reflected as test time reconstruction error for the VAEs:\nDefinition 3.7 (IID reconstruction distance as intra-distribution margin). The intra-distribution\nmargin, mintra, is defined as:\nmintra :=\nsup\nxIID∼PIID\nd(xIID, bxIID)\n(9)\n6\nWe verify VAEs are sufficiently well trained on PIID by checking ∥xIID − bxIID∥2 via sampling from\nPIID in test time. Even with our small DC-VAE models, the reconstruction errors are very small\n(Appendix B.3). We therefore assume mintra < 1\n2minter henceforth, for any reasonable desired level\nof separation minter. Our main theoretical result:\nTheorem 3.8 (Provable OOD detection). Fix PIID, POOD, mintra > 0 and minter > 2 · mintra. Assume\nwithout loss of generality the corresponding arg min in Definition 3.4 for minter exists, denoted as:\n(ϵ∗\nIID, ϵ∗\nOOD). Suppose the encoder qϕ : x −→ (µz(x), σz(x)) is co-Lipschitz with degrees (K, k), or\nthe decoder pθ : z −→ (µx(z), σx(z)) is L Lipschitz with L ≤ K 8.\nThen for any metric in the input space dX(·, ·) 9 upon which minter and mintra margins are defined,\nwith probability ≥ 1 − (ϵ∗\nIID + ϵ∗\nOOD) over (PIID, POOD), at least one of the following holds:\n∥µz(xIID) − µz(xOOD)∥2 ≥ minter − k\nK\nand\n∥σz(xIID) − σz(xOOD)∥2 ≥ minter − k\nK\n(10)\ndX(xOOD, bxOOD) ≥ 2K − L\n2K\nminter − mintra + kL\n2K\n(11)\nSee Appendix B.3 for the proof and Figure 1 for an illustration. These two bounds decouple the\nminimal sufficient statistics’ detection efficacy to: minter, the desired level of separation (depending on\nPIID and POOD but independent of models), L, the Lipschitz constant of pθ, (K, k), the co-Lipschitz\ndegrees of qϕ, and mintra, the test time reconstruction errors in PIID. Theorem 3.8 suggests OOD\nsamples can be detected either via the latent code distances (Equation 37) or the reconstruction error\n(Equation 38). We discuss how Theorem 3.8 is a weaker solution concept than aiming for better\npθ estimation for OOD detection, its implication on algorithmic design (break VAEs in the right\nway), its statistical aspects, and its limitations (e.g. hard to track k, K, L exactly, similar to Lipschitz\nconstants in optimization theory Bubeck et al. (2015)) in Appendix B.3.\n3.2\nNOT ALL OOD SAMPLES ARE CREATED EQUAL, NOT ALL STATISTICS ARE APPLIED THE\nSAME\nThis section presents our computation-ready summary statistics. While Equation 38 is readily\navailable, Equation 37 does not manifest itself as computationally friendly, as we need to sample\nfrom PIID in inference time. In this section, we delve further into the geometric and combinatorial\nstructures in VAEs, seeking computationally fast substitutes for Equation 37.\nNot all OOD samples are created equal: classify xOOD’ likelihood paths to four cases, based on\nTheorem 3.8, and demonstrated in Figure 1 and 2. Breaking it down this way clarifies how Theorem\n3.8 works. We use Definitions 3.5, 3.6, B.6 and B.7 throughout. We set z = µz(x) (and thus ignore\nσz(x)) to simplify the notations. The reasoning for σz(x) is identical and thus omitted.\nCase (1) [qϕ “many-to-one” and pθ reconstructs well: difficult case]: Corresponding to Figure\n1, encoder qϕ maps both xOOD (left yellow 1) and xIID (left blue) to nearby regions: zOOD ≈ zIID.\nFurthermore, the decoder pθ “tears” zOOD nearby regions (middle yellow 1 inside middle blue) to\nreconstruct both xOOD and xIID well (right blue and right yellow 1), mapping nearby latent codes to\ndrastically different locations in the visible space. Case (2) [qϕ “one-to-one” and pθ reconstructs\nwell on POOD]: In this scenario, qϕ maps xOOD and xIID to different latent locations. As long as xOOD\nis far from xIID in the visible space, zOOD is far from any zIID, but xOOD is well reconstructed. The\nstatistics ∥zIID − zOOD∥2 can flag xOOD. Case (3) [ qϕ “many-to-one” and pθ reconstructs POOD\npoorly ]: Like Case (1), qϕ makes “many-to-one” errors: zIID ≈ zOOD for some xIID. But thanks to\npθ’s continuity, bxOOD(zOOD) ≈ bxIID(zIID). If xOOD is away from xIID by a detectable margin, and\nVAEs are well trained: bxIID ≈ xIID, ∥xOOD − bxOOD∥2 ≈ ∥xOOD − bxIID∥2 ≈ ∥xOOD − xOOD∥2 is\nlarge. Case (4) [ qϕ “one-to-one” and pθ reconstructs POOD poorly ]: When both Case (2) and\nCase (3) are true, it is detectable either way.\nNot all statistics are sufficient and simple: empirical concentrations and distance to zIID latent\nmanifold. Previous discussion leaves out the calculation of Equation 37. Because this involves\n8This condition is evoked when qϕ fails to be co-Lipschitz with degrees (K, k). L ≤ K is sensible because\nVAEs learns to reconstruct PIID.\n9We mean metric spaces that obey the triangle inequality. This is extremely general, including widely used\nl∞ in adversarial robustness, perceptual distance in vision Gatys et al. (2016), etc. Our result also extends to any\nmetric in the latent spaces. We use l2 norm for the latent variable parameters for simplicity.\n7\nFigure 5: Illustration of v statistics in Equation 12. Region 1\n(turquoise) and Region 3 (grey) indicate OOD regions, Region 2\n(blue) IID is for latent manifold region. µz(x) empirically con-\ncentrates around a spherical shell. To screen xOOD, we can track\nzOOD := µz(xOOD), and compute its distances to the IID latent\nmanifold, infzIID d(zIID, zOOD). Since zIID concentrates on some\nspherical shell of radius r0, infzIID d(zIID, zOOD) can be efficiently\napproximated. This is one illustrative case, our reasoning holds\neven if zOOD is in the blue or turquise region.\nAlgorithm: Two Stage OOD Training\n1: Input: x ∈ Dtrain;\n2: Train VAE for Dtrain;\n3: Compute (u(x), v(x)), w(x)) (Eq. 12)\nfor the trained VAE;\n4: Use (u(x), v(x)), w(x)) in the second stage\ntraining, as input data to fit COPOD;\n5: Output: fitted COPOD on (u(x), v(x)), w(x))\nin training dataset, Dtrain D(x) to {D(x)}x∈Dtrain\nAlgorithm:\nDual Feature Levels OOD Detection\n1: Input: x ∼ POOD;\n2: Compute (u(x), v(x)), w(x))\n(Eq. 12) for the trained VAE;\n3: Use the fitted COPOD, D\nto get a decision score D(x);\n4: Output: Determine if x is OOD\nby comparing D(x) to {D(x)}x∈Dtrain\nsampling from PIID and POOD, it appears non-trivial to compute. We propose an approximation based\non the empirical observation that µz(xIID) concentrates around the spherical shell, Sµ(z) centered\nat 0 with radius r0. (Figure 2). In other words, the supports of µz(xIID) where xIID ∼ PIID, can be\napproximated by a spherical shell. Suppose the (unknown but fixed) spherical radius is r0. For any\nxOOD and most xIID, ∥µz(xIID)−µz(xOOD)∥ ≈ |∥µz(xOOD)∥−r0| . The argument for σz is identical\nand won’t be repeated. A formalization of the aforementioned heuristics is given in Appendix B.4.1.\nWe therefore further modify the training objective to encourage this concentration effect. The details\nof our modification can be found in Appendix B.5.1. We hence finalize the OOD scoring statistics:\nu(x) = ∥x − bx∥2 = ∥x − µx(µz(x))∥2\n(12)\nv(x) = ∥µz(x)∥2 ≈ |∥µz(x)∥2 − r0|\n(13)\nw(x) = ∥σz(x)∥2 ≈ |∥σz(x)∥2 − rI|\n(14)\nwhere r0 (or rI for σz) is dropped because: (1) the operation | · −r0| (or | · −rI|) is a function of\n∥µz(x)∥2 (or ∥σz(x)∥2), so it does not contain more information 10; (2) it saves us from estimating r0\n(or rI). These simple functions of the minimal sufficient statistics align with the geometry of Theorem\n3.8 while being computationally fast. They also enjoy provable guarantees, shown in Appendix B.4.1.\nTheorem 3.8 also has implications on algorithmic design, and we explore such heuristics in Appendix\nB.4.2. Section 4 details how our theory and heuristics translate to OOD detection algorithms.\n4\nMETHODOLOGY AND ALGORITHM\nIn this section, we describe our two-stage algorithm, with a similar framework as Morningstar et al.\n(2021). Our algorithm can be used for only one VAE model (LPath-1M) or a pair of two models\n(LPath-2M). In the first stage (neural feature extraction), for LPath-2M, we train two VAEs . One\nVAE has a very high latent dimension (e.g. 1000) and another with a very low dimension (e.g. 1\nor 2), following our analysis in Section B.4.2 and B.4.3. In the second stage (classical density\nestimation), we extract the following statistics, (u(x)low D, v(x)high D, w(x)high D) as in Equations\n12, where u(x)low D is taken from the low dimensional VAE and v(x)high D, w(x)high D from the high\ndimensional VAE. Section B.4.3 explains the reasoning behind such combination. For LPath-1M,\nwe use the same VAE to extract all of u(x), v(x), w(x). We then fit a classical statistical density\nestimation algorithm (COPOD Li et al. (2020) or MD Lee et al. (2018); Maciejewski et al. (2022))\n10Ddata processing inequality from information theory is one way to formalize this: since X → ∥µz(X)∥2 →\n|∥µz(X)∥2 −r0| forms a Markov chain, the following mutual information inequality holds: I(X; ∥µz(X)∥2) ≥\nI(X; |∥µz(X)∥2 − r0|). Our theoretical discussion around µz(X)’s concentration suggests |∥µz(X)∥2 − r0|,\nbut data processing inequality gives us a computationally faster and no less informative candidate ∥µz(X)∥2.\n8\nIID\nCIFAR10\nSVHN\nFMNIST\nMNIST\nOOD\nSVHN\nCIFAR100\nHflip\nVflip\nCIAFR10\nHflip\nVflip\nMNIST\nHflip\nVflip\nFMNIST\nHflip\nVflip\nELBO\n0.08\n0.54\n0.5\n0.56\n0.99\n0.5\n0.5\n0.87\n0.63\n0.83\n1.00\n0.59\n0.6\nLR (Xiao et al., 2020)\n0.88\nN/A\nN/A\nN/A\n0.92\nN/A\nN/A\n0.99\nN/A\nN/A\nN/A\nN/A\nN/A\nBIVA (Havtorn et al., 2021)\n0.89\nN/A\nN/A\nN/A\n0.99\nN/A\nN/A\n0.98\nN/A\nN/A\n1.00\nN/A\nN/A\nDoSE (Morningstar et al., 2021)\n0.97\n0.57\n0.51\n0.53\n0.99\n0.52\n0.51\n1.00\n0.66\n0.75\n1.00\n0.81\n0.83\nFisher (Bergamin et al., 2022)\n0.87\n0.59\nN/A\nN/A\nN/A\nN/A\nN/A\n0.96\nN/A\nN/A\nN/A\nN/A\nN/A\nDDPM (Liu et al., 2023)\n0.98\nN/A\n0.51\n0.63\n0.99\n0.62\n0.58\n0.97\n0.65\n0.89\nN/A\nN/A\nN/A\nLMD (Graham et al., 2023)\n0.99\n0.61\nN/A\nN/A\n0.91\nN/A\nN/A\n0.99\nN/A\nN/A\n1.00\nN/A\nN/A\nLPath-1M-COPOD (Ours)\n0.99\n0.62\n0.53\n0.61\n0.99\n0.55\n0.56\n1.00\n0.65\n0.81\n1.00\n0.65\n0.87\nLPath-2M-COPOD (Ours)\n0.98\n0.62\n0.53\n0.65\n0.96\n0.56\n0.55\n0.95\n0.67\n0.87\n1.00\n0.77\n0.78\nLPath-1M-MD (Ours)\n0.99\n0.58\n0.52\n0.60\n0.95\n0.52\n0.52\n0.97\n0.63\n0.82\n1.00\n0.75\n0.76\nTable 1: AUROC of OOD Detection with different IID and OOD datasets. LPath-1M is LPath with\none model, LPath-2M is LPath with two models, one VAE with overly small latent space and another\nwith overly large latent space.\nto (u(x), v(x), w(x)) for LPath-1M or (u(x)low D, v(x)high D, w(x)high D) for LPath-2M viewed as\nsecond stage training data. This second stage scoring is our OOD decision rule, detecting OOD\naccording to Theorem 3.8.\n5\nEXPERIMENTS\nWe compare our methods with state-of-the-art OOD detection methods Kirichenko et al. (2020);\nXiao et al. (2020); Havtorn et al. (2021); Morningstar et al. (2021); Bergamin et al. (2022); Liu\net al. (2023); Graham et al. (2023), under the unsupervised, single batch, no data inductive bias\nassumption setting. Following the convention in those methods, we have conducted experiments with\na number of common benchmarks, including CIFAR10 (Krizhevsky & Hinton, 2009), SVHN (Netzer\net al., 2011), CIFAR100 (Krizhevsky & Hinton, 2009), MNIST(LeCun et al., 1998), FashionMNIST\n(FMNIST)(Xiao et al., 2017), and their horizontally flipped and vertically flipped variants.\nExperimental Results in Table 1, shows that our methods surpass or are on par with state-of-the-art\n(SOTA). Because our setting assumed no access to labels, batches of test data, or even any inductive\nbias on the dataset, OOD datasets like Hflip and VFlip become very challenging (reflected as small\nminter). Most prior methods achieved only near chance AUROC on Vflip and Hflip for CIFAR10\nand SVHN as IID data. This is expected, because horizontally flipped CIFAR10 or SVHN differs\nfrom in-distribution only by one latent dimension. Even so, our methods still managed to surpass\nprior SOTA in some cases, though only marginally. This improvement is made more significant\ngiven that that we only used a very small VAE architecture, while competitive prior methods used\nlarger models like Glow (Kingma & Dhariwal, 2018) or diffusion models (Rombach et al., 2022). We\nremark that ours clearly exceed other VAEs based methods Xiao et al. (2020); Havtorn et al. (2021),\nand is the only VAE based method that is competitive against bigger models. More experimental\ndetails, including various ablation studies are in Appendix C, D.\nMinimality and sufficiency are advantageous. DoSE Morningstar et al. (2021) conducted experi-\nments on VAEs with five carefully chosen statistics. Assuming better results are reported therein,\nour methods surpass their Glow based scores, which should in turn be better than their VAEs’. On\none hand, Glow’s likelihood is arguably much better estimated than our small DC-VAE model, by\ncomparing the generative samples’ quality. On the other hand, their statistics appear to be more\nsophisticated. However, our simple method based on LPath manages to surpass their scores. This\nshowcases the benefits of minimal sufficient statistics.\n6\nCONCLUSION\nWe presented the likelihood path principle applied to unsupervised, one-sample OOD detection.\nThis leads to our provable method, which is arguably more interesting as OOD data are unknown\nunknowns. Our theory and methods are supported by SOTA results. In future works, we plan to adapt\nour principles and techniques to more powerful DGMs, such as Glow or Diffusion models.\n9\nREFERENCES\nAmirhossein Ahmadian and Fredrik Lindsten. Likelihood-free out-of-distribution detection with\ninvertible generative models. In Zhi-Hua Zhou (ed.), Proceedings of the Thirtieth International\nJoint Conference on Artificial Intelligence, IJCAI-21, pp. 2119–2125. International Joint Con-\nferences on Artificial Intelligence Organization, 8 2021. doi: 10.24963/ijcai.2021/292. URL\nhttps://doi.org/10.24963/ijcai.2021/292. Main Track.\nDara Bahri, Heinrich Jiang, Yi Tay, and Donald Metzler. Label smoothed embedding hypothesis for\nout-of-distribution detection, 2021.\nJens Behrmann, Paul Vicol, Kuan-Chieh Wang, Roger Grosse, and Jörn-Henrik Jacobsen. Understand-\ning and mitigating exploding inverses in invertible neural networks. In International Conference\non Artificial Intelligence and Statistics, pp. 1792–1800. PMLR, 2021.\nFederico Bergamin, Pierre-Alexandre Mattei, Jakob Drachmann Havtorn, Hugo Senetaire, Hugo\nSchmutz, Lars Maaløe, Soren Hauberg, and Jes Frellsen. Model-agnostic out-of-distribution\ndetection using combined statistical tests. In International Conference on Artificial Intelligence\nand Statistics, pp. 10753–10776. PMLR, 2022.\nSébastien Bubeck et al. Convex optimization: Algorithms and complexity. Foundations and Trends®\nin Machine Learning, 8(3-4):231–357, 2015.\nAdrian Chun-Pong Chu and Yangyang Li. A strong multiplicity one theorem in min-max theory.\narXiv preprint arXiv:2309.07741, 2023.\nBin Dai, Li Kevin Wenliang, and David Wipf. On the value of infinite gradients in variational\nautoencoder models. In Advances in Neural Information Processing Systems.\nR Fernandes de Mello and M Antonelli Ponti. Statistical learning theory. Rodrigo Fernandes de\nMello, pp. 75, 2018.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep\nbidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.\nZhen Fang, Yixuan Li, Jie Lu, Jiahua Dong, Bo Han, and Feng Liu. Is out-of-distribution detection\nlearnable? Advances in Neural Information Processing Systems, 35:37199–37213, 2022.\nStanislav Fort, Jie Ren, and Balaji Lakshminarayanan. Exploring the limits of out-of-distribution\ndetection. Advances in Neural Information Processing Systems, 34:7068–7081, 2021.\nNicholas Frosst, Nicolas Papernot, and Geoffrey Hinton. Analyzing and improving representations\nwith the soft nearest neighbor loss, 2019.\nLeon A Gatys, Alexander S Ecker, and Matthias Bethge. Image style transfer using convolutional\nneural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition,\npp. 2414–2423, 2016.\nMark S Graham, Walter HL Pinaya, Petru-Daniel Tudosiu, Parashkev Nachev, Sebastien Ourselin,\nand Jorge Cardoso. Denoising diffusion models for out-of-distribution detection. In Proceedings\nof the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2947–2956, 2023.\nArthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bernhard Schölkopf, and Alexander Smola. A\nkernel two-sample test. The Journal of Machine Learning Research, 13(1):723–773, 2012.\nThéo Guénais, Dimitris Vamvourellis, Yaniv Yacoby, Finale Doshi-Velez, and Weiwei Pan. Bacoun:\nBayesian classifers with out-of-distribution uncertainty. arXiv preprint arXiv:2007.06096, 2020.\nJakob D Drachmann Havtorn, Jes Frellsen, Soren Hauberg, and Lars Maaløe. Hierarchical vaes know\nwhat they don’t know. In International Conference on Machine Learning, pp. 4117–4128. PMLR,\n2021.\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image\nrecognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,\npp. 770–778, 2016.\n10\nDan Hendrycks and Kevin Gimpel. A baseline for detecting misclassified and out-of-distribution\nexamples in neural networks. arXiv preprint arXiv:1610.02136, 2016.\nAgnan Kessy, Alex Lewin, and Korbinian Strimmer. Optimal whitening and decorrelation. The\nAmerican Statistician, 72(4):309–314, 2018.\nDurk P Kingma and Prafulla Dhariwal. Glow: Generative flow with invertible 1x1 convolutions.\nAdvances in neural information processing systems, 31, 2018.\nPolina Kirichenko, Pavel Izmailov, and Andrew G Wilson. Why normalizing flows fail to detect\nout-of-distribution data. Advances in neural information processing systems, 33:20578–20589,\n2020.\nAlex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images.\nTechnical report, Citeseer, 2009.\nBalaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive\nuncertainty estimation using deep ensembles. arXiv preprint arXiv:1612.01474, 2016.\nGilles Lancien and Aude Dalet. Some properties of coarse lipschitz maps between banach spaces.\nNorth-Western European Journal of Mathematics, 2017.\nPeter S Landweber, Emanuel A Lazar, and Neel Patel. On fiber diameters of continuous maps. The\nAmerican Mathematical Monthly, 123(4):392–397, 2016.\nCharline Le Lan and Laurent Dinh. Perfect density models cannot guarantee anomaly detection.\nEntropy, 23(12):1690, 2021.\nYann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to\ndocument recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.\nKimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. A simple unified framework for detecting\nout-of-distribution samples and adversarial attacks. Advances in neural information processing\nsystems, 31, 2018.\nZheng Li, Yue Zhao, Nicola Botta, Cezar Ionescu, and Xiyang Hu. Copod: copula-based outlier\ndetection. In 2020 IEEE International Conference on Data Mining (ICDM), pp. 1118–1123. IEEE,\n2020.\nZhenzhen Liu, Jin Peng Zhou, Yufan Wang, and Kilian Q Weinberger.\nUnsupervised out-of-\ndistribution detection with diffusion inpainting. arXiv preprint arXiv:2302.10326, 2023.\nHenryk Maciejewski, Tomasz Walkowiak, and Kamil Szyc. Out-of-distribution detection in high-\ndimensional data using mahalanobis distance-critical analysis. In Computational Science–ICCS\n2022: 22nd International Conference, London, UK, June 21–23, 2022, Proceedings, Part I, pp.\n262–275. Springer, 2022.\nWarren Morningstar, Cusuh Ham, Andrew Gallagher, Balaji Lakshminarayanan, Alex Alemi, and\nJoshua Dillon. Density of states estimation for out of distribution detection. In International\nConference on Artificial Intelligence and Statistics, pp. 3232–3240. PMLR, 2021.\nMichael Müger. A remark on the invariance of dimension. Mathematische Semesterberichte, 62(1):\n59–68, 2015.\nEric Nalisnick, Akihiro Matsukawa, Yee Whye Teh, Dilan Gorur, and Balaji Lakshminarayanan. Do\ndeep generative models know what they don’t know? In International Conference on Learning\nRepresentations.\nEric Nalisnick, Akihiro Matsukawa, Yee Whye Teh, Dilan Gorur, and Balaji Lakshminarayanan. Do\ndeep generative models know what they don’t know? arXiv preprint arXiv:1810.09136, 2018.\nEric Nalisnick, Akihiro Matsukawa, Yee Whye Teh, and Balaji Lakshminarayanan. Detecting out-of-\ndistribution inputs to deep generative models using typicality. arXiv preprint arXiv:1906.02994,\n2019.\n11\nYuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading\ndigits in natural images with unsupervised feature learning. 2011.\nKazuki Osawa, Siddharth Swaroop, Anirudh Jain, Runa Eschenhagen, Richard E Turner, Rio Yokota,\nand Mohammad Emtiyaz Khan. Practical deep learning with bayesian principles. arXiv preprint\narXiv:1906.02506, 2019.\nNicolas Papernot and Patrick McDaniel. Deep k-nearest neighbors: Towards confident, interpretable\nand robust deep learning, 2018.\nTim Pearce, Felix Leibfried, and Alexandra Brintrup. Uncertainty in neural networks: Approximately\nbayesian ensembling. In International conference on artificial intelligence and statistics, pp.\n234–244. PMLR, 2020.\nJonathan Peck, Joris Roels, Bart Goossens, and Yvan Saeys. Lower bounds on the robustness to\nadversarial perturbations. Advances in Neural Information Processing Systems, 30, 2017.\nJie Ren, Peter J Liu, Emily Fertig, Jasper Snoek, Ryan Poplin, Mark Depristo, Joshua Dillon, and\nBalaji Lakshminarayanan. Likelihood ratios for out-of-distribution detection. In Advances in\nNeural Information Processing Systems, pp. 14707–14718, 2019.\nRobin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-\nresolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF confer-\nence on computer vision and pattern recognition, pp. 10684–10695, 2022.\nChandramouli Shama Sastry and Sageev Oore. Detecting out-of-distribution examples with Gram\nmatrices. In Hal Daumé III and Aarti Singh (eds.), Proceedings of the 37th International Conference\non Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 8491–8501.\nPMLR, 13–18 Jul 2020.\nJoan Serrà, David Álvarez, Vicenç Gómez, Olga Slizovskaia, José F Núñez, and Jordi Luque.\nInput complexity and out-of-distribution detection with likelihood-based generative models. In\nInternational Conference on Learning Representations, 2019.\nNoah Simon and Robert Tibshirani. Comment on\" detecting novel associations in large data sets\" by\nreshef et al, science dec 16, 2011. arXiv preprint arXiv:1401.7645, 2014.\nMingxing Tan and Quoc V. Le. Efficientnet: Rethinking model scaling for convolutional neural\nnetworks, 2020.\nHan Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking\nmachine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.\nZhisheng Xiao, Qing Yan, and Yali Amit. Likelihood regret: An out-of-distribution detection score\nfor variational auto-encoder. Advances in neural information processing systems, 33:20685–20696,\n2020.\nLily Zhang, Mark Goldstein, and Rajesh Ranganath. Understanding Failures in Out-of-Distribution\nDetection with Deep Generative Models. In Proceedings of the 38th International Conference on\nMachine Learning, pp. 12427–12436. PMLR, July 2021. URL https://proceedings.mlr.\npress/v139/zhang21g.html. ISSN: 2640-3498.\n12\nA\nAPPENDIX FOR SECTIION 1\nA.1\nRELATED WORK\nPrior works have approached OOD detection from various perspectives and with different data\nassumptions, e.g., with or without access to training labels, batches of test data or single test data\npoint in a steaming fashion, and with or without knowledge and inductive bias of the data. In the\nfollowing, we give an overview organized by different data assumptions with a focus on where our\nmethod fits.\nThe first assumption is whether the method has access to training labels. There has been extensive\nwork on classifier-based methods that assume access to training labels (Hendrycks & Gimpel, 2016;\nFrosst et al., 2019; Sastry & Oore, 2020; Bahri et al., 2021; Papernot & McDaniel, 2018; Osawa et al.,\n2019; Guénais et al., 2020; Lakshminarayanan et al., 2016; Pearce et al., 2020). Within this category\nof methods, there are different assumptions as well, such as access to a pretrained-net, or knowledge\nof OOD test examples. See Table 1 of (Sastry & Oore, 2020) for a summary of such methods.\nWhen we do not assume access to the training labels, this problem becomes a more general one and\nalso harder. Under this category, some methods assume access to a batch of test data where either\nall the data points are OOD or not (Nalisnick et al., 2019). A more general setting does not assume\nOOD data would come in as batches. Under this setup, there are methods that implicitly assume prior\nknowledge of the data, such as the input complexity method (Serrà et al., 2019), where the use of\nimage compressors implicitly assumed an image-like structure, or the likelihood ratio method (Ren\net al., 2019) where a noisy background model is trained with the assumption of a background-object\nstructure.\nLastly, as mentioned in Section 1, our method is among the most general and difficult setting where\nwe assumed no access to labels, batches of test data, or even any inductive bias of the dataset (Xiao\net al., 2020; Kirichenko et al., 2020; Havtorn et al., 2021; Ahmadian & Lindsten, 2021; Morningstar\net al., 2021; Bergamin et al., 2022). Xiao et al. (2020) fine-tune the VAE encoders on the test data\nand take the likelihood ratio to be the OOD score. Kirichenko et al. (2020) trained RealNVP on\nEfficientNet (Tan & Le, 2020) embeddings and use log-likelihood directly as the OOD score. Havtorn\net al. (2021) trained hierarchical VAEs such as HVAE and BIVA and used the log-likelihood directly\nas the OOD score. Recent works by Morningstar et al. (2021); Bergamin et al. (2022); Liu et al.\n(2023); Graham et al. (2023) were discussed in Section 1. Notably, recent works benefit from bigger\nmodels such as Glow Morningstar et al. (2021) or diffusion models Liu et al. (2023); Graham et al.\n(2023). We compare our method with the above methods in Table 1.\nB\nAPPENDIX FOR SECTION 3\nDefinition of diameter in metric-measure spaces\nWe define Diameter(U) = supx,y∈U d(x, y) (as a generalization of diameter of a rectangle) for a\nsubset U ⊂ X in a metric-measure space (X, dX, µ).\nB.1\nSUPPLEMENTARY MATERIALS FOR SECTION 3.1.1\nDefinition of supports in metric-measure spaces\nDefinition B.1. Let (X, dX, µ) be a metric-measure space. The support of the measure µ is the set\n{x ∈ X | µ(BdX(x, r)) > 0, for all r > 0} where BdX(x, r) = Br(x) denotes the metric ball with\ncenter at x and radius r. The latter abbreviated notation is used when the context is clear.\nIn particular, if X ⊂ Rn, the support is a subset of Rn. For a random variable defined on a metric-\nmeasure space, we define the support of its distribution to be the support of the corresponding\nprobability measure.\nMore examples to illustrate Definition 3.2 In this section, we give more examples to illustrate\nDefinition 3.2.\n13\nExample B.2 (Partially overlapping Gaussians). To see how nearly essential support can be useful,\nconsider Gaussian N(0, 1). Although Supt(N(0, 1)) = R, the interval [−3, 3] contain 99.7 % of the\nevents. [−3, 3] is a nearly essential support for N(0, 1) with ϵ = 0.003.\nExample B.3 (Essential distance between Gaussians). To concretize essential distance between\ndistributions, we can consider PIID = N(−6, 1) and POOD = N(6, 1).\nBecause both have\nsupports R, d(Supt(PIID), Supt(POOD)) = 0. However, their samples are fairly separable. If\nwe choose ϵ = 0.003 to truncate two tails symmetrically for both, DX|ϵIID,ϵOOD(PIID, POOD) =\nDR|0.003,0.003(N(−6, 1), N(6, 1)) = 6.\nExample B.4 (Partially overlapping uniforms). Consider UIID supported on [0, 1] and UOOD sup-\nported on [0.75, 1.75]. Let minter = 0.25. Then setting ϵ∗\nIID = ϵ∗\nOOD = 0.25, and ignoring parts\nof UIID and UOOD, we have: ESupt(UIID; −0.25) = [0, 0.75], ESupt(UOOD; −0.25) = [1, 1.75].\nDX|minter=0.25(UIID, UOOD) = DX|ϵ∗\nIID=0.25,ϵ∗\nOOD=0.25(UIID, UOOD) = 0.25. In other words, with prob-\nability at least 1 - (0.25 + 0.25) = 0.5 over the joint distribution UIID, UOOD, UIID, UOOD are separated\nby 0.25.\nExample B.5 (Totally overlapped uniforms). Consider UIID = UOOD supported on [0, 1]. Let minter =\n0. Then setting ϵ∗\nIID = ϵ∗\nOOD = 0.5, we have: ESupt(UIID; −0.5) = [0, 0.5], ESupt(UOOD; −0.5) =\n[0.5, 1]. DX|minter=0.5(UIID, UOOD) = DX|ϵ∗\nIID=0.5,ϵ∗\nOOD=0.5(UIID, UOOD) = 0. In other words, with\nprobability at least 1 - (0.5 + 0.5) = 0 over the joint distribution UIID, UOOD, UIID, UOOD are separated\nby 0. This example shows that the definition captures the extreme case well and remain well-behaved.\nEssential separation in measure theoretic terms\nDefinitions 3.1, 3.2, 3.3 are related to some standard constructions in measure theory. Our main\nexposition does not assume readers are familiar with measure theory, in order to make the main paper\nmore accessible. Moreover, our writings are tailored for the applications of interests.\nIn here, we cover the measure theoretic perspective here for completeness. From the mathematical\nperspective, only the inter-dependency between the probabilistic notions (ϵIID, ϵOOD), and the margin\nor distance minter between PIID and POOD are new constructions. Definition 3.1 can be rephrased in\nthe following way:\nIn the spirits of measure decomposition, we divide PIID and POOD into components PIID = P likely\nIID\n+\nP unlikely\nIID\nand POOD = P likely\nOOD + P unlikely\nOOD\nsuch that:\n- P likely\nIID\n⊥ P unlikely\nIID\n- P likely\nOOD ⊥ P unlikely\nOOD\n- P likely\nIID\n⊥ P likely\nOOD\n- P unlikely\nIID\n≤ ϵIID\n- P unlikely\nOOD\n≤ ϵOOD\nwhere the notation ⊥ means the two measures are supported on disjoint sets. These are reminiscent\nto the Lebesgue decomposition theorem.\nThe more mathematical readers may notice that our constructions, Definitions 3.1, 3.2, 3.3 are based\non min, max, inf and sup operators. These are intuitively related to Hausdorff distances, and more\ngenerally min-max theory applied to geometry (Chapter 2 of Chu & Li (2023)). While exploring and\nfurther extending our constructions is interesting, it is beyond the scope of the present paper and is\nleft to future works.\nB.2\nSUPPLEMENTARY MATERIALS FOR SECTION 3.1.2\nIn this section, we give the negations of Lipschitzness and Definition 3.6.\nDefinition B.6 (Anti-Co-Lipschitz: region-wise “many-to-one”). Let K > 0, k ≥ 0 be given. Under\nthe same settings as Definition 3.5, a function f : X → Y is anti-co-Lipschitz with degrees (K, k),\nif there exist y ∈ Y and R > 0 such that:\nDiameter(f −1(BR(y))) > K · Diameter(BR(y)) + k\n(15)\n14\nHeuristically, we call it region-wise “many-to-one”, because the diameter of the inverse image,\nf −1(BR(y)), is bounded below. That means f −1(BR(y)) sweeps out a big region. In other words,\nthese far away points in the domain are mapped by f to a small region in the codomain/target space.\nDefinition B.7 (Anti-Lipschitz: region-wise “one-to-many”). Under the same settings as Definition\n3.5, a function f : X → Y is anti-Lipschitz with degrees L, if there exist x ∈ Y and R > 0 such\nthat:\nDiameter(f(BR(x))) > L · Diameter(BR(x))\n(16)\nHeuristically, we call it region-wise “one-to-many”, because the diameter of f(BR(y)), is bounded\nbelow. That means f(BR(x)) sweeps out a big region in the codomain/target space. In other words,\nsmall regions are mapped by f to a big region in the codomain. Intuitively, L-Lipschitz continuity\nquantifies how much f can stretch a metric ball. We call it region-wise not “one-to-many”, because\nLipschtiz functions cannot stretch one small region into a region with big diameter. As L → ∞,\nhowever, f becomes increasingly more “one-to-many”, approaching a discontinuous function. More\nheuristics or interpretations can be found below.\nEquivalence of Definition 3.5 to the standard Lipschitzness.\nProof. Recall the classic definition:\nDefinition B.8 (L-Lipschitz). Let (X, dX, µ) and (Y, dY , ν) be two metric-measure spaces, with\nequal (probability) measures µ(X) = ν(Y ). Let L > 0 be fixed. A function f : X → Y is\nL-Lipschitz, if for any any x1, x2 ∈ X:\ndY (f(x1), f(x2)) ≤ LdX(x1, x2)\n(17)\n1. Classic Lipschitz → geometric Lipschitz.\nTake any x1, x2 ∈ BR(x1) such that d(y1, y2) ≈ Diameter(f(BR(x))) and d(x1, x2) = 2R\nfor the corresponding y1, y2. Without loss of generality and saving us from tracking ϵ, assume\nd(y1, y2) = Diameter(f(BR(x))). By classic Lipschitz condition, d(y1, y2) ≤ Ld(x1, x2), so:\nd(y1, y2) = Diameter(f(BR(x))) ≤ L · Diameter(BR(x)) = 2R.\n2. Geometric Lipschitz → classic Lipschitz. Take any x1, x2 ∈ X and define R = d(x1,x2)\n2\n. By\ngeometric Lipschitzness, Diameter(f(BR(x1))) ≤ L · Diameter(BR(x1)) = 2R = d(x1, x2).\nSince f(x1), f(x2) ∈ f(BR(x1)), d(f(x1), f(x2)) ≤ L · d(x1, x2).\nMore discussion and Intuition for Lipschitz and co-Lipschitz\nWe discuss our new definitions with more details. We recall some standard definitions before defining\nours. We let f −1 denote the pre-image or inverse image of the function f. Recall Diameter(U) is\ndefined as supx1,x2∈U dX(x1, x2) in a metric space (X, dX). We remind ourselves that a functions\nis injective or one-to-one, if for any y ∈ Y , f −1(y) = x, i.e. f −1(y) is a singleton set. Otherwise, a\nfunction is many-to-one.\nOur key observation is that a generalization of the above characterizes VAEs’ abilities to detect OOD\nsamples. We introduce quantitative analogues to capture how one-to-one and many-to-one a function\nf is. Concretely, a function is one-to-one, if the inverse image of a point is one point. Having only\none point in both the domain and codomain can be interpreted as a way of measuring the size of a set.\nThis naturally admits two extensions, by relaxing the sizes of sets in both domain and codomain. For\nexample, we can measure the size of the set f −1(y).\nWe begin the discussion in the domain. we mostly use Diameter(f −1(y)) as in Landweber et al.\n(2016). If Diameter(f −1(y)) is big, we can say it is relatively “more” many-to-one. Otherwise, it is\n“less” many-to-one or more “one-to-one”. Consider the encoder map, qϕ : x −→ (µz(z), σz(z)). We\ncare about how “one-to-one” f is, because we don’t want to to be “many-to-one” as both IID and\nOOD samples can be mapped to the same latent code neighborhood. Definition 3.6 relaxes injectivity\nin two ways: 1. taking R → 0 and k = 0, Definition 3.6 states that f −1(y) has zero diameter; 2.\nWhen k = 0, applying co-Lipschitz with non-asymptotic radius R > 0, we say f is region-wise\n“one-to-one” if for “small” R, f −1(BR(y)) has “small” diameter.\n15\nIn machine learning, we seldom care one about latent code, but the continuous neighborhood around\nit. For this reason, we consider the inverse image of a metric ball around a point. Instead of measuring\nDiameter(f −1(y)), we thus measure: Diameter(f −1(BR(y))). This quantifies how “one-to-one”\nf is: if the inverse image of a metric ball in the codomain has small diameters, we then say f is\nregion-wise “one-to-one”. Otherwise, it is very “many-to-one”:\nTo gain some intuition on Definition B.6, if (K = 100, k = 0), f = qϕ can map two points more\nthan 100R away to the same latent code. If such one point happens to be OOD and another is IID,\nwe won’t be able to detect the OOD in the latent space. On the other hand, if f = qϕ is region-wise\none-to-one or co-Lipschitz at (K = 100, k = 0) and xOOD is 100 distance away from xIID, we can\ndetect it in theory.\nDefinition B.6 and Definition 3.6 form a natural pair. They are kind of the opposite of the other. Note\nthat they are both defined in the backward manner: both are defined in the codomain using inverse\nimages. That is, we compare the diameters between: f −1(BR(y)) in the domain and BR(y) in the\ncodomain. We now discuss the next pair.\nNote that f(BR(x)) is in the codomain and BR(x) is in the domain in Definition 3.5 and Definition\nB.7. These are in the forward direction. They form a polar pair, just like region-wise one-to-one and\nregion-wise many-to-one. We end this discussion by the next lemma, which formalizes in a sense\nL-Lipschiz maps cannot be “one-to-many”.\nLemma B.9 (L-Lipschitz functions cannot be one-to-many with degree L). Let f : z ∈ Rm −→ Rn\nbe a L-Lipschitz function. Then f cannot be one-to-many with degree larger than L.\nThe proof directly follows from definition and we omit it.\nCo-Lipschitzness and Quasi-Isometric Embedding\nThe high level idea behind Sections 3.1.1 and 3.1.2 is to seek relaxed or “soft” versions of the\n“hard” versions of classical metric space separations, distances, and Lipscthitzness. The constructions\nare inspired by the field of quantitative geometry and topology. Concretely, our definition of co-\nLipschtizness, Definition, 3.6 is closely related to quasi-isometry in geometric group theory. We now\nrelate them rigorously.\nThe high level idea of quasi-isomety is to relax the more rigid concept of isometry by an affine\ntransformation type of inequalities. Recall the definition of isometry:\nDefinition B.10 (Isometry). Let (M1, d1) and (M2, d2) be metric spaces. A map f : M1 → M2 is\ncalled an isometry or distance preserving if for any x, y ∈ M1, we have:\nd1(x, y) = d2(f(x), f(y))\nThe requirement seems a little too rigid to be useful in probabilistic applications, for example, when\nmodels are learnt approximately, or that they differ by some scales locally. The next relaxed one,\nallowing more room (at the linear rate) for errors, is arguably more suitable.\nDefinition B.11 (Quasi-Isometry). Suppose f : M1 → M2 between two metric spaces as in\nDefinition B.10. Then f is called a quasi-isometry from (M1, d1) to (M2, d2) if there exist constants\nA ≥ 1, B ≥ 0, and C ≥ 0 such that the following two properties both hold:\n1. For every two points x and y in M1, the distance between their images is up to the additive constant\nB within a factor of A of their original distance:\n∀x, y ∈ M1 : 1\nAd1(x, y) − B ≤ d2(f(x), f(y)) ≤ Ad1(x, y) + B\n(18)\n2. Every point of M2 is within the constant distance C of an image point. More formally:\n∀z ∈ M2 : ∃x ∈ M1 : d2(z, f(x)) ≤ C.\nThe two metric spaces (M1, d1) and (M2, d2) are called quasi-isometric if there exists a quasi-\nisometry f from (M1, d1) to (M2, d2). A map is called a quasi-isometric embedding if it satisfies\nthe first condition but not necessarily the second. In other words, (M1, d1) is quasi-isometric to a\nsubspace of (M2, d2).\n16\nQuasi-isometric embedding is a much more relaxed concept, because we allow the additional scale\nparameters A, B that control how M1 and M2 look alike, at scales A, B.\nThe right hand side of Equation 18 generalizes Lipschitzness by an additional additive constant\nB. It is known as coarse-Lipscthiz (Proposition 2.2 in Lancien & Dalet (2017)). At first glance,\nco-Lipschitzness (Definition 3.6) is defined in terms diameter of the pre-image or inverse-image f −1,\nand may not be readily related to quasi-isometry. In the geometric spirit, Definition 3.6 should be\ncalled co-coarse-Lipschiz, and Theorem 3.8 is perhaps better framed under coarse-Lipschitz and\nco-coarse-Lipschiz settings. But since these terms are less widely used in machine learning, our\nexposition in the main paper does not delve into the mathemtical fine differences. We now relate the\nleft hand side of Equation 18 to co-Lipschitzness.\nLemma B.12 (Equivalance of LHS of Equation 18 and co-Lipschitizness). Under the same settings\nas Definition B.11, the left hand side of Equation 18,\n∀x, y ∈ M1 : d1(x, y) ≤ Kd2(f(x), f(y)) + k\n(19)\nis equivalent to Definition 3.6 up to a constant factor of 2, i.e. For any y ∈ Y , any R > 0:\nDiameter(f −1(BR(y))) ≤ K · Diameter(BR(y)) + k\n(20)\nThe significance of this lemma is that it opens up doors on how we may empirically measure or\neven certify the co-Lipschitzness. Co-Lipschtizness is defined in terms of the diameter of the inverse\nimage, which can be very difficult to estimate. Now, the lemma suggests measuring encoder’s\nco-Lipschitz degrees by means of encoder’s “bi-Lipschitz\" alike constants. This in turn allows us\nto apply techniques from related fields, such as lower bound on adversarial perturbations Peck et al.\n(2017). Concretely, estimating K above is locally reduced to asking the following question. If we\nperturb x to y, what is the minimum change of f accordingly? To gain further intuition in the context\nof VAEs, if the encoder is nearly a constant function, K and k need to be very large for the first\ninequality in the lemma to hold. On the other hand, if the encoder is very sensitive, K and k would\nbe smaller. While estimating K and k are very interesting, it is far beyond the scope of the present\npaper.\nProof. Co-Lipschtizness =⇒ LHS of Equation 18. Given any x1 and x2, we want to estimate\nd(x1, x2). We denote their corresponding images: (y1 = f(x1), y2 = f(x2)). Consider R =\nd1(y1, y2). By co-Lipschtizness:\nDiameter(f −1(Bd1(y1,y2)(y1))) ≤ K · Diameter(Bd1(y1,y2)(y1)) + k\n(21)\n= 2K · d1(y1, y2) + k\n(22)\nBy construction, f −1(Bd1(y1,y2)(y1)) includes both x1 and x2. Thus,\nd1(x1, x2) ≤ Diameter(f −1(Bd1(y1,y2)(y1))) ≤ 2K · d1(f(x1), f(x2)) + k\n(23)\nLHS of Equation 18\n=⇒\nCo-Lipschtizness.\nFor any y, R ≥ 0, we want to estimate\nDiameter(f −1(BR(y))). Without loss of generality (otherwise, use a limit argument), assume\nthe existence of x1, x2 such that d(x1, x2) = Diameter(f −1(BR(y))). By the definition of LHS\nand definition of Diameter,\nDiameter(f −1(BR(y)))\n(24)\n=d(x1, x2)\n(25)\n≤Kd2(f(x1), f(x2)) + k\n(26)\n≤K · Diameter(BR(y)) + k\n(27)\nIn other words, requiring the encoder mapping Enc : x → (µ(x), σ(x)) to be co-Lipschitz (co-\ncoarse-Lipschiz) with degrees (K, k) is to ask Enc to obey the LHS of the quasi-isometry inequality\n18.\n∀x1, x2 ∈ESupt(PIID) ∪ ESupt(POOD) :\n(28)\n1\nK d1(x1, x2) − k\nK ≤ d2(Enc(x1), Enc(x2))\n(29)\n17\nFigure 6: Small test time reconstruction for IID.\nOn the other hand, if Dec : z → (µ(z), σ(z)) is Lipschiz or coarse-Lipschitz,\n∀z1, z2 ∈Enc(ESupt(PIID)) ∪ Enc(ESupt(POOD)) :\n(30)\nd2(z1, z2) ≤ Ld1(Dec(z1), Dec(z2)) + l\n(31)\nd2(Enc(x1), Enc(x2)) ≤ Ld1(Dec(Enc(x1)), Dec(Enc(x2))) + l\n(32)\nPut together:\n∀x1, x2 ∈ESupt(PIID) ∪ ESupt(POOD) :\n(33)\n1\nK d1(x1, x2) − k\nK\n(34)\n≤d2(Enc(x1), Enc(x2))\n(35)\n≤Ld1(Dec(Enc(x1)), Dec(Enc(x2))) + l\n(36)\nIf d1(Dec(Enc(x1)), Dec(Enc(x2))) ≈ d1(x1, x2), which can be verified empirically for all VAEs,\nwe observe that VAEs’ unique encoder-decoder structure tries to learn a probabilistic relaxed version\nof quasi-isometry with different parametric constants (K, k) and (L, l) on both sides of the inequali-\nties. As a by-product of our theory, we reveal VAEs’ nearly quasi-geometric learning behaviour.\nB.3\nSUPPLEMENTARY MATERIALS FOR SECTION 3.1.3\nIn this section, we restate and prove the Theorem 3.8 rigorously. While the proof utilizes some apriori\nestimates, the main idea can be illustrated in the following Figure 7:\nTheorem B.13 (Provable OOD detection bounds, Theorem 3.8 in the main text). Fix PIID, POOD\nand mintra > 0 and choose minter > 2 · mintra. Assume without loss of generality the corresponding\narg min in Definition 3.4 for minter exists, denoted as: (ϵ∗\nIID, ϵ∗\nOOD).\nSuppose the encoder qϕ : x −→ (µz(x), σz(x)) is co-Lipschitz with degrees (K, k), or the decoder\npθ : z −→ (µx(z), σx(z)) is L Lipschitz with L ≤ K 11. Then for any metric in the input space\ndX(·, ·) 12 upon which minter and mintra margins are defined, with probability ≥ 1 − (ϵ∗\nIID + ϵ∗\nOOD)\n11This condition is evoked when qϕ fails to be co-Lipschitz with degrees (K, k). L ≤ K is sensible because\nVAEs learns to reconstruct PIID.\n12We mean metric spaces that obey the triangle inequality. This is extremely general, including widely used\nl∞ in adversarial robustness, perceptual distance in vision Gatys et al. (2016), etc. Our result also extends to any\nmetric in the latent spaces. We use l2 norm for the latent variable parameters for simplicity.\n18\nFigure 7: Proof by geometry.\nover the joint distribution (PIID, POOD), at least one of the following holds:\n∥µz(xIID) − µz(xOOD)∥2 ≥ minter − k\nK\nand\n∥σz(xIID) − σz(xOOD)∥2 ≥ minter − k\nK\n(37)\ndX(xOOD, bxOOD) ≥ 2K − L\n2K\nminter − mintra + kL\n2K\n(38)\nProof. We begin by proving the first inequality when the encoder’s latent code µz is co-Lipschitz\nwith degrees (K, k). Recall by definition, for any y:\nDiameter((µz, σz)−1(BR(y))) ≤ K · Diameter(BR(y)) + k\n(39)\nWe denote zIID = (µz(xIID), σz(xIID)) and zOOD = (µz(xOOD), σz(xOOD)). Plugging R = ∥zIID −\nzOOD∥/2, y = zIID to the above inequality, we have:\nDiameter((µz, σz)−1(B∥zIID−zOOD∥/2(zIID))) ≤ K · Diameter(B∥zIID−zOOD∥/2(zIID)) + k\n(40)\nwhich by the definition of Diameter, simplifies the right hand side (RHS) to:\nDiameter((µz, σz)−1(B∥zIID−yOOD∥/2(zIID))) ≤ K · ∥zIID − zOOD∥ + k\n(41)\nNote that by assumption, DX|minter(PIID, POOD) ≥ minter. Thus with probability at least 1 − (ϵ∗\nIID +\nϵ∗\nOOD) over the joint distribution (PIID, POOD), (µz, σz)−1(B∥zIID−zOOD∥/2(zIID)) contains xIID and\nxOOD that are minter apart. This translates the above deterministic inequality to the following. With\nprobability at least 1 − (ϵ∗\nIID + ϵ∗\nOOD) over (PIID, POOD), we have:\nminter ≤ Diameter((µz, σz)−1(B∥zIID−zOOD∥/2(zIID))) ≤ K · ∥zIID − zOOD∥ + k\n(42)\nAs a result, with probability at least 1 − (ϵ∗\nIID + ϵ∗\nOOD) over (PIID, POOD):\n∥(µz(xIID), σz(xIID)) − (µz(xOOD), σz(xOOD))∥2 ≥ minter − k\nK\n(43)\nWe remark that the above proof does not utilize the full strength of co-Lipschitzness; we merely use\nit between PIID and POOD. We also note that the above does not use any particular properties of the l2\nnorm, and extends to any metric dZ(·, ·) in the latent spaces.\n19\nNext, we prove the second inequality. We will break down the proof into cases. First, we observe that\nthe second inequality is more interesting when the first inequality fails. Otherwise, the first inequality\ncan give an OOD detection score with high probability. We will henceforth use the fact that encoder\nqϕ is anti co-Lipschtiz with degree (K, k).\nCase 1 [Encoder is anti co-Lipschtiz within PIID or POOD]. In this case, if encoder remains\nco-Lipschtiz between PIID and POOD, the first inequality is unaffected. And our statement holds\ntrivially.\nCase 2 [Encoder is anti co-Lipschtiz between PIID and POOD]. In this case, we will need the\nsecond condition where decoder is assumed to be Lipschitz. By assumption in this case, we also have\nencoder is anti co-Lipschitz. Thus, we have the following inequalities:\nSince the encoder is anti co-Lipsthiz with degrees (K, k), there exist R > 0, zIID and zOOD such that:\nfor some xIID ∈ (µz, σz)−1(BR(zIID)) and xOOD ∈ (µz, σz)−1(BR(zIID)), we have:\ndX(xIID, xOOD) > K · Diameter(BR(zIID)) + k\n(44)\nwhich implies in particular:\ndX(xIID, xOOD) > 2K · ∥zIID − zOOD∥2 + k\n(45)\nSince the decoder is L-Lipschitz, we have: for every zIID and zOOD, we have:\ndX(bxIID, bxOOD)\n(46)\n=dX((µx, σx)(zIID), (µx, σx)(zOOD))\n(47)\n≤L∥zIID − zOOD∥2\n(48)\n≤ L\n2K (dX(xIID, xOOD) − k)\n(49)\n<1\n2dX(xIID, xOOD)\n(50)\nWe call the above a-prior estimate, and it will be useful for our second apriori estimate. We want to\nestablish another apriori estimate on dX(xIID, bxOOD).\nFor any metric dX, by the assumption of Definition 3.4, with probability at least 1 − (ϵ∗\nIID + ϵ∗\nOOD)\nover (PIID, POOD), we can estimate the following:\ndX(xIID, bxOOD)\n(51)\n≤dX(xIID, bxIID) + dX(bxIID, bxOOD)\n(52)\n≤mintra + L\n2K (dX(xIID, xOOD) − k)\n(53)\n<minter\n2\n+ 1\n2(dX(xIID, xOOD))\n(54)\n≤dX(xIID, xOOD)\n(55)\nwhere the first inequality follows from triangle inequality, and the last inequality is where we invoke\nthe essential separation properties, that requires a probabilistic statement.\nNow we estimate dX(xOOD, bxOOD) using reverse-triangle inequality repeatedly.\ndX(xOOD, bxOOD)\n(56)\n≥\n\f\f\f\fdX(xOOD, xIID) − dX(xIID, bxOOD)\n\f\f\f\f\n(57)\n=dX(xOOD, xIID) − dX(xIID, bxOOD)\n(58)\n≥dX(xOOD, xIID) − mintra − L\n2K (dX(xIID, xOOD) − k)\n(59)\n≥2K − L\n2K\nminter − mintra + kL\n2K\n(60)\nwhere the first inequality follows from reverse triangle inequality, the second equality allows us to\nremove the absolute sign due to our second aprior estimate (Equation 55), the second inequality\nfollows from our first aprior estimate (Equation 53). This holds with probability at least 1 − (ϵ∗\nIID +\nϵ∗\nOOD) over (PIID, POOD), because Equation 55 uses the essential distance or margin.\n20\nDiscussions and Remarks\nTheorem 3.8 identifies a set of more relaxed or weaker solution concepts to OOD detection. Instead of\naiming for perfect density estimation, we can try to reduce (K, k) for better latent code separation,\nenlarge K and reduce L for reconstruction based separation, or smaller mintra. We investigate\nand exploit such inevitable trade-offs on K in Sections B.4.2 and B.4.3, which in particular leads to\nour LPath-2M algorithm (Section 4). Nevertheless, not requiring perfect density doesn’t imply our\nmethod doesn’t benefit from it. Recall log pθ(x) ≈ log\n\u0014\n1\nK\nPK\nk=1\npθ(x|zk)p(zk)\nqϕ(zk|x)\n\u0015\n. Better log pθ(x)\nestimation means it is higher on IID samples and lower on OOD region. This translates to higher\npθ\n\u0000x | zk\u0001\nand p\n\u0000zk\u0001\nfor IID, lower on OOD, or both. In other words, we’d expect lower ∥xOOD −\nbxOOD∥2, higher ∥(µz(xIID), σz(xIID)) − (µz(xOOD), σz(xOOD))∥2, or both. As a result, our method\ncan benefit from improved density estimation and remain robust when pθ(x) estimation is difficult.\nLike other Lipschitz conditions in machine learning 13, the co-Lipshitzness of the encoder qϕ and\nthe Lipshitzness of the decoder pθ are theoretical quantities that are difficult to check. Moreover, it\nis unclear how to enforce them. We propose some heuristics for encouraging these conditions in\nSection B.4.2 and evaluate them empirically in Section 5. The statistical aspects of the geometrically\ndistilled sufficient statistics in Theorem 3.8 are discussed in greater details in Appendix B.5. While\nsome hard-to-evaluate quantities are involved, this may be the first provable result in the unsupervised\nOOD detection problem. The importance of such theorems stem from the OOD setting. Unlike\nthe IID case, where we can reliably evaluate an algorithm’s generalization performance, there is no\nway control the streaming OOD data. A provable method that comes with theoretical guarantees or\nlimitations is therefore particularly desired.\nB.4\nSUPPLEMENTARY MATERIALS FOR SECTION 3.2\nB.4.1\nJUSTIFICATION OF THE STATISTICS ∥µz(xOOD)∥\nSince ∥µz(xIID) − µz(xOOD)∥2 involves sampling from PIID, we replace it by ∥µz(xOOD) − r0∥ in\nthe main paper. In this section, we unfold its relation to Theorem 3.8. We formalize the empirical\nobservation first mentioned Figure\nAssumption B.14 (Concentration of Latent Code Parameters). Let qϕ : x −→ (µz(x), σz(x)) denote\nthe encoder latent parameter mapping from the input space. We say, the latent codes concentrate on\nspherical shells Sµ(z)(0, r0) and Sσ(z)(I, rI) centered at 0 and I with radii r0 > 0 and rI > 0, if for\nevery ϵ > 0 and every xIID ∈ ESupt(PIID):\nPIID(|r0 − ∥µz(xIID)∥| ≥ ϵ) ≤ C0(PIID)\nγ(ϵ)\n(61)\nPIID(|rI − ∥σz(xIID)∥| ≥ ϵ) ≤ CI(PIID)\nγ(ϵ)\n(62)\nwhere γ is a strictly monotonic increasing function and C0(PIID) and CI(PIID) are constants depend-\ning only on the distribution PIID (e.g. variance of PIID).\nWe also need the following definition for the below proof:\nDefinition B.15 (Projection in metric spaces). ProjY (x) := arg miny∈Y d(y, X) denote the projec-\ntion of x ∈ X onto Y .\nFor an concrete example, ProjSz(µz(xOOD)) := arg miny∈Sz∥y−µz(xOOD))∥ denote the projection\nof µz(xOOD) onto Sz. In other words, ProjSz(µz(xOOD)) maps µz(xOOD) to its closest point on Sz.\narg min is achieved because Sz is a complete metric space.\nProposition B.16 (Performance guarantee for ∥µz(xOOD) − r0∥). Fix ϵ > 0. Under the conditions\nof Theorem 3.8, and Assumption B.14, with probability at least 1 − (ϵ∗\nIID + ϵ∗\nOOD) − C0(PIID)\nγ(ϵ)\nfor µz\n13For example, Lipschitz gradient condition in the optimization literature, i.e. stochastic gradient descent\nconverges depending on the unknown Lipschitz constant.\n21\nand 1 − (ϵ∗\nIID + ϵ∗\nOOD) − CI(PIID)\nγ(ϵ)\nfor σz, we have the following inequalities:\n|r0 − ∥µz(xOOD)∥| ≥ minter − k\nK\n− ϵ\n(63)\n|rI − ∥σz(xOOD)∥| ≥ minter − k\nK\n− ϵ\n(64)\nProof. First, we use the distance the relation between µz(xOOD) and µz(xIID) (Figure 5), and apply\nthe reverse triangle inequality:\n|r0 − ∥µz(xOOD)∥|\n(65)\n=∥ProjSµ(z)(µz(xOOD)) − µz(xOOD)∥\n(66)\n=∥ProjSµ(z)(µz(xOOD)) − µz(xIID) + µz(xIID) − µz(xOOD)∥\n(67)\n≥|∥ProjSµ(z)(µz(xOOD)) − µz(xIID)∥ − ∥µz(xIID) − µz(xOOD)∥|\n(68)\n(69)\nNext, by Assumption B.14, with probability at least 1 − C0(PIID)\nγ(ϵ)\n:\n|∥ProjSµ(z)(µz(xOOD)) − µz(xIID)∥ − ∥µz(xIID) − µz(xOOD)∥|\n(70)\n≥∥µz(xIID) − µz(xOOD)∥ − ϵ\n(71)\nNow we can apply Theorem 3.8 to the first term. As a result, with probability at least (1 − (ϵ∗\nIID +\nϵ∗\nOOD))(1− C0(PIID)\nγ(ϵ)\n) = 1−(ϵ∗\nIID +ϵ∗\nOOD)− C0(PIID)\nγ(ϵ)\n+(ϵ∗\nIID +ϵ∗\nOOD)( C0(PIID)\nγ(ϵ)\n), we have the following:\n|r0 − ∥µz(xOOD)∥| ≥ minter − k\nK\n− ϵ\n(72)\nThe proof for the σz(xOOD) is similar and we omit it.\nCorollary B.17 (Performance guarantee for ∥µz(xOOD)∥). Under the condition of Proposition B.16,\nwith probability at least 1 − (ϵ∗\nIID + ϵ∗\nOOD) − C0(PIID)\nγ(ϵ)\nfor µz and 1 − (ϵ∗\nIID + ϵ∗\nOOD) − CI(PIID)\nγ(ϵ)\nfor σz,\nwe have the following inequalities:\n∥µz(xOOD)∥ ≥ r0 + minter − k\nK\n− ϵ\nor\n∥µz(xOOD)∥ ≤ r0 − minter − k\nK\n+ ϵ\n(73)\n∥σz(xOOD)∥ ≥ r0 + minter − k\nK\n− ϵ\nor\n∥σz(xOOD)∥ ≤ r0 − minter − k\nK\n+ ϵ\n(74)\nThese are to be compared with Assumption B.14 that characterize the corresponding norms for PIID.\nAs a result, our approximation statistics also enjoy provable properties.\nB.4.2\nNOT ALL VAES ARE BROKEN THE SAME: ENCODER, DECODER AND LATENT\nDIMENSION\nTheorem 3.8 also has quantitative implications on algorithmic design: we may choose VAEs training\nhyperparameters to empirically optimize OOD performances by searching though K, k, L. While it\nis unclear how to make qϕ more co-Lipschitz, we can avoid conditions that break it. By the same\nargument, we want to avoid cases that make pθ less Lipschitz continuous. In this section, we discuss\nheuristics inspired by Theorem 3.8 for training VAEs in the setting of OOD detection.\nThe higher the latent dimension, the better encoder can discriminate against OOD. Theorem 3.8\nprefers qϕ to be region-wise one-to-one. Formally, Equation 37 in Theorem 3.8 suggests we can make\nthe latent code between IID and OOD cases more separable if both K and k are smaller. In other\nwords, when the encoder has small co-Lipschitz degrees. While it is unclear how to make encoder\nregion-wise one-to-one, we identify a condition on the latent dimension (of z) that can make qϕ fail\nto be region-wise one-to-one. This condition is on the latent code dimension m, which can make K\nor k arbitrarily large and we would like to avoid it.\nLemma B.18 (Continuous maps and region-wise one-to-one). Let n < m. There exists continuous\nf : z ∈ Rm −→ Rn such that it is not region-wise one-to-one with any degrees.\n22\nProof. By the proof of Theorem 1 in Landweber et al. (2016), for any M > 0, there is a Lip-\nschitz continuous map f such that Diameter(f −1(y)) > M, for some y ∈ Rn. In particular,\nDiameter(f −1(BR(y))) > M since the above is a subset of this. Since Diameter(f −1(BR(y)))\ncan be arbitrarily large, by choosing R = 1, there will be no (K, k) pair in Definition 3.6 that can\nbound Diameter(f −1(BR(y))), proving our claim.\nSetting f = qϕ, Lemma B.18 implies we can no longer confidently rely on Theorem 3.8 to detect\nOOD, as long as the latent dimension (m) is smaller than input ambient dimension (n) (e.g. 784\nfor MNIST). While such pathelogical cases may not happen in practice, making latent dimension\nbigger is sensible for OOD detection: as we increase VAEs’ latent dimension, qϕ can find more\nroom so that xIID does not mix up with xOOD much. More precisely, the “large fiber lemma” and its\nassociated results from Landweber et al. (2016) implies Diameter(f −1(y)) can be arbitrarily large,\nwhenever target space dimension is smaller than the input’s. Letting f(x) = y = (µz(x), σz(x))\nin qϕ(z|µz(x), σz(x)), since f −1(y) is big in diameter, f(xIID) and f(xOOD) can be mapped to\nnearly the same y = (µz(x), σz(x)), even if xIID and xOOD are farther away. While setting higher\nlatent dimension is not a sufficient condition for qϕ to be region-wise one-to-one, not meeting it will\nmake qϕ susceptible to region-wise one-to-one pathological cases. This mathematical intuition does\nsuggest us to try training VAEs with very high latent dimension for OOD detection, even at the cost\nof over-fitting, etc.\nThe lower the latent dimension, the better decoder screens for OOD. Theorem 3.8 also prefers\npθ to have a small Lipschitz constant, i.e. more Lipschitz continuous. More precisely, since VAEs’\nlearning objective is to reconstruct, i.e. learning an approximate identity: bx ≈ x, it is sensible to\nexpect K and L to be at the same order of magnitudes. Thus, the dominating term on the right\nhand side of Equation 38 in Theorem 3.8 is the first term: 2K−L\n2K minter. To make this term bigger\nthrough VAEs function analytic properties, we can make L smaller and make K bigger. In the prior\nparagraph, we discussed why encoder prefers smaller K to be better at screening OOD data. This\nposes a conflicting requirement on K. Since L is also at our disposal, our heuristics in this section\nfocuses on L.\nIn the spirit of Definition 3.5, we measure L, how continuous pθ(z) is, by bounding its Jacobian:\nLemma B.19 (Jacobian matrix estimates). Let f : z ∈ Rm −→ Rn be any differentiable function.\nAssume each entry of Jzf(z) is bounded by some constant C. We have f is Lipschitz with Lipschitiz\nconstant L:\nL = sup\nz ∥Jzf∥2 := sup\nz sup\nu̸=0\n∥Jzfu∥2\n∥u∥2\n≤ C√m√n\n(75)\nProof. First, if ∥Jzf∥2 is bounded, then f is Lipschitz by the mean value theorem. It suffices\nto prove Jacobian is bounded. Next, ∥Jzf∥2 ≤ √mn∥Jzf∥Max ≤ √mnC by the matrix norm\nequivalence.\nLemma B.19 suggests one way to globally control pθ’s modulus of continuity: by making the\nlatent dimension m unusually small (we cannot choose the input dimension.). This will break\npθ’ ability to reconstruct xOOD well whenever zOOD is mapped to near any zIID. In other words,\nbxOOD = pθ(zOOD) ≈ bxIID. In this way, we mix bxIID and bxOOD together, leading to large reconstruction\nerrors.\nThis happens when zIID and zOOD are mixed together, and pθ is Lipschitz continuous, which leads\nus to rethink OOD’s representation learning objective. What makes u(x) an discriminative scoring\nfunction for OOD detection? In the OOD detection sense, we want a DGM to learn tailored features\nto reconstruct IID data well only, while such specialized representations will fail to recover OOD\ndata. These OOD detection requirements drastically differ from that of conventional supervised and\nunsupervised learning, that aims to learn universal features (Devlin et al., 2018; He et al., 2016).\nWhile ML research aims for general AI and universal representations, VAE OOD detection seems to\nask for the opposite.\nSection B.4.2 gives conflicting requirements on the latent dimension m (also see our discussion of\nit in terms of unclear signs of K (The discussion paragraph after Theorem 3.8)). Making K bigger\nsuggests setting larger m, while making L smaller implies setting smaller m.\n23\nWe further discuss how to take advantage of this paradox in Appendix B.4.3, leading us to pair two\nbroken VAEs. To sum our heuristics for OOD detection, we try to encourage bigger K for encoder\nand smaller L for decoder.\nB.4.3\nBROKEN VAES PAIRING: IT TAKES TWO TO TRANSCEND\nOne VAE faces a trade-off in latent dimension: qϕ wants it to be big while pθ wants it small.\nSection B.4.2 leaves us with a paradox: enlarging latent dimension m is necessary for qϕ’s region-\nwise one-to-one, but can allow pθ to be less continuous. It does not seem we can leverage this\nobservation in a single VAE.\nTwo VAEs face no such trade-offs. We propose to train two VAEs, take the latent dimensionally\nconstrained (small m) pθ’s u(x), get the overparamterized (big m) qϕ’s v(x) and w(x), and combine\nthem as the joint statistics for OOD detection. In this way, we avoid the dimensional trade-off in any\nsingle VAE. In the very hard cases where a DGM is trained on CIFAR 10 as in-distribution, and CIFAR\n100, VFlip and HFlip as OOD, we advanced SOTA empirical results significantly. This is surprising\ngiven both VAEs are likely broken with poorly estimated likelihoods. The over-parameterized VAE\nis likely broken, because it may over-fit more easily (generalization error). The overly constrained\none is probably also broken, since it has trouble reconstructing many training data (approximation\nerror). However, together they achieved better performance, even better than much bigger model\narchitectures specifically designed to model image data better. See Table 1.\nB.5\nFROM LIKELIHOOD AND SUFFICIENCY PRINCIPLES TO LIKELIHOOD PATH PRINCIPLE\nIn this section, we show Section 3.1’s geometric argument is related to the well-known likelihood and\nsufficiency principles, applied to encoder and decoder conditional likelihoods. This further solidifies\nthe likelihood path principle in Section 2.\nScreening xOOD using log pθ(xOOD) alone does not perform explicit statistical inferences. In the\nfully unsupervised cases, i.e. Morningstar et al. (2021); Havtorn et al. (2021); Xiao et al. (2020), most\nOOD detection methods use log pθ(x) or its close cousins to screen, instead of performing explicit\nhypothesis testing. This is probably because pθ(x) is parameterized by neural nets, having no closed\nform. In particular, pθ(x) doesn’t have an instance dependent parameter to be tested against in test\ntime. Thus, it is less clear what inferences are performed to test the IID v.s. OOD hypothesis.\nLatent variable models can perform instance dependent statistical inferences. On the other hand,\nlatent variable DGMs such as Gaussian VAE, perform explicit statistical inferences on latent parame-\nters µz(x), σz(x) in the encoder qϕ(z|µz(x), σz(x)). Then after observing zk ∼ qϕ(z|µz(x), σz(x)),\nµx(zk), σx(zk) are inferred by the decoder pθ(x|µx(zk), σx(zk)) in the visible space. In other words,\nµz(x), σz(x) and µx(zk), σx(zk) can be interpreted as a hypothesis proposed by VAEs to explain\nthe observations x and zk. Standard decision based on log pθ(x) alone, without considering the\nconditional likelihood path, can lead to information loss (Section 2).\nVAEs’ likelihood paths are sufficient for OOD detection, as per likelihood and sufficiency\nprinciples. Applying Equations 37 and 38 can be interpreted as following the likelihood principle\nin both the latent and visible spaces. In the inference about model parameters, after x or zk is\nobserved, all relevant information is contained in the conditional likelihood function. Implicitly,\nthere lies the sufficiency principle: for two different observations x1 and x2 (z1 and z1, respectively)\nhaving the same values T(x1) = T(x2) (T(z1) = T(z2), respectively) of a statistics T sufficient\nfor some model family p(·|ξ), the inferences about ξ based on x1 and x2 should be the same. For\nGaussian VAEs, a pair of minimal sufficient statistics T for ξ is (µz(x), σz(x)) for encoder, and\n(µx(z), σx(z)) for decoder respectively. In other words, in the likelihood information theoretic sense,\nall other information such as neural net intermediate activation is irrelevant for screening xOOD and\n(µz(x), σz(x)), µx(z), σx(z) are sufficiently informative. Therefore, the geometric arguments in\nSection 3.1 in fact are also grounded in statistical inferences.\nRecall the likelihood path principle proposed in Section 1 and Section 2. Our geometric and statistical\narguments reveal particularly informative neural activation paths: the minimal sufficient statistics\nof pθ and qϕ. In this case, the likelihood path principle reduces down to likelihood and sufficiency\nprinciples for the encoder and decoder likelihoods, because how VAEs estimate log pθ(x) (See\nEquation 1).\n24\nFraming OOD detection as statistical hypothesis testing. A rigorous and obvious way of using\nthese inferred parameters is the likelihood ratio test. We begin our discussion with the decoder\npθ(x|µzk(x), σzk(x))’s parameter inferences, where zk ∼ qϕ(z|µz(x), σz(x)) from the encoder.\nSince zk ∼ qϕ(z|µz(x), σz(x)) is indexed by x, we consider the following average likelihood ratio:\nλx\nLR(x) = log\nEzk∼qϕ(z|µz(x),σz(x))pθ(x | µx(zk), σx(zk))\nsupxIID Ezl∼qϕ(z|µz(xIID),σz(xIID))pθ(x | µx(zl), σx(zl))\n(76)\nThis tests the goodness of fit of two competing statistical models, the null hypothesis proposed\nby VAEs: (µz(x), σz(x)), v.s. the alternative hypotheses which are the set of all decoder latent\ncode indexed by xIID, at the observed evidence x. We compare the average decoder density over\nzk ∼ qϕ(z|µz(x), σz(x)) to those indexed by xIID. If x comes from the same distribution as xIID,\nthe two average likelihoods should differ no more than the sampling error. Similarly, we have the\nfollowing for the latent space:\nλz\nLR(x) = log\nEzk∼qϕ(z|µz(x),σz(x))p(zk | µz(x), σz(x))\nsupxIID Ezk∼qϕ(z|µz(x),σz(x))p(zk | µz(xIID), σz(xIID))\n(77)\nAs observed in Nalisnick et al., VAEs can assign higher likelihood to OOD data. This can affect the\nefficacy of Equations 76 and 77. Similar to Morningstar et al. (2021)’s OOD detection approach,\nthe likelihood having wrong orders problem (assigning higher likelihood to OOD samples) can be\npartially addressed by fitting another classical algorithm on top. We follow the same approach by\nconsidering the distribution of (λx\nLR(x), λz\nLR(x)). In other words, to deal with typicality, which can\naffect the order of the conditional likelihood ratios, we regard (λx\nLR(x), λz\nLR(x)) as random variables\nand use their distributions to discriminate against OOD samples. As a result, ratios that are too small\nor too big would be considered as OOD.\nFrom a minimal sufficient statistics perspective, instead of (λx\nLR(x), λz\nLR(x)): we can consider\n(µz(x), σz(x), µx(z), σx(z)) which may enjoy some numerical/arithmetic cancellation advantages,\nas we shall explain below.\nRelation to Theorem 3.8. Encoder’s Equation 37 corresponds to the z’s Equation 77’s numerator,\nand decoder’s Equation 38 corresponds to x’s Equation 76’s numerator. In typical VAE learning,\ndecoder’s variance is fixed Dai et al., so it cannot be used as an inferential parameter. This reduces\nthe minimal sufficient statistics for encoder and decoder pair:\n(µz(x), σz(x), µx(z), σx(z)) −→ (µz(x), σz(x), µx(z))\n(78)\nAs a result, the decoder variance won’t be used. We begin discussing the decoder’s remaining\ninferential parameters. Since we fit a second stage classical statistical algorithm, the magnitude of\nµz(x) can cause comparison issues. For this reason, it is natural to use the normalized version and its\nnorm instead:\n∥µx(z) − x∥2\n(79)\nwhich, up to some constant factor adjustment, is the log pθ(x|z) in Equation 76.\nWe can apply the same reasoning to the encoder when zk is chosen to be 0, as a one point approx-\nimation to zk sampling procedure. One justification is that the encoder to regularized to be close\nto N(0, I). This is not perfect, but will expedite computation in test time. More importantly, it\ncorresponds to our geometric analysis in Theorem 3.8 nicely. Recall:\ninf\nxIID,xOOD∥µz(xIID) − µz(xOOD)∥2\n(80)\nIn test time, we won’t observe all OOD samples in a full batch. For a single sample, we can\napproximate the above by the following one point approximation by taking out the inf over OOD:\ninf\nxIID,xOOD∥µz(xIID) − µz(xOOD)∥2 ≈ inf\nxIID∥µz(xIID) − µz(xOOD)∥2\n(81)\nBy the observed concentration phenomenon discussed in Section 3.2 and Figure 5,\ninf\nxIID∥µz(xIID) − µz(xOOD)∥2 ≈ |∥µz(x)∥2 − r0| ≈ ∥µz(x)∥2\n(82)\nwhere the last approximation is because when screening OOD samples in test time, for all x, be it\nIID or OOD, r0 is a constant. We can further drop it before feeding this statistics to the second stage\nstatistical algorithm such as COPOD Li et al. (2020). The reasoning for σz(x) is identical and we\nomit it here. This relates our remaining test statistics to Equation 77.\n25\nB.5.1\nTRAINING OBJECTIVE MODIFICATION FOR STRONGER CONCENTRATION\nTo encourage stronger concentration empirically observed in Section 3.2, we propose the following\nmodifications to standard VAEs’ loss functions:\nWe replace the initial KL divergence by:\nDtypical[Qϕ(z | µz(x), σ(x))∥P(z)]\n(83)\n=Dtypical[N(µz(x), σz(x))∥N(0, I)]\n(84)\n=1\n2\n\u0000tr(σz(x)) + |(µz(x))⊤(µz(x)) − m| − m − log det(σz(x))\n\u0001\n(85)\nwhere m is the latent dimension. This will encourage the latent code µ(x) to concentrate on the\nspherical shell with radius √m. This is chosen due to the well known concentration of Gaussian\nprobability measures.\nIn training, we also use Maximum Mean Discrepancy (MMD) Gretton et al. (2012) as a discriminator\nsince we are not dealing with complex distribution but Gaussian. The MMD is computed with\nGaussian kernel. This extra modification is because the above magnitude regularization does not take\ndistribution in to account.\nThe final objective:\nEx∼PIIDEz∼QϕEn∼N [log Pθ(x | z)] − Dtypical[Qϕ(z | µz(x), σ(x))∥P(z)] − MMD(n, µz(x))\n(86)\nThe idea is that for PIID, we encourage the latent codes to concentrate around the prior’s typical sets.\nThat way, POOD may deviate further from PIID in a controllable manner. In experiments, we tried the\ncombinations of the metric regularizer, Dtypical, and the distribution regularizer, MMD. This leads to\ntwo other objectives:\nEx∼PIIDEz∼Qϕ[log Pθ(x | z)] − Dtypical[Qϕ(z | µz(x), σ(x))∥P(z)]\n(87)\nEx∼PIIDEz∼QϕEn∼N [log Pθ(x | z)] − D[Qϕ(z | µz(x), σ(x))∥P(z)] − MMD(n, µz(x))\n(88)\nwhere D is the standard KL divergence. In Section C.3, we also describe more experimental details.\nIn short, we found the differences insignificant among the different variations. The minimal sufficient\nstatistics are fairly robust for AUC.\nC\nEXPERIMENTAL DETAILS\nC.1\nFEATURE PROCESSING TO BOOST COPOD PERFORMANCES\nLike most statistical algorithms, COPOD/MD is not scale invariant, and may prefer more dependency\nstructures closer to the linear ones. When we plot the distributions of u(x) and v(x), we find that\nthey exhibit extreme skewness. To make COPOD’s statistical estimation easier, we process them by\nquantile transform. That is, for IID data, we map the the tuple of statistics’ marginal distributions to\nN(0, 1). To ease the low dimensional empirical copula, we also de-correlate the joint distribution\nof (u(x), v(x)), w(x)). We do so using Kessy et al. (2018)’s de-correlation method, similar to\nMorningstar et al. (2021).\nC.2\nWIDTH AND HEIGHT OF A VECTOR INSTEAD OF ITS l2 NORM TO EXTRACT\nCOMPLEMENTARY INFORMATION\nIn our visual inspection, we find that the distribution of the scalar components of (u(x), v(x), w(x))\ncan be rather uneven. For example, the visible space reconstruction x − bx error can be mostly low\nfor many pixels, but very high at certain locations. These information can be washed away by the l2\nnorm. Instead, we propose to track both lp norm and lq norm for small p and large q.\nFor small p, lp measures the width of a vector, while lq measures the height of a vector for big\nq. To get a sense of how they capture complementary information, we can borrow intuition from\n26\nlp ≈ l0, for small p and lq ≈ l∞, for large q. ∥x∥0 counts the number of nonzero entries, while ∥x∥∞\nmeasures the height of x. For x with continuous values, however, l0 norm is not useful because it\nalways returns the dimension of x, while l∞ norm just measures the maximum component.\nExtreme measures help screen extreme data. We therefore use lp norm and lq norm as a continuous\nrelaxation to capture this idea: lp norm will “count” the number of components in x that are unusually\nsmall, and lq norm “measures” the average height of the few biggest components. These can be more\ndiscriminitive against OOD than l2 norm alone, due to the extreme (proxy for OOD) conditions they\nmeasure. We observe some minor improvements, detailed in Table 2’s ablation study.\nIID: CIFAR10\nOOD\nOOD Dataset\nSVHN\nCIFAR100\nHflip\nVflip\nl2 norm\n0.96\n0.60\n0.53\n0.61\n(lp, lq)\n0.99\n0.62\n0.53\n0.61\nTable 2: Comparing the AUC of l2 norm versus our (lp, lq) measures.\nC.3\nVAE ARCHITECTURE AND TRAINING\nFor the architecture and the training of our VAEs, we followed Xiao et al. (2020). In addition,\nwe have trained VAEs of varying latent dimensions, {1, 2, 5, 10, 100, 1000, 2000, 3096, 5000,\n10000}, and instead of training for 200 epochs and taking the resulting model checkpoint, we took\nthe checkpoint that had the best validation loss. For LPath-1M, we conducted experiments on VAEs\nwith all latent dimensions and for LPath-2M, we paired one high-dimensional VAE from the group\n{3096, 5000, 10000} and one low-dimensional VAE from the group {1, 2, 5}.\nIn addition to Gaussian VAEs as mentioned in Section B.5, we also empirically experimented with a\ncategorical decoder, in the sense the decoder output is between the discrete pixel ranges, as in Xiao\net al. (2020). Strictly speaking, this no longer satisfies the Gaussian distribution anymore, which\nmay in turn violate our sufficient statistics perspective. However, we still experimented with it to\ntest whether LPath principles can be interpreted as a heuristic to inspire methods that approximate\nsufficient statistics that can work reasonably well, and we observed that categorical decoders work\nsimilarly with Guassian decoders.\nIn addition, we also experimented with VAEs with slightly varied training objectives as detailed\nin Appendix B.5.1 where we added though we did not observe a significant difference in the final\nAUROC. In Table 1, we report the best test AUROC in our experiments following the convention in\nprior works.\nD\nABLATION STUDIES\nD.1\nCOPOD ON FOUR CASES\nTo verify that the dataset can be divided into four cases as depicted in Figure 1, we separate the\ndataset into four cases and use our methods on each case. We use the modes of the IID and OOD\ndistributions on mse reconstruction (u(x)) and the norm of the latent code (v(x)) to decide where the\ntwo distributions are considered to overlap, see Figure 8 for a visualization.\nThe four cases correspond to:\nCase 1: zoverlap + xoverlap\nCase 2: zseparable + xoverlap\nCase 3: zoverlap + xseparable\nCase 4: zseparable + xseparable\nResults are reported in Table 3. We can see that the order of the performances respect their conjectured\nlevel of difficulty. Our method performs considerably better than other statistics, primarily on Case 1.\nIf we make the overlapping region smaller, for example, by using more extreme quantiles, Case 1\nwill have fewer samples and the OOD detection would become more difficult.\n27\n(a) Histogram of u(x) (MSE)\n(b) Histogram of v(x) (z_norm)\n(c) xseparable: Outside regions of u(x) (MSE)\n(d) zseparable: Outside regions of v(x) (z_norm)\n(e) xoverlap: Overlap region of u(x) (MSE)\n(f) zoverlap: Overlap region of v(x) (z_norm)\nFigure 8: How overlap and outside regions are defined in Appendix D.1\n.\n28\nCase 1\nCase 2\nCase 3\nCase 4\nv(x)\n0.75\n0.74\n0.93\n0.96\nu(x)\n0.93\n0.98\n1.00\n0.98\nELBO\n0.83\n0.87\n1.00\n0.96\nOurs\n0.99\n0.99\n1.00\n0.99\nTable 3: COPOD results for four different cases using various statistics.\nOOD Dataset\nStatistic\nSVHN\nCIFAR100\nHflip\nVflip\nu(x)\n0.96\n0.59\n0.54\n0.59\nv(x)\n0.94\n0.56\n0.54\n0.59\nw(x)\n0.93\n0.58\n0.54\n0.61\nv(x) & w(x)\n0.94\n0.58\n0.54\n0.60\nu(x) & v(x)\n0.97\n0.61\n0.53\n0.61\nu(x) & w(x)\n0.98\n0.61\n0.54\n0.61\nTable 4: COPOD on individual statistics. IID dataset is CIFAR10.\nIn this dataset, u(x) alone outperforms v(x) in Table 3. We can see that ELBO’s performance is\nsomewhere between u(x) and v(x). This showcases the arithmetic cancellation discussed in Section\n2. Our LPath method, in contrast, does not suffer from it and can combine their strengths to achieve\nstable and superior performances.\nD.2\nINDIVIDUAL STATISTICS\nTo empirically validate how (u(x), v(x), w(x)) complement each other suggested by Theorem 3.8,\nwe use individual component alone in first stage and fit the second stage COPOD as usual. We notice\nsignigicant drops in performances. We fit COPOD on individual statistics u(x), v(x), w(x) and show\nthe results in Table 4. We can see that our original combination in Table 1 is better overall.\nD.3\nMD\nTo test the efficacy of (u(x), v(x), w(x)) without COPOD, we replace COPOD by a popular algorithm\nin OOD detection, the MD algorithm Lee et al. (2018) and report such scores in Table 1. The scores are\ncomparable to COPOD, suggesting (u(x), v(x), w(x)) is the primary contributor to our performances.\nD.4\nLATENT DIMENSIONS\nOne hypothesis on the relationship between latent code dimension and OOD detection performance is\nthat lowering dimension incentivizes high level semantics learning, and higher level feature learning\ncan help discriminate OOD v.s. IID. We conducted experiments on the below latent dimensions and\nreport their AUC based on v(x) (norm of the latent code) in Table 5\nLatent dimension\n1\n2\n5\n10\n100\n1000\n3096\n5000\nv(x) AUC\n0.39\n0.63\n0.52\n0.45\n0.22\n0.65\n0.76\n0.59\nTable 5: Lower latent code dimension doesn’t help to discriminate in practice.\nClearly, lowering the dimension isn’t sufficient to increase OOD performances.\n29\n"
}