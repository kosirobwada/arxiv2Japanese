{
    "optim": "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational AutoEncoder Hee-Jun Jung1 , Jaehyoung Jeong1 and Kangil Kim1∗ 1Gwangju Institute of Science and Technology {jungheejun93, jaehyoung98}@gm.gist.ac.kr, kikim01@gist.ac.kr, Abstract Symmetries of input and latent vectors have pro- vided valuable insights for disentanglement learning in VAEs. However, only a few works were pro- posed as an unsupervised method, and even these works require known factor information in training data. We propose a novel method, Composite Factor- Aligned Symmetry Learning (CFASL), which is in- tegrated into VAEs for learning symmetry-based disentanglement in unsupervised learning without any knowledge of the dataset factor information. CFASL incorporates three novel features for learn- ing symmetry-based disentanglement: 1) Injecting inductive bias to align latent vector dimensions to factor-aligned symmetries within an explicit learn- able symmetry codebook 2) Learning a compos- ite symmetry to express unknown factors change between two random samples by learning factor- aligned symmetries within the codebook 3) Inducing group equivariant encoder and decoder in training VAEs with the two conditions. In addition, we pro- pose an extended evaluation metric for multi-factor changes in comparison to disentanglement evalua- tion in VAEs. In quantitative and in-depth quali- tative analysis, CFASL demonstrates a significant improvement of disentanglement in single-factor change, and multi-factor change conditions com- pared to state-of-the-art methods. 1 Introduction Disentangling representations by intrinsic factors of datasets is a crucial issue in machine learning literature [Bengio et al., 2013]. In Variational Autoencoder (VAE) frameworks, a preva- lent method to handle the issue is to factorize latent vector dimensions to encapsulate specific factor information [Kingma and Welling, 2013; Higgins et al., 2017; Chen et al., 2018; Kim and Mnih, 2018; Jeong and Song, 2019; Shao et al., 2020; Shao et al., 2022]. Although their effective disentanglement learning methods, [Locatello et al., 2019] raises the serious difficulty of disentanglement without sufficient inductive bias. ∗corresponding author In VAE literature, recent works using group theory offer a possible solution to inject such inductive bias by decom- posing group symmetries [Higgins et al., 2018] in the latent vector space. To implement group equivariant VAE, [Win- ter et al., 2022a; Nasiri and Bepler, 2022] achieve the trans- lation and rotation equivariant VAE. The other branch im- plements the group equivariant function [Yang et al., 2022; Keller and Welling, 2021a] over the pre-defined group ele- ments. All of the methods effectively improve disentangle- ment by adjusting symmetries, but they focused on learning symmetries among observations to inject inductive bias rather than factorizing group elements to align them on a single factor and a single dimension changes, as introduced in the definition provided in [Higgins et al., 2018]. In current works, unsupervised learning approaches of group equivariant models are introduced. [Miyato et al., 2022; Quessard et al., 2020] represent the symmetries on the la- tent vector space, which correspond to the symmetries on the input space, by considering the sequential observations. Also, [Winter et al., 2022b] proposes the group invariant and equivariant representations with different modules to learn the different groups of dataset structure. However, these ap- proaches, despite being unsupervised learning, require the factor information of the dataset to construct the sequential input and to set different modules for learning symmetries. This paper introduces a novel disentanglement method for Composite Factor-Aligned Symmetry Learning (CFASL) within VAE frameworks, aimed at addressing the challenges encountered in unsupervised learning scenarios, particularly the absence of explicit knowledge about the factor structure in datasets. Our methodology follow as 1) a network architecture to learn an explicit codebook of symmetries, responsible for each single factor change, called factor-aligned symmetries, 2) training losses to inject inductive bias to be an explicit code- book where each factor-aligned symmetry only impacts to a single dimension value of latent vectors for disentangled repre- sentations, 3) learning composite symmetries by prediction of single factor changes itself without information of factor labels for unsupervised learning, 4) implementing group equivariant encoder and decoder functions that factor-aligned symmetry affects latent vector space, 5) an extended metric (m-FVMk) to evaluate disentanglement in the multi-factor change con- dition. We conduct quantitative and qualitative analyses of our method onn common benchmarks of disentanglement in arXiv:2401.08897v2  [cs.LG]  19 Jan 2024 VAEs. 2 Limits of Disentanglement Learning of VAE By the definition of disentangled representation [Bengio et al., 2013; Higgins et al., 2018], the disentangled representa- tions distribute on the flattened surface as shown in Fig. 1g because each change of the factor only affects to single dimension of latent vector. However, the previous meth- ods [Higgins et al., 2017; Chen et al., 2018; Shao et al., 2020; Zhu et al., 2021; Yang et al., 2022] show the entangled representations on their latent vector space as shown in Fig. 1a-1c. Even though the group theory-based methods improve the disentanglement performance [Zhu et al., 2021; Yang et al., 2022], these are still struggling with the same problem as shown in Fig. 1d and 1e. In addition, symme- tries are represented on the latent vector space for disentan- gled representations. In current works [Miyato et al., 2022; Keller and Welling, 2021a; Quessard et al., 2020], the se- quential observation is considered with unsupervised learn- ing. However, these works need the knowledge of sequential changes of images to set up inputs manually. To enhance these two problems of disentanglement learning of group theory-based methods, addressing two questions is crucial: 1. Do the explicitly defined symmetries impact to the struc- turing of a disentangled space as depicted in Fig. 1g? 2. can these symmetries be represented through unsuper- vised learning without any prior knowledge of factor information? 3 Methods 3.1 Input: A Pair of Two Samples To learn the symmetries between inputs with unknown fac- tors changes, we randomly pair the two samples as an in- put. During the training, samples in the mini-batch X|B| are divided into two parts X1 |B| = {x1 1, x1 2, . . . , x1 |B| 2 }, and X2 |B| = {x2 1, x2 2, . . . , x2 |B| 2 }, where |B| is a mini- batch size. In the next, our model pairs the samples (x1 1, x2 1), (x1 2, x2 2), . . . , (x1 |B| 2 , x2 |B| 2 ) and is used for learning symmetries between the elements of each pair. 3.2 Factor-Aligned Symmetry Learning with Inductive Bias We define the factor-aligned symmetry that represents a corre- sponding factor change on the latent vector space. For factor- aligned symmetry, we compose the symmetry codebook and inject inductive bias via Parallel loss Lpl and Perpendicu- lar loss Lpd that matches each symmetry to a single factor changes. Then we add sparsity loss Ls to the losses for disen- tangled representations as shown in Fig. 3. It aligns a single factor change to an axis of latent vector space. Also, we im- plement the commutative loss Lc to reduce the computational costs for matrix exponential multiplication. Explicit and Learnable Symmetry Representation for In- ductive Bias Injection To allow the direct injection of in- ductive bias into symmetries, we implement an explicit and trainable codebook for symmetry representation. we consider the symmetry group on the latent vector space as a subgroup of the general lie group GL(n) under a matrix multiplica- tion. The codebook G = {G1, G2, . . . , Gk} is composed of sections Gi, which are affect to a different single factor, where k ∈ {1, 2, . . . |S|}, and |S| is the number of sections. The section Gi is composed of Lie algebra {gi 1, gi 2, . . . , gi l}, where gi j ∈ R|D|×|D|, l ∈ {1, 2, . . . , |SS|}, |SS| is the number of el- ements in each section, and |D| is a dimension size of latent z. We assume that each Lie algebra consists of linearly indepen- dent bases B = {Bi|Bi ∈ Rn×n, P i αiBi ̸= 0, αi ̸= 0}: gi j = P b αi,j b Bb, where b ∈ {1, 2, . . . , kl}. Then the di- mension of the element of the codebook is equal to |B| and the dimension of the Lie group composited by the codebook element is also |B|. To utilize previously studied effective expression of symmetry for disentanglement, we set the sym- metry to be continuous [Higgins et al., 2022] and invert- ible via matrix exponential form [Xiao and Liu, 2020] as gi j = egi j = P∞ k=0 1 k!(gi j)k to construct the Lie group [Hall, 2015]. Inductive Bias: Group Elements of the Same Section Im- pacts on the Same Factor Changes We add a bias that latent vector changes by two symmetries for the same factor should be parallel (z−gi jz ∥ z−gi lz for ith section) as shown in Fig. 3a. We define a loss function to make them parallel as: Lpl = |S| X i=1 |SS| X j,k=1 log < z − gi jz, z − gi kz > ||z − gi jz||2 · ||z − gi kz||2 , (1) where gi j = egi j, < ·, · > is a dot product, and || · ||2 is a L2 norm. Inductive Bias: Group Elements of the Different Section Impacts on the Different Factor Changes Similarly to the parallel loss, we inject another bias that changes by two sym- metries for different factors should satisfy the orthogonality ( z − gi jz ⊥ z − gk l z for different ith and kth sections) as shown in Fig. 3c. The loss for inducing the orthogonality is Lpd = |S| X i,k=1,i̸=k |SS| X j,l=1 < z − gi jz, z − gk l z > ||z − gi jz||2 · ||z − gk l z||2 . (2) This loss is computationally expensive to calculate (O(|S|2 · |SS|2)), so we randomly select a (j, l) pair of symmetries of different sections. This random selection still holds the or- thogonality, because if all elements in the same section satisfy Equation 1 and a pair of elements from a different section (Gi, Gj) satisfies Equation 2, then any pair of the element (gi ∈ Gi, gj ∈ Gj) satisfies the Equation 2. More details are in Appendix B. Inductive Bias: Align Each Factor Changes to the Axis of Latent Space for Disentangled Representations Factoriz- ing latent dimensions to represent the change of independent factors is an attribute of disentanglement defined in [Bengio et (a) β-VAE (b) β-TCVAE (c) Control-VAE (d) CLG-VAE (e) G-VAE (f) CFASL (ours) (g) Ideal Figure 1: Distribution of latent vectors for dimensions responsible for Shape, X-pos, Y-pos factors in the dSprites dataset. The groupified-VAE method is applied to β-TCVAE because this model shows a better evaluation score. The results show disentanglement for Shape from the combination of the other two factors by coloring three shapes (square, ellipse, heart) as red, blue, and green color, respectively. Each 3D-plot shows the whole distribution. We fix Scale and Orientation factor values, and plot randomly sampled 640 inputs (20.8% of all possible observations (32 × 32 × 3 = 3, 072)). We select the dimensions responsible for the factors by selecting the largest value of the Kullback-Leibuler divergence between the prior and the posterior. al., 2013] and derived by ELBO term in VAE training frame- works [Chen et al., 2018; Kim and Mnih, 2018]. However, it is noteworthy that neither the parallel loss nor the perpendic- ular loss exhibits specific constraints aimed at inducing this characteristic as shown in Fig. 3a, 3c. To guide symmetries to hold the attribute, we enforce the change ∆i jz = z − gi jz to be a parallel shift to a unit vector as Fig. 3b, 3d via sparsity loss defined as Ls = |S| X i=1 |SS| X j h\u0002 |D| X k=1 (∆i jzk)2\u00032 − max k ((∆i jzk)2)2i , (3) where ∆i jzk is a kth dimension value. 3.3 Composition of Factor-Aligned Symmetries via Two-Step Attention for Unsupervised Learning First Step: Select Factor-Aligned Symmetry In the first step, the model generate the factor-aligned symmetries of each section through the attention score: gi c = egi c, where gi c = P|S.S| j=1 attni jgi j, attni j = softmax([M; Σ]W i c + bi c) [M; Σ] = [µ1; σ1; µ2; σ2], W i c ∈ R4|D|×|SS| and bi c ∈ R|SS| are learnable parameters, and i ∈ {1, 2, . . . |S|}. Second Step: Section Selection In the second step of our proposed model, we enforce the prediction of factors deemed to have undergone changes. We assume that if some factor value of two inputs is equal, then the variance of the corre- sponding latent vector dimension value is smaller compared to others. Based on this assumption, we define the target (T) for factor prediction: if z1,i − z2,i > threshold, then we set Ti as 1 and 0 otherwise, where Ti is a ith dimension value of T ∈ R|D|, zj,i is an ith dimension value of zj, and we set the threshold as a hyper-parameter. For section prediction, we utilize the cross-entropy loss: Lp = |S| X i=1 X c∈C 1[Ti = c] · log softmax(pi s), (4) where pi s = [M; Σ]W i s + bi s, W i s ∈ R4|D|×2 and bi s ∈ R2 are learnable parameters, and c ∈ {0, 1}. To infer the activated section of the symmetries codebook, we utilize the Gumbel softmax function to handle binary on- and-off scenarios, akin to a switch operation: sw(G(pi s)) = \u001aG(pi s,2) if pi s,2 ≥ 0.5 1 − G(pi s,1) if pi s,2 < 0.5 , (5) where pi s,j is a jth dimension value of pi s, and G(·) is the Gumbel softmax with temperature as 1e-4. Integration for Composite Symmetry For the composite symmetry gc, we compute it s the product of weighted sums of switch function sw(ps) and prediction distribution attn as: gc = Q|S| i=1 ˆgi c, where ˆgi c = esw(G(pi s))·gi c. Commutativity Loss for Computational Efficiency In the computation of the composite symmetry gc, the production Q|S| i=1 ˆgi c is a computationally expensive Taylor series repeated for all (i, j) pairs. To reduce the cost by repetition, we enforce all pairs of basis gj i to be commutative to convert the produc- tion to e P i gi c (By the matrix exponential property: eAeB = eA + B as AB = BA, where A, B ∈ Rn×n). The loss for the commutativity is Lc = P|S| i,k=1 P|SS| j,l=1 gi jgk l − gk l gi j → 0. 3.4 Equivariance Induction of Composite Symmetries How to Induce Equivariance? Motivated by the implemen- tations of equivariant mapping in prior studies [Yang et al., 2022; Miyato et al., 2022] for disentanglement learning, we implement an equivariant encoder and decoder that satisfies qϕ(ψi ∗ x) = gi ◦ qϕ(x) and pθ(gi ◦ z) = ψi ∗ pθ(z) respec- tively, where qϕ is an encoder, and pθ is the decoder. In the notation, ψi and gi are group elements of the group (Ψ, ∗) and (G, ◦) respectively, and both groups are isomorphic. Each group acts on the input and latent vector space with group action ∗, and ◦, respectively. We specify the form of symmetry gi and ◦ as an invertible matrix, and group action as matrix multiplication on the latent vector space. Then, the encoder equivariant function can be rewritten by multiplying the inver- sion of gi on both sides and z can be replaced with the qϕ(x) in the decoder equivariant function as qϕ(x) = g−1 i ◦ qϕ(ψi ∗ x) ⇐⇒ qϕ(x) − g−1 i ◦ qϕ(ψi ∗ x) → 0 (for encoder). (6) pθ(gi ◦ qϕ(x)) = ψi ∗ pθ(qϕ(x)) ⇐⇒ pθ(gi ◦ qϕ(x)) − ψi ∗ pθ(qϕ(x)) → 0 (for decoder), (7) where xj = ψi→j ∗ xi. For the equivariant encoder and decoder, we differently propose the single forward process by the encoder and decoder objective functions compared to previous work [Yang et al., 2022]. Figure 2: The overall architecture of our proposed method. The loss function is divided into four parts: 1) commutative loss (Lc), 2) perpendicular, parallel, and sparsity loss (Lpd, Lpl, and Ls) in Equation 1-3, 3) factor prediction loss (Lp) in Equation 4), and 4) equivariant loss (Lee, and Lde) in Equation 8). MLP is a multi-layer perceptron, and, tr is a threshold. Attention score attne, sw(·), and pi s are introduced in section 3.3. Equivariance Loss for Encoder and Decoder In order for the equivariant function between the input and latent vector space, the mapping function qϕ(·) must satisfy Equation 6. Therefore, we directly induce an equivariant encoder between input and latent space with MSE loss (Lee). Additionally, we induce the equivariant decoder (Lde) with MSE loss following Equation 7: Lequiv = Lee + ϵLde = MSE(qϕ(x1 i ), g−1 i ◦ qϕ(x2 i )) + ϵMSE(pθ(gi ◦ (qϕ(x1 i )), ψi ∗ pθ(qϕ(x1 i )), (8) where x2 i = ψi ∗ x1 i . During the training, we replace the pθ(qϕ(x1 i )) as a x1 i because the ELBO term includes the re- construction error between pθ(qϕ(x1 i )) and x1 i to be close to zero. Objective and Base model Our method can be plugged into existing VAE frameworks, where the objective function is integrated additively as follows: L(ϕ, θ; x) = LV AE + Lcodebook + Lequiv, (9) where LV AE is the loss function of a VAE framework (Ap- pendix A). The other loss Lcodebook = Lpl +Lpd +Ls +Lc + Lp and Lequiv = Lee + ϵLde where ϵ is a hyper-parameter, which are introduced in the following subsections. 3.5 Extended Evaluation Metric: m-FVM Metric for Disentanglement in Multi-Factor Change We define the multi-factor change condition as simultaneously altering more than two factors in the transformation between two samples or representations. To the best of our knowl- edge, there is no evaluation metric for disentanglement in multi-factor change, so we propose the extended version of the Factor-VAE metric (FVM) score called as multi-FVM score (m-FVMk), where k ∈ {2, 3, . . . , |F| − 1}, and |F| is a number of factors. Similar to FVM, 1) we randomly choose the k fixed factors (Fi, Fj, . . .). 2) We sample each fac- tor’s value (fi, fj, . . .) and fix the corresponding factor dimen- sion value in the mini-batch, where fi ∈ {1, 2, . . . |Fi|}, fj ∈ {1, 2, . . . |Fj|}, . . ., |Fi| and |Fj| is a maximum value of each factor label. 3) Subsequently, we estimate the standard devia- tion (std.) of each dimension to find the number of k lowest std. dimension (zl1, zl2, . . .) in one epoch. 4) We then count each pair of selected dimensions by std. values (the num- ber of (zl1, zl2, . . .), which are corresponded to fixed factors). 5) In the last, we add the maximum value of the number of (zl1, zl2, . . .) on all fixed factor cases, and divide with epoch. 4 Related Work Disentanglement Learning Diverse works for unsupervised disentanglement learning have elaborated in the machine learn- ing field. The VAE based approaches have factorized latent vector dimensions with weighted hyper-parameters or con- trollable weighted values to penalize Kullback-Leibler diver- gence (KL divergence) [Higgins et al., 2017; Shao et al., 2020; Shao et al., 2022]. Extended works penalize total correlation for factorizing latent vector dimensions with divided KL diver- (a) parallel loss (b) (a) + sparsity loss (c) perpendicular loss (d) (c) + sparsity loss Figure 3: Roles of parallel, perpendicular, and sparsity loss on symmetries in the codebook for adjusting representation change. Parallel loss is for symmetries of the same section, and perpendicular loss is for different sections. Each axis (x and y) only affects to a single factor. 3D Car FVM beta VAE MIG SAP DCI m-FVM2 m-FVM3 m-FVM4 β-VAE 91.83(±4.39) 100.00(±0.00) 11.44(±1.07) 0.63(±0.24) 27.65(±2.50) 61.28(±9.40) - - β-TCVAE 92.32(±3.38) 100.00(±0.00) 17.19(±3.06) 1.13(±0.37) 33.63(±3.27) 59.25(±5.63) - - Factor-VAE 93.22(±2.86) 100.00(±0.00) 10.84(±0.93) 1.35(±0.48) 24.31(±2.30) 50.43(±10.65) - - Control-VAE 93.86(±5.22) 100.00(±0.00) 9.73(±2.24) 1.14(±0.54) 25.66(±4.61) 46.42(±10.34) - - CLG-VAE 91.61(±2.84) 100.00(±0.00) 11.62(±1.65) 1.35(±0.26) 29.55(±1.93) 47.75(±5.83) - - CFASL 95.70(±1.90) 100.00(±0.00) 18.58(±1.24) 1.43(±0.18) 34.81(±3.85) 62.43(±8.08) - - smallNORB FVM beta VAE MIG SAP DCI m-FVM2 m-FVM3 m-FVM4 β-VAE 60.71(±2.47) 59.40(±7.72) 21.60(±0.59) 11.02(±0.18) 25.43(±0.48) 24.41(±3.34) 15.13(±2.76) - β-TCVAE 59.30(±2.52) 60.40(±5.48) 21.64(±0.51) 11.11(±0.27) 25.74(±0.29) 25.71(±3.51) 15.66(±3.74) - Factor-VAE 61.93(±1.90) 56.40(±1.67) 22.97(±0.49) 11.21(±0.49) 24.84(±0.72) 26.43(±3.47) 17.25(±3.50) - Control-VAE 60.63(±2.67) 61.40(±4.33) 21.55(±0.53) 11.18(±0.48) 25.97(±0.43) 24.11(±3.41) 16.12(±2.53) - CLG-VAE 62.27(±1.71) 62.60(±5.17) 21.39(±0.67) 10.71(±0.33) 22.95(±0.62) 27.71(±3.45) 17.16(±3.12) - CFASL 62.73(±3.96) 63.20(±4.13) 22.23(±0.48) 11.42(±0.48) 24.58(±0.51) 27.96(±3.00) 17.37(±2.33) - dSprites FVM beta VAE MIG SAP DCI m-FVM2 m-FVM3 m-FVM4 β-VAE 73.54(±6.47) 83.20(±7.07) 13.19(±4.48) 5.69(±1.98) 21.49(±6.30) 53.80(±10.29) 50.13(±11.98) 48.02(±8.98) β-TCVAE 79.19(±5.87) 89.20(±4.73) 23.95(±10.13) 7.20(±0.66) 35.33(±9.07) 61.75(±6.71) 57.82(±5.39) 63.81(±9.45) Factor-VAE 78.10(±4.45) 84.40(±5.55) 25.74(±10.58) 6.37(±1.82) 32.30(±9.47) 58.39(±5.18) 51.63(±2.88) 53.71(±4.22) Control-VAE 69.64(±7.67) 82.80(±7.79) 5.93(±2.78) 3.89(±1.89) 12.42(±4.95) 38.99(±9.31) 29.00(±10.75) 19.33(±5.98) CLG-VAE 82.33(±5.59) 86.80(±3.43) 23.96(±6.08) 7.07(±0.86) 31.23(±5.32) 63.21(±8.13) 48.68(±9.59) 51.00(±8.13) CFASL 82.30(±5.64) 90.20(±5.53) 33.62(±8.18) 7.28(±0.63) 46.52(±6.18) 68.32(±0.13) 66.25(±7.36) 71.35(±12.08) 3D Shapes FVM beta VAE MIG SAP DCI m-FVM2 m-FVM3 m-FVM4 β-VAE 84.33(±10.65) 91.20(±4.92) 45.80(±21.20) 8.66(±3.80) 66.05(±7.44) 70.26(±6.27) 61.52(±8.62) 60.17(±8.48) β-TCVAE 86.03(±3.49) 87.80(±3.49) 60.02(±10.05) 5.88(±0.79) 70.38(±4.63) 70.20(±4.08) 63.79(±5.66) 63.61(±5.90) Factor-VAE 79.54(±10.72) 95.33(±5.01) 52.68(±22.87) 6.20(±2.15) 61.37(±12.46) 66.93(±17.49) 63.55(±18.02) 57.00(±21.36) Control-VAE 81.03(±11.95) 95.00(±5.60) 19.61(±12.53) 4.76(±2.79) 55.93(±13.11) 62.22(±11.35) 55.83(±13.61) 51.66(±12.08) CLG-VAE 83.16(±8.09) 89.20(±4.92) 49.72(±16.75) 6.36(±1.68) 63.62(±3.80) 65.13(±5.26) 58.94(±6.59) 60.51(±7.62) CFASL 89.70(±9.65) 96.20(±4.85) 62.12(±13.38) 9.28(±1.92) 75.49(±8.29) 74.26(±2.82) 67.68(±2.67) 63.48(±4.12) Table 1: Disentanglement scores for single factor change (left 5 metrics) and multi-factor change (m-FVMs) with 10 random seeds. 3D Car smallNORB dSprites 3D Shapes Avg. β-VAE 3.33 4.86 4.88 3.38 4.11 β-TCVAE 2.50 4.29 2.50 2.88 3.04 Factor-VAE 3.17 2.71 3.38 4.00 3.31 Control-VAE 3.67 3.86 6.00 5.50 4.76 CLG-VAE 3.00 3.86 3.13 4.13 3.53 CFASL 1.00 1.43 1.13 1.13 1.17 Table 2: Disentanglement performance rank. Each dataset rank is an average of evaluation metrics, and Avg. is an average of all datasets. gence [Chen et al., 2018] and discriminator [Kim and Mnih, 2018]. Differently, we induce disentanglement learning with group equivariant VAE for inductive bias. Group Theory-Based Approaches for Disentangled Rep- resentation In recent periods, various unsupervised disen- tanglement learning research proposes different approaches with another definition of disentanglement, which is based on the group theory [Higgins et al., 2018]. To learn the equivariant function, Topographic VAE [Keller and Welling, 2021b] proposes the sequentially permuted activations on the latent vector space called shifting temporal coherence, and Groupified VAE [Yang et al., 2022] method proposes that inputs pass the encoder and decoder two times to im- plement permutation group equivariant VAE models. Also, Commutative Lie Group VAE (CLG-VAE) [Zhu et al., 2021; Mercatali et al., 2022] maps latent vectors into Lie algebra with one-parameter subgroup decomposition for inductive bias to learn the group structure from abstract canonical point to inputs. Differently, we propose the trainable symmetries that are extracted between two samples directly on the latent space while maintaining the equivariance function between input and latent vector space. Symmetry Learning with Equivariant Model Lie group equivariant CNN [Dehmamy et al., 2021] and [Finzi et al., 2020] construct the In the other literature, several works ex- tract symmetries, which consist of matrices, between two inputs or objects. [Miyato et al., 2022] extracts the symme- tries between sequential or sequentially augmented inputs by penalizing the transformation of difference of the same time interval. Other work extracts the symmetries by comparing two inputs, in which the differentiated factor is a rotation or translation, and implements symmetries with block diagonal matrices [Bouchacourt et al., 2021]. Furthermore, [Marchetti et al., 2023] decomposes the class and pose factor simultane- ously by invariant and equivariant loss function with weakly supervised learning. The unsupervised learning work [Winter et al., 2022a] achieves class invariant and group equivariant function in less constraint conditions. Differently, we gener- ally extend the a class invariant and group equivariant model in the more complex disparity condition without any knowledge of the factors of datasets. 5 Experiments 5.1 Settings We implement β-VAE [Higgins et al., 2017], β-TCVAE [Chen et al., 2018], Factor-VAE [Kim and Mnih, 2018], control- VAE [Shao et al., 2020], and Commutative Lie Group VAE (CLG-VAE) [Zhu et al., 2021] for baseline. For common settings to baselines, we set batch size 64, learning rate 1e-4, and random seed from {1, 2, . . . , 10} without weight decay. We train for 3 × 105 iterations on dSprites smallNORB and 3D Cars, and 5 × 105 iterations on 3D Shapes. Also, each dataset guarantees the commutativity of transformation. More details for experimental settings are in Appendix C. 5.2 Quantitative Analysis Results and Discussion Disentanglement Performance in Single and Multi-Factor Change We evaluate four common disentanglement met- rics: FVM [Kim and Mnih, 2018], MIG [Chen et al., 2018], SAP [Kumar et al., 2018], and DCI [Eastwood and Williams, 2018], and more details of evaluation settings are in Ap- pendix C. As shown in Table 1, our method gradually im- proves the disentanglement learning in dSprites, 3D Cars, 3D Shapes, and smallNORB datasets in most metrics. This result also shows that our method positively affects single factor change conditions. More details are in Appendix D.1. To show the quantitative score of the disentanglement in multi-factor change, we evaluate the m-FVMk, where max(k) is 2, 3, and 4 in 3D Cars, smallNORB, and dSprites datasets respectively. As shown in Table 2, the proposed method shows a statistically significant improvement, as indicated by the higher average rank of dataset metrics compared to other ap- proaches. It implies that our method has the benefit of disen- tanglement learning in the multi-factor change condition. We provide additional results in Appendix D.1. Ablation Study Table 3 shows the ablation study to evaluate the impact of each component of our method for disentangle- ment learning. To compare factor-aligned losses (w/o Lpl, w/o Lpd, w/o Ls, and w/o Lpl +Lpd +Ls), the best of among four cases is the w/o Lpl +Lpd +Ls and it implies that these losses are interrelated. In the case of w/o Lpl, the extraction of the composite symmetry gc becomes challenging due to the lack of unified roles among individual sections. Composite symmetry gc is affected by the second section selection method, which is whether to use the section or not (0 or 1). Therefore, composite that has a different role on elements in the same section strug- gles with constructing adequate composite symmetry gc. With the similar perspective referred to w/o Lpl case, the coverage of code w/o Lpd is limited due to the absence of assurance that each section aligns with distinct factors. In the case of w/o Ls, each section assigns a different role and the elements of each section align on the same factor, w/o Ls case is better than w/o Lpl and w/o Lpd. Also, constructing the symmetries without the equivariant model is meaningless because the model does not satisfy Equation 6- 8. The w/o Lequiv naturally shows the lowest results compared to other cases except w/o Lpd and Lpl. Moreover, the w/o Lp case shows the impact of the second section selection for unsupervised learning. Above all, each group exhibits a positive influence on disentanglement when compared to the base model (β-VAE). When combining all loss functions, our method consistently outperforms the others across the majority of evaluation metrics. The inductive bias for symmetry changes (Lpl + Lpd) is less effective than that for composition because the bias is only for symmetry change control without latent dimension matching to a factor. The inclusion of a sparsity loss effectively addresses this con- cern and yields the best improvement. More details are in the Appendix D.2. Lp Lc Le. Lpl Lpd Ls FVM MIG SAP DCI m-FVM2 β-VAE ✗ ✗ ✗ ✗ ✗ ✗ 88.19(±4.60) 6.82(±2.93) 0.63(±0.33) 20.45(±3.93) 42.36(±7.16) ✗ ✓ ✓ ✓ ✓ ✓ 88.57(±6.68) 7.18(±2.52) 1.85(±1.04) 18.39(±4.80) 48.23(±5.51) ✓ ✓ ✗ ✓ ✓ ✓ 88.56(±7.78) 7.27(±4.16) 1.31(±0.70) 19.58(±4.45) 42.63(±4.21) ✓ ✓ ✓ ✗ ✓ ✓ 86.95(±5.96) 7.11(±3.49) 1.09(±0.40) 18.35(±3.32) 41.90(±7.80) ✓ ✓ ✓ ✓ ✗ ✓ 85.42(±7.89) 7.30(±3.73) 1.15(±0.70) 21.69(±4.70) 41.90(±6.07) ✓ ✓ ✓ ✗ ✗ ✗ 89.34(±5.18) 9.44(±2.91) 1.26(±0.40) 23.14(±5.51) 51.37(±9.29) ✓ ✓ ✓ ✓ ✓ ✗ 90.71(±5.75) 9.29(±3.74) 1.07(±0.65) 22.74(±5.06) 45.84(±7.71) ✓ ✓ ✓ ✓ ✓ ✓ 91.91(±3.45) 9.51(±2.74) 1.42(±0.52) 20.72(±3.65) 55.47(±10.09) Table 3: Ablation study for loss functions on 3D-Cars and β-VAE with 10 random seeds. (a) Generated images by composite symmetry and its factor-aligned symmetries. Image 1⃝ and 2⃝ are inputs, and image 3⃝ is an output from image 1⃝ (pθ(z1)). Image 5⃝ is a output of group element gc acted on z1 (p(gcz1)). Images 4⃝ are outputs of decomposed composite symmetry gc acted on z1 sequentially. (b) Generated images by dimension change. Red and blue colored squares represent the value of latent vector dimensions of z1 and z2. The images of baseline and CAFSL are the generated images from each latent vector. (c) Generalization over unseen pairs of images. We set pairs {(xi−1, xi)|1 ≤ i ≤ ||X||−1} then extract the symmetries between elements of each pair gp = {g(1,2), g(2,3), . . . g(k−1,k)} in inference step, where g(k−1,k) is a symmetry between zk−1 and zk. The first row images are inputs (targets) and the second row images are the generated images by symmetry codebook. Figure 5: Qualitative Analysis to Generate Images from Latent Vectors in Various Conditions. More details are in the Appendix D.3. 5.3 Qualitative Analysis Results and Discussion Figure 4: Heatmaps of Eigenvectors for latent vector representations. Is Latent Vector Space Close to Disentangled Space? The previous result as shown in Fig. 1 is a clear example of of whether the latent vector space closely approximates a disentangled space. The latent vector space of previous works (Fig. 1a-1e) are far from disentangled space (Fig. 1g) but CFASL shows the closest disentangled space compare to other methods. Alignment of Latent Dimensions to Factor-Aligned Sym- metry In the principal component analysis of latent vectors shown in Fig. 4, the eigenvectors V = [v1, v2, . . . , v|D|] are close to one-hot vectors compared to the baseline, and the dominating dimension of the one-hot vectors are all different. This result implies that the representation (factor) changes are aligned to latent dimensions. Factor Aligned Symmetries To verify the representation of learnable codebook over composite symmetries and factor- aligned symmetries, we randomly select a sample pair as shown in Fig. 5a. The results imply that gc generated from the codebook represents the composite symmetries between two images ( 1⃝ and 2⃝) because the image 2⃝ and the generated image 5⃝ by symmetry gc are similar (p(z2) ≈ p(gcz1)). Also, each factor-aligned symmetry (gi) generated from codebook section affects a single factor changes as shown in images 4⃝. in Fig. 5a. Factor Aligned Latent Dimension To analyze each factor changes aligned to each dimension of latent vector space, we set the qualitative analysis as shown in 5b. We select two ran- dom samples (x1, x2), generate latent vectors z1 and z2, and select the largest Kullback-Leibler divergence (KLD) value dimension from their posterior. Then, replacing the dimension value of z1 to the value of z2 one by one sequentially. As a result, the shape and color factors are changed when a single dimension value is replaced within the baseline. However, our method results show no overlapped factor changes compared to baseline results. It implies that each latent vector dimension of the proposed method contains a single factor of information. Unseen Change Prediction in Sequential Data The se- quential observation as [Miyato et al., 2022] is rarely observed in our methods, because of the random pairing during training (less 1 pair of observation). But their generated images via trained symmetries of our method are similar to target images as shown in Fig. 5c. This result implies that our method is strongly regularized for unseen change. 6 Conclusion This work tackles the difficulty of disentanglement learning of VAEs in unknown factors change conditions. We propose a novel framework to learn composite symmetries from explicit factor-aligned symmetries by codebook to directly represent the multi-factor change of a pair of samples in unsupervised learning. The framework enhances disentanglement by learn- ing an explicit symmetry codebook, injecting three inductive biases on the symmetries aligned to unknown factors, and inducing a group equivariant VAE model. We quantitatively evaluate disentanglement in the condition by a novel metric (m-FVMk) extended from a common metric for a single factor change condition. This method significantly improved in the multi-factor change and gradually improved in the single factor change condition compared to state-of-the-art disentanglement methods of VAEs. Also, training process does not need the knowledge of factor information of datasets. This work can be easily plugged into VAEs and extends disentanglement to more general factor conditions of complex datasets. References [Bengio et al., 2013] Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: a review and new perspectives. IEEE transactions on pattern analysis and machine intelligence, 35(8):1798—1828, August 2013. [Bouchacourt et al., 2021] Diane Bouchacourt, Mark Ibrahim, and St´ephane Deny. Addressing the topological defects of disentanglement via distributed operators, 2021. [Burgess and Kim, 2018] Chris Burgess and Hyunjik Kim. 3d shapes dataset. https://github.com/deepmind/3dshapes- dataset/, 2018. [Cao et al., 2022] Jinkun Cao, Ruiqian Nai, Qing Yang, Jialei Huang, and Yang Gao. An empirical study on disentan- glement of negative-free contrastive learning. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022. [Chen et al., 2018] Ricky T. Q. Chen, Xuechen Li, Roger B Grosse, and David K Duvenaud. Isolating sources of dis- entanglement in variational autoencoders. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018. [Dehmamy et al., 2021] Nima Dehmamy, Robin Walters, Yanchen Liu, Dashun Wang, and Rose Yu. Automatic sym- metry discovery with lie algebra convolutional network. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan, editors, Advances in Neural Information Process- ing Systems, 2021. [Eastwood and Williams, 2018] Cian Eastwood and Christo- pher K. I. Williams. A framework for the quantitative evaluation of disentangled representations. In International Conference on Learning Representations, 2018. [Finzi et al., 2020] Marc Finzi, Samuel Stanton, Pavel Iz- mailov, and Andrew Gordon Wilson. Generalizing con- volutional neural networks for equivariance to lie groups on arbitrary continuous data. arXiv preprint arXiv:2002.12880, 2020. [Hall, 2015] B. Hall. Lie Groups, Lie Algebras, and Repre- sentations: An Elementary Introduction. Graduate Texts in Mathematics. Springer International Publishing, 2015. [Higgins et al., 2017] Irina Higgins, Lo¨ıc Matthey, Arka Pal, Christopher P. Burgess, Xavier Glorot, Matthew M. Botvinick, Shakir Mohamed, and Alexander Lerchner. beta- vae: Learning basic visual concepts with a constrained variational framework. In ICLR, 2017. [Higgins et al., 2018] Irina Higgins, David Amos, David Pfau, S´ebastien Racani`ere, Lo¨ıc Matthey, Danilo J. Rezende, and Alexander Lerchner. Towards a definition of disentangled representations. CoRR, abs/1812.02230, 2018. [Higgins et al., 2022] Irina Higgins, S´ebastien Racani`ere, and Danilo Rezende. Symmetry-based representations for artificial and biological general intelligence, 2022. [Jeong and Song, 2019] Yeonwoo Jeong and Hyun Oh Song. Learning discrete and continuous factors of data via al- ternating disentanglement. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th In- ternational Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 3091– 3099. PMLR, 09–15 Jun 2019. [Keller and Welling, 2021a] T. Anderson Keller and Max Welling. Topographic VAEs learn equivariant capsules. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan, editors, Advances in Neural Information Process- ing Systems, 2021. [Keller and Welling, 2021b] T. Anderson Keller and Max Welling. Topographic vaes learn equivariant capsules. CoRR, abs/2109.01394, 2021. [Kim and Mnih, 2018] Hyunjik Kim and Andriy Mnih. Dis- entangling by factorising. In Jennifer Dy and Andreas Krause, editors, Proceedings of the 35th International Con- ference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 2649–2658. PMLR, 10–15 Jul 2018. [Kingma and Welling, 2013] Diederik P Kingma and Max Welling. Auto-encoding variational bayes, 2013. [Kumar et al., 2018] Abhishek Kumar, Prasanna Sattigeri, and Avinash Balakrishnan. VARIATIONAL INFERENCE OF DISENTANGLED LATENT CONCEPTS FROM UN- LABELED OBSERVATIONS. In International Conference on Learning Representations, 2018. [LeCun et al., 2004] Yann LeCun, Fu Jie Huang, and L´eon Bottou. Learning methods for generic object recognition with invariance to pose and lighting. In Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR’04, page 97–104, USA, 2004. IEEE Computer Society. [Liu et al., 2015] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. 2015 IEEE International Conference on Computer Vision (ICCV), pages 3730–3738, 2015. [Locatello et al., 2019] Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly, Bernhard Sch¨olkopf, and Olivier Bachem. Challenging common as- sumptions in the unsupervised learning of disentangled rep- resentations. In Kamalika Chaudhuri and Ruslan Salakhut- dinov, editors, Proceedings of the 36th International Con- ference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 4114–4124. PMLR, 09–15 Jun 2019. [Marchetti et al., 2023] Giovanni Luca Marchetti, Gustaf Tegn´er, Anastasiia Varava, and Danica Kragic. Equivariant representation learning via class-pose decomposition. In Francisco Ruiz, Jennifer Dy, and Jan-Willem van de Meent, editors, Proceedings of The 26th International Conference on Artificial Intelligence and Statistics, volume 206 of Pro- ceedings of Machine Learning Research, pages 4745–4756. PMLR, 25–27 Apr 2023. [Matthey et al., 2017] Loic Matthey, Irina Hig- gins, Demis Hassabis, and Alexander Lerchner. dsprites: Disentanglement testing sprites dataset. https://github.com/deepmind/dsprites-dataset/, 2017. [Mercatali et al., 2022] Giangiacomo Mercatali, Andre Fre- itas, and Vikas Garg. Symmetry-induced disentanglement on graphs. In S. Koyejo, S. Mohamed, A. Agarwal, D. Bel- grave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems, volume 35, pages 31497– 31511. Curran Associates, Inc., 2022. [Michlo, 2021] Nathan Juraj Michlo. Disent - a modular dis- entangled representation learning framework for pytorch. Github, 2021. [Miyato et al., 2022] Takeru Miyato, Masanori Koyama, and Kenji Fukumizu. Unsupervised learning of equivariant structure from sequences. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022. [Nasiri and Bepler, 2022] Alireza Nasiri and Tristan Bepler. Unsupervised object representation learning using trans- lation and rotation group equivariant VAE. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022. [Quessard et al., 2020] Robin Quessard, Thomas Barrett, and William Clements. Learning disentangled representa- tions and group structure of dynamical environments. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors, Advances in Neural Information Process- ing Systems, volume 33, pages 19727–19737. Curran Asso- ciates, Inc., 2020. [Reed et al., 2015] Scott E Reed, Yi Zhang, Yuting Zhang, and Honglak Lee. Deep visual analogy-making. In C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Gar- nett, editors, Advances in Neural Information Processing Systems, volume 28. Curran Associates, Inc., 2015. [Shakerinava et al., 2022] Mehran Shakerinava, Arnab Ku- mar Mondal, and Siamak Ravanbakhsh. Structuring repre- sentations using group invariants. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022. [Shao et al., 2020] Huajie Shao, Shuochao Yao, Dachun Sun, Aston Zhang, Shengzhong Liu, Dongxin Liu, Jun Wang, and Tarek Abdelzaher. ControlVAE: Controllable varia- tional autoencoder. In Hal Daum´e III and Aarti Singh, editors, Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Ma- chine Learning Research, pages 8655–8664. PMLR, 13–18 Jul 2020. [Shao et al., 2022] Huajie Shao, Yifei Yang, Haohong Lin, Longzhong Lin, Yizhuo Chen, Qinmin Yang, and Han Zhao. Rethinking controllable variational autoencoders. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition (CVPR), pages 19250–19259, June 2022. [Winter et al., 2022a] Robin Winter, Marco Bertolini, Tuan Le, Frank Noe, and Djork-Arn´e Clevert. Unsupervised learning of group invariant and equivariant representations. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022. [Winter et al., 2022b] Robin Winter, Marco Bertolini, Tuan Le, Frank Noe, and Djork-Arn´e Clevert. Unsupervised learning of group invariant and equivariant representations. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022. [Xiao and Liu, 2020] Changyi Xiao and Ligang Liu. Genera- tive flows with matrix exponential. In Hal Daum´e III and Aarti Singh, editors, Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceed- ings of Machine Learning Research, pages 10452–10461. PMLR, 13–18 Jul 2020. [Yang et al., 2022] Tao Yang, Xuanchi Ren, Yuwang Wang, Wenjun Zeng, and Nanning Zheng. Towards building a group-based unsupervised representation disentanglement framework. In International Conference on Learning Rep- resentations, 2022. [Zhu et al., 2021] Xinqi Zhu, Chang Xu, and Dacheng Tao. Commutative lie group VAE for disentanglement learning. CoRR, abs/2106.03375, 2021. A Loss Function of Baseline As shown in Table 4, we train the baselines with each objective function. VAEs LV AE β-VAE Eqϕ(z|x) log pθ(x|z) − βDKL(qϕ(z|x)||p(z)) β-TCVAE Eqϕ(z|x) log pθ(x|z) − αDKL(q(z, n)||q(z)p(n)) −βDKL(q(z)|| Q j a(zj)) − γ P j DKL(q(zj)||p(zj)) Factor-VAE 1 N PN i [Eq(z|xi)[log p(xi|z)] − DKL(q(z|xi)||p(z))] −γDKL(q(z)|| Q j(zj)) Control-VAE Eqϕ(z|x) log pθ(x|z) − β(t)DKL(qϕ(z|x)||p(z)) CLG-VAE Ea(z|x)q(t|z) log p(x|z)p(z|t) −Eq(z|x)DKL(q(t|z)||p(t)) − Eq(z|x) log q(z|x) Table 4: Objective Function of the VAEs. B Perpendicular and Parallel Loss Relationship We define parallel loss Lp to set two vectors in the same section of the symmetries codebook to be parallel: z − gi j ∥ z − gi j′z then, z − gi jz = c(z − gi j′z) (10) ⇒ (1 − c)z = (gi j − cgi j′)z (11) ⇒ (1 − c)I = gi j − cgi j′ or [(1 − c)I + cgi j′ − gi j]z = 0, (12) where I is an identity matrix and constant c ∈ R. However, all latent z is not eigenvector of [(1 − c)I + cgi j′ − gi j]. Then, we generally define symmetry as: gi j′ = 1 c gi j + c − 1 c I, (13) where i, j, and j′ are natural number 1 ≤ i ≤ |S|, 1 ≤ j, j′ ≤ |SS|, and k ̸= j. Therefore, all symmetries in the same section are parallel then, any symmetry in the same section is defined by a specific symmetry in the same section. We define orthogonal loss Lo between two vectors, which are in different sections, to be orthogonal: z −gi jz ⊥ z −gk l z, where i ̸= k, 1 ≤ i, k ≤ |S|, and 1 ≤ j, l ≤ |SS|. By the Equation 13, z − gi jz ⊥ z − gk l z (14) ⇒ ( 1 ca gi a + ca − 1 ca I)z − z ⊥ ( 1 cb gk b + cb − 1 cb I)z − z (15) ⇒ 1 ca (gi az − z) ⊥ 1 cb (gk b z − z), (16) where ca and cb are any natural number, and 1 ≤ a, b ≤ |SS|. Therefore, if two vectors from different sections are orthogonal and satisfied with Equation 13, then any pair of vectors from different sections is always orthogonal. C Experiment Details Device We set the below settings for all experiments in a single Galaxy 2080Ti GPU for 3D Cars and smallNORB, and a single Galaxy 3090 for dSprites 3D Shapes and CelebA. More details are in README.md file. Datasets 1) The dSprites dataset consists of 737,280 bi- nary 64 × 64 images with five independent ground truth fac- tors(number of values), i.e. x-position(32), y-position(32), orientation(40), shape(3), and scale(6), [Matthey et al., 2017]. Any composite transformation of x- and y-position, orienta- tion (2D rotation), scale, and shape is commutative. 2) The 3D Cars dataset consists of 17,568 RGB 64 × 64 × 3 images with three independent ground truth factors: elevations(4), azimuth directions(24), and car models(183) [Reed et al., 2015]. Any composite transformation of elevations(x-axis 3D rotation), azimuth directions (y-axis 3D rotation), and models are com- mutative. 3) The smallNORB [LeCun et al., 2004] dataset consists of total 96 × 96 24,300 grayscale images with four factors, which are category(10), elevation(9), azimuth(18), light(6) and we resize the input as 64 × 64. Any compos- ite transformation of elevations(x-axis 3D rotation), azimuth (y-axis 3D rotation), light, and category is commutative. 4) The 3D Shapes dataset consists of 480,000 RGB 64 × 64 × 3 images with six independent ground truth factors: orienta- tion(15), shape(4), floor color(10), scale(8), object color(10), and wall color(10) [Burgess and Kim, 2018]. 5) The CelebA dataset [Liu et al., 2015] consists of 202,599 images, and we crop the center 128 × 128 area and then, resize to 64 × 64 images. Evaluation Settings We set prune dims.threshold as 0.06, 100 samples to evaluate global empirical variance in each dimension, and run it a total of 800 times to estimate the FVM score introduced in [Kim and Mnih, 2018]. For the other metrics, we follow default values introduced in [Michlo, 2021], training and evaluation 10,000 and 5,000 times with 64 mini-batches, respectively [Cao et al., 2022]. Model Hyper-parameter Tuning We implement β- VAE [Higgins et al., 2017], β-TCVAE [Chen et al., 2018], control-VAE [Shao et al., 2020], Commutative Lie Group VAE (CLG-VAE) [Zhu et al., 2021], and Groupified-VAE (G- VAE) [Yang et al., 2022] for baseline. For common settings to baselines, we set batch size 64, learning rate 1e-4, and random seed from {1, 2, . . . , 10} without weight decay. We train for 3×105 iterations on dSprites smallNORB and 3D Cars, 6×105 iterations on 3D Shapes, and 106 iterations on CelebA. We set hyper-parameter β ∈ {1.0, 2.0, 4.0, 6.0} for β-VAE and β- TCVAE, fix the α, γ for β-TCVAE as 1 [Chen et al., 2018]. We follow the ControlVAE settings [Shao et al., 2020], the desired value C ∈ {10.0, 12.0, 14.0, 16.0}, and fix the Kp = 0.01, Ki = 0.001. For CLG-VAE, we also follow the settings [Zhu et al., 2021] as λhessian = 40.0, λdecomp = 20.0, p = 0.2, and balancing parameter of lossrec group ∈ {0.1, 0.2, 0.5, 0.7}. For G-VAE, we follow the official settings [Yang et al., 2022] with β-TCVAE (β ∈ {10, 20, 30}), because applying this method to the β-TCVAE model usually shows higher perfor- mance than other models [Yang et al., 2022]. Then we select the best case of models. We run the proposed model on the β-VAE and β-TCVAE because these methods have no induc- tive bias to symmetries. We set the same hyper-parameters of baselines with ϵ ∈ {0.1, 0.01}, threshold ∈ {0.2, 0.5}, |S| = |SS| = |D|, where |D| is a latent vector dimension. More details for experimental settings. C.1 Best Models for Quantitative Analysis In this section, we show how we pick the best model among hyper-parameter tuning results. As shown in Table 5-7, we choose the best model on each datasets. β beta VAE FVM MIG SAP DCI 1.0 78.80(±6.61) 65.13(±12.78) 4.62(±3.21) 2.67(±1.52) 9.22(±3.05) 2.0 81.00(±7.62) 64.78(±10.02) 6.34(±3.66) 3.37(±1.70) 10.95(±4.42) 4.0 82.67(±7.28) 73.54(±6.47) 13.19(±4.48) 5.69(±1.98) 21.49(±6.30) 6.0 74.80(±10.46) 63.20(±6.76) 8.35(±2.95) 2.43(±1.27) 13.45(±5.07) (a) β-VAE β beta VAE FVM MIG SAP DCI 1.0 77.20(±8.01) 65.46(±8.79) 4.32(±1.46) 2.41(±1.30) 9.34(±1.23) 2.0 78.20(±9.59) 70.68(±11.16) 11.74(±8.51) 3.84(±2.83) 16.80(±11.20) 4.0 87.40(±4.72) 78.18(±7.31) 19.47(±6.61) 6.32(±1.70) 30.05(±8.57) 6.0 89.20(±4.73) 79.19(±5.87) 23.95(±10.13) 7.20(±0.66) 35.33(±9.07) (b) β-TCVAE C beta VAE FVM MIG SAP DCI 10.0 82.80(± 7.79) 69.64(±7.67) 5.93(±2.78) 3.89(±1.89) 12.42(±4.95) 12.0 75.20(±5.43) 68.00(±8.67) 5.10(±2.24) 2.49(±1.50) 9.82(±3.69) 14.0 73.60(±9.03) 61.58(±7.87) 4.53(±2.60) 2.11(±1.67) 9.30(±1.89) 16.0 76.20(±8.14) 63.28(±7.98) 4.09(±2.00) 2.08(±1.37) 8.91(±1.88) (c) Control-VAE lossrec group beta VAE FVM MIG SAP DCI 0.1 86.80(±3.43) 82.33(±5.59) 23.96(±6.08) 7.07(±0.86) 31.23(±5.32) 0.2 88.20(±4.57) 82.88(±3.55) 20.39(±6.31) 6.82(±1.80) 28.28(±7.09) 0.5 88.20(±5.53) 81.05(±7.51) 20.63(±6.64) 6.49(±1.98) 27.45(±6.07) 0.7 88.00(±4.81) 79.93(±8.16) 18.95(±6.86) 6.94(±1.19) 27.27(±6.76) (d) Commutative Lie Group VAE Table 5: Baselines hyper-parameter tuning results on dSprites dataset with 10 random seeds. β FVM MIG SAP DCI m-fvm2 1.0 88.19(±4.60) 6.82(±2.93) 0.63(±0.33) 20.45(±3.93) 42.36(±7.16) 2.0 88.51(±5.44) 10.00(±3.84) 0.79(±0.38) 28.78(±7.28) 50.98(±8.33) 4.0 90.95(±4.01) 12.76(±1.19) 0.61(±0.36) 30.70(±3.06) 55.76(±9.97) 6.0 91.83(±4.39) 11.44(±1.07) 0.63(±0.24) 27.65(±2.50) 61.28(±9.40) (a) β-VAE β FVM MIG SAP DCI m-fvm2 1.0 89.85(±7.17) 7.27(±3.94) 0.71(±0.40) 21.21(±6.26) 41.99(±3.09) 2.0 91.29(±3.95) 11.62(±3.70) 0.79(±0.27) 30.60(±5.23) 54.87(±3.20) 4.0 92.70(±3.41) 17.31(±2.91) 1.07(±0.36) 33.19(±3.38) 59.12(±2.20) 6.0 92.32(±3.38) 17.20(±3.06) 1.13(±0.36) 33.63(±3.27) 59.25(±5.63) (b) β-TCVAE C FVM MIG SAP DCI m-fvm2 10.0 93.86(±5.12) 9.73(±2.24) 1.14(±0.54) 25.66(±4.61) 46.42(±10.34) 12.0 91.43(±5.32) 8.65(±3.59) 11.28(±0.70) 21.05(±3.93) 46.06(±11.20) 14.0 88.09(±5.46) 6.11(±3.46) 1.05(±0.57) 22.09(±4.34) 45.87(±10.84) 16.0 89.65(±6.87) 8.12(±3.71) 0.71(±0.36) 20.89(±6.30) 45.77(±10.23) (c) Control-VAE lossrec group FVM MIG SAP DCI m-fvm2 0.1 91.64(±3.91) 10.68(±3.18) 1.22(±0.47) 31.24(±5.42) 45.74(±8.68) 0.2 91.18(±3.18) 11.45(±1.12) 1.06(±0.25) 31.09(±4.15) 48.12(±6.04) 0.5 90.19(±3.46) 10.90(±1.53) 1.51(±0.30) 30.68(±3.01) 49.53(±8.44) 0.7 91.61(±2.84) 11.62(±1.65) 1.35(±2.61) 29.55(±1.93) 47.75(±5.83) (d) Commutative Lie Group VAE Table 6: Baselines hyper-parameter tuning results on 3D Cars dataset with 10 random seeds. β beta VAE FVM MIG SAP DCI 1.0 59.40(±7.72) 60.71(±2.47) 21.61(±0.59) 11.02(±0.18) 25.43(±0.48) 2.0 56.80(±7.90) 54.69(±2.96) 19.97(±0.31) 10.45(±0.24) 21.15(±0.47) 4.0 52.40(±7.65) 55.19(±1.73) 19.14(±0.49) 9.67(±0.24) 20.54(±0.41) 6.0 52.67(±7.28) 53.42(±1.54) 18.05(±0.27) 10.10(±0.28) 21.03(±0.27) (a) β-VAE β beta VAE FVM MIG SAP DCI 1.0 60.40(±5.48) 59.30(±2.52) 21.64(±0.51) 11.11(±0.27) 25.74(±0.29) 2.0 56.60(±9.24) 59.48(±2.14) 21.72(±0.44) 11.08(±0.35) 23.74(±0.33) 4.0 58.00(±6.86) 56.40(±1.55) 21.50(±0.62) 10.98(±0.35) 22.29(±0.73) 6.0 56.00(±8.17) 55.46(±1.42) 21.49(±0.52) 10.50(±0.25) 20.24(±0.51) (b) β-TCVAE C beta VAE FVM MIG SAP DCI 10.0 59.80(±5.77) 60.34(±2.58) 21.53(±0.33) 10.91(±0.37) 25.55(±0.49) 12.0 60.20(±10.60) 61.00(±1.86) 21.39(±0.41) 11.25(±0.32) 25.71(±0.37) 14.0 61.40(±4.33) 60.63(±2.67) 21.55(±0.53) 11.18(±0.48) 25.97(±0.43) 16.0 60.20(±7.69) 60.50(±2.89) 21.72(±0.31) 11.30(±0.41) 25.60(±0.33) (c) Control-VAE lossrec group beta VAE FVM MIG SAP DCI 0.1 59.20(±5.75) 59.54(±1.64) 20.61(±0.41) 10.93(±0.36) 23.77(±0.60) 0.2 63.40(±9.14) 59.74(±1.60) 20.87(±0.36) 10.80(±0.47) 23.59(±0.63) 0.5 64.20(±8.24) 61.28(±1.68) 21.20(±0.53) 10.58(±0.36) 22.88(±0.52) 0.7 62.60(±5.17) 62.26(±1.71) 21.39(±0.67) 10.71(±0.33) 22.95(±0.62) (d) Commutative Lie Group VAE Table 7: Baselines hyper-parameter tuning results on smallNORB dataset with 10 random seeds. D Additional Experiment D.1 Disentanglement Performance Statistically Significant Improvements As shown in Fig- ure 6, our model significantly improves disentanglement learn- ing. 3D Shapes As shown in Table 9, CFASL also shows an advantage on multi-factor change. D.2 Ablation Studies How Commutative Lie Group Improves Disetanglement Learning? The Lie group is not commutative, however most factors of the used datasets are commutative. For example, 3D Shapes dataset factors consist of the azimuth (x-axis), yaw (z-axis), coloring, scale, and shape. Their 3D rotations are all commutative. Also, other composite symmetries as coloring and scale are commutative. Even though we restrict the Lie group to be commutative, our model shows better results than baselines as shown in Table 1. Impact of Hyper-Parameter tuning We operate a grid search of the hyper-parameter ϵ. As shown in Figure 7a, the Kullback-Leibler divergence convergences to the high- est value, when ϵ is large (ϵ = 1.0) and it shows less stable results. It implies that the CFASL with larger ϵ struggles with disentanglement learning, and is shown in Tabel 10a. Also, the Lee in Figure 7b is larger than other cases, which implies that the model struggles with extracting adequate composite sym- metry because its encoder is far from the equivariant model and it is also shown in Table 10a. Even though ϵ = 0.01 case shows the lowest value in the most loss, Lde in Figure 7e is higher than others and it also implies the model struggles with learning symmetries, as shown in Table 10a because the model does not close to the equivariant model compare to ϵ = 0.1 case. Impact of Factor-Aligned Symmetry Size We set the code- book size as 100, and 10 to validate the robustness of our method. In Table 10b, the larger size shows better results than the smaller one, and is more stable by showing a low standard deviation. 3D Cars Lc without Lc x4.63 x1.00 Table 11: Complexity. Impact of Commutative Loss on Computational Complexity As shown in Table 11, our methods reduce the composite symmetries computation. Matrix expo- nential is based on the Taylor series and it needs high compu- tation cost though its approximation is lighter than the Taylor series. We need one matrix exponential computation for com- posite symmetries with commutative loss, in contrast, the other case needs the number of symmetry codebook elements |S| · |SS| for the matrix exponential and also |S| · |SS| − 1 time matrix multiplication. Comparison of Plug-in Methods To compare plug-in meth- ods, we evaluate common disentanglement metrics on G- VAE [Shakerinava et al., 2022] and apply both methods to β-TCVAE. As shown in Table 12, our method shows statis- tically significant improvements in disentanglement learning although β hyper-parameter of CFASL is smaller than G-VAE. As shown in Table 8, we estimate the p-value over common disentanglement metrics on each dataset. Most values show that improvements in disentanglement learning are statistically significant. p-value FVM MIG SAP DCI dSprites 0.011 0.005 0.016 0.001 3D Cars 0.006 0.000 0.97 0.003 smallNORB 0.000 0.002 0.000 1.000 Table 8: p-value estimation on each datasets. 3D Shapes β-VAE β-TCVAE Factor-VAE Control-VAE CLG-VAE OURS m-FVM5 80.26(±3.78) 79.21(±5.87) 76.69(±5.08) 73.31(±6.54) 73.61(±4.22) 83.03(±2.73) Table 9: m-FVMs results. Figure 6: Disentanglement Scores with box plots. ϵ FVM beta VAE MIG SAP DCI 0.01 76.98(±8.63) 87.33(±7.87) 29.68(±11.38) 6.96(±1.16) 41.28(±11.93) 0.1 82.21(±1.34) 90.33(±5.85) 34.79(±3.26) 7.45(±0.61) 48.07(±5.62) 1.0 76.77(±7.05) 78.33(±13.88) 22.42(±11.14) 6.02(±0.48) 38.87(±7.83) (a) Hyper-parameter tuning with 6 random seeds. 3D Cars |G|=100 |G|=10 FVM 95.70(±1.90) 48.63(±24.55) MIG 18.58(±1.24) 2.99(±6.04) SAP 1.43(±0.18) 0.29(±0.34) DCI 34.81(±3.85) 6.12(±10.44) FVM2 62.43(±8.08) 37.94(±10.01) (b) Codebook size impact Table 10: Table Datasets FVM MIG SAP DCI G-VAE CFASL G-VAE CFASL G-VAE CFASL G-VAE CFASL dSprites 69.75(±13.66) 82.30(±5.64) 21.09(±9.20) 33.62(±8.18) 5.45(±2.25) 7.28(±0.63) 31.08(±10.87) 46.52(±6.18) 3D Car 92.34(±2.96) 95.70(±1.90) 11.95(±2.16) 18.58(±1.24) 2.10(±0.96) 1.43(±0.18) 26.91(±6.24) 34.81(±3.85) smallNROB 46.64(±1.45) 61.15(±4.23) 20.66(±1.22) 22.23(±0.48) 10.37(±0.51) 11.12(±0.48) 27.77(±0.68) 24.59(±0.51) Table 12: Comparison of disentanglement scores of plug-in methods in single factor change. (a) kld (hyper) (b) encoder (hyper) (c) kld (w/o) (d) encoder (w/o) (e) decoder (hyper) (f) perpendicular (hyper) (g) decoder (w/o) (h) perpendicular (w/o) (i) parallel (hyper) (j) sparsity (hyper) (k) parallel (w/o) (l) sparsity (w/o) Figure 7: Loss curves: 1) HT: hyper-parameter tuning (ϵ ∈ {0.01, 0.1, 1.0}) with β-TCVAE based CFASL. 2) AB: ablation study with β-VAE based CFASL. D.3 Additional Qualitative Analysis (Baseline vs. CFASL) Fig. 8-9 show the qualitative results on 3D Cars introduced in Fig. 5. Fig. 10-11, and Fig. 14 show the dSprites and small- NORB dataset results respectively. Additionally, we describe Fig. 12-13results over 3D Shapes datasets respectively. We randomly sample the images in all cases. 3D Cars As shown in Figure 8c, CFASL shows better re- sults than the baseline. In the 1st and 2nd rows, the baseline changes shape and color factor when a single dimension value is changed, but ours clearly disentangle the representations. Also in the 3rd row, the baseline struggles with separating color and azimuth but CFASL successfully separates the color and azimuth factors. • 1st row: our model disentangles the shape and color factors when the 2nd dimension value is changed. • 2nd row: ours disentangles shape and color factors when the 1st dimension value is changed. • 4th row: ours disentangles the color, and azimuth factors when the 2nd dimension value is changed. dSprites As shown in Figure 10c, the CFASL shows better results than the baseline. The CFASL significantly improves the disentanglement learning as shown in the 4th and 5th rows. The baseline shows the multi-factor changes during a single dimension value is changed, while ours disentangles all factors. • 1st row: ours disentangles the x- and y-pos factor when the 2nd dimension value is changed. • 2nd row: ours disentangles the rotation and scale factor when the 2nd dimension value is changed. • 3rd row: ours disentangles the x- and y-pos, and rota- tion factor when the 1st and 2nd dimension values are changed. • 4th row: ours disentangles the all factors when the 1st and 2nd dimension values are changed. 3D Shapes As shown in Figure 12c, the CFASL shows bet- ter results than the baseline. In the 1st, 3rd, and 5th rows, our model clearly disentangles the factors while the baseline struggles with disentangling multi-factors. Even though our model does not clearly disentangle the factors, compared to the baseline, which is too poor for disentanglement learning, ours improves the performance. • 1st row: our model disentangles the object color and floor color factor when the 2nd and 3rd dimension values are changed. • 2nd row: ours disentangles shape factor in 1st dimen- sion, and object color and floor color factors at the 4th dimension value are changed. • 3rd row: ours disentangles the object color and floor color factor when the 3rd dimension value is changed. • 4th row: ours disentangles the scale, object color, wall color, and floor color factor when the 2nd and 3rd dimen- sion values are changed. • 5th row: ours disentangles the shape, object color, and floor color factor when the 1st and 2nd dimension values are changed. smallNORB Even though our model does not clearly disen- tangle the multi-factor changes, ours shows better results than the baseline as shown in Figure 14c. • 1st row: our model disentangles the category and light factor when the 2nd dimension value is changed. • 3rd row: ours disentangles category factor and azimuth factors when the 5th dimension value is changed. (a) Generated images by composite symmetry on 3D Cars dataset. The images in the red box are inputs. The images in the blue box at odd column are same as 3⃝ and even column are same as 5⃝ in Fig. 5a. (b) Generated images by its factor-aligned symmetries on 3D Cars datset. The images are same as 4⃝ in Fig 5a. (c) Generated images by dimension change on 3D Cars dataset. Figure 8: Generalization over unseen pairs of images on 3D Cars dataset. Figure 9: Fig. 8a shows the generation quality of composite symmetries results, Fig. 8b shows the disentanglement of symmetries by factors results, and Fig. 8c shows the disentanglement of latent dimensions by factors results. (a) Generated images by composite symmetry on dSprites dataset. The images in the red box are inputs. The images in the blue box at odd column are same as 3⃝ and even column are same as 5⃝ in Fig. 5a. (b) Generated images by its factor-aligned symmetries on dSprites datset. The images are same as 4⃝ in Fig 5a. (c) Generated images by dimension change on dSprites dataset. Figure 10: Generalization over unseen pairs of images on dSprites dataset. Figure 11: Fig. 10a shows the generation quality of composite symmetries results, Fig. 10b shows the disentanglement of symmetries by factors results, and Fig. 10c shows the disentanglement of latent dimensions by factors results. (a) Generated images by composite symmetry on 3DShapes dataset. The images in the red box are inputs. The images in the blue box at odd column are same as 3⃝ and even column are same as 5⃝ in Fig. 5a. (b) Generated images by its factor-aligned symmetries on 3DShapes datset. The images are same as 4⃝ in Fig 5a (c) Generated images by dimension change on 3DShapes dataset. Figure 12: Generalization over unseen pairs of images on 3DShapes dataset. Figure 13: Fig. 12a shows the generation quality of composite symmetries results, Fig. 12b shows the disentanglement of symmetries by factors results, and Fig. 12c shows the disentanglement of latent dimensions by factors results. (a) Generated images by composite symmetry on smallNORB dataset. The images in the red box are inputs. The images in the blue box at odd column are same as 3⃝ and even column are same as 5⃝ in Fig. 5a. (b) Generated images by its factor-aligned symmetries on smallNORB datset. The images are same as 4⃝ in Fig 5a (c) Generated images by dimension change on smallNORB dataset. Figure 14: Fig. 14a shows the generation quality of composite symmetries results, Fig. 14b shows the disentanglement of symmetries by factors results, and Fig. 14c shows the disentanglement of latent dimensions by factors results. "
}