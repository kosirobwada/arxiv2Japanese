{
    "optim": "WildGEN: Long-horizon Trajectory Generation for Wildlife\nAli Al-Lawati\naha112@psu.edu\nPenn State\nState College, Pennsylvania, USA\nElsayed Eshra\neme5375@psu.edu\nPenn State\nState College, Pennsylvania, USA\nPrasenjit Mitra\npum10@psu.edu\nPenn State\nState College, Pennsylvania, USA\nABSTRACT\nTrajectory generation is an important concern in pedestrian, ve-\nhicle, and wildlife movement studies. Generated trajectories help\nenrich the training corpus in relation to deep learning applications,\nand may be used to facilitate simulation tasks. This is especially\nsignificant in the wildlife domain, where the cost of obtaining addi-\ntional real data can be prohibitively expensive, time-consuming, and\nbear ethical considerations. In this paper, we introduce WildGEN: a\nconceptual framework that addresses this challenge by employing a\nVariational Auto-encoders (VAEs) based method for the acquisition\nof movement characteristics exhibited by wild geese over a long\nhorizon using a sparse set of truth samples. A subsequent post-\nprocessing step of the generated trajectories is performed based on\nsmoothing filters to reduce excessive wandering. Our evaluation is\nconducted through visual inspection and the computation of the\nHausdorff distance between the generated and real trajectories. In\naddition, we utilize the Pearson Correlation Coefficient as a way to\nmeasure how realistic the trajectories are based on the similarity of\nclusters evaluated on the generated and real trajectories.\nKEYWORDS\nTrajectory Generation, Wildlife Trajectory, Trajectory Framework\nACM Reference Format:\nAli Al-Lawati, Elsayed Eshra, and Prasenjit Mitra. 2023. WildGEN: Long-\nhorizon Trajectory Generation for Wildlife. In Proceedings of InfoWild (In-\nfoWildâ€™23). ACM, New York, NY, USA, 9 pages. https://doi.org/XXXXXXX.\nXXXXXXX\n1\nINTRODUCTION\nAnimals in the wild move for a variety of reasons, including for-\naging, exploration, or migration [19]. A better understanding of\nthe drivers of wildlife movement can have tremendous benefits in\nenvironmental planning, preservation efforts, and anti-poaching.\nIt contributes to mitigating conflict between wildlife and human\nsettlements [11].\nScientists in wildlife studies use datasets of animal trajectories\ncollected, typically, using telemetry devices, such as GPS collars,\nto capture the animalsâ€™ exact location over time. However, the\nlimitations of using these devices arise from the complications\nand dangers associated with attaching the devices to the animals,\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nInfoWildâ€™23, Oct 2023, Birmingham, UK\nÂ© 2023 Association for Computing Machinery.\nACM ISBN 978-1-4503-XXXX-X/18/06...$15.00\nhttps://doi.org/XXXXXXX.XXXXXXX\nFigure 1: Real (green) vs Generated (blue) Trajectories\nincluding constraints on device size and weight depending on the\nanimal, potential failures, and battery life.\nAs a result, considerable work in movement ecology attempts to\ngenerate wildlife trajectories based on concepts such as Correlated\nRandom Walk (CRW) [13] and Brownian Motion [5]. However,\nsome of these methods are limited in their effectiveness to land-\nbased animals. Furthermore, in their basic form, these methods can\nonly model the wandering effect of animals within a foraging area\n[2]. Methods such as Brownian Bridges [18] extend these movement\nmodels using a beginning and endpoint, and interpolate the in-\nbetween points based on the maximum speed and time budget of\nthe animal over the expected duration of the trajectory. However,\nthese methods fail to take existing measured trajectories as input in\nthe process of trajectory generation. Instead, they rely on random\nvariables to induce movement, and thereby achieve limited success.\nOn the other hand, pedestrian and vehicle trajectory generation\nproblems are constrained by the road and pedestrian networks\nwhich are not applicable in the wildlife domain. Likewise, trajectory\ngeneration in the UAV literature is irrelevant as it is more concerned\nwith optimization, and minimizing flying time through the target\nwaypoints [17].\nIn this paper, we present a novel framework we call WildGEN\nthat attempts to generate trajectories by learning the statistical\nproperties of a sparse set of known trajectories. The framework,\nWildGEN, is based on proven deep learning-based Variational Auto-\nencoders (VAEs) which have successfully been applied to similar\nproblems [4]. WildGEN applies a post-processing filter on each\ntrajectory path using a Minimum Bounding Region (MBR) based\nconstraint. Furthermore, in order to reduce the excessive wandering\neffect, a smoothing filter is applied.\nIn the next section, we discuss some related work, followed by a\nbrief motivation of the methods we used to develop our Framework.\nSection 4 presents the experimental settings, experimental results,\nand an ablation study that demonstrates the contribution of each\narXiv:2401.05421v1  [cs.LG]  30 Dec 2023\nInfoWildâ€™23, Oct 2023, Birmingham, UK\ncomponent to the overall results. We conclude and discuss future\nwork in Section 5.\nThe contributions of this work can be summarized as follows:\nâ€¢ We propose a framework that generates realistic long-horizon\nwildlife trajectories based on a sparse set of real trajectories.\nâ€¢ We experimentally test our framework and we validate the\nempirical results using Hausdorff distance and the Pearson\nCorrelation Coefficient metrics to measure path and cluster\nsimilarities, respectively between the real and generated\ntrajectory sets.\nâ€¢ We benchmark our method against Levy Walk/Flight [22],\nwhich is state-of-the-art in long-horizon trajectory genera-\ntion in the wildlife domain. We also evaluate our methods\nover kriging [6], using a Heteroscedastic Gaussian Process\nRegression (GPR) of multiple trajectories on the same time\nhorizon.\nFigure 1 visually demonstrates the potential of this approach. We\nfurther evaluate our approach using well-established trajectory\nsimilarity measures.\n1.1\nProblem Statement\nGiven a set of ğ‘› real trajectories, each consisting of ğ‘š (ğ‘¥,ğ‘¦) points,\nthe objective is to produce a set of synthetic trajectories that maxi-\nmize the following:\n(1) (Path Similarity) How similar are the points of the synthetic\ntrajectories to the real trajectories?\n(2) (Cluster Similarity) How well do the synthetic trajectories\nalign with the real trajectories in terms of areas of concen-\ntration?\nFormally, given ğ‘› real trajectories, denoted as\nğ‘‡1,ğ‘‡2, . . . ,ğ‘‡ğ‘›\nwhere each ğ‘‡ğ‘– consists of ğ‘š points:\nğ‘‡ğ‘– = (ğ‘ğ‘–\n1, ğ‘ğ‘–\n2, . . . , ğ‘ğ‘–\nğ‘š)}\nfor 1 â‰¤ ğ‘– â‰¤ ğ‘›, and ğ‘ğ‘–\nğ‘— (ğ‘— âˆˆ {1, 2, . . . ,ğ‘š}) is a spatio-temporal point\nconsisting of latitude and longitude values. Find a set of:\nğ‘†1,ğ‘†2, . . . ,ğ‘†ğ‘›\nsuch that we maximize the similarity between the two sets:\nmax Similarity(ğ‘‡,ğ‘†)\nwhere ğ‘‡ = {ğ‘‡1,ğ‘‡2, . . . ,ğ‘‡ğ‘›},ğ‘† = {ğ‘†1,ğ‘†2, . . . ,ğ‘†ğ‘›}, and similarity en-\ncompasses Path and Cluster similarity. For the sake of simplicity, we\nassume the number of synthetic trajectories is equal to the number\nof real trajectories. We discuss the metrics used in Section 3.5.\n2\nRELATED WORKS\nTrajectory generation in the wildlife domain is dominated by mod-\nels based on Correlated Random Walk (CRW) [3], Brownian motion\n[5], and Levy Walk/Flight [21]. These methods are based on random\nsteps and turning angles that follow a pre-defined distribution of\nstep length. Trajr is a popular wildlife trajectory R library that pro-\nvides tools to generate trajectories using each of the aforementioned\nmodels [12].\nFigure 2: The proposed WildGEN Framework\nIn [18], the authors proposed a CRW trajectory generation method\nbased on the maximum speed and expected direction of movement.\nHowever, the approach requires known starting and endpoints\nand is based on random distributions of velocity and movement\nangle. Nonetheless, such methods are more effective for simpler\nconcerns such as missing data imputation, i.e. the estimation of\nmissing points between two known points. They are more useful in\ncapturing the micro movement of animals within their home range\n[14].\nOn the other hand, the generation of trajectory in the pedes-\ntrian literature is constrained by road, other agents, and physical\nconstraints. In [4], an additional embedding layer is introduced to\nthe VAE Encoder to account for the road network. This ensures\nthe road features are embedded in the learning and understood by\nthe generated trajectories. This has limited applicability in wildlife\nmovement where constraints are terrain-based. On the other hand,\na minimum bounding region (MBR) is capable of establishing con-\nstraints on the spatial areas that a trajectory may be allowed to\nnavigate.\nGenerative Adversarial Networks (GANs) are another class of\ngenerative algorithms that have been utilized for the trajectory\ngeneration problem [20]. However, GANs are well known for their\npoor convergence properties [23]. In addition, GANs generally\nrequire a large sample of training data and are thus ineffective for\na sparse sample set [4].\n3\nMETHODOLOGY\nFigure 2 depicts the architecture of the proposed WildGEN to gen-\nerate and post-process a set of real trajectories. The framework is\ncomposed of four main components:\nWildGEN: Long-horizon Trajectory Generation for Wildlife\nInfoWildâ€™23, Oct 2023, Birmingham, UK\nâ€¢ A Variational Auto Encoder (VAE): takes a data set consisting\nof a training set of n-day long trajectories, each of which\nrepresents a single latitude/longitude pair per day for each\nsubject.\nâ€¢ A Gaussian Mixture Model (GMM): learns the probability\ndistribution of the training set in the latent space.\nâ€¢ A trajectory smoothing filter: utilizes Savitzky-Golay smooth-\ning to reduce the excessive wandering effect observed on\nthe generated trajectories.\nâ€¢ A Minimum Bounding Region (MBR): analyzes the gener-\nated trajectories violation of the constraints on acceptable\nmovement region, and excludes outliers.\nThe framework consists of a training phase where the embed-\ndings of each trajectory are learned in the latent space. This allows\nthe GMM to learn the distribution of the training set in the latent\nspace, and hence generate new trajectories based on the distribu-\ntion. The trajectories are decoded using the learned weights from\nthe decoding space. A smoothing post-processing step is utilized\non each synthetic trajectory, followed by an MBR step that accepts\nor rejects it.\n3.1\nVariational Autoencoders\nVariational Autoencoders (VAEs) [7] are a class of generative mod-\nels that have gained significant traction in the field of trajectory\ngeneration due to their ability to capture complex data distributions\nand generate new samples. VAEs consist of two primary compo-\nnents: the Encoder and the Decoder.\n3.1.1\nEncoder. The Encoder, denoted as ğ‘(ğ‘§|ğ‘‡), takes an input\ntrajectory ğ‘‡ and maps it to a latent space representation ğ‘§. The\nEncoder learns to capture the essential features and patterns present\nin the trajectory data. It compresses the high-dimensional trajectory\nspace into a lower-dimensional latent space, effectively creating a\ndata-driven embedding of the input trajectory.\n3.1.2\nDecoder. The Decoder, denoted as ğ‘(ğ‘‡ |ğ‘§), takes a point ğ‘§\nfrom the latent space and generates a trajectory ğ‘‡ in the original\ndata space. The Decoderâ€™s role is to reconstruct trajectories from\nthe latent space representations, effectively learning the weights\nthat convert latent data back to the original data space.\n3.2\nSavitzky-Golay Smoothing\nTrajectory data, often obtained from GPS or motion tracking sys-\ntems, can be inherently noisy due to measurement errors and en-\nvironmental factors. Savitzky-Golay smoothing is a valuable tool\nfor enhancing trajectory data quality while preserving essential\ntrajectory characteristics [16].\nBy applying Savitzky-Golay smoothing to trajectory data, one\ncan effectively reduce the noise present in position (ğ‘¥ğ‘–) or velocity\n(ğ‘£ğ‘–) measurements. This noise reduction is achieved through a con-\nvolution operation using a set of smoothing coefficients (ğ‘ğ‘—) within\na local window:\nğ‘¦ğ‘– =\nğ‘›\nâˆ‘ï¸\nğ‘—=âˆ’ğ‘›\nğ‘ğ‘—ğ‘¥ğ‘–+ğ‘—\nwhere ğ‘¦ğ‘– represents the smoothed trajectory data at point ğ‘–, ğ‘¥ğ‘–+ğ‘—\nare the neighboring data points within a window of size 2ğ‘› + 1, and\nğ‘ğ‘— are the coefficients of the polynomial of order ğ‘š that minimize\nthe mean squared error between the smoothed data and the noisy\ntrajectory data.\nThe choice of polynomial order (ğ‘š) and the window size (2ğ‘› + 1)\nin the context of trajectory data should be carefully considered.\nToo aggressive smoothing (high ğ‘š) may lead to the loss of impor-\ntant trajectory details, while too little smoothing (low ğ‘š) may not\nadequately mitigate noise. Savitzky-Golay smoothing, when appro-\npriately tuned, is a valuable mathematical tool for improving the\ninterpretability and reliability of trajectory data.\n3.3\nMinimum Bounding Region\nMinimum Bounding Rectangles are the smallest axis-aligned rectan-\ngles (in two dimensions) or hyperrectangles (in higher dimensions)\nthat enclose a set of trajectory points. In this paper, we generalize\nthem using a convex hull and refer to them as Minimum Bounding\nRegions (MBR). By encapsulating trajectories within MBRs, we es-\ntablish constraints on movement, such as maximum and minimum\nbounds in both spatial dimensions.\nThe advantages of using MBRs lie in their simplicity and ef-\nficiency. They provide a compact representation of the potential\nspatial footprint of trajectory data, making it easier to detect out-\nliers or unusual behavior. Moreover, MBRs facilitate quick assess-\nments of whether trajectories remain within predefined geographi-\ncal bounds, aiding in the enforcement of constraints in the environ-\nment, whether it is regional bounds, rivers, mountain ranges, and\nother physical constraints.\n3.4\nBaselines\nIn order to assess the performance of our framework we compare\nthe results obtained to existing methods for animal trajectory gen-\neration. As discussed earlier, CRW-based and Brownian motion\nmethods fail at generating long-horizon trajectories for tasks such\nas migration. Similarly, deep learning methods require large train-\ning samples.\nAs such we utilize two baselines that appear to be plausible for\nthe task of long-horizon trajectory generation, namely:\nâ€¢ Levy Walk/Flight\nâ€¢ Heteroscedastic Multi-variate Gaussian Process Regression\n(Heteroscedastic GPR)\nNext, we discuss the details of each of these methods, accordingly.\n3.4.1\nLevy Walk/Flight. is a stochastic process that models move-\nment using a Cauchy distribution to generate trajectory points,\nwhich are determined by a combination of step length, variance,\nand angular standard deviation. These parameters are derived from\nempirical data or real-world samples and are crucial inputs for the\nLevy trajectory generation process.\nThe algorithm combines these parameter values of step length,\nvariance, and angular standard deviation with actual data points to\nproduce the Levy trajectory, which is a dynamic and realistic path\nthat captures the distinctive properties of the moving animal.\n3.4.2\nHeteroscedastic GPR. Heteroscedastic GPR [10] is an exten-\nsion of traditional Gaussian Process Regression (GPR) that explicitly\nmodels and accounts for varying levels of noise in the data. GPR is a\npowerful and versatile non-parametric method commonly used for\nInfoWildâ€™23, Oct 2023, Birmingham, UK\nReal (green) vs Generated (blue)\nReal (green) vs Generated (blue)\nReal (green) vs Generated (blue)\nFigure 3: Three different sets of Generated Trajectories mapped against a background of Real Trajectories\nmodeling complex relationships in data. Traditionally, GPR assumes\nthat the noise in the observed data is homoscedastic, meaning that\nthe variance of the noise is constant across all data points. How-\never, real-world data often exhibits heteroscedasticity, where the\nvariance of the noise varies across the input space or with respect\nto the magnitude of the predictions. In such cases, traditional GPR\nmay provide suboptimal results, leading to biased predictions and\ninaccurate uncertainty estimates.\nHeteroscedastic GPR addresses the issue of varying noise levels\nby modeling the noise variance as a function of input variables. This\nis achieved through the introduction of a separate Gaussian process,\noften referred to as the noise process or the noise model. The noise\nprocess provides an estimate of the noise variance associated with\neach data point, which is then used to adjust the likelihood function\nin the GPR model.\nGiven a dataset of ğ‘ observations {(ğ‘¥ğ‘–,ğ‘¦ğ‘–)}ğ‘\nğ‘–=1, where ğ‘¥ğ‘– rep-\nresents the input variable and ğ‘¦ğ‘– represents the observed output\nvariable. The observed data ğ‘¦ğ‘– is affected by heteroscedastic noise,\nmeaning that the variance of the noise ğœ–ğ‘– depends on the input\nvariable ğ‘¥ğ‘–.\nThe model can be characterized by:\nâ€¢ Latent Function: The underlying latent function ğ‘“ (ğ‘¥) is\nmodeled as a Gaussian process with a mean function ğœ‡(ğ‘¥)\nand a covariance (kernel) function ğ‘˜(ğ‘¥,ğ‘¥â€²), as in traditional\nGPR.\nâ€¢ Noise Model: A separate Gaussian process is introduced to\nmodel the noise variance as a function of the input variables.\nThis is represented as ğ‘”(ğ‘¥), where ğ‘”(ğ‘¥ğ‘–) models the noise\nvariance for each data point ğ‘¥ğ‘–.\nThe likelihood function in Heteroscedastic GPR is modified to\naccount for the varying noise levels:\nğ‘(ğ‘¦ğ‘– |ğ‘“ (ğ‘¥ğ‘–),ğ‘”(ğ‘¥ğ‘–)) =\n1\nâˆšï¸\n2ğœ‹ğ‘”(ğ‘¥ğ‘–)\nexp\n\u0012\nâˆ’ (ğ‘¦ğ‘– âˆ’ ğ‘“ (ğ‘¥ğ‘–))2\n2ğ‘”(ğ‘¥ğ‘–)\n\u0013\nHere:\nâ€¢ ğ‘(ğ‘¦ğ‘– |ğ‘“ (ğ‘¥ğ‘–),ğ‘”(ğ‘¥ğ‘–)) is the likelihood of observing ğ‘¦ğ‘– given the\nlatent function ğ‘“ (ğ‘¥ğ‘–) and the noise variance ğ‘”(ğ‘¥ğ‘–).\nâ€¢ ğ‘”(ğ‘¥ğ‘–) represents the estimated noise variance for data point\nğ‘¥ğ‘–.\nâ€¢ ğ‘“ (ğ‘¥ğ‘–) is the value of the latent function at ğ‘¥ğ‘–.\nâ€¢ ğ‘¦ğ‘– is the observed data point at ğ‘¥ğ‘–.\nThe need for Heteroscedastic GPR arises from the requirement\nto model multiple data points for a given input, where the input\n(ğ‘¥ğ‘–) is the day number in the trajectory, and the output (ğ‘¦ğ‘–) is the\nset of all real points from that day.\n3.5\nEvaluation Metrics\nWe base our selection of evaluation based on the objectives of\ntrajectory generation, which we reiterate here for convenience:\n(1) (Path Similarity) How similar are the points of the synthetic\ntrajectories to the real trajectories?\n(2) (Cluster Similarity) How well do the synthetic trajectories\nalign with the real trajectories in terms of areas of concen-\ntration?\nIn order to measure the first point, we use Hausdorff Distance\nsimilar to [4], and we utilize the Pearson Correlation Coefficient\nto measure the similarity of the cluster sets for the second metric.\nNext, we describe both of them in further detail.\n3.5.1\nHausdorff Distance. Hausdorff Distance is a valuable met-\nric for assessing the similarity or dissimilarity between movement\npaths. Trajectory data can be compared using the Hausdorff dis-\ntance to understand how closely two trajectories align or diverge.\nThe Hausdorff distance thus provides a way to measure the dis-\nsimilarity between two trajectories by considering the maximum\nminimum distance between points of one trajectory to the other\ntrajectory.\nThe mathematical formulation of the Hausdorff distance (Haus-\ndorff metric) between two sets of points, A and B, in a metric space\ncan be expressed as follows:\nGiven two sets, A and B, each containing a number of points\nthe Hausdorff distance from set A to set B, denoted as H(A, B), is\ndefined as:\nHausdorff distance from set ğ´ to set ğµ:\nğ» (ğ´, ğµ) = max\nğ‘âˆˆğ´\n\u0012\nmin\nğ‘âˆˆğµ ğ‘‘(ğ‘,ğ‘)\n\u0013\nHausdorff distance from set ğµ to set ğ´:\nğ» (ğµ,ğ´) = max\nğ‘âˆˆğµ\n\u0012\nmin\nğ‘âˆˆğ´ ğ‘‘(ğ‘,ğ‘)\n\u0013\nwhere d(a,b) is the distance function that computes the distance\nbetween two points.\n3.5.2\nCoefficient of Correlation. Pearsonâ€™s coefficient of correla-\ntion [1], denoted as \"r\" is a fundamental statistical measure used to\nWildGEN: Long-horizon Trajectory Generation for Wildlife\nInfoWildâ€™23, Oct 2023, Birmingham, UK\nquantify the strength and direction of linear relationships between\ntwo distributions. It is a widely used statistical measure that quan-\ntifies the strength and direction of a linear relationship between\ntwo distributions. Here are the key characteristics and aspects of\nPearsonâ€™s correlation coefficient:\nâ€¢ An â€œğ‘Ÿâ€ value of -1 indicates a perfect negative linear relation-\nship, where one variable decreases as the other increases in\na perfectly linear fashion.\nâ€¢ An â€œğ‘Ÿâ€ value of 1 signifies a perfect positive linear relation-\nship, where both variables increase together linearly.\nâ€¢ An â€œğ‘Ÿâ€ value of 0 implies no linear relationship, indicating\nthat the variables are independent of each other.\nThe calculation of Pearsonâ€™s correlation coefficient is based on\nthe formula:\nğ‘Ÿ =\nÃ (ğ‘‹ğ‘– âˆ’ Â¯ğ‘‹)(ğ‘Œğ‘– âˆ’ Â¯ğ‘Œ)\nâˆšï¸Ã (ğ‘‹ğ‘– âˆ’ Â¯ğ‘‹)2 Ã (ğ‘Œğ‘– âˆ’ Â¯ğ‘Œ)2\nHere, ğ‘‹ğ‘– and ğ‘Œğ‘– represent individual data points from the two\nvariables, and Â¯ğ‘‹ and Â¯ğ‘Œ are their respective means.\n4\nEXPERIMENTS\n4.1\nDatasets\nThe dataset used for our validation is The Western Palearctic greater\nwhite-fronted geese dataset [9]. The dataset is hosted and was ob-\ntained from Movebank1. The dataset contains reading of 91 different\nbirds over a period of several months to multiple years. We prepro-\ncessed the dataset using Moveapps [8] to limit the observations to\none observation per day. Next, the time frames were clipped to a\nwindow between March 1 to September 1 (185 days) to capture the\nnorthward migration. Any subjects that had significant readings\nmissing during this time frame were dropped. Subjects that were\ntracked over multiple years were split into multiple samples. Simple\ndata interpolation was utilized to fill in any remaining isolated gaps\nin the trajectories. The resultant dataset consists of 60 trajectories\nover a period of 185 days.\n4.2\nExperimental Settings\nHere we discuss the implementation details of the WildGEN frame-\nwork as well as the two baselines we compare it against.\n4.2.1\nLevy Walk/Flight Implementation Details. A simple way of\nimplementing Levy Walk/Flight involves analyzing the step lengths\nof the trajectory and learning the coefficient of Cauchy distribution\n(ğ›¼) from that data. However, the ğ›¼ value computed for the dataset\nwas less than 1, which suggests that your step lengths have a very\nheavy-tailed distribution with an increased likelihood of extremely\nlong steps as depicted by Figure 5. Nonetheless, for the purposes of\nthis work, we used the Trajr R library [12], fed with the following\ninput variables:\nâ€¢ Step Length\nâ€¢ Angular Error\nâ€¢ Linear Error\nThese variables were measured based on the training dataset.\n1https://www.movebank.org\nFigure 4: Real (green) vs Generated (red) Trajectories using\nLevy Walk/Flight\nFigure 5: A Histogram of the step length distribution. Note\nthat both axis have a power multiple\nAs per the documentation of Trajr [12], the generated trajectory\nis computed with direction = 0. In order to guide the movement\nin the correct northeast direction, the azimuth angle between the\naverage starting point and the average ending point was computed.\nThe generated trajectories were rotated counterclockwise with the\ncomputed angle.\nSimilar to WildGEN, the post-processing steps including Smooth-\ning and MBR inclusiveness check were applied to the generated\ntrajectories, and trajectories that violated the MBR were discarded.\nFigure 4 demonstrates the generated trajectories from Levy\nWalk/Flight.\n4.2.2\nHeteroscedastic GPR Implementation Details. The Python\nGPy2 library was used to model Heteroscedastic GPR using the\nğºğ‘ƒğ»ğ‘’ğ‘¡ğ‘’ğ‘Ÿğ‘œğ‘ ğ‘ğ‘’ğ‘‘ğ‘ğ‘ ğ‘¡ğ‘–ğ‘ğ‘…ğ‘’ğ‘”ğ‘Ÿğ‘’ğ‘ ğ‘ ğ‘–ğ‘œğ‘› class with a trained MLP and Bias\nkernels optimized on the training data. The GPR utilized a random\nset of 50% of the training data. This reduced the computational\nrequirements needed to train the Heteroscedastic GPR.\n2https://github.com/SheffieldML/GPy\nInfoWildâ€™23, Oct 2023, Birmingham, UK\nFigure 6: Real (green) vs Generated (red) Trajectories using\nHeteroscedastic GPR\nFigure 7: Training MSE\nIn addition, the variances were computed using the norm of the\nğ‘™ğ‘›ğ‘” and ğ‘™ğ‘ğ‘¡ at each point. This helped limit overfitting of the model.\nIt is noteworthy that we also attempted to use the mean tra-\njectory to model the GPR and train a Matern kernel based on the\nmean squared error against each training data sample. This ap-\nproach was overfitting, and the samples generated were almost\nindistinguishable.\nFigure 6 depicts trajectories generated by Heteroscedastic GPR\ncompared to real trajectories. It can be observed that the clusters\nformed do not visually appear to align with the clusters of the real\ntrajectories.\n4.2.3\nWildGEN Implementation Details. In the context of this study,\nthe input structure comprises a dataset consisting of 60 records,\neach encompassing longitude and latitude coordinates, spanning a\nperiod of 185 days. These spatial-temporal records are meticulously\nrearranged into a vector representation composed of 370 inputs.\nIt is noteworthy that prior to further processing, the input data\nundergoes a normalization step, which involves dividing each input\nFigure 8: Compressed Space\nvalue by 0.3 times the maximum input value, ensuring that the data\nadheres to a standardized scale.\nThe neural network architecture takes the form of an VAE. It ini-\ntiates with an input layer of 370 neurons, which serves as the point\nof entry for the data. Sequentially, the network progresses through\na hidden layer featuring 300 neurons, followed by another hid-\nden layer consisting of 100 neurons. Subsequently, the architecture\ntransitions into a lower-dimensional latent space representation,\ncharacterized by a dimensionality of 3. Following the latent space\nencoding, the network proceeds with two additional hidden layers,\neach comprising 100 neurons, facilitating the extraction of essential\ndata features. The network culminates in a final hidden layer con-\ntaining 300 neurons, serving as the penultimate stage. Ultimately,\nthe networkâ€™s journey concludes with an output layer designed to\nmatch the initial inputâ€™s dimensionality, comprising 370 units. This\nVAE architecture effectively captures data patterns, allowing for\nboth data compression and reconstruction.\nActivation functions are carefully chosen for each layer to regu-\nlate the flow of information through the neural network. The first\nhidden layer is governed by a modified Rectified Linear Unit (ReLU)\nactivation function, while the second hidden layer employs a linear\nactivation function. The latent space is also characterized by a lin-\near activation function. Notably, the fourth and fifth hidden layers\nutilize a modified ReLU activation function, which is characterized\nin this work by a slope of 0.06 for positive values of the argument\nand a slope of 0.001 for negative values.\nIn this VAE-based study, the Mean Squared Error (MSE) is the\nprimary loss function, assessing data reconstruction quality. The\nMSE, as shown in Figure7, quantifies the modelâ€™s ability to suc-\ncessfully replicate input data within its latent space. Additionally, a\nGaussian Mixture Model (GMM) with 15 components is fitted to\nthe latent space using the 60 compressed samples shown in Figure\n8, for deeper insight into data distribution. To generate trajectories,\nwe employ a sampling approach within the latent space, drawing\nsamples from the GMM, as showcased in Figure 8, and subsequently\npropagate these samples through the decoder network.\nSmoothing: The Savitzky-Golay Smoothing was implemented\nagainst each trajectory based on a manual visual tuning of the\nWildGEN: Long-horizon Trajectory Generation for Wildlife\nInfoWildâ€™23, Oct 2023, Birmingham, UK\nFigure 9: Savitzky-Golay Smoothing Filter: Before (blue) and\nAfter (red) for a sample generated trajectory\nFigure 10: A Minimum Bounding Region based on the real\ntrajectories\nparameters, namely window size and polynomial order. As Fig\n9 demonstrates, the filter can reduce excessive wandering of the\ngenerated trajectories in comparison with the real trajectories.\nMBR: The Minimum Bounding Region (MBR) was calculated\nfrom the real trajectories to constrain the region in which the birds\ncan fly. In different problems, one or multiple MBRs can be used\nto signify water bodies, impenetrable mountain ranges, and other\nterrain-based obstacles. The MBR step discards any trajectory that\ndoes not fully lie inside the calculated MBR. This has resulted in\ndiscarding 29.6% of the generated trajectories and retaining the\nremaining trajectories.\n4.3\nModel Comparison\nIn order to compare the models, the first 60 eligible trajectories\nfrom each modelâ€™s synthetic set were used to match the set of real\n(a) Sillouhette score\n(b) Distortion (Elbow Method)\nFigure 11: Choosing the best value of K for K-means cluster-\ning based on two separate methods\ntrajectories on the evaluation metrics. The remaining trajectories\nwere not used during the benchmarking process in this step.\n4.3.1\nPath Similarity. The Hausdorff distance between each pair\nof trajectories from the synthetic and real set were compared. Only\nthe lowest value was retained for each synthetic trajectory. In other\nwords, for each generated trajectory, the distance was computed\nwith the trajectory closest to it from the real trajectory set.\nWe report the minimum, mean, and average distance for each\nmodel in Table 2.\n4.3.2\nCluster Similarity Calculation. K-means clustering was per-\nformed on the set of all points, i.e.\nÃ˜\nğ‘–\n{ğ‘ğ‘–\n1, ğ‘ğ‘–\n2, . . . , ğ‘ğ‘–\nğ‘›}\nfor all ğ‘‡ğ‘–. The value of ğ¾ was chosen using a Silhouette Score and\nvalidated visually using the Elbow method [15]. The number of\nclusters based on the geographic projection of the real trajectory\nshould be between 10 and 15; K=13 was used in our experiments.\nThe trained clustering model was applied to the generated trajec-\ntory points of each model, and the Pearson Correlation Coefficient\nwas calculated based on the distribution of points in each cluster.\n4.3.3\nResults. From Table 2, we can observe that WildGEN pro-\nvides a better overall Hausdorff Distance on average than the other\nmodels. Further, the clusters of WildGEN have better correspon-\ndence to the real trajectories. While Heteroscedastic GPR performs\nwell on the Hausdorff distance metric, the results are influenced by\nthe low variance in the model. It is visually apparent that trajecto-\nries generated by Heteroscedastic GPR follow the same path with\nlittle variance through the first half of the trajectory as depicted in\nFigure 6.\nOn the other hand, it can be observed that Levy Walk/Flight\nfails to generate any realistic trajectories. The metrics also indicate\nthat the trajectories generated fail to capture any properties of the\nreal trajectories. This is not surprising given the limited amount\nof information about the real trajectories that can be fed into the\nalgorithm.\nHowever, WildGEN performs well on the metrics in line with vi-\nsual inspection. It performs significantly better than Levy Walk/Flight\non average Hausdorff Distance and provides a 15.5% improvement\non average compared to Heteroscedastic GPR. There is a very high\ncorrelation between the cluster distributions and the generated\npoints are closer on average to real trajectory points which is al-\nmost double the cluster similarity observed using Heteroscedastic\nGPR.\nInfoWildâ€™23, Oct 2023, Birmingham, UK\nTable 1: Test Results for Hausdorff Distance and Pearson\nCorrelation Coefficient\nMethod\nHausdorff Distance\nPearson (r)\nMin\nMax\nAvg\nLevy Walk/Flight\n22.251\n39.799\n30.590\n-0.0669\nHeteroscedastic GPR\n5.760\n7.155\n6.208\n0.4563\nWildGEN\n3.542\n7.450\n5.244\n0.9936\n4.4\nAblation Study\nIn the ablation study, we want to measure the effects of Smoothing\nand Minimum Bounding Region (MBR) on the metrics measured.\nTable 2: Test Results for Hausdorff Distance and Pearson\nCorrelation Coefficient\nMethod\nHausdorff Distance\nPearson (r)\nMin\nMax\nAvg\nNo Post Processing\n0.306\n9.440\n4.172\n0.9881\nSmoothing Only\n3.542\n10.047\n5.565\n0.9865\nMBR Only\n0.395\n6.425\n3.849\n0.9928\nWildGEN\n3.542\n7.450\n5.244\n0.9936\nIn order to perform the ablation study correctly, we ran the ex-\nperiments on a random sample of trajectories, applied the specified\nmethod on the same set, and retained only the first 60 trajectories\nin line with the experiments in the previous section.\nThe outcomes of our ablation study reveal that smoothing alone\nyields diminished results of the Hausdorff distance and Pearson\nCorrelation Coefficient. However, as discussed previously, smooth-\ning effectively addresses a specific visual challenge, notably the\nmitigation of excessive wandering. To provide a mathematical eval-\nuation of the advantages provided by smoothing, we may need to\nconsider additional metrics.\nOn introducing MBR to our trajectories, the measurable impact\nof smoothing diminishes. Nevertheless, the combined application of\nboth smoothing and MBR yields a small improvement in the Pearson\nCorrelation Coefficient. It can be observed that the penalization\nagainst the Hausdorff distance metric extends to the WildGEN\nscenario.\nOur findings also serve to validate the viability of the raw tra-\njectories generated by the VAE, as corroborated by the metrics\nintroduced. Notably, the utilization of smoothing significantly con-\ntributes to their improved visual inspection when compared to real\ntrajectory data.\nIt is important to note that comparing Smoothing Only and MBR\nOnly scenarios is not completely objective. This is because MBR\nexcludes many trajectories that the smoothing step retains. On\nthe other hand, if we doctor the random set to ensure that only\ntrajectories that meet the MBR criteria are used in the ablation\nstudy, it would defeat the purpose of the improvements of MBR.\nIn that case, MBR and No Post Processing would have identical\nresults.\n5\nCONCLUSIONS AND FUTURE WORK\nThis work presented a novel method by which synthetic trajectories\nmay be generated on a long horizon. The framework, WildGEN,\ncan be characterized as follows:\nâ€¢ Generate near-real, long-horizon trajectories based on a rel-\natively small number of real trajectories\nâ€¢ Performs post-processing steps to further improve the gen-\nerated trajectories\nâ€¢ Shows improved accuracy compared to the state-of-the-art\nmethods\nBased on the findings from this work, there are multiple avenues\nfor future work. A key limitation identified is the evaluation met-\nrics used are not sufficiently representative of a good trajectory.\nIn particular, Hausdorff distance fails to capture the enhancement\nin the trajectory, and it is necessary to test other metrics such as\nFrechet Distance to better assess the effect of smoothing. It is also\ninteresting to identify and utilize other potential smoothing filters.\nIn addition, as a follow-up to this work, we intend to:\nâ€¢ Utilize other generative models, including normalizing flows\nthat can provide the pertinent statistical weights of the gen-\nerated trajectories\nâ€¢ Extend and further investigate the applicability of Wild-\nGEN for various wildlife trajectory scenarios, including land-\nbased and water-based animals.\nREFERENCES\n[1] Agustin Garcia Asuero, Ana Sayago, and AG GonzÃ¡lez. 2006. The correlation\ncoefficient: An overview. Critical reviews in analytical chemistry 36, 1 (2006),\n41â€“59.\n[2] Helen Bailey and Paul Thompson. 2006. Quantitative analysis of bottlenose\ndolphin movement patterns and their relationship with foraging. Journal of\nAnimal Ecology 75, 2 (2006), 456â€“465.\n[3] Carita M Bergman, James A Schaefer, and SN Luttich. 2000. Caribou movement\nas a correlated random walk. Oecologia 123, 3 (2000), 364â€“374.\n[4] Xinyu Chen, Jiajie Xu, Rui Zhou, Wei Chen, Junhua Fang, and Chengfei Liu.\n2021. TrajVAE: A Variational AutoEncoder model for trajectory generation.\nNeurocomputing 428 (2021), 332â€“339. https://doi.org/10.1016/j.neucom.2020.03.\n120\n[5] Jon S Horne, Edward O Garton, Stephen M Krone, and Jesse S Lewis. 2007.\nAnalyzing animal movements using Brownian bridges. Ecology 88, 9 (2007),\n2354â€“2363.\n[6] I Iglesias, F Montes, M MartÃ­nez, A Perez, A Gogin, D Kolbasov, and A de la\nTorre. 2018. Spatio-temporal kriging analysis to identify the role of wild boar in\nthe spread of African swine fever in the Russian Federation. Spatial statistics 28\n(2018), 226â€“235.\n[7] Diederik P Kingma, Max Welling, et al. 2019. An introduction to variational\nautoencoders. Foundations and TrendsÂ® in Machine Learning 12, 4 (2019), 307â€“392.\n[8] Andrea KÃ¶lzsch, Sarah C Davidson, Dominik Gauggel, Clemens Hahn, Julian\nHirt, Roland Kays, Ilona Lang, Ashley Lohr, Benedict Russell, Anne K Scharf,\net al. 2022. MoveApps: a serverless no-code analysis platform for animal tracking\ndata. Movement Ecology 10, 1 (2022), 30.\n[9] A KÃ¶lzsch, GJDM MÃ¼skens, S Moonen, H Kruckenberg, P Glazov, and M Wikelski.\n2019. Data from: Flyway connectivity and exchange primarily driven by moult\nmigration in geese [North Sea population].\nhttps://doi.org/doi:10.5441/001/1.\nct72m82n\n[10] Quoc V Le, Alex J Smola, and StÃ©phane Canu. 2005. Heteroscedastic Gaussian\nprocess regression. In Proceedings of the 22nd international conference on Machine\nlearning. 489â€“496.\n[11] Michael T. Main, Robert A. Davis, David Blake, Harriet Mills, and Tim S. Doherty.\n2020. Human impact overrides bioclimatic drivers of red fox home range size\nglobally. Diversity and Distributions 26, 9 (2020), 1083â€“1092. Publisher: Wiley\nOnline Library.\n[12] Donald James McLean and Marta A Skowron Volponi. 2018. trajr: an R package\nfor characterisation of animal trajectories. Ethology 124, 6 (2018), 440â€“448.\n[13] Eric Renshaw and Robin Henderson. 1981. The correlated random walk. Journal\nof Applied Probability 18, 2 (1981), 403â€“414.\nWildGEN: Long-horizon Trajectory Generation for Wildlife\nInfoWildâ€™23, Oct 2023, Birmingham, UK\n(a) Raw\n(b) Smoothed\n(c) MBR Filtered\n(d) WildGEN\nFigure 12: The effect of different components on WildGEN on the generated trajectories\n[14] A. M. Reynolds. 2009. Scale-free animal movement patterns: LÃ©vy walks outper-\nform fractional Brownian motions and fractional LÃ©vy motions in random search\nscenarios. Journal of Physics A: Mathematical and Theoretical 42, 43 (Oct. 2009),\n434006. https://doi.org/10.1088/1751-8113/42/43/434006\n[15] Danny Matthew Saputra, Daniel Saputra, and Liniyanti D Oswari. 2020. Effect\nof distance metrics in determining k-value in k-means clustering using elbow\nand silhouette method. In Sriwijaya International Conference on Information\nTechnology and Its Applications (SICONIAN 2019). Atlantis Press, 341â€“346.\n[16] Ronald W Schafer. 2011. What is a Savitzky-Golay filter?[lecture notes]. IEEE\nSignal processing magazine 28, 4 (2011), 111â€“117.\n[17] Leena Singh and James Fuller. 2001. Trajectory generation for a UAV in ur-\nban terrain, using nonlinear MPC. In Proceedings of the 2001 American Control\nConference.(Cat. No. 01CH37148), Vol. 3. IEEE, 2301â€“2308.\n[18] Georgios Technitis, Walied Othman, Kamran Safi, and Robert Weibel. 2015. From\nA to B, randomly: a point-to-point random trajectory generator for animal move-\nment. International Journal of Geographical Information Science 29, 6 (2015),\n912â€“934.\n[19] Jan A. Venter, Herbert HT Prins, Alla Mashanova, Willem F. de Boer, and Rob\nSlotow. 2015. Intrinsic and extrinsic factors influencing large African herbivore\nmovements. Ecological Informatics 30 (2015), 257â€“262. Publisher: Elsevier.\n[20] Xingrui Wang, Xinyu Liu, Ziteng Lu, and Hanfang Yang. 2021. Large scale GPS\ntrajectory generation using map based on two stage GAN. Journal of Data Science\n19, 1 (2021), 126â€“141.\n[21] Marina E Wosniack, Marcos C Santos, Ernesto P Raposo, Gandhi M Viswanathan,\nand Marcos GE Da Luz. 2017. The evolutionary origins of LÃ©vy walk foraging.\nPLoS computational biology 13, 10 (2017), e1005774.\n[22] Vasily Zaburdaev, Sergey Denisov, and Joseph Klafter. 2015. LÃ©vy walks. Reviews\nof Modern Physics 87, 2 (2015), 483.\n[23] Zhaoyu Zhang, Mengyan Li, and Jun Yu. 2018. On the convergence and mode\ncollapse of GAN. In SIGGRAPH Asia 2018 Technical Briefs. 1â€“4.\n"
}