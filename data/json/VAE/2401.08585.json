{
    "optim": "From Conceptual Spaces to Quantum Concepts:\nFormalising and Learning Structured Conceptual\nModels\nSean Tull, Razin A. Shaikh, Sara Sabrina Zemljiˇc and Stephen Clark\nQuantinuum\n17 Beaumont Street, Oxford, UK\n{sean.tull,razin.shaikh,sara.zemljic,steve.clark}@quantinuum.com\n6 November 2023\nAbstract\nIn this article we present a new modelling framework for structured\nconcepts using a category-theoretic generalisation of conceptual spaces,\nand show how the conceptual representations can be learned automati-\ncally from data, using two very different instantiations: one classical and\none quantum. A contribution of the work is a thorough category-theoretic\nformalisation of our framework. We claim that the use of category the-\nory, and in particular the use of string diagrams to describe quantum\nprocesses, helps elucidate some of the most important features of our\napproach. We build upon G¨ardenfors’ classical framework of conceptual\nspaces, in which cognition is modelled geometrically through the use of\nconvex spaces, which in turn factorise in terms of simpler spaces called\ndomains. We show how concepts from the domains of shape, colour,\nsize and position can be learned from images of simple shapes, where\nconcepts are represented as Gaussians in the classical implementation,\nand quantum effects in the quantum one.\nIn the classical case we de-\nvelop a new model which is inspired by the β-VAE model of concepts,\nbut is designed to be more closely connected with language, so that the\nnames of concepts form part of the graphical model.\nIn the quantum\ncase, concepts are learned by a hybrid classical-quantum network trained\nto perform concept classification, where the classical image processing is\ncarried out by a convolutional neural network and the quantum repre-\nsentations are produced by a parameterised quantum circuit. Finally, we\nconsider the question of whether our quantum models of concepts can be\nconsidered conceptual spaces in the G¨ardenfors sense.\n1\narXiv:2401.08585v1  [q-bio.NC]  6 Nov 2023\n1\nIntroduction\nThe study of concepts has a long history in a number of related fields, including\nphilosophy, linguistics, psychology and cognitive science (Murphy, 2002; Mar-\ngolis & Laurence, 2015). More recently, researchers have begun to consider how\nmathematical tools from quantum theory can be used to model cognitive phe-\nnomena, including conceptual structure. The general use of quantum formalism\nin psychology and cognitive science has led to an emerging area called quantum\ncognition (Aerts, 2009; Pothos & Busemeyer, 2013). The idea is that some of the\nfeatures of quantum theory, such as entanglement, can be used to account for\npsychological data which can be hard to model classically. Examples include or-\ndering effects in how subjects answer questions (Trueblood & Busemeyer, 2011)\nand concept combination (Aerts & Gabora, 2005; Tomas & Sylvie, 2015).\nAnother recent development in the study of concepts has been the applica-\ntion of machine learning to the problem of how artificial agents can automati-\ncally learn concepts from raw perceptual data (Higgins et al., 2017, 2018). The\nmotivation for endowing an agent with conceptual representations, and learning\nthose representations automatically from the agent’s environment, is that this\nwill enable it to reason and act more effectively in that environment, similar to\nhow humans use concepts (Lake et al., 2017). One hope is that the explicit use\nof concepts will ameliorate some of the negative consequences of the “black-box”\nnature of neural architectures currently being used in AI.\nIn this article we present a new modelling framework for concepts based\non the mathematical formalism used in quantum theory, and demonstrate how\nthe conceptual representations can be learned automatically from data, using\nboth classical and quantum-inspired models.\nA contribution of the work is\na thorough category-theoretic formalisation of our framework, following Bolt\net al. (2019) and Tull (2021). Formalisation of conceptual models is not new\n(Ganter & Obiedkov, 2016), but we claim that the use of category theory (Fong,\n2019), and in particular the use of string diagrams to describe quantum processes\n(Coecke & Kissinger, 2017), helps elucidate some of the most important features\nof our approach to concept modelling. This aspect of our work also fits with the\nrecent push to introduce category theory into machine learning and AI more\nbroadly. The motivation is to make deep learning less ad-hoc and less driven\nby heuristics, by viewing deep learning models through the compositional lens\nof category theory (Shiebler et al., 2021).\nMurphy (2002, p.1) describes concepts as “the glue that holds our mental\nworld together”. But how should concepts be modelled and represented math-\nematically? There are many modelling frameworks in the literature, including\nthe classical theory (Margolis & Laurence, 2022), the prototype theory (Rosch,\n1973), and the theory theory (Gopnik & Meltzoff, 1997). Here we build upon\nG¨ardenfors’ framework of conceptual spaces (G¨ardenfors, 2004, 2014), in which\ncognition is modelled geometrically through the use of convex spaces, which in\nturn factorise in terms of simpler spaces called domains.\nOur category-theoretic formalisation of conceptual spaces allows flexibility\nin how the framework is instantiated and then implemented, with the partic-\n2\nular instantiation determined by the choice of category.\nFirst we show how\nthe framework can be instantiated and implemented classically, by using the\nformalisation of “fuzzy” conceptual spaces from Tull (2021), and developing\na probabilistic model based on Variational Autoencoders (VAEs) (Rezende et\nal., 2014; Kingma & Welling, 2014). Having “fuzzy” probabilistic representa-\ntions not only extends G¨ardenfors’ framework in a useful way, it also provides a\nnatural mechanism for dealing with the vagueness inherent in the human con-\nceptual system, and allows us to draw on the toolkit from machine learning\nto provide effective learning mechanisms. Our new model—which we call the\nConceptual VAE—is an extension of the β-VAE from Higgins et al. (2017), with\nthe concepts having explicit labels and represented as multivariate Gaussians in\na factored conceptual space.\nWe use the Spriteworld software (Watters et al., 2019) to generate simple im-\nages consisting of coloured shapes of certain sizes in certain positions, meaning\nour conceptual spaces contain four domains: colour, size, shape and posi-\ntion. The main question we investigate for the classical model is a representa-\ntional learning one: can the Conceptual VAE induce factored representations in\na latent conceptual space which neatly separates the individual concepts, and\nunder what conditions? Here we demonstrate that, if the system is provided\nwith supervision regarding the domains, and provided with the corresponding\nfour labels for each training instance (e.g. (blue, small, circle, top)), then the\nVAE can learn Gaussians which faithfully represent the colour spectrum, for\nexample. We also show how the Conceptual VAE naturally provides a concept\nclassifier, in the form of the encoder, which predicts a Gaussian for an image\nthat can be compared with the induced conceptual representations using the\nKL divergence.\nOur second instantiation of the abstract framework uses a category for de-\nscribing quantum processes (Coecke & Kissinger, 2017). In this case, the images\nof shapes are represented as quantum states in an underlying Hilbert space and\nconcepts are quantum effects. Applying a concept effect to an instance state\nyields a scalar, which we interpret as specifying how well the instance fits the\nconcept. The factoring of the conceptual space is represented naturally in our\nmodels through the use of the tensor product as the monoidal product. We\nchoose to implement our quantum model using a hybrid quantum-classical net-\nwork trained to perform concept classification, where the classical image pro-\ncessing is carried out by a convolutional neural network (Goodfellow et al.,\n2016, Ch.9) and the quantum representations are produced by a parameterised\nquantum circuit (Benedetti et al., 2019). Even though the framework is instan-\ntiated at a level of abstraction independent of any particular implementation,\nthe use-case we have in mind is one in which the models are (eventually) run\non a quantum computer, exploiting the potential advantages such computers\nmay bring.\nHere the implementation is a classical simulation of a quantum\ncomputation.1\n1Note that we are not making any claims of “quantum supremacy” (Preskill, 2012) for the\nparticular set of quantum models that we implement in this article. However, we do anticipate\n3\nWe demonstrate how the training of the hybrid network produces concep-\ntual representations in the Hilbert space which are neatly separated within the\ndomains. We also show how discarding—which produces mixed effects—can be\nused when the concept to be learned only applies to a subset of the domains, and\nhow entanglement (together with discarding) can be used to capture interesting\ncorrelations across domains.\nWhat are some of the main reasons for applying the formalism of quantum\ntheory to the modelling of concepts?\nFirst, it provides an alternative, and\ninteresting, mathematical structure to the convex structure of conceptual spaces\n(see Section 2.7). Second, this structure comes with features which are well-\nsuited to modelling concepts, such as entanglement for capturing correlations,\nand partial orders for capturing conceptual hierarchies.2 Third, the use of the\ntensor product for combining domains leads to machine learning models with\ndifferent characteristics to those typically employed in concept learning, such as\nthe Conceptual VAE (i.e. neural networks which use direct sum as the monoidal\nproduct plus non-linearities to capture interactions between features) (Havlicek\net al., 2019; Schuld & Killoran, 2019). The advantages this may bring, especially\nwith the advent of larger, fault-tolerant quantum computers in the future, is\nstill being worked out by the quantum machine learning community, but the\npossibilities are intriguing at worst and transformational at best.\nNote that, in this article, our goal is to set out a novel framework for concept\nmodelling, and demonstrate empirically—with two very different implementations—\nhow concepts can be learned in practice. Further work is required to demon-\nstrate that the framework can be applied fruitfully to data from a psychology\nlab—which is one of the goals of quantum cognition (Pothos & Busemeyer,\n2013)—and also to agents acting in (virtual) environments—one of the goals of\nagent-based AI (Abramson et al., 2020). Note also that no claims are being\nmade here regarding the existence of quantum processes in the brain, only that\nsome cognitive processes can be effectively modelled at an abstract level using\nthe quantum formalism.\nThe rest of the article is structured as follows. Section 2 provides a thor-\nough category-theoretic formalisation of our modelling framework, using the\nlanguage of string diagrams to describe the structured models. Section 3 then\ndescribes our first instantiation of the framework, which is a novel adapation\nof the variational autoencoder. This section also contains experiments showing\nhow Gaussian concept representations can be learned from images of coloured\nshapes. Section 4 then describes our quantum instantiation, as well as a hy-\nbrid implementation applied to the same image data. The hybrid network uses a\nCNN for the classical image processing and a parameterised quantum circuit for\ninducing the concept representations (as quantum effects). Finally, Sections 5\nand 6 describe related and future work.\nthe possibility of quantum models of concepts satisfying our framework which require quantum\nhardware for their efficient training and deployment, especially as we scale to more realistic\ndatasets and larger quantum circuits.\n2Section 2.6 describes entanglement; we leave the use of partial orders in experiments for\nfuture work.\n4\n2\nFormalising Conceptual Spaces\nG¨ardenfors’ framework of conceptual spaces (G¨ardenfors, 2004, 2014) models\nconceptual reasoning in both human and artificial cognition.\nThe approach\nmodels cognition geometrically, using convex spaces factorised in terms of “el-\nementary” spaces called domains. Examples include the domains of colour,\ntaste, sound, and time. Concepts are represented as convex regions, or more\ngenerally as “fuzzy” functions defined over the space. We begin with a brief\nformalisation of this framework.\nWhile many have been presented (Aisbett\n& Gibbon, 2001; Rickard et al., 2007; Lewis & Lawry, 2016; Bechberger &\nK¨uhnberger, 2017), we draw on the categorical approaches (Bolt et al., 2019;\nTull, 2021) and the latter’s treatment of fuzzy concepts.\nDefinition 1. A convex space is a set Z coming with operations which allow us\nto take convex combinations, in that for all z1, . . . , zn ∈ Z and p1, . . . , pn ∈ [0, 1]\nwith Pn\ni=1 pi = 1, there is an element:\nn\nX\ni=1\npi · zi\nThese combinations satisfy natural axioms; for example iterated combinations\nare given by multiplying weights as the notation suggests (see Bolt et al. (2019)\nfor details).\nAdditionally we here require that Z forms a measurable space,\nmeaning it comes with a σ-algebra of measurable subsets ΣZ ⊆ P(Z).\nDefinition 2. A conceptual space is a convex space Z given as a subset of a\nproduct of convex spaces:\nZ ⊆ Z1 × · · · × Zn\nwhere the product is equipped with element-wise convex operations. We call\nan element z = (z1, . . . , zn) ∈ Z an instance of the conceptual space, following\nClark et al. (2021).\nAny factor Zi can be considered a conceptual space itself, with each zi an\ninstance. A conceptual space is often written as a product of domains, such\nas colour or sound. Each domain itself factorises as a (subset of a) product\nof dimensions. For example, the sound domain has the dimensions of pitch\nand volume.\nHere we simply use the neutral term “factor” to treat either\ndimensions or domains.\nDefinition 3. A crisp concept in a conceptual space Z is a measurable subset\nC ⊆ Z which is convex, meaning it is closed under convex combinations. When\nz ∈ C we say z is an instance of C.\nConvexity means that any point lying “in-between” two instances of a con-\ncept will again form an instance of the concept, and is justified by G¨ardenfors\nusing experimental evidence in the division of colour space, and the ease of\nlearning convex regions (G¨ardenfors, 2004).\n5\nMore generally, it is natural to consider concepts C which are graded or\n“fuzzy”, so that the degree C(z) to which z is an instance of a concept can take\nany value from 0 (“not at all”) to 1 (“fully satisfied”). In Tull (2021) it is shown\nthat to be well-behaved compositionally and also satisfy a natural generalisa-\ntion of convexity known as “quasi-concavity”, the membership function should\nsatisfy the following.\nDefinition 4. A fuzzy concept of Z is a measurable function C : Z → [0, 1]\nwhich is log-concave:\nC(pz + (1 − p)z′) ≥ C(z)pC(z′)1−p\n(1)\nfor all z, z′ ∈ Z and p ∈ [0, 1]. A prototypical instance of C is an instance z with\nC(z) = maxw∈Z C(w).\nThe prototypical instances of a fuzzy concept always form a crisp concept,\nand conversely any crisp concept P forms a fuzzy concept via its indicator\nfunction C = 1P .\nExample 1. Any convex subset Z ⊆ Rd forms a conceptual space, taking ΣZ\nto be the Lebesgue measurable subsets. Thus any product Z = Z1 × · · · × Zn\nof convex subsets Zi ⊆ Rdi forms a conceptual space. In general any product of\nfuzzy concepts yields a new one on any convex subset Z ⊆ Z1 × · · · × Zn via:\nC(z) =\nn\nY\ni=1\nCi(zi)\n(2)\nThe following example of a fuzzy concept will form the basis of our classical\nimplementation of the framework in Section 3.\nExample 2. We may define a fuzzy concept on Z = Rn from any multivariate\nGaussian with mean µ and covariance matrix Σ:\nC(z; µ, Σ) = e− 1\n2 (z−µ)TΣ−1(z−µ)\n(3)\n= e\nPn\ni=1 −\n1\n2σ2\ni\n(zi−µi)2\n(4)\nIn the second line we restrict to the case where Σ is diagonal, with i-th diagonal\nentry σ2\ni . In this case C is given as a product of one-dimensional Gaussians\nCi(zi; µi, σ2\ni ) as in (2).\nExample 3. A simple taste domain from Bolt et al. (2019), left-hand below,\nis given as a convex subset of R3 generated by the points sweet, bitter, salt\nand sour. Highlighted in red is a crisp concept for sweet. Right-hand below\nshows a fuzzy concept on R2 from Tull (2021). From a set of exemplars (white\ncrosses) the convex closure is formed, yielding the crisp concept P given by the\ninner triangle. A fuzzy concept is then defined by C(x) = e−\n1\n2σ2 d(x,P )2 where\n6\ndH(x, P) = infp∈P d(x, p), where each point in P is prototypical.\n2.1\nCategorical Setup\nOur aim will now be to lift these basic notions from conceptual space theory into\na general categorical framework, allowing us to pass them from the classical to\nthe quantum setting in a principled manner. Here we introduce the categorical\npreliminaries.\nWe will work in a symmetric monoidal category (C, ⊗, I), making use of\nthe graphical calculus (Selinger, 2010) in which objects are depicted as labelled\nwires, and morphisms f : A → B as boxes with input wire A and output wire\nB, read here from bottom to top. Identities and sequential composition are\ndepicted as follows.\nidA\n=\nA\nA\nA\nA\ng ◦ f\n=\nA\nA\nC\nC\nf\ng\nB\nParallel composition via the tensor ⊗ is given by drawing diagrams side-by-side.\nf ⊗ g\nA ⊗ B\nC ⊗ D\n=\nf\nA\nC\ng\nB\nD\nThe (identity on the) monoidal unit I is the empty diagram. Morphisms ω: I →\nA, e: A → I and r: I → I are called states, effects and scalars respectively,\ndepicted with no input, output or neither, respectively.\nHere we consider categories C with further structure. First, each object A\nwill come with a distinguished discarding effect denoted\nA, which we interpret\nas “throwing the system away”, with\nI = idI and\nX⊗Y =\nX ⊗\nY .\nA\nmorphism f is a channel when it preserves discarding, as in left-hand below. A\n7\nspecial case is that of a normalised state ω, right-hand below.\nf\n=\nB\nA\nA\nω\n=\n1\nA\nWe also assume C is enriched in partial orders, so that each homset C(A, B)\nforms a partially ordered set ≤, respected by composition. This allows us to\ngeneralise inclusions of convex subsets via the following, related to “comprehen-\nsions” (Cho et al., 2015) and “compression” maps in quantum reconstructions\n(Tull, 2019, Chap. 4).\nDefinition 5. A projection is a morphism p: A → A with\n◦ p ≤\nand such\nthat for all morphisms f with output (resp. input) A we have:\n1.\n◦ f ≤\n◦ p =⇒ f = f ◦ p;\n2.\n◦ f ≤\n◦ p ◦ f =⇒ f = p ◦ f.\nIt follows that p = p ◦ p. An embedding of an object A into B is given by a\nchannel e: A → B and morphism e† : B → A, depicted using triangles below,\nsuch that e† ◦ e = idA and p = e ◦ e† is a projection.\nA\nA\nB\n=\nA\nA\ne\ne\nA\nB\nB\nis a projection\nWe often call the morphism e the embedding and e† the projection of the pair.\nAny channel which is an isomorphism A ≃ B forms a special case of an\nembedding, where e† = e−1. Another important special case is an embedding\nof I into A, which we call a point of A.3 By definition it includes a normalised\nstate ψ with an effect ψ† ≤\nsatisfying:\nψ\nψ\n=\n1\n(5)\nEmbeddings are always closed under composition in the following sense.\nLemma 6. If d: A → B and e: B → C are embeddings then so is e◦d: A → C,\nwith projection d† ◦ e†.\n3Later we will define instances as special cases of points. Instances and points differ in\nquantum models, because of entanglement, but coincide classically.\n8\n2.2\nConceptual Models\nLet us now see how each of our earlier features from conceptual space theory can\nbe described in a general category C with the structure outlined in Section 2.1.\nFirstly, monoidal categories immediately allow us to describe the compositions\nof factors Zi appearing in a conceptual space, as follows.\nDefinition 7. A conceptual model4 is given by an object Z along with an\nindexed collection of objects Z1, . . . , Zn, called the factors, and an embedding\nof Z into Z1 ⊗ · · · ⊗ Zn.\n. . .\nZ1\nZn\nZ\nFor simplicity we refer to a model as Z, with the factors and embedding\nimplicit. Often the embedding is an isomorphism Z ≃ Z1 ⊗ · · · ⊗ Zn exhibiting\nZ as a product of the factors.\nDefinition 8. A concept of a conceptual model Z is an effect C on Z.\nC\nZ\nAn instance is a point z of Z which forms a product of points zi of the factors\nZi, as below:\n. . .\nZ1\nZn\n=\nz\n. . .\nZ1\nZn\nz1\nzn\nZ\n(6)\nThe order structure on morphisms means that the concepts are automatically\npartially ordered. We interpret C ≤ D as stating that D is a “more general”\nconcept than C. The factorisation property (6) generalises the fact that in a\nconceptual space every instance z = (z1, . . . , zn) factors as a product of one\ninstance zi per factor Zi.\nComposing a concept C with any input state, in\nparticular any instance z, will yield a scalar. For an instance we interpret this\nas specifying how well the instance fits the concept:\nz\nC\nZ\nWe say that an instance z is prototypical for a concept C when C ◦ w ≤ C ◦ z\nfor all instances w. It remains for us to identify those concepts which are crisp.\n4Henceforth we use the generic term “model” rather than “space” since a conceptual model\ncan be defined in a category without any spatial character.\n9\nDefinition 9. A concept C on Z is crisp when it is of the form\nK\nZ\nC\n=\nZ\nfor some projection morphism Z → K induced by an embedding of K into Z.\nWhen the projection is given by a point of Z we call C a pure concept.\nBy definition each crisp concept has C ≤\n. Intuitively we can identify the\ncrisp concept with object K via its embedding e. Indeed by the definition of an\nembedding, for any instance z of Z we have C ◦z = 1 iff z = e◦k for some point\nk of K. Moreover any concept D with D ≤ C restricts to K in that D = E ◦ e†\nfor some effect E on K. A pure concept can be thought of as a “maximally\nsharp” concept, being of the form z = ψ† as in (5) where z = ψ is in fact a\npoint of Z.\n2.3\nClassical Conceptual Models\nLet us now meet our main classical examples of categories and their notions of\nconceptual model.\nClass: Discrete probability.\nIn the category Class the objects are finite\nsets and the morphisms M : X → Y are matrices (M(y | x))x∈X,y∈Y with values\nin R+. Composition is matrix multiplication:\n(N ◦ M)(x, z) :=\nX\ny∈Y\nN(z | y)M(y | x)\nIdentity morphisms satisfy idX(y | x) = δx,y. X ⊗Y = X ×Y , with I = {⋆} the\nsingleton set, and M ⊗ N the Kronecker product of matrices. We can equate\nstates ω and effects e of X each with functions X → R+. In particular, scalars\ncorrespond to positive reals s ∈ R+.\nis the function x 7→ 1 for all x ∈ X.\nA state ω of X is normalised iff it describes a probability distribution, with\nP\nx∈X ω(x) = 1. More generally, a morphism M : X → Y is a channel iff it is a\nfinite probability channel (Stochastic matrix) with P\ny∈Y M(y | x) = 1 for each\nx ∈ X. ≤ is the element-wise ordering from R+. The points of X are precisely\nthe point distributions δx for x ∈ X. An embedding X ,→ Y is given by an\ninclusion of a subset X ⊆ Y via x 7→ δx, and its projection Y → X is given by\ny 7→ δy when y ∈ X and y 7→ 0 otherwise.\nA conceptual model in Class is thus a finite set Z given as a subset Z ⊆\nZ1×· · ·×Zn. A concept is an arbitrary function C : Z → R+, ordered point-wise.\nAn instance is any element z = (z1, . . . , zn) ∈ Z, with (6) holding automatically.\nApplying a concept C to an instance z gives C(z) ∈ R+. Crisp concepts are\nthe indicator functions 1K of arbitrary subsets K ⊆ Z, while pure concepts are\nthose of instances z ∈ Z.\n10\nProb: Measure-theoretic probability.\nIn Prob the objects are measur-\nable spaces (X, ΣX). A morphism f : X → Y is a Markov (sub)kernel, a function\nsending each x ∈ X to a sub-probability measure f(x) over Y , in a “measur-\nable” way (Panangaden, 1998; Cho & Jacobs, 2019). Composition of f : X → Y\nand g: Y → Z is via integration:\n(g ◦ f)(x, A) :=\nZ\ny∈Y\ng(y, A)df(x)(y)\nfor each x ∈ X, A ∈ ΣZ. The identity sends each x to the point measure δx. We\nset X ⊗Y = X ×Y , with I being the singleton set, and define f ⊗g to send each\npair (x, y) to the product measure of the measures f(x) and g(y). States of X\nmay be identified with sub-probability measures ω over X, and are normalised\niff they form a probability measure, with ω(X) = 1.\nEffects correspond to\nmeasurable functions e: X → [0, 1].\nis the constant function at 1. Scalars are\nprobabilities p ∈ [0, 1]. Composing a state with an effect yields the expectation\nvalue e ◦ ω =\nR\nx∈X e(x)dω(x) ∈ R+.\nA morphism f : X → Y is a channel iff it sends each x ∈ X to a probability\nmeasure. Then f ≤ g whenever f(x, A) ≤ g(x, A) for all x ∈ X, A ∈ ΣY . An\nembedding X ,→ Y is an inclusion of a subset X ⊆ Y via x 7→ δx for x ∈ X,\nwith the projection Y → X given by y 7→ δy when y ∈ X and y 7→ 0 otherwise.\nA conceptual model in Prob is thus a measurable space given as a measur-\nable subset Z ⊆ Z1 × · · · × Zn of spaces Zi. Concepts are measurable functions\nC : Z → [0, 1], instances and pure concepts correspond to points z ∈ Z, crisp\nconcepts 1K correspond to arbitrary measurable subsets K ⊆ Z.\nConSp: Conceptual spaces.\nThe category ConSp (Tull, 2021) is defined\njust like Prob except that the objects are now convex spaces and morphisms\nare (sub)kernels f which are log-concave, meaning that\nf(px + (1 − p)y, pA + (1 − p)B) ≥ f(x, A)pf(y, B)1−p\n(7)\nfor all p ∈ [0, 1], x, y ∈ X and A, B ∈ ΣY . Here X ⊗ Y = X × Y is the product\nof convex spaces, with element-wise convex operations.\nA conceptual model in ConSp is precisely a conceptual space, i.e. a convex\nspace viewed as a convex subset Z ⊆ Z1×· · ·×Zn of convex spaces Zi. Instances\nare points z ∈ Z. Crisp concepts are precisely those of Definition 3, namely the\nindicator functions 1K of convex measurable subsets K ⊆ Z, with pure concepts\nbeing the indicator functions 1z of points z ∈ Z. Concepts are fuzzy concepts\nC : Z → [0, 1] in the sense of Definition 4.\n2.4\nQuantum Conceptual Models\nWe can now define our quantum model of concepts inspired by the conceptual\nspace framework. To do so we will simply unpack our definitions from Section\n2.2 in the following category of quantum processes.\n11\nQuant: Quantum processes.\nIn the category Quant the objects are finite\ndimensional Hilbert spaces, and morphisms f : H → K are completely positive\n(CP) maps f : L(H) → L(K), where L(H) is the space of linear operators on\nH. Such a map f is linear, and such that for any H′ the map g = f ⊗ idH′\nis positive in that whenever a is a positive operator then g(a) is also. We set\nf ≤ g whenever g − f is CP.\nHere ⊗ is the usual tensor of Hilbert spaces and linear maps, with I = C.\nIn particular, states ω and effects e on H may both be identified with positive\noperators a ∈ L(H) via a = ω(1) and e(b) = Tr(ab), respectively, where Tr\ndenotes the trace. Scalars are again positive reals r ∈ R+. Discarding is the\nfunctional\n(a) = Tr(a), corresponding to the identity operator idH.\nA morphism f is a channel iff it is a completely positive trace-preserving\n(CPTP) map, with Tr(f(a)) = Tr(a) for all a ∈ L(H). A state ρ is normalised\nprecisely when it is a density matrix, with Tr(ρ) = 1.\nA special class of morphisms are the pure CP maps ˆf : L(H) → L(K), given\nby ˆf(a) = f ◦ a ◦ f † for some linear map f : H → K. All other morphisms are\ncalled mixed. Embedding morphisms are the pure maps induced by inclusions\ni: K ,→ H of subspaces into H. The corresponding projection is the pure map\ninduced by the linear projection i† onto K. A point of H may be identified with\na pure quantum state |ψ⟩ ⟨ψ| for some unit vector ψ ∈ H.5\nWe now arrive at our quantum adaptation of the conceptual space frame-\nwork.\nDefinition 10. A quantum conceptual model is a conceptual model in Quant:\n. . .\nH1\nHn\nH\nThus a quantum conceptual model is a Hilbert space H given as a subspace\nof a tensor product of Hilbert spaces H ⊆ H1 ⊗· · ·⊗Hn. A quantum concept is\nthen precisely a quantum effect, i.e. a positive operator C ∈ L(H), ordered via\nC ≤ D whenever D − C is positive. An instance is a pure state |ψ⟩ ⟨ψ| given by\na unit vector ψ ∈ H, which furthermore factorises as\nψ = ψ1 ⊗ · · · ⊗ ψn\n(8)\nfor unit vectors ψi ∈ Hi, giving it a well-defined pure state value on each\nfactor Hi. All instances are pure, with mixed states ρ interpreted as states of\nuncertainty (i.e. probabilistic mixtures) over pure states such as instances. In\ncontrast concepts may be mixed or pure. The application of a quantum concept\n5Here we use the standard “bra-ket” notation whereby vectors and linear functionals on\nH are written in the form |ψ⟩, ⟨ϕ| respectively. Then for a unit vector ψ ∈ H, |ψ⟩ ⟨ψ| is the\ndensity operator of the corresponding pure state on H.\n12\nC to an instance ψ is given by\nC\nψ\nH\n=\n⟨ψ| C |ψ⟩ ∈ R+\nMore generally applying C to a mixed state ρ yields Tr(Cρ) ∈ R+.\nCrisp concepts correspond to subspaces K ⊆ H. More precisely, any such\nsubspace defines a crisp concept via the projection operator P onto K with\nP(ψ) = ψ for ψ in K and P(ψ) = 0 for ψ in K⊥.\nPure quantum concepts are precisely those crisp quantum concepts which are\nthemselves pure as effects. For these, K is given by a one-dimensional subspace\n⟨ψ⟩ spanned by some unit vector ψ ∈ H. Thus pure quantum concepts are\nprecisely effects of the form |ψ⟩ ⟨ψ| where ψ is any unit vector (not necessarily\nan instance). Such a concept sends each instance ϕ to | ⟨ψ|ϕ⟩ |2 ∈ [0, 1].\nExample 4. A quantum conceptual model H = HHue ⊗ HSat ⊗ HLight for\ncolour with factors hue, saturation and lightness is given in Yan et al.\n(2021), where hue is encoded on a single qubit, represented on the Bloch sphere.\nIn particular each instance (colour) is taken to be a tensor of pure states over\neach of the factors.\nWe will meet further examples of quantum conceptual models in Section 4.\n2.5\nEntangled Concepts\nIt is natural to wonder what advantages, if any, quantum concepts might possess\nover classical ones. One feature distinguishing quantum models from classical\nones is the presence of pure entangled concepts. For the following, we restrict\nto categories with scalars given by R+, as in all of our examples here.\nDefinition 11. A concept C is a product concept when there are effects C1, . . . , Cn\nsuch that\nC\nZ\n=\n. . .\nC1\nCn\nZ\nZ1\nZn\n(9)\nA concept C is separable when its value on instances is equal to a convex mixture\nof product concepts. That is, there are product concepts C(1), . . . , C(k) such that\nC ◦ z = Pk\nj=1 C(j) ◦ z for all instances z, where the sum is taken in R+. If a\nconcept C is not separable we say that it is entangled.\nA product concept treats the factors independently, applying a fixed con-\ncept to each. Entangled concepts capture correlations between factors which\ncannot be reduced to any mixture over such product concepts. Class, Prob\n13\nand ConSp contain product concepts as well as separable (but non-product)\nconcepts.\nNonetheless in Class every concept is separable.\nHowever, these\ncategories do not contain any pure entangled concepts, since every point of a\nmodel Z ⊆ Z1 × · · · × Zn forms an instance z = (z1, . . . , zn) and hence every\npure concept is a product of pure effects z†\ni on each factor.\nIn contrast, quantum models H contain both entangled and pure entangled\nconcepts. For any unit vector ψ ∈ H which is entangled in the usual sense, i.e.\nnot of the form (8), the point |ψ⟩ ⟨ψ| is not an instance, and its corresponding\npure concept on H is entangled.\nExample 5. Consider a Hilbert space H with orthonormal basis {|i⟩}n−1\ni=0 . An\nentangled pure concept on H⊗H is given by the Bell effect, induced by the (un-\nnormalised) vector Pn−1\ni=0 |i i⟩ (where sum denotes superposition), with operator\nPn−1\ni,j=0 |i i⟩ ⟨j j|.\nRemark 1. The finite sum in Def. 11 should ultimately be replaced with an\nintegral, so that each concept in Prob is separable. It would be interesting to\nexplore whether entanglement exists in ConSp.\n2.6\nQuantum and Classical Concept Combinations\nTo compare classical and quantum concepts, and to demonstrate the role of\nentangled concepts in quantum models, let us now consider the ways in which\nwe may “combine” (crisp) concepts in each of our example categories. Given\na collection of crisp concepts (Ci)n\ni=1, by a combination we mean a new (crisp)\nconcept C such that every prototypical instance of one of the Ci is a prototypical\ninstance of C.6\nWe will focus in particular on the natural scenario in which we are given a\nmodel Z and wish to combine (the pure concepts induced by) a collection of\ninstances z1, . . . , zn. The result is a concept C with the z1, . . . , zn as prototypical\ninstances, which we think of as learned from these exemplars.\nA starting point is to observe that crisp concepts in each category are closed\nunder intersections T\ni∈I Ci (of arbitrary, measurable, convex, linear subsets\nrespectively). They hence form a complete lattice with top element\n(and\nso may be viewed as a Formal Concept Lattice in the sense of Ganter and\nWille (1999)). This means that one way to combine crisp concepts is via their\ndisjunction or least upper bound C = W\ni∈I Ci.\nClassical combinations\nIn Class and Prob, the disjunction is given by\nthe union of subsets Ci.\nIn fact this is seemingly the only natural way to\ncombine concepts. Indeed here any crisp concept may be identified with its set\nof prototypical instances, so that any combination C satisfies Wn\ni=1 Ci ≤ C. In\n6In this article “combination” of concepts is always meant in this sense. However there are\nmany distinct meaningful operations on concepts which could also be called their combination,\nsuch as the more conjunction-like notion of combining “pet” and “fish” into “pet fish” (Aerts\n& Gabora, 2005).\n14\nparticular the classical combination z†\n1 ∨ · · · ∨ z†\nn of instances z1, . . . , zn is the\nsubset {z1, . . . , zn}.\nSpatial combinations\nIn ConSp the disjunction is given by the convex clo-\nsure C = Conv(S\ni∈I Ci) of the convex subsets Ci, the smallest convex subset\ncontaining all of them. Again any combination C has Wn\ni=1 Ci ≤ C. The spatial\ncombination of z1, . . . , zn now includes any convex combination of them.\nExample 6. Consider a model with factors C = colour and T = taste and\na concept B for banana which combines two instances: a yellow (Y ) sweet (S)\nbanana, and a green (G) bitter (B) banana.\nY\nS\nG\nB\nB\nB\n=\n=\n1\nC\nT\nT\nC\nFor simplicity, suppose yellow and green are “orthogonal” in that Y † ◦ G = 0.\nThe classical combination yields the crisp concept whose only points are the two\ninstances (Y, S), (G, B) themselves, which by orthogonality can be equivalently\nwritten as a sum using element-wise addition of matrices in Class:\nD\nC\nT\n=\nY\nS\nG\nB\nC\nT\nC\nT\n+\n(10)\nThe classical combination is depicted left-hand below. The spatial combination\ninstead corresponds to the line connecting the two points (right-hand below).\n✕\n✕\ny, s\ng, b\nColour\nTaste\n✕\n✕\ny, s\ng, b\nColour\nTaste\n(11)\nQuantum combinations\nIn Quant, the disjunction is given by the linear\nclosure C = Lin(S\ni∈I Ci) of all the subspaces Ci, the smallest subspace contain-\ning all of them. This yields a mixed quantum concept which we may interpret as\ntheir “coarse-graining”, and again refer to as their classical combination. Cru-\ncially, however, in a quantum conceptual model there are in fact many possible\nways to combine crisp concepts, aside from the disjunction, even into a pure\nconcept. That is, there are combinations C of the crisp concepts Ci which do\nnot satisfy W\ni Ci ≤ C.\n15\nDefinition 12. In a quantum conceptual model, by a quantum combination of\ninstances ψ1, . . . , ψn we mean a pure concept C = ϕ† with these instances as\nprototypical.\nThe presence of quantum combinations is closely related to entanglement,\ncoming from the fact that instances are only a subset of the points in a quantum\nmodel, since they are non-entangled. Indeed any quantum combination of two\nor more instances will be entangled.\nExample 7. The Bell effect in Example 5 is a pure concept with prototypical\ninstances being precisely those of the form |ψ∗⟩⊗|ψ⟩ for unit vectors |ψ⟩, where\n|ψ∗⟩ denotes the conjugate vector with respect to the given basis. Thus it forms\na pure quantum combination of any such instances.\nExample 8. Consider again the setting of the banana concept combination from\nExample 6. In Quant we can form the classical combination of instances which\nis again of the form (10), where + is now the sum of CP maps. Alternatively,\nwe may form a a quantum combination |ψ⟩ ⟨ψ| where:\nψ = |Y, S⟩ + |G, B⟩ ∈ C ⊗ T\n(12)\nMore generally any linear map f : C → T such that f(|Y ⟩) = |S⟩, f(|G⟩) = |B⟩\ndefines a suitable entangled concept E =\n◦(f ⊗id), where\ndenotes the Bell\nEffect from Example 5. Consider the case where C = T = C2, |Y ⟩ = |S⟩ = |0⟩\nand |G⟩ = |B⟩ = |1⟩. A quantum combination E is now given by the Bell effect.\nThe classical and quantum combinations D, E act on instances as follows:\nD\nψ\nϕ\n=\n1\nX\ni=0\n| ⟨i|ψ⟩ |2| ⟨i|ϕ⟩ |2\nE\nψ\nϕ\n=\n| ⟨ψ∗ | ϕ⟩ |2\nThe classical combination D simply compares any input to the two instances,\nwith no further prototypical instances besides those given.\nAs a result the\nstructure of each space “between” |0⟩ and |1⟩ is lost, with the orthogonal states\n|±⟩ =\n1\n√\n2(|0⟩ ± |1⟩) treated identically and D(|+⟩ ⊗ |−⟩) = 1\n2. In contrast the\nquantum combination E can be seen to encode a structural relationship between\nthe factors, generalising from |00⟩ , |11⟩. Any instance |ϕ∗⟩ ⊗ |ϕ⟩ is prototypical,\nand conversely, tensors of (conjugate) orthogonal points will not fit the concept,\ne.g. E(|+⟩ ⊗ |−⟩) = 0.\nIn the above example we see that entangled quantum concept combinations\ncan encode relationships between factors, rather than simply (weighted) collec-\ntions of exemplars. Indeed any pure entangled concept on C ⊗T corresponds to\na pure linear map f : C → T. We can understand this as a generalisation from\n16\nthe instances into a structural relationship between the factors, akin to a concept\nof the form {(x, f(x)) | x ∈ C} where f is now affine (convexity-preserving).\nAs such, quantum combinations share the benefits of spatial combinations\non a conceptual space, in that one may form structured concepts by generalising\nfrom a small set of instances, as on the right of (11). However, in the quantum\ncase this can be encoded even within a single pure concept. Our conclusion is\nthat entanglement provides an effective way for concepts to encode relationships\nbetween factors in quantum conceptual models.\n2.7\nIs a Quantum Model a Conceptual Space?\nIn comparing conceptual spaces with quantum models, it is natural to ask\nwhether we may view the latter as an instance of the former, while our dis-\ncussion of entangled concepts in the previous section suggested they should be\nconsidered distinct. We now discuss this question in detail. We begin with the\ncase of a model with only a single factor, described by a Hilbert space H.\nHilbert space as a convex space.\nNaively we can first observe that, as\na complex vector space, H does indeed count as a convex space according to\nDefinition 1. However, arbitrary vectors in H do not have a direct physical\ninterpretation as states, but only the unit vectors ψ (after identification up to\nglobal phase) which form the pure states. These pure states do not straightfor-\nwardly form a convex space in the sense of Def. 1, since convex combinations\nof unit vectors are not unit vectors in general.\nPure states as a betweenness space.\nWe can nonetheless view the pure\nstates as a geometric space, in a different way. This is most evident for a qubit\nH = C2, whose pure states are visualised via the surface of the Bloch sphere.\nThough the surface of the sphere does not come with convex mixing in the sense\nof Definition 1, it forms an instance of a broader notion of convex space which\nmay be used to formalise conceptual spaces, known as a Betweenness space\n(G¨ardenfors, 2004, 2014; Aisbett & Gibbon, 2001). This is a set Z along with a\nternary operation B(x, y, z) which says that the point y is “in-between” x and z.\nA subset S is then convex if whenever x, z ∈ S and B(x, y, z), then y ∈ S also.\nThe Bloch sphere forms a Betweenness space when defining B(x, y, z) whenever\na geodesic from x to z passes through y; see Figure 1.\nWe now ask: is the quantum model of concepts on C2 the same as that given\nby the Bloch sphere as a Betweenness space? In fact the sets of concepts in each\nmodel are distinct. Firstly, crisp concepts in the quantum model correspond to\nsubspaces, which on the Bloch sphere are either single points (dimension 1) or\nthe entire sphere (dimension 2). So most convex regions on the sphere, the crisp\nconcepts in the Betweenness space Z, are not valid quantum concepts. Con-\nversely, most quantum concepts are not valid fuzzy concepts in the Betweenness\nspace Z. As argued in Tull (2021) and mentioned before in Def. 4, a fuzzy con-\ncept C : Z → [0, 1] should at least satisfy the notion of quasi-concavity, which\n17\nFigure 1: The Bloch sphere as a Betweenness space, with marked examples of\nbetweenness B(x, y, z), and a convex region shown in purple. The states |ψi⟩ ⟨ψi|\nare used to show that |0⟩ ⟨0| is not quasi-concave.\nstates that if C(x), C(z) ≥ t then the same holds for any y with B(x, y, z).\nExample 9 below demonstrates that quantum concepts can fail to satisfy this\ncondition.\nExample 9. Consider the pure concept C = |0⟩ ⟨0|. Let |ψi⟩ = cos( θi\n2 ) |0⟩ +\nsin( θi\n2 ) |1⟩ for i = 1, 2, 3, as in Figure 1. Setting θ1 =\n2π\n3 , θ2 = π, θ3 =\n4π\n3\nthen |ψ2⟩ ⟨ψ2| = |1⟩ ⟨1| is between |ψ1⟩ ⟨ψ1| and |ψ3⟩ ⟨ψ3|, making C not quasi-\nconcave, since C(|ψ1⟩ ⟨ψ1|) = C(|ψ3⟩ ⟨ψ3|) = 1\n4 > 0 = C(|ψ2⟩ ⟨ψ2|).\nSpaces of mixed states.\nOne may be tempted to instead view a quantum\nconceptual model as a different convex space, namely the space Z = St(H)\nof (pure and mixed) density matrices on H, so that these form the instances\nz ∈ Z. Indeed it follows from linearity that quantum concepts C do satisfy\nquasi-concavity on this space. However, since density matrices are interpreted\nas states of uncertainty over pure quantum states, it is more natural to view\nthem as the analogues of distributions over a conceptual space, rather than\ninstances. Finally, even if one attempts to view a quantum model as a convex\nspace St(H), the manner in which we compose such models via the tensor is\nfundamentally different, making both classes of models distinct:\nSt(H ⊗ K) = St(H) ⊗ St(K) ̸= St(H) × St(K)\nIn summary, due to their treatment of entangled concepts and the arguments\nabove, it is most natural to view quantum models as distinct from conceptual\nspaces. Nonetheless they possess the same benefits for learnability, replacing\nconvex by linear subspaces, and thanks to entanglement may be even more\nnatural for describing correlated concepts.\n18\nx\nz\nθ\nx\nz\nc\nc\nϕ\nN\nψ\nϕ\nθ\nx\nz\nθ\nϕ\nN\nN\nFigure 2: Graphical models for the VAE (left), conditional VAE (centre) and\nthe Conceptual VAE (right). Grey nodes represent observed variables and white\nnodes hidden variables.\n3\nClassical Implementation: The Conceptual VAE\nOur first implementation comes from instantiating the framework using the\nConSp category from Section 2.3, and implementing fuzzy concepts as Gaus-\nsians, as described in Example 2. There is already an existing literature on\nlearning Gaussian representations of concepts, using a tool from machine learn-\ning called the Variational Autoencoder (VAE) (Higgins et al., 2017). Here we\nshow how to extend that work by defining a new VAE model which provides\nexplicit representations of concepts which fit our framework.\n3.1\nVAEs for Concept Modelling\nThe Variational Autoencoder (VAE) (Kingma & Welling, 2014; Rezende et al.,\n2014) provides a framework for the generative modeling of data, where the data\npotentially lives in some high-dimensional space. It uses the power of neural\nnetworks to act as arbitrary function approximators to capture complex depen-\ndencies in the data (e.g. between the pixels in an image). The VAE uses a\nlatent space Z which acts as a bottleneck, compressing the high-dimensional\ndata into a lower dimensional space.7 The question we investigate is whether\nthe VAE model can be adapted so that Z has desirable properties from a concep-\ntual space perspective, such as interpretable dimensions which contain neatly\nseparated, labelled concepts from individual domains.\nFirst we describe the\nstandard VAE model before describing how to adapt it in order to incorporate\nlabelled concepts.\n3.1.1\nThe Vanilla VAE\nFig. 2 (left) shows the graphical model for the VAE. In terms of the generative\nstory, which is represented by the solid arrows in the plate diagram, first a\n7In this section we use bold font for variables, e.g. the conceptual space Z, to be consistent\nwith the machine learning literature.\n19\npoint z in the latent space Z is sampled according to the prior p(z), and then\na data point x is generated according to the likelihood pθ(x|z). The dashed\narrows denote the variational approximation qϕ(z|x) to the intractable posterior\npθ(z|x). The prior is assumed to be a centered isotropic multivariate Gaussian\np(z) = N(z; 0, 1) (Kingma & Welling, 2014). The approximate posterior qϕ(z|x)\nis also assumed to be a multivariate Gaussian with a diagonal covariance matrix,\nbut with means and variances predicted by a neural network with learnable\nparameters ϕ. In our case, since X is a dataset of images, qϕ will be instantiated\nby a convolutional neural network (CNN), which is referred to as the encoder.\nSimilarly, pθ will be instantiated by a de-convolutional neural network (de-\nCNN), and referred to as the decoder.\nThe function that is optimised during training is the RHS of the following\nequation (Doersch, 2016):\nlog p(x) − D(q(z|x), p(z|x)) =\nEz∼q(z|x)[log p(x|z)] − D(q(z|x), p(z))\n(13)\nwhere D is the KL divergence. Note that, since the KL on the LHS is positive,\nthe equation provides a lower bound on the likelihood, known as the evidence\nlower bound (ELBO). The advantage of this formulation is that the RHS can be\nmaximised using gradient-based optimisation techniques. Since the KL on the\nRHS is between two multivariate Gaussians, there is an analytical expression\nfor calculating this quantity, and estimate of the expectation can be obtained\nusing numerical methods, in particular Monte Carlo sampling (together with\nthe reparametrisation trick (Kingma & Welling, 2014)).\nAre the latent representations induced by a VAE in any way conceptual?\nFirst, note that there is no pressure within the model to induce the sorts of\nfactored representations in which the dimensions of Z correspond to conceptual\ndomains. Higgins et al. (2017) attempt to address this problem by introducing\na weighting factor on the KL loss. Second, there is currently no mechanism in\nthe model which allows concepts to be referred to using their names (e.g. blue\nsquare).\n3.1.2\nThe Conceptual VAE\nOne feature that we would like in the model is an explicit representation of\nthe words or symbols that are used to refer to a concept (which we’ll call the\nconcept label). The obvious way to include the concept label in the model is as\nan explicit random variable c. We could use a conditional VAE (Doersch, 2016),\nwith the label acting as an additional input into the decoder, so that when the\ndecoder generates a data instance x, it does so conditioned on c as well as a\npoint from the latent space z (Figure 2; centre). However, with this model there\nis no explicit representation of a concept (beyond its symbolic label). The key to\nthe conceptual VAE is to introduce a new random variable for a concept label,\nc, but introduce it at the very top of the graphical model (Figure 2; right). The\ndifference with the conditional VAE is that each concept c now has an explicit\nset of parameters associated with it, which acts as c’s representation.\n20\nIn terms of the generative story, first a concept label c is generated, and\nthen a point z in the latent conceptual space is generated, conditioned on c;\nafter that the generative story is the same as for the vanilla VAE: an instance\nx is generated conditioned on z. In this work we assume a uniform prior over\nthe concept labels (more specifically a uniform prior over the atomic labels\ncorresponding to each conceptual domain ci), and c can effectively be thought\nof as a fixed input to the model, as provided by the data.\nHow do we model p(z|c)? As before we use multivariate Gaussians with\ndiagonal covariance matrices, but now the means and variances are learnable\nparameters ψ. We will sometimes refer to pψ(z|c) for a given concept c as a\nconceptual “prior” (since these Gaussians replace the unit normal prior in the\nvanilla VAE), as well as c’s learned representation. Since c is factored, each ci\nhas its own (univariate) Gaussian distribution; e.g., red will have its own mean\nand variance which define a Gaussian on the dimension corresponding to the\ncolour domain. It is this Gaussian which provides the anwser to the question\n“what is the conceptual representation for red?”.\nThe ELBO equation now takes the following form:\nlog p(x|c) − D(q(z|x), p(z|x, c)) =\nEz∼q(z|x)[log p(x|z)] − D(q(z|x), p(z|c))\n(14)\nHow is this model trained, and what are the pressures that lead to conceptual\nrepresentations being learned? For a training instance x labelled with a concept\nc, the training proceeds as before for the vanilla VAE: the encoder predicts a\nGaussian q(z|x); this is sampled from (using the reparametrisation trick) to\ngive a sample zs; and − log p(x|zs) is calculated to give the reconstruction loss.\nThe key difference is in the calculation of the KL loss.\nSuppose that c =\n(green, medium, triangle, bottom). The KL is calculated for each dimension,\nrelative to the Gaussian for the particular atomic label for that dimension. For\nexample, for the colour domain (dimension 0), the KL would be between\nqϕ(z0|x) and pψ(z0|green). So note that the supervision regarding the domains\nis provided here in the calculation of the KL.8 Unlike the vanilla VAE, the\nconceptual “priors” depend on the learned parameters ψ, which are the means\nand variances of the individual (univariate) Gaussians. We expect these learned\nmeans and variances to result in a neat separation along a dimension, since\nthis will make it easier for the model to fit q to the conceptual representations,\nleading to a lower KL.\nConceptual space description\nExplicitly, in terms of our framework from\nSection 2.2, our conceptual model is given in the category ConSp, i.e.\nby\na conceptual space.\nThe model is Z = Rn, viewed as a product of n one-\ndimensional domains Z = Qn\ni=1 Zi with Zi = R. An instance is a vector z =\n(z1, . . . , zn) ∈ Z. In particular for each image x ∈ X we obtain an instance via\n8The question of whether, and how, the level of supervision could be reduced and the\ndomains learned automatically is an ongoing debate (Higgins et al., 2017; Locatello et al.,\n2019).\n21\nFigure 3: Example shapes: (green, large, triangle, centre); (blue, small, square,\nbottom); (red, medium, circle, top); (red, medium, square, centre); (green, large, circle,\nbottom).\nthe (deterministic) encoder qϕ(x). Each concept label c = (c1, . . . , cn) defines\na Gaussian fuzzy concept c(z) = p(z | c) with diagonal covariance matrix, as in\nExample 2. It forms a product concept over the domains as in (9), via:\nc(z) =\nn\nY\ni=1\nci(zi)\nwhere each ci(zi) = ci(zi; µi, σ2\ni ) is a one-dimensional Gaussian concept for\nconcept label ci on Zi, with mean µi and variance σ2\ni as trainable parameters.\n3.1.3\nA Concept Classifier\nHere we show how the model can be adapted to act as a concept classifier. Note\nthat, from a computer vision perspective, the classification task is trivial, and\none that we would expect a well-trained CNN to solve. The classification task\nis being used here as a test of whether the induced conceptual representations\ncan be employed in a useful way.\nFrom a probabilistic perspective, the goal is to find the most probable con-\ncept c′ given an input image x:\nc′\n=\narg max\nc\np(c|x)\n(15)\n=\narg max\nc\np(x|c)\n(16)\n≈\narg max\nc\n−D(q(z|x), p(z|c)) + recon loss\n(17)\n=\narg max\nc\n−D(q(z|x), p(z|c))\n(18)\nLine (16) follows from (15) because of the assumed uniform prior over concepts,\nand we use the ELBO from (14) as an approximation to the likelihood in going\nfrom (16) to (17) (where recon loss is the remaining part of the loss after the\nKL). The reconstruction loss is independent of c and so we end up with the\nsatisfying form of the classifier in (18), in which the most likely concept for\nan input x is the one with the smallest KL relative to the encoding of x, as\nprovided by q.\n22\n3.2\nExperiments\nWe use the Spriteworld software (Watters et al., 2019) to generate simple images.\nThese consist of coloured shapes of particular sizes in particular positions in a\n2D box, against a black background.\nFor the main dataset, there are three\nshapes: {square, triangle, circle}; three colours: {red, green, blue}; three sizes:\n{small, medium, large}; and three (vertical) positions: {bottom, centre, top}\n(see Fig. 3). We ran the sampler to generate a training set of 3,000 instances,\nand development and test sets with 300 instances each. Appendix A contains\nthe parameters used in the Spriteworld software to generate the main dataset.\nThe encoder, which takes an image x as input, is instantiated as a CNN,\nwith 4 convolutional layers followed by a fully-connected layer. A final layer\npredicts the means and variances of the multivariate Gaussian qϕ(z|x). The\nReLU activation function is used throughout. The decoder, which takes a latent\npoint z as input, is instantiated as a de-CNN, with essentially the mirrored\narchitecture of the encoder. The reconstruction loss we use on the decoder for\npredicting the pixel values in an image x is the MSE loss.\nThe implementation was in Tensorflow. The full set of parameters to be\nlearned is θ ∪ ϕ ∪ ψ, where θ is the set of parameters in the encoder, ϕ the\nparameters in the decoder, and ψ the means and variances for the conceptual\nrepresentations (12 each for the main dataset). The training was run for 200\nepochs (unless stated otherwise), with a batch size of 32, and the Adam op-\ntimizer was used. Finally, we added 2 “slack” dimensions to the latent space\nZ, in addition to the 4 dimensions for the conceptual domains. These slack\ndimensions are intended to capture any remaining variability in the images,\nbeyond that contained in the concepts themselves. Appendix B contains more\ndetails of the neural architectures used in our experiments, including the various\nhyper-parameter choices.\n3.2.1\nClustering Effects and Classification Accuracy\nFigure 4 shows the means and log-variances predicted by the encoder for each\ndimension, for a set of instances, with the colour-coding indicating the atomic\nconcept labels from the different domains. For example, in the set of 4 plots\nat the top left, the means and log-variances for dimension 0 are plotted; and\nin the top-left of those 4 plots, each point is colour-coded with the colour of\nthe corresponding instance. What this plot shows is the neat separation for the\nmeans along the colour dimension, for each of the 3 colours. The other 3 plots\ncontain the same set of points, but colour-coded with atomic labels from the\nremaining domains of size, shape and position. With the 3 remaining plots\nwe expect to see no discerning pattern, since we would like the first dimension to\nencode colour only (although note that, in this particular training run, dimen-\nsion 1—corresponding to size—does appear to be encoding some information\nabout the colour).\nThe plots were created using the model evaluated on classification accuracy\nbelow, which performed well on the development data. The instances were taken\n23\nFigure 4: The means and log-variances for each dimension predicted by the\nencoder, for a set of instances; means on the x-axis, log-variances on the y-axis.\nColour-coding, from top-left clockwise: colour, size, position, slack-dim-2,\nslack-dim-1, shape.\n24\nfrom the training data.9 The plots in the top-right are for dimension 1 (corre-\nsponding to size), and again we obtain a neat separation for the means, when\ncolour-coded with the size of the instance, with instances labelled medium sit-\nting in the middle. The second-row (right) plots are for dimension 3 (position),\nand again we see a neat separation of the means with instances labelled centre\nsitting between those labelled top and bottom. The second-row (left) plots are for\ndimension 2 (shape). Here we see a clear separation with the predicted means\noccupying a short range, which reflects the discrete nature of these concepts.\nThe plots for the slack dimensions are in the bottom row, with no discernible\npattern (except perhaps in the size dimension bottom-right).\nWe evaluated the same model as a classifier, using the formulation in (15)-\n(18) above. The accuracy on the development data for the colour and shape\ndomains was 100%, with accuracies above 98% for the other two domains. These\nhigh accuracies transferred over to the test data.\n3.2.2\nContinuity within Domains\nFigures 5 and 6 provide further qualitative demonstration of how the conceptual\ndomains are neatly represented on each dimension. An instance of a large red\ncircle in the centre and a medium-sized blue square at the bottom are passed\nthrough the encoder, giving a mean for each of the 4 dimensions. Then, the mean\nvalue is systematically varied for one of the dimensions only (through regular\nincreases and decreases), keeping the other 3 fixed. All resulting combinations\nof the 4 mean values are then input to the decoder, giving the images in the\nfigure.10 What the transitions clearly demonstrate is not only how one latent\ndimension encodes just one domain, but also how the concepts smoothly vary\nalong one dimension. Note how in both examples dimension 2 encodes a shape\nsomewhere between a triangle and a circle, and also a shape somewhere between\na circle and a square. Dimension 1 shows a smooth transition from small to\nmedium to large, and dimension 3 from bottom to center to top.\nIn order to investigate these ordering effects further, we created a new dataset\nwhich contains all the colours of the rainbow, with the same shapes, sizes and\npositions. The continuous colour ranges now cover a much larger proportion of\nthe range of possible values (see Appendix A.1), with the occasional gap (e.g.\nbetween green and blue). The training data again consisted of 3,000 randomly\ngenerated instances, with a development set of 300 instances.\nAgain we chose a trained model which performed well on the classification\ntask on the development data (with accuracies well into the 90s for all domains),\nand plotted the colour-coded means and variances as predicted by the encoder.\nFigure 7 again shows a neat separation for the colour domain, with very similar\npatterns for the other domains (not shown), and to those exhibited in Figure 4.\nLooking carefully at the plot in the top-left, we see that the colours are not\nonly neatly separated along the colour dimension, but also that the ordering\n9The same patterns were observed on the development data. We used the training data\nsince this gives denser plots.\n10The idea of plotting transitions along a dimension is taken from Higgins et al. (2017).\n25\nFigure 5: Traversals along each latent dimension for a large red circle in the\ncentre.\nFigure 6: Traversals along each latent dimension for a medium-sized blue square\nat the bottom.\n26\nFigure 7: The means and log-variances for colour predicted by the encoder,\nfor the rainbow colour set.\nFigure 8: Traversals along the colour dimension for two examples from the\ncolour-extended dataset.\n27\nof the rainbow is faithfully represented: blue, indigo, violet, red, orange, yellow,\ngreen. Fig. 8 shows an example traversal along the colour dimension only, for\nthe colour-extended dataset, again demonstrating an ordering consistent with a\nrainbow.\n4\nQuantum Implementation: A Hybrid Network\nwith PQCs\nIn this section we also set up a probabilistic learning objective in order to induce\nconceptual representations, but using a discriminative classifier rather than a\ngenerative model. In addition, the classifier is implemented as a hybrid network\nconsisting of a classical convolutional neural network (CNN) (Goodfellow et al.,\n2016, Ch.9) followed by a parameterised quantum circuit (PQC) (Benedetti et\nal., 2019). We use the network to classify the same set of images and labels\nfrom the classical experiments in Section 3.\n4.1\nThe Hybrid Network\nAn input image is first processed by a CNN which outputs classical parameters\nwhich are fed into a PQC. This PQC we call the encoder PQC; it implements a\nquantum state z which is the representation of the image in our model. Given a\nconcept C, a separate concept PQC implements a quantum effect corresponding\nto C which can be applied to the instance z, as described in Sections 2.2 and 2.4.\nWe assume that the factorisation of the model into the domains H1, . . . , Hn is\nknown by the model; in our experiments these will be the four domains shape,\ncolour, size, position. The overall setup is shown below, with thin wires\ndenoting classical data and each thick wire denoting a Hilbert space given by\nsome number of qubits.\nCNN\nEncoder PQC\nConcept PQC\nImage\nθ\nConcept\nparams\n. . .\nClassification\nH1\nHn\n. . .\nMeasurement\n28\nGiven an input image and the parameters encoding a concept, a single run of\nthe circuit produces a “yes” or “no” to determine whether the concept has been\ndeemed to fit the image. The probability of each outcome is obtained either\nby sampling the circuit many times (on a physical device) or direct calculation\n(in simulation). With the probabilities for each concept, one can then classify\nwhich concept best fits the input image.\nIn more detail, each instance z is a pure quantum state given by passing an\nimage X into the CNN and then using the resulting parameters in the encoder\nPQC network:\nCNN\nEncoder PQC\nX\n. . .\nH1\nHn\nz\n. . .\nH1\nHn\n=\nEach specific concept C can be understood as a measurement with two out-\ncomes “yes” and “no”, such that outcome “yes” means the concept has been\ndeemed to fit the instance. The measurement is given by a Pauli-Z measure-\nment on each qubit, with the overall outcome “yes” identified with obtaining\noutcome 0 on every qubit individually, and all other outcomes labelled as “no”.\nDiagrammatically this is expressed as follows:\nConcept PQC\n. . .\nH1\nHn\nC\n. . .\nH1\nHn\n:=\n0\nϕC\n0\n(19)\nwhere ϕC are the parameters encoding the concept C. Each concept C can be\neither pure or mixed, depending on whether a pure or mixed circuit is chosen\nfor the concept PQC, which we discuss in Section 4.1.1.\n4.1.1\nThe CNN and PQCs\nWe use the same CNN from the classical experiments in Section 3.2 for the\nimage processing. For the classical experiments the CNN predicted the means\nand variances of a multivariate Gaussian, whereas here the CNN predicts the\nparameters of the encoder PQC. The PQCs make use of the parameterised\ncircuit ansatz shown below, defined over any finite collection of qubits. The\nansatz U(θ) is given by performing parameterised X, Y, Z rotations on each\nqubit, followed by entangling pairs of adjacent qubits using controlled Z gates\n(with an additional gate operating on the two outermost qubits to complete the\nchain). Multiple layers of this ansatz can be composed to give a more complex\n29\ncircuit. We define another ansatz V (θ) in the same way but with initial rotations\nin the reverse order Z, Y, X. An important special case is that, when given on\na single qubit, U(θ) is simply equal to sequential parameterised X, Y and Z\nrotations. Similarly V (θ) on a single qubit amounts to rotating in the order\nZ, Y, X.\nRX\nθ1\nRY\nθ1\nRZ\nθ1\nU(θ)\n:=\n. . .\n. . .\n. . .\nRX\nθ2\nRY\nθ2\nRZ\nθ2\nRX\nθ3\nRY\nθ3\nRZ\nθ3\nRX\nθn−1\nRY\nθn−1\nRZ\nθn−1\nRX\nθn\nRY\nθn\nRZ\nθn\n. . .\n(20)\nIn the above each θj = (θj,X, θj,Y , θj,Z) consisting of three single parameters\npassed respectively to the X, Y, Z rotations on qubit j = 1, . . . , n. All are in\nturn contained in the parameters vector θ. In fact this ansatz is universal in\nthat with sufficient layers of the form U(θ) one may implement any unitary\ncircuit.11\nNow let us describe the encoder and concept PQCs in more detail. Both\nconsist of some number of qubits per domain Hi. The form of the encoder PQC\nis as follows:\nEncoder PQC\nH1\nHn\n=\nU(θ1)\nH1\nHn\nU(θn)\n. . .\n. . .\nθ\n0\n0\nMore generally we can compose multiple layers of such U circuits on each do-\nmain. Here the |0⟩ states denote product states |0 . . . 0⟩ on each Hi. Thus by\nconstruction the encoder never involves entanglement across domains, and can\nbe viewed as a single encoder per domain. Since the ansatz U is universal, the\nencoder is able to prepare an arbitrary quantum instance.\nIn the initial basic setup used, beginning in Section 4.2, we only have one\nqubit per domain Hi, and only use one layer in the encoder. In this case the\nencoder simply carries an X, Y and Z rotation per qubit, involving no entan-\nglement. In this basic setup, the concept PQC also involves no entanglement,\n11The entangling layer is self-inverse, so that two layers allow us to implement a rotation on\nany qubit. A swap operation on any pair of qubits can be implemented using three layers, and\nfrom this any CX gate. Hence we may implement the universal gate set given by single-qubit\nphase and Clifford gates; see, for example, Van de Wetering (2021).\n30\ntaking the following form.\nConcept PQC\nH1\nHn\n:=\nV (ϕC\n1 )\nH1\nHn\nV (ϕC\nn )\n. . .\n. . .\n. . .\nH1\nHn\nH1\nHn\nϕC\n(21)\nConcretely, with four domains and one qubit per domain, in this setup the\napplication of a concept C to an instance z amounts to the (probability of the)\ncircuit shown below with post-selection, where θ is the encoding of the image\nfrom the CNN, ϕC are the learned concept parameters and each wire is a single\nqubit.\nRX\nϕC\n1\nRY\nϕC\n1\nRZ\nϕC\n1\nRX\nϕC\n2\nRY\nϕC\n2\nRZ\nϕC\n2\nRX\nϕC\n3\nRY\nϕC\n3\nRZ\nϕC\n3\nRX\nϕC\n4\nRY\nϕC\n4\nRZ\nϕC\n4\n0\n0\n0\n0\n=\nC\nRX\nθ1\nRY\nθ1\nRZ\nθ1\nRX\nθ2\nRY\nθ2\nRZ\nθ2\nRX\nθ3\nRY\nθ3\nRZ\nθ3\nRX\nθ4\nRY\nθ4\nRZ\nθ4\n0\n0\n0\n0\nz\n(22)\nIn order to capture mixed and entangled concepts, in Section 4.4 we use a\nricher form for the concept PQC. Entanglement is provided by using the full\nansatz V (θ) over all domains. To introduce mixing, we use an ancilliary copy\nof each domain H1, . . . Hn, prepared in initial state |0⟩, and then discard the\noriginal domains as in the following circuit:\nConcept PQC\nH1\nHn\n:=\nH1\nHn\n. . .\n. . .\n. . .\nH1\nHn\nH1\nHn\nϕC\nV (ϕC)\n0\nH1\nH1\nHn\nHn\n. . .\n. . .\n. . .\n0\n(23)\nMore generally one can include multiple V layers prior to discarding. Note that\n31\nsince this ansatz is universal we can implement any unitary with sufficient layers\nof the form V , and thus any (sub-normal) quantum concept.\n4.1.2\nDiscriminative Training\nThe classical concepts model from earlier is a generative model consisting of an\nencoder and a decoder. Here we choose to train the quantum model to perform\nbinary classification; hence the basic model is a discriminative model with an\nencoder only.12 The loss function is the standard binary cross entropy (BCE)\nloss for binary classification. The full set of parameters to be learned is ψ ∪ ϕ,\nwhere ψ is the set of parameters in the classical encoder CNN and ϕ is the set\nof PQC parameters associated with the set of 12 basic concepts.\nThe training data contains the 3,000 positive examples from Section 3.2 and\nan additional 3,000 negative examples. Each negative example is created from\na positive one by randomly sampling an incorrect concept for each domain; for\nexample, if the positive example is (green, large, triangle, centre) then a nega-\ntive example could be (blue, medium, square, bottom). Since we are effectively\nlearning each domain independently in the basic model, a negative example\ndisagrees on every domain. Later models will use variations on this data.\nThe implementation is in Tensorflow Quantum, and the whole hybrid network—\nboth the quantum and the classical parts—are trained end-to-end in simulation\non a GPU. The training was run for 100 epochs (unless stated otherwise), with\na batch size of 64 (32 images, each with a postive and negative label), and the\nAdam optimizer was used.\n4.2\nInstance States and Concept Effects\nWe trained a quantum model, using the circuit shown in (22) above, and tested\nit on the 300 examples in the development set.\nThe model was trained to\nperform binary classification, but at test time we choose the concept for each\ndomain which has the highest probability of applying to the input image. The\nclassification model performed with almost perfect accuracy, obtaining 100% on\nthe colour and shape domains, and 99% and 97% on the position and size\ndomains, respectively. This high accuracy carried over to the 300 examples in\nthe test set, obtaining 100% on the colour and shape domains, and 96% and\n97% on the position and size domains, respectively.\nFigure 9 visualises the pure effects for each of the 3 concepts on the 4 do-\nmains, by plotting the corresponding pure states on a Bloch sphere. We are\nable to perform the visualisation for this basic model since only one qubit is\nbeing used per domain, with no entanglement.\nThe clusters of dots around\neach concept are the corresponding instances (pure states) in the training data.\nThis visualisation is for the model which performs as described above on the\nclassification task; a model trained from a different random initialisation would\nhave the concepts and instances distributed differently around the sphere, but\n12In Section 4.2.2 below we investigate how the addition of a decoder can affect the instance\nand concept representations.\n32\nFigure 9: Visualisation of the pure concept effects and instance states on the\nBloch sphere, for shape, colour, size and position.\nFigure 10: Visualisation of the concept effects and instance states on the Bloch\nsphere, for 3 trained models, for the colour domain on the rainbow dataset.\nthis visualisation is representative in terms of how the concepts are typically\nseparated and the instances clustered. Note how the 3 concepts on each domain\nare being pushed apart (strikingly so in the case of the position domain) and\nhow the concepts sit neatly in the centre of each cluster of instances.\n33\n4.2.1\nThe Rainbow Dataset\nIn order to test our model further, we used the rainbow dataset from Section 3.2,\nand in order to train the discriminative model, we added a further 3,000 negative\nexamples (for each epoch) to the 3,000 positive ones, randomly generated as\nbefore. Perhaps unsurprisingly, it was more difficult with this data to obtain a\nclean separation of the colours on a single qubit.13 However, with a weighting\nof 0.5 applied to the negative examples in the binary cross-entropy loss, and\nrunning the training for 200 epochs, we were able to obtain the distribution\nof colours around the Bloch sphere shown in Figure 10 (with instances again\ntaken from the training data). The three visualisations are for three separately\ntrained models (i.e.\nwith three different random initialisations of the model\nparameters).\nIn terms of accuracy on the development data, the classification model for the\nBloch sphere on the far left achieved similar scores on the non-colour domains as\nbefore, and an overall accuracy of 95% on colour, with F1-scores ranging from\n91% to 100% for the individual colours. The Bloch sphere in the middle is for\na model with similar performance, and is shown to demonstrate the variation\nin models. The example on the far right is cherry-picked as an example of how\nthe training is able to neatly represent the various colours on the Bloch sphere:\nnote how the yellow, orange and red instances are beautifully placed on the\ncircumference of a circle, with the red instances leading into orange and then\nyellow.\n4.2.2\nAdding a Decoder Loss\nOne notable feature of the visualisations in Figure 9 is how “tight” the instance\nclusters are, despite the variation in the images for a single concept (for example\nthe variation in red shapes in Figure 3).\nThere may be use-cases where we\nwould like the representation of instances to better reflect the variation in the\nunderlying images, for example in order to better capture correlations across\ndomains (see Section 4.3 below).\nIn order to provide more of a “spread” of the instances, we experimented\nwith an additional decoder loss in the loss function below, where BCE is the\nbinary cross-entropy loss, D is the data with N instances {Xi}i, and ψ and ϕ\nare the parameters of the encoder network:\nLoss(D, ψ, ϕ, χ) = BCE(D, ψ, ϕ) + λ\nN\nX\ni\nSE(DeCNN(χ, CNN(ψ, Xi)), Xi)\n(24)\nThe decoder is a deconvolutional neural network (DeCNN), with parameters χ,\nwhich essentially is the CNN “in reverse”: it takes as input the angles output\n13Of course there is nothing to prevent us from using more than one qubit per domain, in\norder to provide a larger Hilbert space in which to represent the additional colours, but the\nvisualisation is harder with more qubits.\n34\nFigure 11: Visualisation of the concept effects and instance states for all 4\ndomains, for the basic dataset with an additional decoder loss.\nby the CNN, given an image Xi, and outputs RGB values for each pixel in the\nimage. SE is the sum of squared errors across all RGB values in the image,\nand λ is a weighting term in the overall loss. The intuition is that, in order to\nobtain a low SE loss, the encoder CNN has to output angles which are sufficiently\ninformative in order for the DeCNN to accurately reconstruct the original image.\nNow the model is similar to the Conceptual VAE (albeit without the generative\nmodel interpretation), in that it has both “encoder” and “decoder” parts to the\nloss.14\nFigure 11 shows how the instances can be distributed more broadly around\nthe Bloch sphere, using the additional decoder loss (with λ = 0.1). This model\nstill performs well as a classification model on the development data, achieving\n98% accuracy on size, 99% on colour, 100% on shape, and 98% on position.\nAs a qualitative demonstration of this approach, note how the instances for\ncentre and top start to merge into each other (blue and red instance dots bottom\nright), and also for medium and small (blue and red instance dots bottom left),\nwhich is what we would expect for a less discrete representation.\n14One possibility for future work is to develop and implement a “quantum VAE”\n(Khoshaman et al., 2018) for concept modelling, and have a generative model in which all\nparts of the model are quantum.\n35\nFigure 12: Examples of twikes (on the left) and non-twikes (on the right).\n4.3\nCapturing Correlations\nHere we show how one of the characteristic features of quantum theory, namely\nentanglement, can be used to capture correlations across domains.\nIn order\nto test whether our model can handle concepts which contain correlations, we\ndefine a new concept which we call twike, which is defined as (red and circle)\nor (blue and square) (i.e. it applies to images containing red circles or blue\nsquares). Figure 12 shows some examples of twikes and non-twikes.\nThe concept PQCs we have considered so far, of the form in (21), are unable\nto learn the concept twike, since the domains have been treated independently,\nwith each of the 4 domains effectively containing its own independent concept.\nIn order to create connections between the domains in the concept PQC, we can\napply our full ansatz V from Section 4.1.1, involving controlled-Z gates between\nwires, across multiple domains. In this first experiment we assume knowledge of\nthe fact that, for the twike concept, the correlations are across the shape and\ncolour domains, with entangling gates only between the qubits for shape and\ncolour. (This assumption will be relaxed for some of the experiments below.)\nWe also assume that the remaining domains are not relevant and so are not\nmeasured, thus effectively being discarded in the concept. We apply potentially\nmultiple layers of ansatz V to the relevant domains, and so the resulting form\nof the twike concept over the four domains is as shown in Figure 13, where ϕ\nare the learned parameters for the twike concept.\nThe training of this model only updates the rotation parameters of the con-\ncept PQC; the parameters of the encoder (i.e. the CNN) are kept fixed from the\nearlier training of the basic model. The loss function is binary cross entropy, as\nbefore, with the 3,000 examples from Section 3.2 used as training data. Roughly\n20% of these instances are positive examples of twike, with the remaining be-\ning negative examples. We trained this model for 50 epochs, using 2 layers of\nthe rotation and entangling V ansatz for the concept PQC, and obtained 100%\naccuracy on the unseen test examples. It was only through the introduction of\nthe entangling gates that we were able to learn the twike concept at all.\nIn terms of the discussion of entanglement and classical correlation in Sec-\ntion 2.5, we can say that the twike concept can be naturally described without\n36\ntwike\n:=\n0\n0\nV (ϕ1)\nV (ϕ2)\nV (ϕ3)\nHshp Hsize Hcol Hpos\nHshp Hsize Hcol Hpos\nFigure 13: Encoder PQC for learning twike, here shown with 3 layers of the\nrotation and entangling V ansatz.\nentanglement, as a classical combination of the pure concepts red circle and blue\nsquare (at least in the case where these pure effects are orthogonal). However,\nsuch correlations are not always immediately implementable in many conven-\ntional classical models. In terms of the Conceptual VAE, it would be possible to\ncapture correlations using the covariance matrix of the multivariate Gaussian.\nHowever, a standard assumption in VAEs is to assume a multivariate Gaus-\nsian with a diagonal covariance matrix (and so no correlations across domains).\nWhether a concept like twike could be easily modelled using the Conceptual\nVAE, especially as the number of domains is increased, is left as a question for\nfuture work.\n4.4\nLearning General Mixed and Entangled Concepts\nOne assumption made above in the twike experiments was that the relevant\ndomains—in this case shape and colour—are known in advance, so that the\nconcept PQC can effectively ignore the wires corresponding to the other do-\nmains. One interesting question is whether the concept PQC could also learn\nwhich domains are relevant, as well as which of those domains should be cor-\nrelated, if provided with all 4 wires as input. To allow for such correlations\nbetween arbitrary domains, the concept PQC should allow for entanglement\nbetween any of its domains. Furthermore, to enable discarding of domains, we\nrequire mixed quantum effects. Both of these features can be included by using\nour most general form of the concept PQC (23).\nIn order to test the learning of these general concepts, we set up a similar\nexperiment to twike, but this time with just red as the concept to be learned.\nOf course the encoder had already learned red when trained to perform classifi-\ncation in the basic setup, but in this experiment we remove knowledge of which\nwire the colour domain is on, and see whether a new concept PQC can learn\nred, given red and non-red instances as input.\nAgain the training of this model only updates the rotation parameters of\nthe concept PQC; the parameters of the CNN are kept fixed. The loss function\n37\nis again binary cross entropy, with the usual 3,000 examples as training data.\nRoughly 33% of these instances are positive examples of red, with the remaining\nbeing negative examples. We trained this model for 50 epochs, using 2 layers\nof rotation and entangling gates for the concept PQC, and obtained 100% ac-\ncuracy on the unseen test examples. It was only through the introduction of\nthe discarding (plus entangling gates) that we were able to obtain these high\naccuracies.\n4.5\nConcepts containing Logical Operators\nFor one final set of experiments, we investigated whether the entangling and\ndiscarding PQC (23) could learn concepts built from logical operators, with\nconcepts such as red or blue.\n4.5.1\nConjunction across Domains\nThe first concept with a logical operator that we consider is red and circle, firstly\nwith the knowledge of which domains are relevant for the concept (in this case\ncolour and shape). The encoder PQC is the simple one from (22), but with\nonly the colour and shape wires (so the other two are effectively discarded).\nWe used the same 3,000 training examples, of which roughly 17% are positive\nexamples and 83% negative examples. In this case the learning is particularly\neasy, and the model obtains 100% accuracy with only a single layer of rotations\nfor the PQC, without any entangling gates or discarding of any ancilliary qubits.\nThe reason is that the factorisation of the domains through the tensor product\nhas effectively provided all the structure required to use conjunction.\nWhen the knowledge of which domains are relevant is removed, and the more\ngeneral encoder PQC in (23) is used, learning becomes harder but an encoder\nPQC with 4 layers of rotation and entangling gates is able to learn the concept\nwith 100% accuracy.\n4.5.2\nDisjunction within Domains\nNext we consider disjunction, but within rather than across domains, with the\nconcept to be learned being red or blue. Of the 3,000 training examples, 61% are\npositive examples and 39% negative. Again, when knowledge of which domains\nare relevant is provided to the concept PQC, the learning is easy, with 100%\naccuracy obtained with a single layer of rotations.\nIf each point on the Bloch sphere were to correspond to an instance of the\ncolour domain, i.e. a single colour, as in our model, then the PQC learning\nsuch a pure effect for red or blue will in fact be simply learning a single colour,\nintuitively somewhere “in between” red and blue. When the domain only comes\nwith a few concepts, such as the 3 concepts used here, this single instance may\ndo well in approximating red or blue, as with the 100% accuracy. However, in\nthe presence of more concepts, we expect that a concept for red or blue should\ninvolve mixing.\nAnd when knowledge of which domains are relevant is not\n38\nprovided to the PQC, red or blue can also be successfully learned with the more\ngeneral PQC in (23) with 3 layers of rotation and entangling gates, including\ndiscarding.\n5\nRelated Work\nThe Conceptual VAE is inspired by Higgins et al. (2017), who introduced the\nβ-VAE for unsupervised concept learning. However, the focus of Higgins et al.\nis on learning the conceptual domains, i.e. the underlying factors generating\nthe data (Bengio et al., 2013), which they refer to as learning a disentangled\nrepresentation. The main innovation to encourage the VAE to learn a disen-\ntangled, or factored, latent space is the introduction of a weighting term β on\nthe KL loss. Higgins et al. show that setting β to a value greater than 1 can\nresult in the dimensions of Z corresponding to domains such as the lighting or\nelevation of a face in the celebA images dataset, or the width of a chair in a\ndataset of chair images. Our focus is more on the conceptual representations\nthemselves, assuming the domains are already known, and the question of how\nconcept labels can be introduced into the VAE model.\nA paper in NLP that uses a model very similar to the Conceptual VAE\nis Braˇzinskas et al. (2018) which introduces the Bayesian skip-gram model for\nlearning word embeddings. One key difference which distinguishes our work\nfrom the word embeddings typically used in NLP is that we do not restrict our-\nselves to the textual domain, meaning that our conceptual representations are\ngrounded in some other modality (in our case images) (Harnad, 1990), bringing\nthem closer to the human conceptual system. Another relevant paper from the\nNLP literature, which does consider grounding, is Schlangen et al. (2016), where\nthe meanings of words are treated as classifiers of perceptual contexts, similar\nto how we use classification to induce conceptual representations.\nThe Conceptual VAE uses Gaussians to represent concepts, since they are\nthe typical distributions used with VAEs and because they are convenient from\na mathematical perspective. However, the use of Gaussians is also prevalent in\nthe neuroscience literature, appearing for example as the Laplace assumption in\nthe “free-energy” or “predictive processing” framework (Friston & Kiebel, 2009;\nBogacz, 2017).\nIn terms of the quantum models, Smolensky has a large body of work argu-\ning for tensor product representations in linguistics and cognitive science more\nbroadly (Smolensky & Legendre, 2006). Recently these techniques have been\nintegrated into neural models for NLP (Huang et al., 2018). Another line of\nwork which associates tensor-product representations with grammatical struc-\nture is the “DisCoCat” research program attempting to build distributed, com-\npositional representations of language, which began with Coecke et al. (2010).\nRecently this work has culminated in the running of quantum NLP models on\nreal quantum hardware (Lorenz et al., 2023).\nThe field of quantum cognition (Pothos & Busemeyer, 2013) has already\nbeen mentioned. Some recent work in this area includes Epping and Busemeyer\n39\n(2022) and Epping et al. (2021), where the latter is concerned with modelling\nhuman judgements of colour similarity and uses a Hilbert space representation\nsimilar to our models. The learning of concepts containing logical operators\nhas a formal connection to quantum logic (Birkhoff & von Neumann, 1936)\nand Boolean concept learning in general, for which there is a large literature\n(Goodwin & Johnson-Laird, 2013).\n6\nConclusion and Further Work\nIn this article we have presented a new modelling framework for structured\nconcepts using a category-theoretic generalisation of G¨ardenfors’ conceptual\nspaces, and shown how the conceptual representations can be learned automat-\nically from data, using two very different instantiations: one classical and one\nquantum. The main contributions of this foundational work are the category-\ntheoretic formalisation, and the two practical demonstrations, especially the\nquantum implementation which is particularly novel. Substantial further work\nis required to demonstrate that the framework can be applied fruitfully to data\nfrom a psychology lab, which would connect our work directly with quantum\ncognition, and also to agents acting in (virtual) environments, which would\nconnect it to agent-based AI (Abramson et al., 2020).\nIn future more interpretative work on quantum concepts is needed to clarify\ntheir advantages, such as those offered by entanglement discussed in Section 2.5,\nand their naturality as a model in cognition. Another benefit of quantum models\nover conceptual spaces not explored here is the presence of a “negation” C⊥ on\nconcepts with C ≤\n(Rodatz et al., 2021; Shaikh et al., 2021). In contrast,\nnegation is harder to define for concepts in conceptual spaces; for example the\ncomplement of a convex region is generally non-convex.\nAnother interesting question is whether the Conceptual VAE can be applied\nto data generated from a conceptual hierarchy—for example having shades of\ncolour such as dark-red—and whether the learned Gaussian representations for\nconcepts can be partially ordered in an appropriate way (Clark et al., 2021). The\nquantum concepts as effects have a natural ordering, as discussed in Section 2.4,\nand it would be an interesting comparison to see if hierarchies could be more\neasily learned with the quantum models.\nTo make full use of the compositional approach, one should also describe\nconceptual processes, such as reasoning processes and “metaphorical” mappings\nbetween domains, now given by CP maps between quantum models. One could\nthen compare these with the processes in the category ConSp of fuzzy concep-\ntual processes from Tull (2021).\nFinally, even though all the practical work here has been carried out in\nsimulation on a classical computer, the number of qubits is relatively small,\nand the circuits relatively shallow, and so the running of these models on real\nquantum hardware is a distinct possibility. Also left for future work is the search\nfor tasks which could demonstrate advantages for our quantum representations,\nfor example establishing whether non-separable effects in the theory do provide\n40\nan advantage over classical correlation in modelling conceptual structure.\nAcknowledgements\nThanks to Lia Yeh, Robin Lorenz and Douglas Brown for extremely detailed\nand helpful comments on an earlier draft, and also to the rest of the Oxford\nQuantum Compositional Intelligence team.\nDeclarations\n• Authors’ contributions: Sean Tull developed the mathematical formalisa-\ntion and wrote the theory sections. Razin A. Shaikh wrote the code, ran\nthe experiments, and prepared some of the figures. Sara Sabrina Zemljiˇc\ncreated the data and helped run the experiments. Stephen Clark oversaw\nthe project, ran some of the experiments, and wrote the remainder of the\nmanuscript. All authors took part equally in setting the general direction\nof the project.\n• Code availability: The code for generating the data and running the ex-\nperiments is available at: https://github.com/CQCL/concepts-vae.\nReferences\nAbramson, J., Ahuja, A., Barr, I., Brussee, A., Carnevale, F., Cassin, M., . . .\nDeepMind-Interactive-Agents-Group (2020). Imitating interactive intelli-\ngence. arXiv preprint arXiv:2012.05672.\nAerts, D. (2009). Quantum structure in cognition. J. Math. Psychol, 53(5),\n314–348.\nAerts, D., & Gabora, L. (2005). A state-context-property model of concepts and\ntheir combinations I: the structure of the sets of contexts and properties.\nKybernetes, 34, 151-175.\nAisbett, J., & Gibbon, G. (2001). A general formulation of conceptual spaces\nas a meso level representation. Artificial Intelligence, 133(1-2), 189–232.\nBechberger, L., & K¨uhnberger, K.-U.\n(2017).\nA thorough formalization of\nconceptual spaces. In Joint German/Austrian conference on artificial in-\ntelligence (k¨unstliche intelligenz) (pp. 58–71).\nBenedetti, M., Lloyd, E., Sack, S., & Fiorentini, M. (2019). Parameterized\nquantum circuits as machine learning models.\nQuantum Sci. Technol.,\n4(043001).\nBengio, Y., Courville, A., & Vincent, P. (2013). Representation learning: A\nreview and new perspectives. IEEE Transactions on Pattern Analysis &\nMachine Intelligence.\nBirkhoff, G., & von Neumann, J. (1936). The logic of quantum mechanics.\nAnnals of Mathematics, 37(4), 823–843.\n41\nBogacz, R.\n(2017).\nA tutorial on the free-energy framework for modelling\nperception and learning. Journal of mathematical psychology, 76, 198–\n211.\nBolt, J., Coecke, B., Genovese, F., Lewis, M., Marsden, D., & Piedeleu, R.\n(2019). Interacting conceptual spaces I: Grammatical composition of con-\ncepts. In Conceptual spaces: Elaborations and applications (pp. 151–181).\nSpringer.\nBraˇzinskas, A., Havrylov, S., & Titov, I. (2018, August). Embedding words as\ndistributions with a Bayesian skip-gram model. In Proceedings of the 27th\ninternational conference on computational linguistics (pp. 1775–1789).\nSanta Fe, New Mexico, USA: Association for Computational Linguistics.\nRetrieved from https://aclanthology.org/C18-1151\nCho, K., & Jacobs, B. (2019). Disintegration and bayesian inversion via string\ndiagrams. Mathematical Structures in Computer Science, 29(7), 938–971.\nCho, K., Jacobs, B., Westerbaan, B., & Westerbaan, A. (2015). An introduction\nto effectus theory. arXiv preprint arXiv:1512.05813.\nClark, S., Lerchner, A., von Glehn, T., Tieleman, O., Tanburn, R., Dashevskiy,\nM., & Bosnjak, M. (2021). Formalising concepts as grounded abstractions\n(Tech. Rep.). https://arxiv.org/pdf/2101.05125.pdf: DeepMind, London.\nCoecke, B., & Kissinger, A. (2017). Picturing quantum processes: A first course\nin quantum theory and diagrammatic reasoning. Cambridge University\nPress. doi: 10.1017/9781316219317\nCoecke, B., Sadrzadeh, M., & Clark, S.\n(2010).\nMathematical foundations\nfor a compositional distributional model of meaning. In van Bentham &\nMoortgat (Eds.), Linguistic analysis 36 (1-4): A festschrift for Joachim\nLambek.\nDoersch, C.\n(2016).\nTutorial on variational autoencoders (Tech. Rep.).\nhttps://arxiv.org/abs/1606.05908: UC Berkeley.\nEpping, G. P., & Busemeyer, J. R. (2022). Using diverging predictions from clas-\nsical and quantum models to dissociate between categorization systems.\nPsyArXiv. doi: doi:10.31234/osf.io/fq2k5\nEpping, G. P., Fisher, E. L., Zeleznikow-Johnston, A., Pothos, E., & Tsuchiya,\nN. (2021). A quantum geometric framework for modeling color similarity\njudgements. PsyArXiv. doi: doi:10.31234/osf.io/vtzrq\nFong, B. (2019). An invitation to applied category theory - seven sketches in\ncompositionality. Cambridge University Press.\nFriston, K., & Kiebel, S. (2009). Predictive coding under the free-energy princi-\nple. Philosophical transactions of the Royal Society B: Biological sciences,\n364(1521), 1211–1221.\nGanter, B., & Obiedkov, S. (2016). Conceptual exploration. Springer.\nGanter, B., & Wille, R. (1999). Formal concept analysis: mathematical foun-\ndations. Springer Science & Business Media.\nG¨ardenfors, P. (2004). Conceptual spaces: The geometry of thought. MIT press.\nG¨ardenfors, P. (2014). The geometry of meaning. The MIT Press.\nGoodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. The MIT\nPress.\n42\nGoodwin,\nG. P., & Johnson-Laird,\nP. N.\n(2013).\nThe acquisition\nof\nboolean\nconcepts.\nTrends\nin\nCognitive\nSciences,\n17.\ndoi:\nhttps://doi.org/10.1016/j.tics.2013.01.007\nGopnik, A., & Meltzoff, A. (1997). Words, thoughts, and theories. MIT Press.\nHarnad, S.\n(1990).\nThe symbol grounding problem.\nPhysica D: Nonlinear\nPhenomona, 42, 335-346.\nHavlicek, V., Corcoles, A. D., Temme, K., Harrow, A. W., Kandala, A., Chow,\nJ. M., & Gambetta, J. M. (2019). Supervised learning with quantum-\nenhanced feature spaces. Nature, 567, 209-212.\nHiggins, I., Matthey, L., Pal, A., Burgess, C. P., Glorot, X., Botvinick, M.,\n. . . Lerchner, A. (2017). β-VAE: Learning basic visual concepts with a\nconstrained variational framework. In Proceedings of ICLR 2017.\nHiggins, I., Sonnerat, N., Matthey, L., Pal, A., Burgess, C. P., Boˇsnjak, M., . . .\nLerchner, A. (2018). SCAN: Learning hierarchical compositional visual\nconcepts. In Proceedings of ICLR 2018.\nHuang, Q., Smolensky, P., He, X., Deng, L., & Wu, D. (2018, June). Tensor\nproduct generation networks for deep NLP modeling. In Proceedings of the\n2018 conference of the north American chapter of the association for com-\nputational linguistics: Human language technologies, volume 1 (long pa-\npers) (pp. 1263–1273). New Orleans, Louisiana: Association for Computa-\ntional Linguistics. Retrieved from https://aclanthology.org/N18-1114\ndoi: 10.18653/v1/N18-1114\nKhoshaman, A., Vinci, W., Denis, B., Andriyash, E., Sadeghi, H., & Amin,\nM. H. (2018). Quantum variational autoencoder. Quantum Science and\nTechnology, 4(1), 014001.\nKingma, D. P., & Welling, M. (2014). Auto-encoding variational Bayes. In Pro-\nceedings of the international conference on learning representations (ICLR\n2014).\nLake, B. M., Ullman, T. D., Tenenbaum, J. B., & Gershman, S. J. (2017).\nBuilding machines that learn and think like people. Behavioral and Brain\nSciences, 40.\nLewis, M., & Lawry, J.\n(2016).\nHierarchical conceptual spaces for concept\ncombination. Artificial Intelligence, 237, 204–227.\nLocatello, F., Bauer, S., Lucic, M., R¨atsch, G., Gelly, S., Sch¨olkopf, B., &\nBachem, O. (2019). Challenging common assumptions in the unsuper-\nvised learning of disentangled representations. In Proceedings of the 36th\ninternational conference on machine learning. Long Beach, California.\nLorenz, R., Pearson, A., Meichanetzidis, K., Kartsaklis, D., & Coecke, B.\n(2023).\nQNLP in practice: Running compositional models of meaning\non a quantum computer. Journal of Artificial Intelligence Research, 76.\ndoi: https://doi.org/10.1613/jair.1.14329\nMargolis, E., & Laurence, S. (Eds.). (2015). The conceptual mind: New direc-\ntions in the study of concepts. The MIT Press.\nMargolis,\nE.,\n&\nLaurence,\nS.\n(2022).\nConcepts.\nhttps://plato.stanford.edu/archives/fall2022/entries/concepts/.\n(The Stanford\nEncyclopedia of Philosophy)\n43\nMurphy, G. L. (2002). The big book of concepts. The MIT Press.\nPanangaden, P. (1998). Probabilistic relations. School of Computer Science\nResearch Reports-University of Birmingham CSR, 59–74.\nPothos, E. M., & Busemeyer, J. R. (2013). Can quantum probability provide\na new direction for cognitive modeling? Behavioral and Brain Sciences,\n36(3).\nPreskill, J.\n(2012).\nQuantum computing and the entanglement frontier.\narXiv:1203.5813.\n(Rapporteur talk at the 25th Solvay Conference on\nPhysics - The Theory of the Quantum World)\nRezende, D. J., Mohamed, S., & Wierstra, D. (2014). Stochastic backpropaga-\ntion and approximate inference in deep generative models. In Proceedings\nof the 31st international conference on machine learning (pp. 1278–1286).\nRickard, J. T., Aisbett, J., & Gibbon, G. (2007). Reformulation of the theory\nof conceptual spaces. Information Sciences, 177(21), 4539–4565.\nRodatz, B., Shaikh, R. A., & Yeh, L. (2021). Conversational negation using\nworldly context in compositional distributional semantics. arXiv preprint\narXiv:2105.05748.\nRosch, E. H. (1973). Natural categories. Cognitive psychology, 4(3), 328–350.\nSchlangen, D., Zarrieß, S., & Kennington, C. (2016, August). Resolving ref-\nerences to objects in photographs using the words-as-classifiers model.\nIn Proceedings of the 54th annual meeting of the association for com-\nputational linguistics (volume 1: Long papers) (pp. 1213–1223). Berlin,\nGermany: Association for Computational Linguistics.\nRetrieved from\nhttps://aclanthology.org/P16-1115 doi: 10.18653/v1/P16-1115\nSchuld, M., & Killoran, N. (2019, Feb). Quantum machine learning in fea-\nture hilbert spaces. Phys. Rev. Lett., 122, 040504. doi: 10.1103/Phys-\nRevLett.122.040504\nSelinger, P. (2010). A survey of graphical languages for monoidal categories. In\nNew structures for physics (pp. 289–355). Springer.\nShaikh, R. A., Yeh, L., Rodatz, B., & Coecke, B. (2021). Composing conversa-\ntional negation. arXiv preprint arXiv:2107.06820.\nShiebler, D., Gavranovic, B., & Wilson, P. (2021). Category theory in machine\nlearning. In The 4th international conference on applied category theory.\nCambridge, UK.\nSmolensky, P., & Legendre, G. (2006). The harmonic mind. The MIT Press.\nTomas, V., & Sylvie, D. (2015). Unitary transformations in the quantum model\nfor conceptual conjunctions and its application to data representation.\nFrontiers in Psychology, 6.\nTrueblood, J. S., & Busemeyer, J. R. (2011). A quantum probability account\nof order effects in inference. Cognitive Science, 35, 1518–1552.\nTull,\nS.\n(2019).\nCategorical\noperational\nphysics.\narXiv\npreprint\narXiv:1902.00343.\nTull, S. (2021). A categorical semantics of fuzzy concepts in conceptual spaces.\nProceedings of Applied Category Theory 2021.\nVan de Wetering, J. (2021). Constructing quantum circuits with global gates.\nNew Journal of Physics, 23(4), 043015.\n44\nWatters, N., Matthey, L., Borgeaud, S., Kabra, R., & Lerchner, A. (2019).\nSpriteworld:\nA flexible, configurable reinforcement learning environ-\nment.\nhttps://github.com/deepmind/spriteworld/.\nRetrieved from\nhttps://github.com/deepmind/spriteworld/\nYan, F., Li, N., & Hirota, K. (2021). Qhsl: A quantum hue, saturation, and\nlightness color model. Information Sciences, 577, 196–213.\n45\nA\nThe Shapes Dataset\nThe parameters used in the Spriteworld software to generate the Shapes dataset:\nAdditional parameters for the colour domain:\nA.1\nThe Extended Colour Dataset\nThe parameters used in the Spriteworld software to generate the Shapes dataset\nwith more (rainbow) colours:\n46\nB\nNeural Architectures and Hyper-parameters\nimage width\n64\nimage height\n64\nimage channels\n3\nCNN kernel size\n4 × 4\nCNN stride\n2 × 2\nCNN layers\n4\nCNN filters\n64\nCNN dense layers\n2\nCNN dense layer size\n256\ndimensions of latent space\n6\ninitialization interval for means of priors\n[−1.0, 1.0]\ninitialization interval for log-variances of priors\n[−7.0, 0.0]\nbatch size\n32\nAdam learning rate\n10−3\nAdam β1\n0.9\nAdam β2\n0.999\nAdam ϵ\n10−7\n47\n"
}