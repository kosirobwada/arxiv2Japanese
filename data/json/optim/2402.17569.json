{
    "optim": "Backpropagation-Based Analytical Derivatives of EKF Covariance for Active Sensing Jonas Benhamou1,2, Silv`ere Bonnabel1, and Camille Chapdelaine2 1Mines Paris, PSL Research University, Centre for Robotics, 60 bd Saint-Michel, 75006 Paris, France, silvere.bonnabel@minesparis.psl.eu 2SAFRAN TECH, Groupe Safran, Rue des Jeunes Bois - Chateaufort, 78772 Magny Les Hameaux CEDEX, France, {camille.chapdelaine, jonas.benhamou}@safrangroup.com February 28, 2024 Abstract To enhance accuracy of robot state estimation, perception-aware (or active sensing) methods seek trajectories that minimize uncertainty. To this aim, one possibility is to seek trajectories that minimize the final covariance of an extended Kalman filter (EKF), w.r.t. its control inputs over a given horizon. However, this can be computationally demanding. In this article, we derive novel backpropaga- tion analytical formulas for the derivatives of the final covariance of an EKF w.r.t. its inputs. We then leverage the obtained gradients as an enabling technology to derive perception-aware optimal motion plans. Simulations validate the approach, showcasing improvements in both estimation accuracy and execution time. Exper- imental results on a real large ground vehicle also support the method. Keywords: perception-aware, extended Kalman filter, trajectory optimization, backpropagation. 1 Introduction In robotics, perception-aware (PA) approaches, [1, 2, 3, 4], or active sensing approaches, seek trajectories that maximize information gathered from sensors so as to perform robotic tasks safely. Notably, in the context of ground vehicles, when localization is based on ranging or bearing measurements relative to beacons, the efficiency of active sensing has been shown by [5, 6]. In [7], trajectories are generated to perform opti- mal online calibration between GPS and inertial measurement unit (IMU), see also [8]. In [3], for visual-inertial navigation systems, the authors have optimized the duration in which landmarks remain within the field of view. In the context of simultaneous localization and mapping (SLAM), those methods pertain to active SLAM, see [9]. 1 arXiv:2402.17569v1  [cs.RO]  27 Feb 2024 One way to attack active sensing is through the use of Partially Observable Markov Decision Processes (POMDPs) [10], see [11], which offer a proper mathematical frame- work, but whose complexity is often prohibitory [12]. Sampling-based planners [13, 14] may be subject to the same issues. A more tractable option, that we presently adopt, is to work with the widespread extended Kalman filter (EKF), which estimates in real time the state xn from various sensor measurements, and (approximately) conveys the associated extent of uncertainty through the state error covariance matrix Pn, that may be used as an objective to minimize, as advocated in, e.g., [15]. Using the Gramian matrix to elicit observability, or as a surrogate for Pn, as advo- cated in [5, 6, 7, 16], is somewhat simpler but may lead to suboptimal motion plans in terms of gathered information [17]. Direct minimization of the final uncertainty encoded in PN is advocated instead in [17, 18, 15]. To find optimal trajectories, one may restrict the problem to the class of differentially flat systems, and use splines, as advocated in [18, 5], or one can try to compute and use directly the gradients of PN with respect to (w.r.t.) the control inputs. To this aim, several approaches are possible. One can use a brute force approach (in the vein of [19]) or numerical differentiation, that may be ill-conditioned and intractable, owing to the complexity of the EKF’s equa- tions. To get around those problems, [15] advocates using backpropagation, through automatic differentiation, and argues that deriving analytical expressions would be dif- ficult. In this paper, we fill a gap by providing closed-form analytical expressions for the derivatives of any smooth function of the final covariance matrix PN of an EKF, w.r.t. all previous control inputs. Those novel equations, that build upon our recent results for the linear Kalman filter [20], extend them to the nonlinear case, using an EKF. In addition to being analytical, and decreasing some numerical errors, these equations lead to further speedups even over automatic differentiation, as we will show in this paper. Then, we apply the technique to derive a novel method for perception-aware optimal motion planning. The main contributions of this paper are as follows: • Deriving novel analytical backpropagation equations for the gradient of the co- variance of an EKF with respect to all inputs of the filter, including control vari- ables, thus partly extending [20] to the relevant nonlinear context; • Hence providing a computationally efficient method whose cost to compute the gradients w.r.t. all control inputs at once, over an N-step horizon, is similar to that of running one EKF over this horizon, • Applying the technique to derive a perception-aware method, which may be an enabler for real-time implementation for planning over longer horizons; • Validate and compare the technique through simulations, and real experiments on a car-size ground vehicle. Section 2 introduces notations and outlines the gradient we want to compute. Sec- tion 3 establishes backpropagation equations for computing this gradient. In Section 4, our path planning formulation is introduced. Finally, we demonstrate the benefits of our approach in simulations (section 5) and real experiments (section 6). 2 2 Primers For partially observed linear dynamical systems affected by white Gaussian noise, the Kalman filter (KF) computes the statistics of the state given past observations, namely p(xn|y0,...,yn), in real time. The Kalman filter (KF) relies on many parameters en- coded in the noise covariance matrices Qn and Rn. There exist various approaches to compute the derivatives of the KF’s outputs w.r.t. those parameters. The early sensitiv- ity equations [21], see also [22], allow for computing the derivative of the likelihood L := log p(y0,...,yn) w.r.t. the noise parameters. A much faster approach is to use backpropagation, either using numerical auto-differentiation, as advocated in [15], or closed-form formulas as very recently derived in [20]. In this paper, we first target closed-form backpropagation formulas for computing the gradients of an EKF w.r.t. all its inputs, from the noise parameters to the control inputs. This provides a nontrivial extension of the results of [20] to nonlinear systems. We start with a few primers. 2.1 Preliminaries Let’s consider a nonlinear discrete-time system: ( xn = f(xn−1,un,wn), x0 = x0 yn = h(xn)+vn (1) where xn ∈ Rp is the system’s state, un ∈ Rq is the control input, wn ∈ Rr represents the process noise which follows a Gaussian distribution with zero mean and covariance matrix Qn. The measured output is denoted by yn ∈ Rl, corrupted by a Gaussian mea- surement noise vn with zero mean and covariance matrix Rn. Owing to unknown noises corrupting the equations, and to the state being only partially observed through yn, one needs to resort to a state estimator. The Extended Kalman Filter (EKF) provides a joint estimation of the state, denoted as ˆxn, and its covariance matrix, denoted as Pn. It consists of two steps: a propagation step and an update step. At the propagation step, the estimated state is evolved through the noise-free model, that is, ˆxn|n−1 = f(ˆxn−1|n−1,un,wn), (2) and the covariance of the state error (such as x− ˆx) is evolved as Pn|n−1 = FnPn−1|n−1FT n +GnQnGT n . (3) At the update step, the estimated state and the covariance are updated in the light of observation yn as Sn = HnPn|n−1HT n +Rn , (4) Kn = Pn|n−1HT n S−1 n , (5) ˆxn|n = ˆxn|n−1 +Kn(yn −h(ˆxn|n−1)) (6) Pn|n = (I −KnHn)Pn|n−1. (7) 3 The Riccati update step (7) proves equivalent to the following update in so-called in- formation form: P−1 n|n = P−1 n|n−1 +HT n R−1 n Hn. (8) In these equations, matrices Fn, Gn and Hn are all jacobians that depend on state esti- mation ˆxn and control inputs un. In the case of linear error (x− ˆx), they read: Fn = ∂ f ∂xn (ˆxn−1|n−1,un,0), Gn = ∂ f ∂wn (ˆxn−1|n−1,un,0), Hn = ∂h ∂xn (ˆxn|n−1). (9) Through these Jacobians, the control inputs un affect the covariances Pn|n−1 and Pn|n, which is in stark contrast with the linear case. Thus, it makes sense to compute the sensitivity of covariance matrices to control. 2.2 Backpropagation based gradient computation The final covariance computed in the EKF PN|N over a fixed window, say n = 0,...,N, is the result of an iterative algorithm, and can thus be viewed as a composition of many functions, as layers in a neural network. As a result, it lends itself to backpropagation, a way of computing the chain rule backwards. Backpropagation (”backprop”) is very efficient when there are numerous inputs and the output is a scalar function. Beyond neural networks, it has applications in control and robotics. In [23], in the context of linear Kalman filtering, it is used to compute the gradient of the negative logarithm of the marginal likelihood (NLL) w.r.t all observations y1,...,yN, allowing for measure- ment selection and fault detection. In [15], perception-aware trajectory generation is performed using an optimisation-based method where gradients are computed using an automatic differentiation algorithm. 2.3 Scalar loss design For backpropagation to be numerically efficient, one needs the objective to be a scalar function. The most common choices to reflect the final uncertainty are the trace L = Tr(PN|N), used in [17, 7, 15], or the maximum eigenvalue, which has to be regularized using Schatten’s norm, see [5]. Other possibilities revolve around the Observability Gramian (OG), where one can elicit observability by trying to minimize the smallest eigenvalue, as in [5], or maximimizing the trace, which is proved in [24] to be in- terpretable as a deterministically propagated average error. Although the covariance matrix and the OG may be related [5]), we will focus on the former that more closely reflects uncertainty in the presence of noise [17]. As Tr(PN|N) sums the diagonal terms, which are variances expressed in possibly different units and choice of scales, it is reasonable to renormalize the matrix, as sug- gested in [7]. We suggest to use the initial inverse covariance matrix as a scaling factor matrix, leading to the modified trace objective L = Tr \u0000P−1 0 PN|N \u0001 . Note that this may also ensure better conditioning of the optimization problem to come. 4 3 Novel sensitivity equations for the EKF We consider a fixed window, say, n = 0...N, and we seek to differentiate a function L (PN|N) of the final uncertainty PN|N, w.r.t. all the previous EKF inputs, that are, the noise parameters Rn,Qn, the control inputs un, for n = 1...N, and the initial values ˆx0,P0|0. They all affect L (PN|N) in a complicated manner, through the EKF equations (2) to (9). For instance a modification of u0, namely u0 +δu0 affects initial Jacobians R0,G0,H0 in (9), that in turn affect all subsequent quantities output by the EKF through eq. (2) to (8), finally affecting L (PN|N) in a non-obvious manner. To analytically compute the derivatives, there are two routes. The historical one is to forward propagate a perturbation, say δun, n < N, through the equations. It is known as the sensitivity equations, and has been done–at least–for the linear Kalman filter in [21], essentially for adaptive filtering. The other route is to compute derivatives back- wards, using the backprop method. It is far less straightforward, and has been proposed only very recently, leading to drastic computation speedups, see [20], in the context of linear systems. In this paper we heavily rely on our prior work [20] to go a step fur- ther, by accommodating nonlinear equations, that is, going from the Kalman Filter to the EKF, with the additional difficulty that the Jacobians depend on the estimates–but restricting ourselves to losses of the form L (PN|N), our end goal being active sensing. We show this additional dependency lends itself to the backprop framework too. We also extend the calculations to get the derivatives w.r.t. control inputs (which would not make sense in the linear case as they are zero). 3.1 Matrix derivatives We now explain the methodology, the main steps, and provide the final equations. As deriving closed-form formulas through backward computation to elicit numerical efficiency is non trivial and lengthy, a full-blown mathematical proof can be found in the online arxiv preprint of the present paper. Our method heavily relies on two ingredients. First, the notion of derivative of a scalar function w.r.t. a matrix, and the associated formulas based on the chain rule. Then, dependency diagrams which encapsulate how the functions are composed. Consider L (M), a scalar function of a matrix M = f(X,Y), where X and Y are also matrices. ∂L ∂M denotes the matrix defined by ( ∂L ∂M )ij = ∂L Mij . To alleviate notation, we similarly write ∂L ∂X as the matrix ∂L ◦f ∂X . The chain rule provides rules of calculus for matrix derivatives. We have the fol- lowing formulas [25]: M = XYXT ⇒ ∂L ∂X = 2∂L ∂M XY T M = YXY T ⇒ ∂L ∂X = Y T ∂L ∂M Y M = X−1 ⇒ ∂L ∂X = −MT ∂L ∂M MT (10) 5 In the particular case where X and M are vectors, we have: M = f(X) ⇒ ∂L ∂X = JT ∂L ∂M , (11) with J the Jacobian matrix of f w.r.t. X. When the matrix X depends on a scalar variable s, we have the following formula: M = X(s) ⇒ ∂L ∂s = Tr \u0012∂XT ∂s ∂L ∂M \u0013 (12) 3.2 Backprop equations for the involved matrices The graph in Figure 1 shows the relationships involved in the calculation of the state’s error covariance, which is our variable of interest. Pn−1|n−1 Pn|n−1 Pn|n Fn,Gn Rn,Hn Figure 1: Dependencies of EKF’s variables in Riccati’s equations (3) and (8). Each variable (node) is a function of its predecessors. The backprop method consists in running an EKF until time N, to fix the values of all variables, and then running the present method backwards to get the derivatives. Let us assume we have computed an expression for ∂L ∂PN|N (initialization step) at final covariance PN|N. It gives how a small variation in PN|N affects the objective, ignoring all the other variables. Starting with n = N, we go backwards as follows. As Pn|n is a function of Pn|n−1 which is a function of Pn−1|n−1 in turn, through (3) and (8), we can use formulas (10) to assess how a small perturbation in Pn|n−1 and Pn−1|n−1 affects the loss in turn (as they affect subsequent quantities, whose variation on L has been computed). This yields ∂L ∂Pn−1|n−1 = FT n ∂L ∂Pn|n−1 Fn (13) ∂L ∂Pn|n−1 = (I −KnHn)T ∂L ∂Pn|n (I −KnHn) (14) In the same way, we apply formula (10) to (3) and (8) to obtain the following 6 relationships: ∂L ∂Fn = 2 ∂L ∂Pn|n−1 FnPn−1|n−1 (15) ∂L ∂Gn = 2 ∂L ∂Pn|n−1 GnQn (16) ∂L ∂HTn = −2Pn|n ∂L ∂Pn|n Pn|nHT n R−1 n (17) ∂L ∂Rn = R−1 n HnPn|n ∂L ∂Pn|n Pn|nHT n R−1 n (18) Knowing ∂L ∂Pn|n and ∂L ∂Pn|n−1 , these equations allow in passing to calculate the partial derivative of the loss with respect to the intermediate variables Fn, Gn, Hn and Rn at each step. 3.3 Backprop equations for the vector variables We can now compute the derivatives w.r.t. the state estimates ˆx and the control inputs u, which are vectors. However, a remark is necessary. Our end goal is to derive optimal controls u1,...,uN that minimize loss L (PN|N). As this is performed ahead of time, the (noisy) observations yn in (6) are not available. The most reasonable choice is then to plan using the a priori value of the yn, i.e., yn = h(ˆxn|n−1). We may thus alleviate notation writing ˆxn|n = ˆxn|n−1 := ˆxn and ˆxn−1|n−1 := ˆxn−1. The graph in Figure 1 only focuses on the covariance variables. If we step back, we see the Jacobians depend on the linearization point ˆxn−1 and the control inputs un, see (9). A bigger picture encapsulating all the dependencies in the EKF is represented in Figure 2. Pn−1|n−1 Pn|n−1 Pn|n Rn−1,Hn−1 Fn,Gn un Rn,Hn ˆxn−1 ˆxn Figure 2: Dependency diagram of all the variables involved in an EKF. First we compute ∂L ∂un . There is a general rule, derived from the chain rule, which is that ∂L ∂un is the sum of all the derivatives w.r.t. the direct successors of un in the graph, see e.g., [20], provided they have been already computed in a previous step of the backward calculation. Additionally using (11) and (12), and computing w.r.t. to 7 each scalar component uk n of vector un, this yields ∂L ∂ukn = Tr   ∂L ∂Fn T ∂Fn ∂ukn ! +Tr   ∂L ∂Gn T ∂Gn ∂ukn ! +(Ju nek)T ∂L ∂ ˆxn (19) where Ju n := ∂ f ∂u \f\f\f ˆxn−1,un,0 with ˆxn−1,un computed when running the EKF forward, and ek the k-th vector of the canonical basis (details are given in the appendix of the online preprint). Similarly, we compute the derivative w.r.t. the k-th scalar component of the sys- tem’s state xk n−1, by adding terms corresponding to each successor in the graph: ∂L ∂ ˆxk n−1 = Tr   ∂L ∂Hn−1 T ∂Hn−1 ∂ ˆxk n−1 ! +Tr   ∂L ∂Rn−1 T ∂Rn−1 ∂ ˆxk n−1 ! +(Jx nek)T ∂L ∂ ˆxn +Tr   ∂L ∂Fn T ∂Fn ∂ ˆxk n−1 ! +Tr   ∂L ∂Gn T ∂Gn ∂ ˆxk n−1 ! (20) where Jx n = ∂ f ∂x \f\f\f ˆxn−1,un,0 (which is equal to Fn). 3.4 Backprop initialization To initialize the backward process, one needs to compute ∂L (PN|N) ∂PN|N . This depends on the retained loss, see Section 2.3. In the case of the normalized trace loss, we have ∂L (PN|N) ∂PN|N = ∂Tr \u0000P−1 0 PN|N \u0001 ∂PN|N = P−1 0 . (21) In the case where one targets the maximum eigenvalue of PN|N as a minimization ob- jective, the loss must be chosen consequently. To handle the non-differentiable of this objective, it is possible to regularize it using Schatten’s norm. The reader is referred to [5]. Note also that at first backward step, n = N, (20) needs to be adapted, as ˆxN only has two successors in the graph, thus: ∂L ∂ ˆxk N = Tr   ∂L ∂HN T ∂HN ∂ ˆx j N ! +Tr   ∂L ∂RN T ∂RN ∂ ˆxk N ! (22) 3.5 Final equations The gradients may be obtained as follows. We first run the EKF forward, to get all the EKF variables given a sequence of inputs. Then, we may compute the derivative of the loss w.r.t. PN|N at the obtained final covariance matrix. Letting n = N, (17)- (18), provide the derivatives w.r.t. HN and RN, and (14) w.r.t. PN|N−1. In turn (22) provides the derivative w.r.t. ˆxN, so that (19) yields the gradient w.r.t. control input uN. 8 Continuing the process backward and using the equations above, we get the derivatives w.r.t. to all control inputs. The process allows for drastic computation savings, as a backward process com- putationally similar to the EKF itself yields derivatives w.r.t. all control inputs, whereas forward propagating perturbations would demand running an entire process from scratch for k = n to N to derive the derivative w.r.t. un. Akin to dynamic programming, back- propagation allows for reusing previous computations at each step. 4 Application to perception-aware planning The computation of the gradients w.r.t. all the EKF’s variables (beyond the control inputs) is a contribution in itself that may prove useful beyond active sensing. How- ever, we presently leverage it to address the following perception-aware optimal path planning problem: (P)                        min x1,...,xN,u1,...,uNL (PN|N) s.t. ∀n ≤ N xn = f(xn−1,un,wn), x0 = xI, ∀n ≤ N Pn|n−1 = FnPn−1|n−1FT n +GnQnGT n , ∀n ≤ N Pn|n = (I −KnHn)Pn|n−1, ∀n ≤ N umin ≤ un ≤ umax (23) where N is the time horizon, and L a scalar loss. This approach is known as partial collocation, as in [15], i.e., we explicitly include states as optimization variables and implicitly compute the covariance. While (23) seeks trajectories that minimize the accumulated uncertainty on the robot state over a given horizon, we note that it is easy to add constraints or another term in the loss to perform a specific task. For example, adding the constraint xN = xF allows for reaching a specific state while being perception-aware. A commonly em- ployed method for solving this problem involves a first-order optimization algorithm, the main steps of which are outlined in Algorithm 1. From a computational perspec- tive, the gradient computation stands out as the most computationally demanding step, hence the interest for the method developed above. 4.1 Algorithm When all the gradients are known, first order nonlinear optimization algorithm such as Sequential Quadratic Programming (SQP) may be brought to bear. This leads to Algorithm 1. The process involves computing the gradient g of the cost function w.r.t. the control variables using forward and backward passes through the EKF. Additionally, we com- pute the gradient of the constraints with respect to decision variables. Subsequently, line search is conducted to determine an appropriate step size α for efficient conver- gence. However, line search requires evaluating the cost function, which corresponds 9 Algorithm 1 Path planning algorithm Require: x0, P0, N,L u ← (u0,...,uN) while L (PN|N) not converge do g ← gradient computation(u) α ← line search(u,g) u ← update(u,g,α) ▷ Using SQP for example end while Return: (u0,...,uN) to running a full EKF in our case. The decision variables are then updated using SQP. Further details are given in the experimental sections. 4.2 Discussion In practice, it is difficult to use a loss L depending on the state’s covariance PN|N. In- deed, the gradient computation of the loss w.r.t each control variable is expensive when using forward difference [7, 17], as explained in Section 3.5. This has motivated [15] to use backpropagation, through automatic differentiation (AD), and argue deriving analytical formulas would be difficult. The interest of our work, that provides analytical formulas, is twofold in this regard. First, it is often preferable to have closed-form formulas when possible, to rule out many numerical errors and keep better control over the calculation process (possibly opening up for some guarantees about the execution). As efficient implementations of the EKF involve Cholesky or SVDs of the covariance matrix, the behaviour of AD seems difficult to anticipate or guarantee. Then, it leads to computation speedups, as it will be shown experimentally in the sequel. 5 Simulation results We now apply our results to the problem of wheeled robot localization. We consider a car-like robot modelled through the unicycle equations, and equipped with a GPS returning position measurements. There are two difficulties associated with the corre- sponding estimation problem. First, the heading is not directly measured. Then, and more importantly, we assume the position of the GPS antenna in the robot’s frame, that we call lever arm, is unknown (or inaccurately known, or may slightly vary over time). The resulting problem pertains to simultaneous self-calibration and navigation, in the vein of [7] but in a simpler context. In straight lines, for instance, the lever arm is not observable, so perception-aware trajectories should lead to more accurate robot state estimation. In this section we present the model, we assess and compare our method through simulations. In the next section, we apply it to a real world off-road vehicle which is the size of a car. 10 5.1 Robot model The system state consists of the orientation θn ∈ R, the position of the vehicle pn ∈ R2, and the lever arm ln ∈ R2. The control inputs are the steering angle νn and the forward velocity µn. The kinematic equations based on a roll-without-slip assumption are as follows:        θn = θn−1 + dt L (µn +wµ n )tan(νn +wν n), pn = pn−1 +dtΩ(θn−1)(µn +wµ n )e1, ln = ln−1 (24) where Ω(θ) = \u0012 cos(θ) −sin(θ) sin(θ) cos(θ) \u0013 , where L is the distance between the front and the rear wheels, e1 = (1,0)T indicates that the velocity is aligned with the robot’s heading, and dt is the sampling time. A Gaussian white noise wn = (wµ n ,wν n)T with covari- ance matrix Q corrupts the forward velocity µn and steering angle νn to account for actuators’ imperfections, and the mismatch with idealized kinematic model (namely slipping). Letting ln ∈ R2 be the position of the GPS antenna in the vehicle’s frame w.r.t. to its center (the midpoint of the rear axle), the position measured by the GPS is yn = pn +Ω(θn)ln +εn (25) where εn is a 2D white noise with covariance matrix Rn. In the simulations, we let L = 4m, dt = 1s. In terms of noise parameters, we let Q = diag(0.1,π/180), and Rn be the identity matrix, i.e., a standard deviation of 1 m for the position measurements. To account for actuator physical limits, we assume |νn| ≤ 30π/180 rad and 0 ≤ µn ≤ 5 m.s−1. To account for acceleration limits, we add the constraints |∆νn| ≤ 15π/180 rad.s−1 and |∆µn| ≤ 1 m.s−2. 5.2 Simulation results We start by sampling admissible control inputs over a horizon N = 150s. Then, the corresponding trajectory is obtained by integration. We then use the sequential least- squares programming (SLSQP) algorithm from Scipy [26] to optimize the sequence of controls to apply. The calculation of the gradient of the loss with respect to the control inputs is performed using the equations detailed in section 3. An example of the initial random trajectory and the solution of the perception-aware problem can be found in Figure 3. It can be observed that the optimal trajectory for the Schatten norm and for the trace are quite similar, and both oscillate around the initial random trajectory. These oscillations are manoeuvres to automatically increase the observability of the lever arm, and reduce the expected covariance trace. To demonstrate that the final covariance minimization translates into an actual re- duction of the average state estimation error, we simulate 200 trials of each optimal trajectory by adding process noise and observation noise. During the simulation, the state is estimated with an EKF based on (24), (25). The evolution of the absolute 11 Figure 3: On the left, an example of an initial random guess in blue. The other two trajectories are solutions to the perception-aware problem where the loss is the trace (in orange) and the Schatten norm (in green). The right plot shows the expected trace of the covariance evolution for each trajectory. estimation error of the lever arm is displayed on Figure 4. For PA trajectories, the er- ror decreases and converges more rapidly, illustrating the benefit of perception-aware optimal trajectory generation. 5.3 Computation time We compared the computation times for the gradient of the loss w.r.t. control inputs with three different methods. The first method using (forward) finite differences to compute the gradient, as in [27]. The second method is an automatic differentiation method, which adopts the backpropagation paradigm, but through a numerical method, akin to [15]. Namely, we used the state-of-the-art PyTorch automatic differentiation (AD) [28]. Finally, the last method uses our backpropagation analytical formulas of Section 3. The code was executed on computer with an Intel Core i5 at 2.60 GHz. Table 1: Average and standard deviation of gradient calculation time (over 100 calcu- lations) using different methods. Method Execution time Finite differences 26.92 ± 8.45s PyTorch Autograd 0.55 ± 0.19s Ours 0.19 ± 0.07s 12 Figure 4: Absolute estimation error of the lever arm during the trajectory. On the left the error for the lever arm in x and on the right in y. One-σ envelope illustrates the dispersion of errors over trials. Table 1 shows that gradient calculation using backpropagation (Autograd and ours) leads to large speedups. Indeed, when using a finite difference based method, opti- mization is computationally expensive, as mentioned in [7], where optimizing the trace of the sum of all covariances takes 13 hours for a 3D inertial navigation system. Even when compared to state-of-the-art PyTorch Autograd, our closed-form formulas are much faster, and more stable in terms of variability of computation time. The computation time for the complete resolution of the optimization problem (23) using our gradient calculation method and Algorithm 1 is 351s. Although this perfectly suits off-line trajectory generation, it means the robot should stop for a few minutes to plan in a real-time context. However, this computation time could be significantly re- duced. First, we may obviously optimize over a shorter horizon. Then, the optimizer currently uses a line search algorithm to determine the descent step size. In our case, evaluating the objective function is computationally expensive [7] because it requires running the EKF along the entire trajectory, which is almost as time-consuming as calculating all the gradients with our backpropagation method. Therefore, finding a method that reduces the number of calls to the objective function should prove effi- cient. Finally, another option to reduce computation time is to decrease the number of decision variables, by for instance parameterizing trajectories using B-splines, as in [5]. 13 5.4 Discussion A few remarks are in order. First, we see that, by replacing state-of-the-art auto- grad differentiation with our formulas, one may (roughly speaking) double the plan- ning horizon for an identical computation budget. Besides, analytical formulas better suit onboard implementation. It is interesting to note that they are totally akin to the EKF equations, which must be implemented on the robot anyway. Finally, analytical formulas–when available–may be preferable to numerical methods, as one keeps a bet- ter control over what is being implemented, possibly opening up for some guarantees (the behavior of autograd may be harder to anticipate, and leads to higher computation time variability). Moreover, we anticipate that coding them in C++ may lead to further speedups. We may also comment on the obtained trajectories. As the optimization problem is highly nonlinear, non-convex, and constrained, one should expect an optimization method to fall into a close-by local minimum. In Figure 3, the local nature of the op- timum proves visible, as the obtained trajectory oscillates around the initial trajectory. Methods to step out of local minima go beyond the scope of this paper. However, it is worth noting that albeit a (close-by) local minimum, the obtained trajectory succeeds in much reducing state uncertainty. It reduces the final average error on the lever arm, which is the most difficult variable to estimate, by a factor 3, see Figure 4. In the context of real-time online planning, this suggests a sensible way to use the formulas of the present paper would be to compute a real-time trajectory that optimizes a control objective, and then to refine it in real time, by performing a few gradient descent steps. This shall (much) increase the information gathered by the sensors. 6 Real-world experiments Real experiments were conducted jointly with the company Safran, a large group that commercializes (among others) navigation systems. With the help from its engineers, we used an experimental off-road car owned by the company, which is approximately 4m long and 2.1m wide1. 6.1 Experimental setting The vehicle is equipped with a standard GPS, odometers, and a RTK (Real Time Kine- matic) GPS, which is not used by the EKF, but serves as ground-truth for position owing to its high accuracy. The lever arm between the GPS and the RTK is denoted by lGPS/RTK, and has been calibrated (it is only used for comparison to the ground-truth). To further test our method, we conducted localization experiments on both ordinary and PA trajectories and compared their performance. We used the model described in Section 5.1, and devised an EKF that fuses odometer data (dynamical model) with GPS position measurements. The vehicle state is represented by a 5-dimensional vector: two 1Because of confidentiality requirements, the company has not wished to publish a picture of its experi- mental vehicle. 14 dimensions for position, one for the orientation, and two for the lever arm between the GPS and the center of the vehicle frame (midpoint of the rear axle). Initially, we generated ordinary trajectories at two different speeds (5 km/h, 10 km/h). Subsequently, we employed our PA path planning Algorithm 1 initialized with those trajectories, to address optimization problem (23), using the final covariance trace as the loss. The constraints used were those relative to the actuators. To demonstrate the ability of optimization-based planning methods to handle further constraints, we also constrained the distance between the initial trajectory and the PA trajectory to be less than 1.5m. Then, we used local tangent plane coordinates computed near the experiment locations to convert 2D planning to world frame coordinates. Then, we followed each trajectory and computed the localization error committed by the EKF. To measure localization accuracy, we utilized the RTK-GPS system as a ground- truth, since its uncertainties are of the order of a few centimeters. The position error of the vehicle was computed as follows: en = \r\rpRTK n −( ˆpn +Ω( ˆθn)(ˆln +lGPS/RTK) \r\r (26) 6.2 Results The experiment comprises 4 runs: 2 reference runs and 2 perception-aware runs (at 5 km/h and 10 km/h). Trajectories returned by RTK-GPS over the first run are displayed in Figure 5. We note that the oscillations of the PA trajectory around the reference trajectory, which enhances state (hence lever arm) observability. Figure 6 shows the trajectories for the second run, along with the evolution of the trace of Pn|n output by the EKF (on the first run, the latter is wholly similar and was not included owing to space limitations, to improve legibility of Fig. 5). We see the improvement in terms of trace through the optimized trajectories. The visible wiggling of the covariance corresponds to the correction steps of the EKF. Indeed, the dynamical model is run at 100Hz, corresponding to the odometer frequency, while corrections are made when GPS data are available, at approximately 1Hz. 6.3 Analysis Although the trace of the covariance is smaller along the PA trajectory, it doesn’t guar- antee that the error with respect to ground truth is reduced. The uncertainty calcu- lated by the filter assumes all random variables are Gaussian, and the EKF is based on approximations. For each trial, we calculated the average error obtained for each type of trajectory. The results presented in Table 2 point out that PA trajectories en- hance localization accuracy. Indeed, in the scenario at 5 km/h, the error decreases by 13.24% between the reference and the PA trajectory, and by 8.25% in the scenario at 10 km/h. However, when compared with results from simulations, the improvement is smaller. Several factors could explain this difference. Firstly, in simulations, we calcu- lated an average result using the Monte Carlo method, whereas here we have a single trial. Additionally, in simulations, model and noises are perfectly known, whereas in reality, they are not. The roll-without-slip assumption is especially challenged when using an off-road vehicle. Finally, due to the limited area, we explicitly constrained 15 Figure 5: Off-road trajectories of the RTK-GPS in a local tangent plane coordinates oriented East-North-Up of the scenario at 5 km/h. Figure 6: On the left, trajectories of the RTK-GPS in local tangent plane coordinates at 10 km/h. On the right, the evolution of the covariance trace along each trajectory in the scenario at a speed of 10 km/h. the optimized trajectory to stay within a 1.5 m radius around the reference one, hence producing a trajectory that optimally “refines” the reference trajectory, but no more. 16 Table 2: Calculation of the estimation error according to Equation (26) is performed for all trajectories. Speed (km/h) Type Mean error (m) 5 Ref 3.32 PA 2.88 10 Ref 4.73 PA 4.34 7 Conclusion Our first contribution has been to introduce novel backpropagation analytical equations to compute the gradient of any loss based on the covariance of an EKF, w.r.t all its in- puts. Beyond the theoretical contribution, they lead to actual numerical speedups. Our second contribution has been to leverage those formulas to address PA path planning, and to test the method in simulation and on real-world experiments over large off-road trajectories over a span of more than 50 meters. In future work, we would like to ap- ply the method to more challenging problems, such as inertial navigation [7], and to improve its scalability, notably by improving the line search. We also would like to combine the method with other objectives such as reaching a desired goal, collision avoidance, or energy consumption. References [1] L. Bartolomei, L. Teixeira, and M. Chli, “Perception-aware Path Planning for UAVs using Semantic Segmentation,” in 2020 IEEE/RSJ International Confer- ence on Intelligent Robots and Systems (IROS), Oct. 2020, pp. 5808–5815. [2] G. Costante, C. Forster, J. Delmerico, P. Valigi, and D. Scaramuzza, “Perception- aware Path Planning,” Feb. 2017. [3] V. Murali, I. Spasojevic, W. Guerra, and S. Karaman, “Perception-aware trajec- tory generation for aggressive quadrotor flight using differential flatness,” in 2019 American Control Conference (ACC), Jul. 2019, pp. 3936–3943. [4] J. Xing, G. Cioffi, J. Hidalgo-Carri´o, and D. Scaramuzza, “Autonomous Power Line Inspection with Drones via Perception-Aware MPC,” in 2023 IEEE/RSJ In- ternational Conference on Intelligent Robots and Systems (IROS), Oct. 2023, pp. 1086–1093. [5] P. Salaris, M. Cognetti, R. Spica, and P. R. Giordano, “Online Optimal Perception-Aware Trajectory Generation,” IEEE Transactions on Robotics, vol. 35, no. 6, pp. 1307–1322, Dec. 2019. [6] O. Napolitano, D. Fontanelli, L. Pallottino, and P. Salaris, “Gramian-based opti- mal active sensing control under intermittent measurements,” in 2021 IEEE Inter- 17 national Conference on Robotics and Automation (ICRA), May 2021, pp. 9680– 9686. [7] J. Preiss, K. Hausman, G. Sukhatme, and S. Weiss, “Simultaneous self-calibration and navigation using trajectory optimization,” The International Journal of Robotics Research, vol. 37, Aug. 2018. [8] S. Xu, J. S. Willners, Z. Hong, K. Zhang, Y. R. Petillot, and S. Wang, “Observability-Aware Active Extrinsic Calibration of Multiple Sensors,” in 2023 IEEE International Conference on Robotics and Automation (ICRA), May 2023, pp. 2091–2097. [9] J. S. Willners, S. Katagiri, S. Xu, T. Łuczy´nski, J. Roe, and Y. Petillot, “Adaptive Heading for Perception-Aware Trajectory Following,” in 2023 IEEE International Conference on Robotics and Automation (ICRA), May 2023, pp. 3161–3167. [10] L. P. Kaelbling, M. L. Littman, and A. R. Cassandra, “Planning and acting in partially observable stochastic domains,” Artificial Intelligence, 1998. [11] S. Candido and S. Hutchinson, “Minimum uncertainty robot path planning using a POMDP approach,” in 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems, Oct. 2010, pp. 1408–1413. [12] C. H. Papadimitriou and J. N. Tsitsiklis, “The Complexity of Markov Decision Processes,” Mathematics of Operations Research, vol. 12, no. 3, pp. 441–450, 1987. [13] R. He, S. Prentice, and N. Roy, “Planning in information space for a quadrotor helicopter in a GPS-denied environment,” in 2008 IEEE International Conference on Robotics and Automation (ICRA), May 2008, pp. 1814–1820. [14] S. Prentice and N. Roy, “The Belief Roadmap: Efficient Planning in Belief Space by Factoring the Covariance,” The International Journal of Robotics Research, vol. 28, no. 11-12, pp. 1448–1465, Nov. 2009. [15] S. Patil, G. Kahn, M. Laskey, J. Schulman, K. Goldberg, and P. Abbeel, “Scaling up gaussian belief space planning through covariance-free trajectory optimiza- tion and automatic differentiation,” in Algorithmic Foundations of Robotics XI: Selected Contributions of the Eleventh International Workshop on the Algorith- mic Foundations of Robotics, H. L. Akin, N. M. Amato, V. Isler, and A. F. van der Stappen, Eds. Cham: Springer International Publishing, 2015, pp. 515–533. [16] C. B¨ohm, P. Brault, Q. Delamare, P. R. Giordano, and S. Weiss, “COP: Control & Observability-aware Planning,” Mar. 2022. [17] M. Rafieisakhaei, S. Chakravorty, and P. R. Kumar, “On the Use of the Observ- ability Gramian for Partially Observed Robotic Path Planning Problems,” in 2017 IEEE 56th Annual Conference on Decision and Control (CDC), Dec. 2017, pp. 1523–1528. 18 [18] M. Cognetti, P. Salaris, and P. Robuffo Giordano, “Optimal Active Sensing with Process and Measurement Noise,” in 2018 IEEE International Conference on Robotics and Automation (ICRA), May 2018, pp. 2118–2125. [19] P. Abbeel, A. Coates, M. Montemerlo, A. Ng, and S. Thrun, “Discriminative Training of Kalman Filters,” in Robotics: Science and Systems, Jun. 2005, pp. 289–296. [20] C. Parellier, A. Barrau, and S. Bonnabel, “Speeding-Up Backpropagation of Gra- dients Through the Kalman Filter via Closed-Form Expressions,” IEEE Transac- tions on Automatic Control, vol. 68, no. 12, pp. 8171–8177, Dec. 2023. [21] N. Gupta and R. Mehra, “Computational aspects of maximum likelihood esti- mation and reduction in sensitivity function calculations,” IEEE Transactions on Automatic Control, vol. 19, no. 6, pp. 774–783, Dec. 1974. [22] J. V. Tsyganova and M. V. Kulikova, “SVD-Based Kalman Filter Derivative Com- putation,” IEEE Transactions on Automatic Control, vol. 62, no. 9, 2017. [23] C. Parellier, A. Barrau, and S. Bonnabel, “A Computationally Efficient Global Indicator to Detect Spurious Measurement Drifts in Kalman Filtering,” in 2023 62nd IEEE Conference on Decision and Control (CDC), Dec. 2023, pp. 8641– 8646. [24] J. Benhamou, S. Bonnabel, and C. Chapdelaine, “Optimal Active Sensing Con- trol for Two-Frame Systems,” in 2023 62nd IEEE Conference on Decision and Control (CDC), Dec. 2023, pp. 5967–5974. [25] K. B. Petersen and M. S. Pedersen, “[ http://matrixcookbook.com ].” [26] P. Virtanen, R. Gommers, T. E. Oliphant, M. Haberland, T. Reddy, D. Cour- napeau, E. Burovski, P. Peterson, W. Weckesser, J. Bright, S. J. van der Walt, M. Brett, J. Wilson, K. J. Millman, N. Mayorov, A. R. J. Nelson, E. Jones, R. Kern, E. Larson, C. J. Carey, ˙I. Polat, Y. Feng, E. W. Moore, J. VanderPlas, D. Laxalde, J. Perktold, R. Cimrman, I. Henriksen, E. A. Quintero, C. R. Har- ris, A. M. Archibald, A. H. Ribeiro, F. Pedregosa, P. van Mulbregt, and SciPy 1.0 Contributors, “SciPy 1.0: Fundamental algorithms for scientific computing in Python,” Nature Methods, vol. 17, no. 3, pp. 261–272, Mar. 2020. [27] V. Indelman, L. Carlone, and F. Dellaert, “Towards planning in generalized be- lief space,” in Robotics Research: The 16th International Symposium ISRR. Springer, 2016, pp. 593–609. [28] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. K¨opf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S. Chin- tala, “PyTorch: An Imperative Style, High-Performance Deep Learning Library,” Dec. 2019. 19 A Matrix derivatives First, we provide an example of how to derive matrix derivative equations. Then, we will list all the matrix derivative equations we have used in the paper. We consider a scalar function L : Rn×n → R and we define ∂L (X) ∂X as the matrix of the derivative of L w.r.t each component of X (i.e. \u0010 ∂L (X) ∂X \u0011 i, j = ∂L (X) ∂xi,j ). Using only matrix multipli- cation, we can express first-order Taylor expansion in the following form: L (X +δX) = L (X)+Tr  \u0012∂L ∂X \u0013T δX ! +o(δX) (27) Now, let’s compute ∂L ◦ϕ(X) ∂X when ϕ(X) = XYXT = M expressed as a function of ∂L ∂M . L ◦ϕ(X +δX) = L ((X +δX)Y(X +δX)T) = L (XYXT +XYδXT +δXYXT +δXYδXT) = L (M)+Tr  \u0012∂L ∂M \u0013T (XYδXT +δXYXT) ! +o(δX) = L (M)+2Tr   YXT \u0012∂L ∂M \u0013T δX ! +o(δX) = L (M)+Tr  \u0012 2∂L ∂M XY T \u0013T δX ! +o(δX) (28) On the other hand, we express the Taylor expansion of L ◦ϕ: L ◦ϕ(X +δX) = L ◦ϕ(X)+Tr  \u0012∂L ◦ϕ ∂X \u0013T δX ! +o(δX) = L (M)+Tr  \u0012∂L ◦ϕ ∂X \u0013T δX ! +o(δX) (29) By identification we conclude that: ∂L ◦ϕ ∂X = 2∂L ∂M XY T Following the same proof structure, we derive: M = XYXT ⇒ ∂L ∂X = 2∂L ∂M XY T M = YXY T ⇒ ∂L ∂X = Y T ∂L ∂M Y M = X−1 ⇒ ∂L ∂X = −MT ∂L ∂M MT (30) 20 Let A : Rq → Mn×n, and we want to compute ∂L (A(x)) ∂x j (x j is the j-th component of vector x) as a function of ∂L (A) ∂A . Employing the Chain rule, we have: ∂L ◦A ∂x j = Tr   ∂A ∂x j T ∂L ∂A ! = ∑ k,l \u0012 ∂A ∂x j \u0013 k,l \u0012∂L ∂A \u0013 k,l (31) Computationally, we favour the first expression. Now, consider a scalar function L : Rn → R and vector-valued function f with jacobian Jx. We want to compute ∂L ◦f(x) ∂x as a function of ∂L (m) ∂m . First, we write the first-order Taylor expansion of L ◦ f: L ◦ f(x+δx) = L ◦ f(x)+⟨∇L ◦ f,δx⟩+o(δx) (32) L ◦ f(x+δx) = L ( f(x)+Jxδx+o(δx)) = L ( f(x))+⟨∇L ,Jxδx⟩+o(δx) = L ◦ f(x)+⟨JT x ∇L ,δx⟩+o(δx) (33) By identification we conclude that: ∇L ◦ f = JT x ∇L ⇔ ∂L ◦ f(x) ∂x = JT x ∂L (m) ∂m (34) B Backpropagation equations in an EKF To compute the gradient w.r.t any varibale using backpropagation, it is necessary to sum all contributions direct successors ,of this variable. For the sake of simplicity in equation derivation, we begin by deriving equations inside the Riccati equation. Subsequently, we calculate the contributions w.r.t input control variable. B.1 Gradient propagation in Riccati equations First we consider the propagation step: Pn|n−1 = FnPn−1|n−1FT n +GnQnGnT , (35) followed by an update step (Riccati equation): Sn = HnPn|n−1HT n +Rn , (36) Kn = Pn|n−1HT n S−1 n , (37) Pn|n = (I −KnHn)Pn|n−1 = (I −KnHn)Pn|n−1(I −KnHn)T +KnRnKT n , (38) We start with a graph showing the relationship between variables to get a better understanding of the dependencies between them. 21 Pn−1|n−1 Pn|n−1 Pn|n Fn,Gn Hn,Rn Figure 7: Dependencies of KF’s variables in Riccati’s equations For the posterior covariance, we apply equation (30) to the Ricatti equation. ∂L ∂Pn−1|n−1 = \u0012 ∂L ∂Pn−1|n−1 \u0013(Pn|n−1) = FT n ∂L ∂Pn|n−1 Fn (39) For the prior covariance, we used the information form of the Riccati equation: P−1 n|n = P−1 n|n−1 +HT n R−1 n Hn we find: ∂L ∂Pn|n−1 = −P−1 n|n−1   ∂L ∂P−1 n|n−1 !(Pn|n) P−1 n|n−1 = P−1 n|n−1Pn|n ∂L ∂Pn|n Pn|nP−1 n|n−1 = (I −KnHn)T ∂L ∂Pn|n (I −KnHn). (40) Then we have: ∂L ∂Fn = \u0012∂L ∂Fn \u0013(Pn|n−1) = 2 ∂L ∂Pn|n−1 FnPn−1|n−1 (41) ∂L ∂Gn = \u0012 ∂L ∂Gn \u0013(Pn|n−1) = 2 ∂L ∂Pn|n−1 GnQn (42) \u0012∂L ∂Hn \u0013T = \u0012∂L ∂Hn \u0013(Pn|n) = 2 ∂L ∂P−1 n|n HT n R−1 n = −2Pn|n ∂L ∂Pn|n Pn|nHT n R−1 n (43) ∂L ∂Rn = \u0012∂L ∂Rn \u0013(Pn|n) = −R−1 n ∂L ∂R−1 n R−1 n = −R−1 n Hn ∂L ∂P−1 n|n HT n R−1 n = R−1 n HnPn|n ∂L ∂Pn|n Pn|nHT n R−1 n (44) Remark: we can do the same in information form and maximize the information gain in the absence of Q process noise, which amounts to observability (or more precisely constructibility) grammian optimization. 22 B.2 Dependencies w.r.t. the controls Assume we have a nonlinear dynamical model: xn = f(xn−1,un,wn), (45) yn = h(xn)+νn. (46) As before we can represent dependencies between variables using a graph: un Fn,Gn Rn,Hn xn−1 xn Figure 8: Graph of dependencies of EKF’s variables involved propagation and linearization step Returning to the Riccati equation, we are interested to use L (PN) as a cost function and we would like to assess the sensitivity of L w.r.t. the controls un’s. The influence of the controls on L is mediated through the parameters Fn, Gn Hn and Rn. Particularly, with non-linear dynamic, the elements of matrices Fn and Gn may exhibit dependence on both xn−1 and un. Furthermore, Hn and Rn depend on xn. Additionally, it is assumed that the remaining parameters in the Riccati equation remain independent of xn and un. Remark: It is easier to suppose there is no relation between function f and matrices Fn. We just see the Fn’s as arbitrary functions of the variables xn−1,un−1 for now. That said, we have computed the sensitivity of L w.r.t. matrices. We now consider L as a function of these matrices: L (F1,...,FN,G1,...,GN,H1,...,HN,R1,...,RN) with known gradients ∂L ∂Fn , ∂L ∂Gn , ∂L ∂Rn and ∂L ∂Hn . Let us replace the dynamical model above with a linearized model: ( xn = f(xn−1,un,wn) ˜xn = f(˜xn−1,un,0) (47) en = xn − ˜xn = f(xn−1,un,wn)− f(˜xn−1,un,0) ≃ f(xn−1 − ˜ n−1+ ˜xn−1,un,0)+Gnwn − f(˜xn−1,un,0) ≃ Jx n(xn−1 − ˜xn−1)+Gnwn = Jx nen−1 +Gnwn (48) which is justified as all calculations are to the first order around a nominal trajectory. We denote by Ju the jacobian w.r.t. u and Jx the jacobian w.r.t. x (albeit matrix F, but it is less confusing to derive the gradients in the more general case where f is generic 23 with generic jacobian Jx). Using this linearization, we calculate the sensitivity of L w.r.t the component k of xn−1: ∂L ∂xk n−1 =   ∂L ∂xk n−1 !(Fn) +   ∂L ∂xk n−1 !(Gn) +   ∂L ∂xk n−1 !(xn) +   ∂L ∂xk n−1 !(Hn−1) +   ∂L ∂xk n−1 !(Rn−1) = Tr   ∂L ∂Fn T ∂Fn ∂xk n−1 ! +Tr   ∂L ∂Gn T ∂Gn ∂xk n−1 ! +(Jx nek)T ∂L ∂xn +Tr   ∂L ∂Hn−1 T ∂Hn−1 ∂xk n−1 ! +Tr   ∂L ∂Rn−1 T ∂Rn−1 ∂xk n−1 ! (49) where ek the k-th base vector. In the same way, we calculate the derivative of L w.r.t the component k of un: ∂L ∂ukn = \u0012∂L ∂ukn \u0013(Fn) + \u0012∂L ∂ukn \u0013(Gn) +   ∂L ∂xk n−1 !(xn) = Tr   ∂L ∂Fn T ∂Fn ∂ukn ! +Tr   ∂L ∂Gn T ∂Gn ∂ukn ! +(Ju nek)T ∂L ∂xn (50) C First backpropagation step After the forward pass, the backpropagation begins by computing gradients at the last time step N. In this initial backpropagation step, dependencies between variables ex- hibit some differences, implying distinct equations. To analyze all dependencies, we refer to the graph in the figure9. PN−1|N−1 PN|N−1 PN|N L RN−1,RN−1 FN,GN uN RN,HN xN−1 xN Figure 9: Graph of dependencies of EKF’s variables involved in the last step N At the last step only successor’s of xN and PN|N are different. In fact, PN|N has only L as a sucessor and xN has HN and RN (at the step n, xn has 5 successors : Hn, Rn, Fn+1, Gn+1 and xn+1). The partial derivative ∂L ∂PN|N depend of the L chosen. For example if we use trace then ∂L ∂PN|N = Id. Using ∂L ∂PN|N we can compute ∂L ∂xN by using the 24 3 following equations: \u0012 ∂L ∂HN \u0013T = −2PN|N ∂L ∂PN|N PN|NHT N R−1 N (51) ∂L ∂RN = R−1 N HNPN|N ∂L ∂PN|N PN|NHT N R−1 N (52) ∂L ∂x j N = Tr   ∂L ∂HN T ∂HN ∂x j N ! +Tr   ∂L ∂RN T ∂RN ∂x j N ! (53) D Equation summary The gradient computation using backpropagation consists of two parts. The first part named forward pass computes all quantities involved in an Extended Kalman Filter, such as xn, Pn|n, Pn|n−1, Fn, Gn .... At each iteration, we set the innovation zn = 0 corresponding to its expected value (this explains why we have only xn and not xn|n or xn|n−1). Additionally, during this step, we compute quantities such as ∂Fn ∂ukn or ∂Fn ∂xkn .... Then, in the backward step, gradients are computing recursively. To initialize the gradients, we first compute ∂L ∂PN|N and ∂L ∂x j N = Tr \u0012 ∂L ∂HN T ∂HN ∂x j N \u0013 +Tr \u0012 ∂L ∂RN T ∂RN ∂x j N \u0013 as ex- plained in Section C. Then, recursively use the equations derived in Section B to back- propagate gradients. ∂L ∂Pn−1|n−1 = FT n ∂L ∂Pn|n−1 Fn (54) ∂L ∂Pn|n−1 = (I −KnHn)T ∂L ∂Pn|n (I −KnHn) (55) ∂L ∂xk n−1 = Tr   ∂L ∂Fn T ∂Fn ∂xk n−1 ! +Tr   ∂L ∂Gn T ∂Gn ∂xk n−1 ! +(Jx nek)T ∂L ∂xn (56) +Tr   ∂L ∂Hn−1 T ∂Hn−1 ∂xk n−1 ! +Tr   ∂L ∂Rn−1 T ∂Rn−1 ∂xk n−1 ! (57) ∂L ∂Fn = 2 ∂L ∂Pn|n−1 FnPn−1|n−1 (58) ∂L ∂Gn = 2 ∂L ∂Pn|n−1 GnQn (59) \u0012∂L ∂Hn \u0013T = −2Pn|n ∂L ∂Pn|n Pn|nHT n R−1 n (60) ∂L ∂Rn = R−1 n HnPn|n ∂L ∂Pn|n Pn|nHT n R−1 n (61) 25 Finally : ∂L ∂ukn = Tr   ∂L ∂Fn T ∂Fn ∂ukn ! +Tr   ∂L ∂Gn T ∂Gn ∂ukn ! +(Ju nek)T ∂L ∂xn 26 "
}