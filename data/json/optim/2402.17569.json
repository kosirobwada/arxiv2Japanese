{
    "optim": "Backpropagation-Based Analytical Derivatives\nof EKF Covariance for Active Sensing\nJonas Benhamou1,2, Silv`ere Bonnabel1, and Camille Chapdelaine2\n1Mines Paris, PSL Research University, Centre for Robotics, 60 bd Saint-Michel,\n75006 Paris, France, silvere.bonnabel@minesparis.psl.eu\n2SAFRAN TECH, Groupe Safran, Rue des Jeunes Bois - Chateaufort, 78772 Magny\nLes Hameaux CEDEX, France, {camille.chapdelaine,\njonas.benhamou}@safrangroup.com\nFebruary 28, 2024\nAbstract\nTo enhance accuracy of robot state estimation, perception-aware (or active\nsensing) methods seek trajectories that minimize uncertainty. To this aim, one\npossibility is to seek trajectories that minimize the final covariance of an extended\nKalman filter (EKF), w.r.t. its control inputs over a given horizon. However, this\ncan be computationally demanding. In this article, we derive novel backpropaga-\ntion analytical formulas for the derivatives of the final covariance of an EKF w.r.t.\nits inputs. We then leverage the obtained gradients as an enabling technology to\nderive perception-aware optimal motion plans. Simulations validate the approach,\nshowcasing improvements in both estimation accuracy and execution time. Exper-\nimental results on a real large ground vehicle also support the method.\nKeywords: perception-aware, extended Kalman filter, trajectory optimization,\nbackpropagation.\n1\nIntroduction\nIn robotics, perception-aware (PA) approaches, [1, 2, 3, 4], or active sensing approaches,\nseek trajectories that maximize information gathered from sensors so as to perform\nrobotic tasks safely. Notably, in the context of ground vehicles, when localization is\nbased on ranging or bearing measurements relative to beacons, the efficiency of active\nsensing has been shown by [5, 6]. In [7], trajectories are generated to perform opti-\nmal online calibration between GPS and inertial measurement unit (IMU), see also [8].\nIn [3], for visual-inertial navigation systems, the authors have optimized the duration\nin which landmarks remain within the field of view. In the context of simultaneous\nlocalization and mapping (SLAM), those methods pertain to active SLAM, see [9].\n1\narXiv:2402.17569v1  [cs.RO]  27 Feb 2024\nOne way to attack active sensing is through the use of Partially Observable Markov\nDecision Processes (POMDPs) [10], see [11], which offer a proper mathematical frame-\nwork, but whose complexity is often prohibitory [12]. Sampling-based planners [13,\n14] may be subject to the same issues. A more tractable option, that we presently adopt,\nis to work with the widespread extended Kalman filter (EKF), which estimates in real\ntime the state xn from various sensor measurements, and (approximately) conveys the\nassociated extent of uncertainty through the state error covariance matrix Pn, that may\nbe used as an objective to minimize, as advocated in, e.g., [15].\nUsing the Gramian matrix to elicit observability, or as a surrogate for Pn, as advo-\ncated in [5, 6, 7, 16], is somewhat simpler but may lead to suboptimal motion plans\nin terms of gathered information [17]. Direct minimization of the final uncertainty\nencoded in PN is advocated instead in [17, 18, 15]. To find optimal trajectories, one\nmay restrict the problem to the class of differentially flat systems, and use splines, as\nadvocated in [18, 5], or one can try to compute and use directly the gradients of PN\nwith respect to (w.r.t.) the control inputs. To this aim, several approaches are possible.\nOne can use a brute force approach (in the vein of [19]) or numerical differentiation,\nthat may be ill-conditioned and intractable, owing to the complexity of the EKF’s equa-\ntions. To get around those problems, [15] advocates using backpropagation, through\nautomatic differentiation, and argues that deriving analytical expressions would be dif-\nficult.\nIn this paper, we fill a gap by providing closed-form analytical expressions for the\nderivatives of any smooth function of the final covariance matrix PN of an EKF, w.r.t.\nall previous control inputs. Those novel equations, that build upon our recent results\nfor the linear Kalman filter [20], extend them to the nonlinear case, using an EKF. In\naddition to being analytical, and decreasing some numerical errors, these equations\nlead to further speedups even over automatic differentiation, as we will show in this\npaper. Then, we apply the technique to derive a novel method for perception-aware\noptimal motion planning.\nThe main contributions of this paper are as follows:\n• Deriving novel analytical backpropagation equations for the gradient of the co-\nvariance of an EKF with respect to all inputs of the filter, including control vari-\nables, thus partly extending [20] to the relevant nonlinear context;\n• Hence providing a computationally efficient method whose cost to compute the\ngradients w.r.t. all control inputs at once, over an N-step horizon, is similar to\nthat of running one EKF over this horizon,\n• Applying the technique to derive a perception-aware method, which may be an\nenabler for real-time implementation for planning over longer horizons;\n• Validate and compare the technique through simulations, and real experiments\non a car-size ground vehicle.\nSection 2 introduces notations and outlines the gradient we want to compute. Sec-\ntion 3 establishes backpropagation equations for computing this gradient. In Section\n4, our path planning formulation is introduced. Finally, we demonstrate the benefits of\nour approach in simulations (section 5) and real experiments (section 6).\n2\n2\nPrimers\nFor partially observed linear dynamical systems affected by white Gaussian noise, the\nKalman filter (KF) computes the statistics of the state given past observations, namely\np(xn|y0,...,yn), in real time. The Kalman filter (KF) relies on many parameters en-\ncoded in the noise covariance matrices Qn and Rn. There exist various approaches to\ncompute the derivatives of the KF’s outputs w.r.t. those parameters. The early sensitiv-\nity equations [21], see also [22], allow for computing the derivative of the likelihood\nL := log p(y0,...,yn) w.r.t. the noise parameters. A much faster approach is to use\nbackpropagation, either using numerical auto-differentiation, as advocated in [15], or\nclosed-form formulas as very recently derived in [20].\nIn this paper, we first target closed-form backpropagation formulas for computing\nthe gradients of an EKF w.r.t. all its inputs, from the noise parameters to the control\ninputs. This provides a nontrivial extension of the results of [20] to nonlinear systems.\nWe start with a few primers.\n2.1\nPreliminaries\nLet’s consider a nonlinear discrete-time system:\n(\nxn = f(xn−1,un,wn),\nx0 = x0\nyn = h(xn)+vn\n(1)\nwhere xn ∈ Rp is the system’s state, un ∈ Rq is the control input, wn ∈ Rr represents\nthe process noise which follows a Gaussian distribution with zero mean and covariance\nmatrix Qn. The measured output is denoted by yn ∈ Rl, corrupted by a Gaussian mea-\nsurement noise vn with zero mean and covariance matrix Rn. Owing to unknown noises\ncorrupting the equations, and to the state being only partially observed through yn, one\nneeds to resort to a state estimator.\nThe Extended Kalman Filter (EKF) provides a joint estimation of the state, denoted\nas ˆxn, and its covariance matrix, denoted as Pn. It consists of two steps: a propagation\nstep and an update step.\nAt the propagation step, the estimated state is evolved through the noise-free model,\nthat is,\nˆxn|n−1 = f(ˆxn−1|n−1,un,wn),\n(2)\nand the covariance of the state error (such as x− ˆx) is evolved as\nPn|n−1 = FnPn−1|n−1FT\nn +GnQnGT\nn .\n(3)\nAt the update step, the estimated state and the covariance are updated in the light of\nobservation yn as\nSn = HnPn|n−1HT\nn +Rn ,\n(4)\nKn = Pn|n−1HT\nn S−1\nn ,\n(5)\nˆxn|n = ˆxn|n−1 +Kn(yn −h(ˆxn|n−1))\n(6)\nPn|n = (I −KnHn)Pn|n−1.\n(7)\n3\nThe Riccati update step (7) proves equivalent to the following update in so-called in-\nformation form:\nP−1\nn|n = P−1\nn|n−1 +HT\nn R−1\nn Hn.\n(8)\nIn these equations, matrices Fn, Gn and Hn are all jacobians that depend on state esti-\nmation ˆxn and control inputs un. In the case of linear error (x− ˆx), they read:\nFn = ∂ f\n∂xn\n(ˆxn−1|n−1,un,0),\nGn = ∂ f\n∂wn\n(ˆxn−1|n−1,un,0),\nHn = ∂h\n∂xn\n(ˆxn|n−1).\n(9)\nThrough these Jacobians, the control inputs un affect the covariances Pn|n−1 and Pn|n,\nwhich is in stark contrast with the linear case. Thus, it makes sense to compute the\nsensitivity of covariance matrices to control.\n2.2\nBackpropagation based gradient computation\nThe final covariance computed in the EKF PN|N over a fixed window, say n = 0,...,N,\nis the result of an iterative algorithm, and can thus be viewed as a composition of many\nfunctions, as layers in a neural network. As a result, it lends itself to backpropagation,\na way of computing the chain rule backwards. Backpropagation (”backprop”) is very\nefficient when there are numerous inputs and the output is a scalar function. Beyond\nneural networks, it has applications in control and robotics. In [23], in the context of\nlinear Kalman filtering, it is used to compute the gradient of the negative logarithm of\nthe marginal likelihood (NLL) w.r.t all observations y1,...,yN, allowing for measure-\nment selection and fault detection. In [15], perception-aware trajectory generation is\nperformed using an optimisation-based method where gradients are computed using an\nautomatic differentiation algorithm.\n2.3\nScalar loss design\nFor backpropagation to be numerically efficient, one needs the objective to be a scalar\nfunction. The most common choices to reflect the final uncertainty are the trace L =\nTr(PN|N), used in [17, 7, 15], or the maximum eigenvalue, which has to be regularized\nusing Schatten’s norm, see [5]. Other possibilities revolve around the Observability\nGramian (OG), where one can elicit observability by trying to minimize the smallest\neigenvalue, as in [5], or maximimizing the trace, which is proved in [24] to be in-\nterpretable as a deterministically propagated average error. Although the covariance\nmatrix and the OG may be related [5]), we will focus on the former that more closely\nreflects uncertainty in the presence of noise [17].\nAs Tr(PN|N) sums the diagonal terms, which are variances expressed in possibly\ndifferent units and choice of scales, it is reasonable to renormalize the matrix, as sug-\ngested in [7]. We suggest to use the initial inverse covariance matrix as a scaling factor\nmatrix, leading to the modified trace objective L = Tr\n\u0000P−1\n0 PN|N\n\u0001\n. Note that this may\nalso ensure better conditioning of the optimization problem to come.\n4\n3\nNovel sensitivity equations for the EKF\nWe consider a fixed window, say, n = 0...N, and we seek to differentiate a function\nL (PN|N) of the final uncertainty PN|N, w.r.t. all the previous EKF inputs, that are, the\nnoise parameters Rn,Qn, the control inputs un, for n = 1...N, and the initial values\nˆx0,P0|0. They all affect L (PN|N) in a complicated manner, through the EKF equations\n(2) to (9). For instance a modification of u0, namely u0 +δu0 affects initial Jacobians\nR0,G0,H0 in (9), that in turn affect all subsequent quantities output by the EKF through\neq. (2) to (8), finally affecting L (PN|N) in a non-obvious manner.\nTo analytically compute the derivatives, there are two routes. The historical one is\nto forward propagate a perturbation, say δun, n < N, through the equations. It is known\nas the sensitivity equations, and has been done–at least–for the linear Kalman filter in\n[21], essentially for adaptive filtering. The other route is to compute derivatives back-\nwards, using the backprop method. It is far less straightforward, and has been proposed\nonly very recently, leading to drastic computation speedups, see [20], in the context of\nlinear systems. In this paper we heavily rely on our prior work [20] to go a step fur-\nther, by accommodating nonlinear equations, that is, going from the Kalman Filter to\nthe EKF, with the additional difficulty that the Jacobians depend on the estimates–but\nrestricting ourselves to losses of the form L (PN|N), our end goal being active sensing.\nWe show this additional dependency lends itself to the backprop framework too. We\nalso extend the calculations to get the derivatives w.r.t. control inputs (which would not\nmake sense in the linear case as they are zero).\n3.1\nMatrix derivatives\nWe now explain the methodology, the main steps, and provide the final equations.\nAs deriving closed-form formulas through backward computation to elicit numerical\nefficiency is non trivial and lengthy, a full-blown mathematical proof can be found in\nthe online arxiv preprint of the present paper.\nOur method heavily relies on two ingredients. First, the notion of derivative of a\nscalar function w.r.t. a matrix, and the associated formulas based on the chain rule.\nThen, dependency diagrams which encapsulate how the functions are composed.\nConsider L (M), a scalar function of a matrix M = f(X,Y), where X and Y are\nalso matrices. ∂L\n∂M denotes the matrix defined by ( ∂L\n∂M )ij = ∂L\nMij . To alleviate notation,\nwe similarly write ∂L\n∂X as the matrix ∂L ◦f\n∂X .\nThe chain rule provides rules of calculus for matrix derivatives. We have the fol-\nlowing formulas [25]:\nM = XYXT\n⇒ ∂L\n∂X = 2∂L\n∂M XY T\nM = YXY T\n⇒ ∂L\n∂X = Y T ∂L\n∂M Y\nM = X−1\n⇒ ∂L\n∂X = −MT ∂L\n∂M MT\n(10)\n5\nIn the particular case where X and M are vectors, we have:\nM = f(X) ⇒ ∂L\n∂X = JT ∂L\n∂M ,\n(11)\nwith J the Jacobian matrix of f w.r.t. X.\nWhen the matrix X depends on a scalar variable s, we have the following formula:\nM = X(s) ⇒ ∂L\n∂s = Tr\n\u0012∂XT\n∂s\n∂L\n∂M\n\u0013\n(12)\n3.2\nBackprop equations for the involved matrices\nThe graph in Figure 1 shows the relationships involved in the calculation of the state’s\nerror covariance, which is our variable of interest.\nPn−1|n−1\nPn|n−1\nPn|n\nFn,Gn\nRn,Hn\nFigure 1: Dependencies of EKF’s variables in Riccati’s equations (3) and (8). Each\nvariable (node) is a function of its predecessors.\nThe backprop method consists in running an EKF until time N, to fix the values\nof all variables, and then running the present method backwards to get the derivatives.\nLet us assume we have computed an expression for\n∂L\n∂PN|N (initialization step) at final\ncovariance PN|N. It gives how a small variation in PN|N affects the objective, ignoring\nall the other variables. Starting with n = N, we go backwards as follows. As Pn|n is\na function of Pn|n−1 which is a function of Pn−1|n−1 in turn, through (3) and (8), we\ncan use formulas (10) to assess how a small perturbation in Pn|n−1 and Pn−1|n−1 affects\nthe loss in turn (as they affect subsequent quantities, whose variation on L has been\ncomputed). This yields\n∂L\n∂Pn−1|n−1\n= FT\nn\n∂L\n∂Pn|n−1\nFn\n(13)\n∂L\n∂Pn|n−1\n= (I −KnHn)T ∂L\n∂Pn|n\n(I −KnHn)\n(14)\nIn the same way, we apply formula (10) to (3) and (8) to obtain the following\n6\nrelationships:\n∂L\n∂Fn\n= 2\n∂L\n∂Pn|n−1\nFnPn−1|n−1\n(15)\n∂L\n∂Gn\n= 2\n∂L\n∂Pn|n−1\nGnQn\n(16)\n∂L\n∂HTn\n= −2Pn|n\n∂L\n∂Pn|n\nPn|nHT\nn R−1\nn\n(17)\n∂L\n∂Rn\n= R−1\nn HnPn|n\n∂L\n∂Pn|n\nPn|nHT\nn R−1\nn\n(18)\nKnowing\n∂L\n∂Pn|n and\n∂L\n∂Pn|n−1 , these equations allow in passing to calculate the partial\nderivative of the loss with respect to the intermediate variables Fn, Gn, Hn and Rn at\neach step.\n3.3\nBackprop equations for the vector variables\nWe can now compute the derivatives w.r.t. the state estimates ˆx and the control inputs\nu, which are vectors. However, a remark is necessary. Our end goal is to derive optimal\ncontrols u1,...,uN that minimize loss L (PN|N). As this is performed ahead of time,\nthe (noisy) observations yn in (6) are not available. The most reasonable choice is then\nto plan using the a priori value of the yn, i.e., yn = h(ˆxn|n−1). We may thus alleviate\nnotation writing ˆxn|n = ˆxn|n−1 := ˆxn and ˆxn−1|n−1 := ˆxn−1.\nThe graph in Figure 1 only focuses on the covariance variables. If we step back,\nwe see the Jacobians depend on the linearization point ˆxn−1 and the control inputs un,\nsee (9). A bigger picture encapsulating all the dependencies in the EKF is represented\nin Figure 2.\nPn−1|n−1\nPn|n−1\nPn|n\nRn−1,Hn−1\nFn,Gn\nun\nRn,Hn\nˆxn−1\nˆxn\nFigure 2: Dependency diagram of all the variables involved in an EKF.\nFirst we compute ∂L\n∂un . There is a general rule, derived from the chain rule, which\nis that ∂L\n∂un is the sum of all the derivatives w.r.t. the direct successors of un in the\ngraph, see e.g., [20], provided they have been already computed in a previous step of\nthe backward calculation. Additionally using (11) and (12), and computing w.r.t. to\n7\neach scalar component uk\nn of vector un, this yields\n∂L\n∂ukn\n= Tr\n \n∂L\n∂Fn\nT ∂Fn\n∂ukn\n!\n+Tr\n \n∂L\n∂Gn\nT ∂Gn\n∂ukn\n!\n+(Ju\nnek)T ∂L\n∂ ˆxn\n(19)\nwhere Ju\nn := ∂ f\n∂u\n\f\f\f\nˆxn−1,un,0 with ˆxn−1,un computed when running the EKF forward, and\nek the k-th vector of the canonical basis (details are given in the appendix of the online\npreprint).\nSimilarly, we compute the derivative w.r.t. the k-th scalar component of the sys-\ntem’s state xk\nn−1, by adding terms corresponding to each successor in the graph:\n∂L\n∂ ˆxk\nn−1\n= Tr\n \n∂L\n∂Hn−1\nT ∂Hn−1\n∂ ˆxk\nn−1\n!\n+Tr\n \n∂L\n∂Rn−1\nT ∂Rn−1\n∂ ˆxk\nn−1\n!\n+(Jx\nnek)T ∂L\n∂ ˆxn\n+Tr\n \n∂L\n∂Fn\nT ∂Fn\n∂ ˆxk\nn−1\n!\n+Tr\n \n∂L\n∂Gn\nT ∂Gn\n∂ ˆxk\nn−1\n!\n(20)\nwhere Jx\nn = ∂ f\n∂x\n\f\f\f\nˆxn−1,un,0 (which is equal to Fn).\n3.4\nBackprop initialization\nTo initialize the backward process, one needs to compute\n∂L (PN|N)\n∂PN|N\n. This depends on\nthe retained loss, see Section 2.3. In the case of the normalized trace loss, we have\n∂L (PN|N)\n∂PN|N\n= ∂Tr\n\u0000P−1\n0 PN|N\n\u0001\n∂PN|N\n= P−1\n0 .\n(21)\nIn the case where one targets the maximum eigenvalue of PN|N as a minimization ob-\njective, the loss must be chosen consequently. To handle the non-differentiable of this\nobjective, it is possible to regularize it using Schatten’s norm. The reader is referred to\n[5].\nNote also that at first backward step, n = N, (20) needs to be adapted, as ˆxN only\nhas two successors in the graph, thus:\n∂L\n∂ ˆxk\nN\n= Tr\n \n∂L\n∂HN\nT ∂HN\n∂ ˆx j\nN\n!\n+Tr\n \n∂L\n∂RN\nT ∂RN\n∂ ˆxk\nN\n!\n(22)\n3.5\nFinal equations\nThe gradients may be obtained as follows. We first run the EKF forward, to get all\nthe EKF variables given a sequence of inputs. Then, we may compute the derivative\nof the loss w.r.t. PN|N at the obtained final covariance matrix. Letting n = N, (17)-\n(18), provide the derivatives w.r.t. HN and RN, and (14) w.r.t. PN|N−1. In turn (22)\nprovides the derivative w.r.t. ˆxN, so that (19) yields the gradient w.r.t. control input uN.\n8\nContinuing the process backward and using the equations above, we get the derivatives\nw.r.t. to all control inputs.\nThe process allows for drastic computation savings, as a backward process com-\nputationally similar to the EKF itself yields derivatives w.r.t. all control inputs, whereas\nforward propagating perturbations would demand running an entire process from scratch\nfor k = n to N to derive the derivative w.r.t. un. Akin to dynamic programming, back-\npropagation allows for reusing previous computations at each step.\n4\nApplication to perception-aware planning\nThe computation of the gradients w.r.t. all the EKF’s variables (beyond the control\ninputs) is a contribution in itself that may prove useful beyond active sensing. How-\never, we presently leverage it to address the following perception-aware optimal path\nplanning problem:\n(P)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmin\nx1,...,xN,u1,...,uNL (PN|N)\ns.t.\n∀n ≤ N xn = f(xn−1,un,wn),\nx0 = xI,\n∀n ≤ N Pn|n−1 = FnPn−1|n−1FT\nn +GnQnGT\nn ,\n∀n ≤ N Pn|n = (I −KnHn)Pn|n−1,\n∀n ≤ N umin ≤ un ≤ umax\n(23)\nwhere N is the time horizon, and L a scalar loss. This approach is known as partial\ncollocation, as in [15], i.e., we explicitly include states as optimization variables and\nimplicitly compute the covariance.\nWhile (23) seeks trajectories that minimize the accumulated uncertainty on the\nrobot state over a given horizon, we note that it is easy to add constraints or another\nterm in the loss to perform a specific task. For example, adding the constraint xN = xF\nallows for reaching a specific state while being perception-aware. A commonly em-\nployed method for solving this problem involves a first-order optimization algorithm,\nthe main steps of which are outlined in Algorithm 1. From a computational perspec-\ntive, the gradient computation stands out as the most computationally demanding step,\nhence the interest for the method developed above.\n4.1\nAlgorithm\nWhen all the gradients are known, first order nonlinear optimization algorithm such\nas Sequential Quadratic Programming (SQP) may be brought to bear. This leads to\nAlgorithm 1.\nThe process involves computing the gradient g of the cost function w.r.t. the control\nvariables using forward and backward passes through the EKF. Additionally, we com-\npute the gradient of the constraints with respect to decision variables. Subsequently,\nline search is conducted to determine an appropriate step size α for efficient conver-\ngence. However, line search requires evaluating the cost function, which corresponds\n9\nAlgorithm 1 Path planning algorithm\nRequire: x0, P0, N,L\nu ← (u0,...,uN)\nwhile L (PN|N) not converge do\ng ← gradient computation(u)\nα ← line search(u,g)\nu ← update(u,g,α)\n▷ Using SQP for example\nend while\nReturn: (u0,...,uN)\nto running a full EKF in our case. The decision variables are then updated using SQP.\nFurther details are given in the experimental sections.\n4.2\nDiscussion\nIn practice, it is difficult to use a loss L depending on the state’s covariance PN|N. In-\ndeed, the gradient computation of the loss w.r.t each control variable is expensive when\nusing forward difference [7, 17], as explained in Section 3.5. This has motivated [15]\nto use backpropagation, through automatic differentiation (AD), and argue deriving\nanalytical formulas would be difficult.\nThe interest of our work, that provides analytical formulas, is twofold in this regard.\nFirst, it is often preferable to have closed-form formulas when possible, to rule out\nmany numerical errors and keep better control over the calculation process (possibly\nopening up for some guarantees about the execution). As efficient implementations\nof the EKF involve Cholesky or SVDs of the covariance matrix, the behaviour of AD\nseems difficult to anticipate or guarantee. Then, it leads to computation speedups, as it\nwill be shown experimentally in the sequel.\n5\nSimulation results\nWe now apply our results to the problem of wheeled robot localization. We consider\na car-like robot modelled through the unicycle equations, and equipped with a GPS\nreturning position measurements. There are two difficulties associated with the corre-\nsponding estimation problem. First, the heading is not directly measured. Then, and\nmore importantly, we assume the position of the GPS antenna in the robot’s frame, that\nwe call lever arm, is unknown (or inaccurately known, or may slightly vary over time).\nThe resulting problem pertains to simultaneous self-calibration and navigation, in the\nvein of [7] but in a simpler context. In straight lines, for instance, the lever arm is not\nobservable, so perception-aware trajectories should lead to more accurate robot state\nestimation.\nIn this section we present the model, we assess and compare our method through\nsimulations. In the next section, we apply it to a real world off-road vehicle which is\nthe size of a car.\n10\n5.1\nRobot model\nThe system state consists of the orientation θn ∈ R, the position of the vehicle pn ∈ R2,\nand the lever arm ln ∈ R2. The control inputs are the steering angle νn and the forward\nvelocity µn. The kinematic equations based on a roll-without-slip assumption are as\nfollows:\n\n\n\n\n\n\n\nθn = θn−1 + dt\nL (µn +wµ\nn )tan(νn +wν\nn),\npn = pn−1 +dtΩ(θn−1)(µn +wµ\nn )e1,\nln = ln−1\n(24)\nwhere Ω(θ) =\n\u0012\ncos(θ)\n−sin(θ)\nsin(θ)\ncos(θ)\n\u0013\n, where L is the distance between the front and the\nrear wheels, e1 = (1,0)T indicates that the velocity is aligned with the robot’s heading,\nand dt is the sampling time. A Gaussian white noise wn = (wµ\nn ,wν\nn)T with covari-\nance matrix Q corrupts the forward velocity µn and steering angle νn to account for\nactuators’ imperfections, and the mismatch with idealized kinematic model (namely\nslipping).\nLetting ln ∈ R2 be the position of the GPS antenna in the vehicle’s frame w.r.t. to\nits center (the midpoint of the rear axle), the position measured by the GPS is\nyn = pn +Ω(θn)ln +εn\n(25)\nwhere εn is a 2D white noise with covariance matrix Rn.\nIn the simulations, we let L = 4m, dt = 1s. In terms of noise parameters, we let\nQ = diag(0.1,π/180), and Rn be the identity matrix, i.e., a standard deviation of 1\nm for the position measurements. To account for actuator physical limits, we assume\n|νn| ≤ 30π/180 rad and 0 ≤ µn ≤ 5 m.s−1. To account for acceleration limits, we add\nthe constraints |∆νn| ≤ 15π/180 rad.s−1 and |∆µn| ≤ 1 m.s−2.\n5.2\nSimulation results\nWe start by sampling admissible control inputs over a horizon N = 150s. Then, the\ncorresponding trajectory is obtained by integration. We then use the sequential least-\nsquares programming (SLSQP) algorithm from Scipy [26] to optimize the sequence of\ncontrols to apply. The calculation of the gradient of the loss with respect to the control\ninputs is performed using the equations detailed in section 3. An example of the initial\nrandom trajectory and the solution of the perception-aware problem can be found in\nFigure 3. It can be observed that the optimal trajectory for the Schatten norm and\nfor the trace are quite similar, and both oscillate around the initial random trajectory.\nThese oscillations are manoeuvres to automatically increase the observability of the\nlever arm, and reduce the expected covariance trace.\nTo demonstrate that the final covariance minimization translates into an actual re-\nduction of the average state estimation error, we simulate 200 trials of each optimal\ntrajectory by adding process noise and observation noise. During the simulation, the\nstate is estimated with an EKF based on (24), (25). The evolution of the absolute\n11\nFigure 3: On the left, an example of an initial random guess in blue. The other two\ntrajectories are solutions to the perception-aware problem where the loss is the trace\n(in orange) and the Schatten norm (in green). The right plot shows the expected trace\nof the covariance evolution for each trajectory.\nestimation error of the lever arm is displayed on Figure 4. For PA trajectories, the er-\nror decreases and converges more rapidly, illustrating the benefit of perception-aware\noptimal trajectory generation.\n5.3\nComputation time\nWe compared the computation times for the gradient of the loss w.r.t. control inputs\nwith three different methods. The first method using (forward) finite differences to\ncompute the gradient, as in [27]. The second method is an automatic differentiation\nmethod, which adopts the backpropagation paradigm, but through a numerical method,\nakin to [15]. Namely, we used the state-of-the-art PyTorch automatic differentiation\n(AD) [28]. Finally, the last method uses our backpropagation analytical formulas of\nSection 3. The code was executed on computer with an Intel Core i5 at 2.60 GHz.\nTable 1: Average and standard deviation of gradient calculation time (over 100 calcu-\nlations) using different methods.\nMethod\nExecution time\nFinite differences\n26.92 ± 8.45s\nPyTorch Autograd\n0.55 ± 0.19s\nOurs\n0.19 ± 0.07s\n12\nFigure 4: Absolute estimation error of the lever arm during the trajectory. On the left\nthe error for the lever arm in x and on the right in y. One-σ envelope illustrates the\ndispersion of errors over trials.\nTable 1 shows that gradient calculation using backpropagation (Autograd and ours)\nleads to large speedups. Indeed, when using a finite difference based method, opti-\nmization is computationally expensive, as mentioned in [7], where optimizing the trace\nof the sum of all covariances takes 13 hours for a 3D inertial navigation system. Even\nwhen compared to state-of-the-art PyTorch Autograd, our closed-form formulas are\nmuch faster, and more stable in terms of variability of computation time.\nThe computation time for the complete resolution of the optimization problem (23)\nusing our gradient calculation method and Algorithm 1 is 351s. Although this perfectly\nsuits off-line trajectory generation, it means the robot should stop for a few minutes to\nplan in a real-time context. However, this computation time could be significantly re-\nduced. First, we may obviously optimize over a shorter horizon. Then, the optimizer\ncurrently uses a line search algorithm to determine the descent step size. In our case,\nevaluating the objective function is computationally expensive [7] because it requires\nrunning the EKF along the entire trajectory, which is almost as time-consuming as\ncalculating all the gradients with our backpropagation method. Therefore, finding a\nmethod that reduces the number of calls to the objective function should prove effi-\ncient. Finally, another option to reduce computation time is to decrease the number\nof decision variables, by for instance parameterizing trajectories using B-splines, as in\n[5].\n13\n5.4\nDiscussion\nA few remarks are in order. First, we see that, by replacing state-of-the-art auto-\ngrad differentiation with our formulas, one may (roughly speaking) double the plan-\nning horizon for an identical computation budget. Besides, analytical formulas better\nsuit onboard implementation. It is interesting to note that they are totally akin to the\nEKF equations, which must be implemented on the robot anyway. Finally, analytical\nformulas–when available–may be preferable to numerical methods, as one keeps a bet-\nter control over what is being implemented, possibly opening up for some guarantees\n(the behavior of autograd may be harder to anticipate, and leads to higher computation\ntime variability). Moreover, we anticipate that coding them in C++ may lead to further\nspeedups.\nWe may also comment on the obtained trajectories. As the optimization problem\nis highly nonlinear, non-convex, and constrained, one should expect an optimization\nmethod to fall into a close-by local minimum. In Figure 3, the local nature of the op-\ntimum proves visible, as the obtained trajectory oscillates around the initial trajectory.\nMethods to step out of local minima go beyond the scope of this paper. However, it is\nworth noting that albeit a (close-by) local minimum, the obtained trajectory succeeds\nin much reducing state uncertainty. It reduces the final average error on the lever arm,\nwhich is the most difficult variable to estimate, by a factor 3, see Figure 4.\nIn the context of real-time online planning, this suggests a sensible way to use the\nformulas of the present paper would be to compute a real-time trajectory that optimizes\na control objective, and then to refine it in real time, by performing a few gradient\ndescent steps. This shall (much) increase the information gathered by the sensors.\n6\nReal-world experiments\nReal experiments were conducted jointly with the company Safran, a large group that\ncommercializes (among others) navigation systems. With the help from its engineers,\nwe used an experimental off-road car owned by the company, which is approximately\n4m long and 2.1m wide1.\n6.1\nExperimental setting\nThe vehicle is equipped with a standard GPS, odometers, and a RTK (Real Time Kine-\nmatic) GPS, which is not used by the EKF, but serves as ground-truth for position\nowing to its high accuracy. The lever arm between the GPS and the RTK is denoted by\nlGPS/RTK, and has been calibrated (it is only used for comparison to the ground-truth).\nTo further test our method, we conducted localization experiments on both ordinary\nand PA trajectories and compared their performance. We used the model described in\nSection 5.1, and devised an EKF that fuses odometer data (dynamical model) with GPS\nposition measurements. The vehicle state is represented by a 5-dimensional vector: two\n1Because of confidentiality requirements, the company has not wished to publish a picture of its experi-\nmental vehicle.\n14\ndimensions for position, one for the orientation, and two for the lever arm between the\nGPS and the center of the vehicle frame (midpoint of the rear axle).\nInitially, we generated ordinary trajectories at two different speeds (5 km/h, 10\nkm/h). Subsequently, we employed our PA path planning Algorithm 1 initialized with\nthose trajectories, to address optimization problem (23), using the final covariance trace\nas the loss. The constraints used were those relative to the actuators. To demonstrate\nthe ability of optimization-based planning methods to handle further constraints, we\nalso constrained the distance between the initial trajectory and the PA trajectory to\nbe less than 1.5m. Then, we used local tangent plane coordinates computed near the\nexperiment locations to convert 2D planning to world frame coordinates. Then, we\nfollowed each trajectory and computed the localization error committed by the EKF.\nTo measure localization accuracy, we utilized the RTK-GPS system as a ground-\ntruth, since its uncertainties are of the order of a few centimeters. The position error of\nthe vehicle was computed as follows:\nen =\n\r\rpRTK\nn\n−( ˆpn +Ω( ˆθn)(ˆln +lGPS/RTK)\n\r\r\n(26)\n6.2\nResults\nThe experiment comprises 4 runs: 2 reference runs and 2 perception-aware runs (at 5\nkm/h and 10 km/h). Trajectories returned by RTK-GPS over the first run are displayed\nin Figure 5. We note that the oscillations of the PA trajectory around the reference\ntrajectory, which enhances state (hence lever arm) observability.\nFigure 6 shows the trajectories for the second run, along with the evolution of the\ntrace of Pn|n output by the EKF (on the first run, the latter is wholly similar and was\nnot included owing to space limitations, to improve legibility of Fig. 5). We see the\nimprovement in terms of trace through the optimized trajectories. The visible wiggling\nof the covariance corresponds to the correction steps of the EKF. Indeed, the dynamical\nmodel is run at 100Hz, corresponding to the odometer frequency, while corrections are\nmade when GPS data are available, at approximately 1Hz.\n6.3\nAnalysis\nAlthough the trace of the covariance is smaller along the PA trajectory, it doesn’t guar-\nantee that the error with respect to ground truth is reduced. The uncertainty calcu-\nlated by the filter assumes all random variables are Gaussian, and the EKF is based\non approximations. For each trial, we calculated the average error obtained for each\ntype of trajectory. The results presented in Table 2 point out that PA trajectories en-\nhance localization accuracy. Indeed, in the scenario at 5 km/h, the error decreases by\n13.24% between the reference and the PA trajectory, and by 8.25% in the scenario at\n10 km/h. However, when compared with results from simulations, the improvement is\nsmaller. Several factors could explain this difference. Firstly, in simulations, we calcu-\nlated an average result using the Monte Carlo method, whereas here we have a single\ntrial. Additionally, in simulations, model and noises are perfectly known, whereas in\nreality, they are not. The roll-without-slip assumption is especially challenged when\nusing an off-road vehicle. Finally, due to the limited area, we explicitly constrained\n15\nFigure 5:\nOff-road trajectories of the RTK-GPS in a local tangent plane coordinates\noriented East-North-Up of the scenario at 5 km/h.\nFigure 6: On the left, trajectories of the RTK-GPS in local tangent plane coordinates\nat 10 km/h. On the right, the evolution of the covariance trace along each trajectory in\nthe scenario at a speed of 10 km/h.\nthe optimized trajectory to stay within a 1.5 m radius around the reference one, hence\nproducing a trajectory that optimally “refines” the reference trajectory, but no more.\n16\nTable 2: Calculation of the estimation error according to Equation (26) is performed\nfor all trajectories.\nSpeed (km/h)\nType\nMean error (m)\n5\nRef\n3.32\nPA\n2.88\n10\nRef\n4.73\nPA\n4.34\n7\nConclusion\nOur first contribution has been to introduce novel backpropagation analytical equations\nto compute the gradient of any loss based on the covariance of an EKF, w.r.t all its in-\nputs. Beyond the theoretical contribution, they lead to actual numerical speedups. Our\nsecond contribution has been to leverage those formulas to address PA path planning,\nand to test the method in simulation and on real-world experiments over large off-road\ntrajectories over a span of more than 50 meters. In future work, we would like to ap-\nply the method to more challenging problems, such as inertial navigation [7], and to\nimprove its scalability, notably by improving the line search. We also would like to\ncombine the method with other objectives such as reaching a desired goal, collision\navoidance, or energy consumption.\nReferences\n[1] L. Bartolomei, L. Teixeira, and M. Chli, “Perception-aware Path Planning for\nUAVs using Semantic Segmentation,” in 2020 IEEE/RSJ International Confer-\nence on Intelligent Robots and Systems (IROS), Oct. 2020, pp. 5808–5815.\n[2] G. Costante, C. Forster, J. Delmerico, P. Valigi, and D. Scaramuzza, “Perception-\naware Path Planning,” Feb. 2017.\n[3] V. Murali, I. Spasojevic, W. Guerra, and S. Karaman, “Perception-aware trajec-\ntory generation for aggressive quadrotor flight using differential flatness,” in 2019\nAmerican Control Conference (ACC), Jul. 2019, pp. 3936–3943.\n[4] J. Xing, G. Cioffi, J. Hidalgo-Carri´o, and D. Scaramuzza, “Autonomous Power\nLine Inspection with Drones via Perception-Aware MPC,” in 2023 IEEE/RSJ In-\nternational Conference on Intelligent Robots and Systems (IROS), Oct. 2023, pp.\n1086–1093.\n[5] P. Salaris, M. Cognetti, R. Spica, and P. R. Giordano, “Online Optimal\nPerception-Aware Trajectory Generation,” IEEE Transactions on Robotics,\nvol. 35, no. 6, pp. 1307–1322, Dec. 2019.\n[6] O. Napolitano, D. Fontanelli, L. Pallottino, and P. Salaris, “Gramian-based opti-\nmal active sensing control under intermittent measurements,” in 2021 IEEE Inter-\n17\nnational Conference on Robotics and Automation (ICRA), May 2021, pp. 9680–\n9686.\n[7] J. Preiss, K. Hausman, G. Sukhatme, and S. Weiss, “Simultaneous self-calibration\nand navigation using trajectory optimization,” The International Journal of\nRobotics Research, vol. 37, Aug. 2018.\n[8] S. Xu, J. S. Willners, Z. Hong, K. Zhang, Y. R. Petillot, and S. Wang,\n“Observability-Aware Active Extrinsic Calibration of Multiple Sensors,” in 2023\nIEEE International Conference on Robotics and Automation (ICRA), May 2023,\npp. 2091–2097.\n[9] J. S. Willners, S. Katagiri, S. Xu, T. Łuczy´nski, J. Roe, and Y. Petillot, “Adaptive\nHeading for Perception-Aware Trajectory Following,” in 2023 IEEE International\nConference on Robotics and Automation (ICRA), May 2023, pp. 3161–3167.\n[10] L. P. Kaelbling, M. L. Littman, and A. R. Cassandra, “Planning and acting in\npartially observable stochastic domains,” Artificial Intelligence, 1998.\n[11] S. Candido and S. Hutchinson, “Minimum uncertainty robot path planning using\na POMDP approach,” in 2010 IEEE/RSJ International Conference on Intelligent\nRobots and Systems, Oct. 2010, pp. 1408–1413.\n[12] C. H. Papadimitriou and J. N. Tsitsiklis, “The Complexity of Markov Decision\nProcesses,” Mathematics of Operations Research, vol. 12, no. 3, pp. 441–450,\n1987.\n[13] R. He, S. Prentice, and N. Roy, “Planning in information space for a quadrotor\nhelicopter in a GPS-denied environment,” in 2008 IEEE International Conference\non Robotics and Automation (ICRA), May 2008, pp. 1814–1820.\n[14] S. Prentice and N. Roy, “The Belief Roadmap: Efficient Planning in Belief Space\nby Factoring the Covariance,” The International Journal of Robotics Research,\nvol. 28, no. 11-12, pp. 1448–1465, Nov. 2009.\n[15] S. Patil, G. Kahn, M. Laskey, J. Schulman, K. Goldberg, and P. Abbeel, “Scaling\nup gaussian belief space planning through covariance-free trajectory optimiza-\ntion and automatic differentiation,” in Algorithmic Foundations of Robotics XI:\nSelected Contributions of the Eleventh International Workshop on the Algorith-\nmic Foundations of Robotics, H. L. Akin, N. M. Amato, V. Isler, and A. F. van der\nStappen, Eds.\nCham: Springer International Publishing, 2015, pp. 515–533.\n[16] C. B¨ohm, P. Brault, Q. Delamare, P. R. Giordano, and S. Weiss, “COP: Control\n& Observability-aware Planning,” Mar. 2022.\n[17] M. Rafieisakhaei, S. Chakravorty, and P. R. Kumar, “On the Use of the Observ-\nability Gramian for Partially Observed Robotic Path Planning Problems,” in 2017\nIEEE 56th Annual Conference on Decision and Control (CDC), Dec. 2017, pp.\n1523–1528.\n18\n[18] M. Cognetti, P. Salaris, and P. Robuffo Giordano, “Optimal Active Sensing with\nProcess and Measurement Noise,” in 2018 IEEE International Conference on\nRobotics and Automation (ICRA), May 2018, pp. 2118–2125.\n[19] P. Abbeel, A. Coates, M. Montemerlo, A. Ng, and S. Thrun, “Discriminative\nTraining of Kalman Filters,” in Robotics: Science and Systems, Jun. 2005, pp.\n289–296.\n[20] C. Parellier, A. Barrau, and S. Bonnabel, “Speeding-Up Backpropagation of Gra-\ndients Through the Kalman Filter via Closed-Form Expressions,” IEEE Transac-\ntions on Automatic Control, vol. 68, no. 12, pp. 8171–8177, Dec. 2023.\n[21] N. Gupta and R. Mehra, “Computational aspects of maximum likelihood esti-\nmation and reduction in sensitivity function calculations,” IEEE Transactions on\nAutomatic Control, vol. 19, no. 6, pp. 774–783, Dec. 1974.\n[22] J. V. Tsyganova and M. V. Kulikova, “SVD-Based Kalman Filter Derivative Com-\nputation,” IEEE Transactions on Automatic Control, vol. 62, no. 9, 2017.\n[23] C. Parellier, A. Barrau, and S. Bonnabel, “A Computationally Efficient Global\nIndicator to Detect Spurious Measurement Drifts in Kalman Filtering,” in 2023\n62nd IEEE Conference on Decision and Control (CDC), Dec. 2023, pp. 8641–\n8646.\n[24] J. Benhamou, S. Bonnabel, and C. Chapdelaine, “Optimal Active Sensing Con-\ntrol for Two-Frame Systems,” in 2023 62nd IEEE Conference on Decision and\nControl (CDC), Dec. 2023, pp. 5967–5974.\n[25] K. B. Petersen and M. S. Pedersen, “[ http://matrixcookbook.com ].”\n[26] P. Virtanen, R. Gommers, T. E. Oliphant, M. Haberland, T. Reddy, D. Cour-\nnapeau, E. Burovski, P. Peterson, W. Weckesser, J. Bright, S. J. van der Walt,\nM. Brett, J. Wilson, K. J. Millman, N. Mayorov, A. R. J. Nelson, E. Jones,\nR. Kern, E. Larson, C. J. Carey, ˙I. Polat, Y. Feng, E. W. Moore, J. VanderPlas,\nD. Laxalde, J. Perktold, R. Cimrman, I. Henriksen, E. A. Quintero, C. R. Har-\nris, A. M. Archibald, A. H. Ribeiro, F. Pedregosa, P. van Mulbregt, and SciPy\n1.0 Contributors, “SciPy 1.0: Fundamental algorithms for scientific computing in\nPython,” Nature Methods, vol. 17, no. 3, pp. 261–272, Mar. 2020.\n[27] V. Indelman, L. Carlone, and F. Dellaert, “Towards planning in generalized be-\nlief space,” in Robotics Research: The 16th International Symposium ISRR.\nSpringer, 2016, pp. 593–609.\n[28] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen,\nZ. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. K¨opf, E. Yang, Z. DeVito,\nM. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S. Chin-\ntala, “PyTorch: An Imperative Style, High-Performance Deep Learning Library,”\nDec. 2019.\n19\nA\nMatrix derivatives\nFirst, we provide an example of how to derive matrix derivative equations. Then, we\nwill list all the matrix derivative equations we have used in the paper. We consider a\nscalar function L : Rn×n → R and we define ∂L (X)\n∂X\nas the matrix of the derivative of\nL w.r.t each component of X (i.e.\n\u0010\n∂L (X)\n∂X\n\u0011\ni, j = ∂L (X)\n∂xi,j ). Using only matrix multipli-\ncation, we can express first-order Taylor expansion in the following form:\nL (X +δX) = L (X)+Tr\n \u0012∂L\n∂X\n\u0013T\nδX\n!\n+o(δX)\n(27)\nNow, let’s compute ∂L ◦ϕ(X)\n∂X\nwhen ϕ(X) = XYXT = M expressed as a function of ∂L\n∂M .\nL ◦ϕ(X +δX) = L ((X +δX)Y(X +δX)T)\n= L (XYXT +XYδXT +δXYXT +δXYδXT)\n= L (M)+Tr\n \u0012∂L\n∂M\n\u0013T\n(XYδXT +δXYXT)\n!\n+o(δX)\n= L (M)+2Tr\n \nYXT\n\u0012∂L\n∂M\n\u0013T\nδX\n!\n+o(δX)\n= L (M)+Tr\n \u0012\n2∂L\n∂M XY T\n\u0013T\nδX\n!\n+o(δX)\n(28)\nOn the other hand, we express the Taylor expansion of L ◦ϕ:\nL ◦ϕ(X +δX) = L ◦ϕ(X)+Tr\n \u0012∂L ◦ϕ\n∂X\n\u0013T\nδX\n!\n+o(δX)\n= L (M)+Tr\n \u0012∂L ◦ϕ\n∂X\n\u0013T\nδX\n!\n+o(δX)\n(29)\nBy identification we conclude that:\n∂L ◦ϕ\n∂X\n= 2∂L\n∂M XY T\nFollowing the same proof structure, we derive:\nM = XYXT\n⇒ ∂L\n∂X = 2∂L\n∂M XY T\nM = YXY T\n⇒ ∂L\n∂X = Y T ∂L\n∂M Y\nM = X−1\n⇒ ∂L\n∂X = −MT ∂L\n∂M MT\n(30)\n20\nLet A : Rq → Mn×n, and we want to compute ∂L (A(x))\n∂x j\n(x j is the j-th component of\nvector x) as a function of ∂L (A)\n∂A\n. Employing the Chain rule, we have:\n∂L ◦A\n∂x j\n= Tr\n \n∂A\n∂x j\nT ∂L\n∂A\n!\n= ∑\nk,l\n\u0012 ∂A\n∂x j\n\u0013\nk,l\n\u0012∂L\n∂A\n\u0013\nk,l\n(31)\nComputationally, we favour the first expression.\nNow, consider a scalar function L : Rn → R and vector-valued function f with\njacobian Jx. We want to compute ∂L ◦f(x)\n∂x\nas a function of ∂L (m)\n∂m\n. First, we write the\nfirst-order Taylor expansion of L ◦ f:\nL ◦ f(x+δx) = L ◦ f(x)+⟨∇L ◦ f,δx⟩+o(δx)\n(32)\nL ◦ f(x+δx) = L ( f(x)+Jxδx+o(δx))\n= L ( f(x))+⟨∇L ,Jxδx⟩+o(δx)\n= L ◦ f(x)+⟨JT\nx ∇L ,δx⟩+o(δx)\n(33)\nBy identification we conclude that:\n∇L ◦ f = JT\nx ∇L ⇔ ∂L ◦ f(x)\n∂x\n= JT\nx\n∂L (m)\n∂m\n(34)\nB\nBackpropagation equations in an EKF\nTo compute the gradient w.r.t any varibale using backpropagation, it is necessary to\nsum all contributions direct successors ,of this variable. For the sake of simplicity\nin equation derivation, we begin by deriving equations inside the Riccati equation.\nSubsequently, we calculate the contributions w.r.t input control variable.\nB.1\nGradient propagation in Riccati equations\nFirst we consider the propagation step:\nPn|n−1 = FnPn−1|n−1FT\nn +GnQnGnT ,\n(35)\nfollowed by an update step (Riccati equation):\nSn = HnPn|n−1HT\nn +Rn ,\n(36)\nKn = Pn|n−1HT\nn S−1\nn ,\n(37)\nPn|n = (I −KnHn)Pn|n−1 = (I −KnHn)Pn|n−1(I −KnHn)T +KnRnKT\nn ,\n(38)\nWe start with a graph showing the relationship between variables to get a better\nunderstanding of the dependencies between them.\n21\nPn−1|n−1\nPn|n−1\nPn|n\nFn,Gn\nHn,Rn\nFigure 7: Dependencies of KF’s variables in Riccati’s equations\nFor the posterior covariance, we apply equation (30) to the Ricatti equation.\n∂L\n∂Pn−1|n−1\n=\n\u0012\n∂L\n∂Pn−1|n−1\n\u0013(Pn|n−1)\n= FT\nn\n∂L\n∂Pn|n−1\nFn\n(39)\nFor the prior covariance, we used the information form of the Riccati equation:\nP−1\nn|n = P−1\nn|n−1 +HT\nn R−1\nn Hn\nwe find:\n∂L\n∂Pn|n−1\n= −P−1\nn|n−1\n \n∂L\n∂P−1\nn|n−1\n!(Pn|n)\nP−1\nn|n−1\n= P−1\nn|n−1Pn|n\n∂L\n∂Pn|n\nPn|nP−1\nn|n−1\n= (I −KnHn)T ∂L\n∂Pn|n\n(I −KnHn).\n(40)\nThen we have:\n∂L\n∂Fn\n=\n\u0012∂L\n∂Fn\n\u0013(Pn|n−1)\n= 2\n∂L\n∂Pn|n−1\nFnPn−1|n−1\n(41)\n∂L\n∂Gn\n=\n\u0012 ∂L\n∂Gn\n\u0013(Pn|n−1)\n= 2\n∂L\n∂Pn|n−1\nGnQn\n(42)\n\u0012∂L\n∂Hn\n\u0013T\n=\n\u0012∂L\n∂Hn\n\u0013(Pn|n)\n= 2 ∂L\n∂P−1\nn|n\nHT\nn R−1\nn\n= −2Pn|n\n∂L\n∂Pn|n\nPn|nHT\nn R−1\nn\n(43)\n∂L\n∂Rn\n=\n\u0012∂L\n∂Rn\n\u0013(Pn|n)\n= −R−1\nn\n∂L\n∂R−1\nn\nR−1\nn\n= −R−1\nn Hn\n∂L\n∂P−1\nn|n\nHT\nn R−1\nn\n= R−1\nn HnPn|n\n∂L\n∂Pn|n\nPn|nHT\nn R−1\nn\n(44)\nRemark: we can do the same in information form and maximize the information gain\nin the absence of Q process noise, which amounts to observability (or more precisely\nconstructibility) grammian optimization.\n22\nB.2\nDependencies w.r.t. the controls\nAssume we have a nonlinear dynamical model:\nxn = f(xn−1,un,wn),\n(45)\nyn = h(xn)+νn.\n(46)\nAs before we can represent dependencies between variables using a graph:\nun\nFn,Gn\nRn,Hn\nxn−1\nxn\nFigure 8: Graph of dependencies of EKF’s variables involved propagation and\nlinearization step\nReturning to the Riccati equation, we are interested to use L (PN) as a cost function\nand we would like to assess the sensitivity of L w.r.t. the controls un’s. The influence\nof the controls on L is mediated through the parameters Fn, Gn Hn and Rn. Particularly,\nwith non-linear dynamic, the elements of matrices Fn and Gn may exhibit dependence\non both xn−1 and un. Furthermore, Hn and Rn depend on xn. Additionally, it is assumed\nthat the remaining parameters in the Riccati equation remain independent of xn and un.\nRemark: It is easier to suppose there is no relation between function f and matrices\nFn. We just see the Fn’s as arbitrary functions of the variables xn−1,un−1 for now.\nThat said, we have computed the sensitivity of L w.r.t. matrices. We now consider\nL as a function of these matrices:\nL (F1,...,FN,G1,...,GN,H1,...,HN,R1,...,RN)\nwith known gradients ∂L\n∂Fn , ∂L\n∂Gn , ∂L\n∂Rn and ∂L\n∂Hn . Let us replace the dynamical model\nabove with a linearized model:\n(\nxn = f(xn−1,un,wn)\n˜xn = f(˜xn−1,un,0)\n(47)\nen = xn − ˜xn = f(xn−1,un,wn)− f(˜xn−1,un,0)\n≃ f(xn−1 −\n˜\nn−1+ ˜xn−1,un,0)+Gnwn − f(˜xn−1,un,0)\n≃ Jx\nn(xn−1 − ˜xn−1)+Gnwn\n= Jx\nnen−1 +Gnwn\n(48)\nwhich is justified as all calculations are to the first order around a nominal trajectory.\nWe denote by Ju the jacobian w.r.t. u and Jx the jacobian w.r.t. x (albeit matrix F, but\nit is less confusing to derive the gradients in the more general case where f is generic\n23\nwith generic jacobian Jx).\nUsing this linearization, we calculate the sensitivity of L w.r.t the component k of\nxn−1:\n∂L\n∂xk\nn−1\n=\n \n∂L\n∂xk\nn−1\n!(Fn)\n+\n \n∂L\n∂xk\nn−1\n!(Gn)\n+\n \n∂L\n∂xk\nn−1\n!(xn)\n+\n \n∂L\n∂xk\nn−1\n!(Hn−1)\n+\n \n∂L\n∂xk\nn−1\n!(Rn−1)\n= Tr\n \n∂L\n∂Fn\nT ∂Fn\n∂xk\nn−1\n!\n+Tr\n \n∂L\n∂Gn\nT ∂Gn\n∂xk\nn−1\n!\n+(Jx\nnek)T ∂L\n∂xn\n+Tr\n \n∂L\n∂Hn−1\nT ∂Hn−1\n∂xk\nn−1\n!\n+Tr\n \n∂L\n∂Rn−1\nT ∂Rn−1\n∂xk\nn−1\n!\n(49)\nwhere ek the k-th base vector.\nIn the same way, we calculate the derivative of L w.r.t the component k of un:\n∂L\n∂ukn\n=\n\u0012∂L\n∂ukn\n\u0013(Fn)\n+\n\u0012∂L\n∂ukn\n\u0013(Gn)\n+\n \n∂L\n∂xk\nn−1\n!(xn)\n= Tr\n \n∂L\n∂Fn\nT ∂Fn\n∂ukn\n!\n+Tr\n \n∂L\n∂Gn\nT ∂Gn\n∂ukn\n!\n+(Ju\nnek)T ∂L\n∂xn\n(50)\nC\nFirst backpropagation step\nAfter the forward pass, the backpropagation begins by computing gradients at the last\ntime step N. In this initial backpropagation step, dependencies between variables ex-\nhibit some differences, implying distinct equations. To analyze all dependencies, we\nrefer to the graph in the figure9.\nPN−1|N−1\nPN|N−1\nPN|N\nL\nRN−1,RN−1\nFN,GN\nuN\nRN,HN\nxN−1\nxN\nFigure 9: Graph of dependencies of EKF’s variables involved in the last step N\nAt the last step only successor’s of xN and PN|N are different. In fact, PN|N has\nonly L as a sucessor and xN has HN and RN (at the step n, xn has 5 successors : Hn,\nRn, Fn+1, Gn+1 and xn+1). The partial derivative\n∂L\n∂PN|N depend of the L chosen. For\nexample if we use trace then\n∂L\n∂PN|N = Id. Using\n∂L\n∂PN|N we can compute ∂L\n∂xN by using the\n24\n3 following equations:\n\u0012 ∂L\n∂HN\n\u0013T\n= −2PN|N\n∂L\n∂PN|N\nPN|NHT\nN R−1\nN\n(51)\n∂L\n∂RN\n= R−1\nN HNPN|N\n∂L\n∂PN|N\nPN|NHT\nN R−1\nN\n(52)\n∂L\n∂x j\nN\n= Tr\n \n∂L\n∂HN\nT ∂HN\n∂x j\nN\n!\n+Tr\n \n∂L\n∂RN\nT ∂RN\n∂x j\nN\n!\n(53)\nD\nEquation summary\nThe gradient computation using backpropagation consists of two parts. The first part\nnamed forward pass computes all quantities involved in an Extended Kalman Filter,\nsuch as xn, Pn|n, Pn|n−1, Fn, Gn .... At each iteration, we set the innovation zn = 0\ncorresponding to its expected value (this explains why we have only xn and not xn|n or\nxn|n−1). Additionally, during this step, we compute quantities such as ∂Fn\n∂ukn or ∂Fn\n∂xkn ....\nThen, in the backward step, gradients are computing recursively. To initialize the\ngradients, we first compute\n∂L\n∂PN|N and ∂L\n∂x j\nN\n= Tr\n\u0012\n∂L\n∂HN\nT ∂HN\n∂x j\nN\n\u0013\n+Tr\n\u0012\n∂L\n∂RN\nT ∂RN\n∂x j\nN\n\u0013\nas ex-\nplained in Section C. Then, recursively use the equations derived in Section B to back-\npropagate gradients.\n∂L\n∂Pn−1|n−1\n= FT\nn\n∂L\n∂Pn|n−1\nFn\n(54)\n∂L\n∂Pn|n−1\n= (I −KnHn)T ∂L\n∂Pn|n\n(I −KnHn)\n(55)\n∂L\n∂xk\nn−1\n= Tr\n \n∂L\n∂Fn\nT ∂Fn\n∂xk\nn−1\n!\n+Tr\n \n∂L\n∂Gn\nT ∂Gn\n∂xk\nn−1\n!\n+(Jx\nnek)T ∂L\n∂xn\n(56)\n+Tr\n \n∂L\n∂Hn−1\nT ∂Hn−1\n∂xk\nn−1\n!\n+Tr\n \n∂L\n∂Rn−1\nT ∂Rn−1\n∂xk\nn−1\n!\n(57)\n∂L\n∂Fn\n= 2\n∂L\n∂Pn|n−1\nFnPn−1|n−1\n(58)\n∂L\n∂Gn\n= 2\n∂L\n∂Pn|n−1\nGnQn\n(59)\n\u0012∂L\n∂Hn\n\u0013T\n= −2Pn|n\n∂L\n∂Pn|n\nPn|nHT\nn R−1\nn\n(60)\n∂L\n∂Rn\n= R−1\nn HnPn|n\n∂L\n∂Pn|n\nPn|nHT\nn R−1\nn\n(61)\n25\nFinally :\n∂L\n∂ukn\n= Tr\n \n∂L\n∂Fn\nT ∂Fn\n∂ukn\n!\n+Tr\n \n∂L\n∂Gn\nT ∂Gn\n∂ukn\n!\n+(Ju\nnek)T ∂L\n∂xn\n26\n"
}