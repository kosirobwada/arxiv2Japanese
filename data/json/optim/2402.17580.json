{
    "optim": "A HIGHLY EFFICIENT COMPUTATIONAL APPROACH FOR\nPART-SCALE MICROSTRUCTURE PREDICTIONS IN TI-6AL-4V\nADDITIVE MANUFACTURING\nSebastian D. Proell∗\nInstitute for Computational Mechanics\nTechnical University of Munich\n85748 Garching b. M¨unchen\nsebastian.proell@tum.de\nJulian Brotz\nInstitute for Computational Mechanics\nTechnical University of Munich\n85748 Garching b. M¨unchen\nMartin Kronbichler\nFaculty of Mathematics\nRuhr University Bochum\n44780 Bochum\nWolfgang A. Wall\nInstitute for Computational Mechanics\nTechnical University of Munich\n85748 Garching b. M¨unchen\nChristoph Meier\nInstitute for Computational Mechanics\nTechnical University of Munich\n85748 Garching b. M¨unchen\nFebruary 28, 2024\nABSTRACT\nFast and efficient simulations of metal additive manufacturing (AM) processes are highly relevant\nto exploring the full potential of this promising manufacturing technique. The microstructure\ncomposition plays an important role in characterizing the part quality and deriving mechanical\nproperties. When complete parts are simulated, one often needs to resort to strong simplifications such\nas layer-wise heating due to the large number of simulated time steps compared to the small time step\nsizes. This article proposes a scan-resolved approach to the coupled thermo-microstructural problem.\nBuilding on a highly efficient thermal model, we discuss the implementation of a phenomenological\nmicrostructure model for the evolution of the three main constituents of Ti-6Al-4V: stable αs-phase,\nmartensite αm-phase and β-phase. The implementation is tailored to modern hardware features\nusing vectorization and fast approximations of transcendental functions. A performance model and\nnumerical examples verify the high degree of optimization. We demonstrate the applicability and\npredictive power of the approach and the influence of scan strategy and geometry. Depending on\nthe specific example, results can be obtained with moderate computational resources in a few hours\nto days. The numerical examples include a prediction of the microstructure on the full NIST AM\nBenchmark cantilever specimen.\nKeywords powder bed fusion additive manufacturing, part-scale, microstructure, performance modeling\n1\nIntroduction\nLaser powder bed fusion (LPBF) is a prominent additive manufacturing (AM) technique that allows the design and\nproduction of parts with complex geometry in a near-net-shape manner. However, a successful build can require\n∗corresponding author\narXiv:2402.17580v1  [cs.CE]  27 Feb 2024\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\nexpensive trial-and-error runs beforehand or the adoption of overly conservative parameter choices. The microstructure\nprovides a critical insight into the material behavior of manufactured parts [34]. Understanding its evolution through\nnumerical simulations offers the opportunity to significantly reduce the costs measured in time and money and\nenhance the physical understanding of the LPBF process. While subsequent heat treatment often changes the as-built\nmicrostructure, the information is highly relevant during processing, as significant differences in material behavior can\nlead to defects during processing and failure to build a part. Ultimately, a great promise lies in the local control of the\nmicrostructural phase composition as the specific application desires.\nFrom a numerical modeling point of view, LPBF is a multi-scale and multi-physics problem [19]. In this contribution,\nwe focus on the effects on the microscale, specifically the composition and evolution of microstructure phases\nfor the commonly used alloy Ti-6Al-4V. The microstructure model in this contribution was first discussed in our\ncontribution [23]. Based on the classification in [12], it falls in the category of phenomenological [8, 17, 21, 29, 35]\nmicrostructure models, with alternative approaches being statistical [22, 14, 27, 9, 28] and phase-field [7, 13] models. A\nphenomenological microstructure model provides a reasonable trade-off between the costly evaluation of a phase-field\nmodel and the limited physical motivation of purely statistical models. A significant difference between [23] and other\nphenomenological models is that the evolution of the microstructural phases is governed by temperature-dependent\ndiffusive and instantaneous forces driving the phase composition towards an equilibrium state. From a mathematical\nperspective, the model consists of coupled ordinary differential equations (ODEs) for the three phases, which are\nβ-phase, stable αs-phase, and metastable martensitic αm-phase.\nTo the best of the authors’ knowledge, no coupled thermo-microstructure simulation with scan-resolved tracks on the\npart-scale has been published before. Nevertheless, efforts in this direction were undertaken by some groups. In [26]\nand [20], the authors determined correlations between experimentally measured microstructural phase compositions and\nnumerical results for the temperature field of larger parts without an explicit microstructure model. In [6], the authors\ninform a phase-field model for microstructure evolution with a single-track melt pool simulation. The cellular automata\nmicrostructure model used in [14] aims at the part-scale by replicating the thermal information from a few representative\nlayers and tracks over multiple layers. A similar strategy is used in [33] and combined with a phase-field model for the\nsub-grain scale. Many authors integrate analytical Johnson-Mehl-Avrami-Kolmogorov (JMAK) equations into thermal\nor thermo-mechanical models [8, 17, 29, 35]. In our publication [23], we already determined the microstructure for\napplication-motivated temperature profiles at selected points and for a quenching example of a large block. In contrast\nto all the cited references, this article presents a fully coupled thermo-microstructure model that considers the resolved\nlaser scan track and is not restricted to regular geometries. The microstructure is determined in the whole domain at all\npoints in time.\nAn essential aspect of macroscale simulations is the question of the implementation’s performance in terms of time to\nsolution. For the coupled thermo-microstructure problem, the thermal history drives the evolution of the microstructure.\nThus, a fast and accurate solution to the thermal problem is necessary. In our previous work [25], we presented a highly\nefficient solution to the thermal problem with a resolved laser scan track over hundreds of layers. In contrast to many\nexisting approaches, we can simulate parts on the centimeter scale in a time frame on the order of hours or days. The\npresent contribution builds on that work and allows us to predict the composition of microstructure phases in the same\nsetting with only marginally increased time to solution. To achieve this level of performance for the microstructure\nmodel, we carefully analyzed the many conditional branches in the governing equations. Our implementation is tailored\nto modern hardware capabilities as it can utilize vectorization efficiently and considers the need to reduce memory\ntransfer as much as possible. Efficient approximations of transcendental functions [30, 18, 24], e.g., the exponential\nfunction, which can be vectorized efficiently, are discussed. We present a detailed performance analysis with the help of\na roofline performance model.\nThe article is structured as follows: after briefly reviewing the thermal and microstructure model, we focus on the latter’s\nnumerical discretization and implementation details. Specifically, we discuss the implementation tailored to modern\nhardware and present efficient approximations for expensive transcendental functions. We study the implementation\nperformance on benchmarks and application examples. The investigated, practically relevant examples demonstrate a\nwide range of applicability of the approach and fast solution times. A notable example is the NIST AMBench 2022\ncantilever geometry [16], for which we predict the as-built microstructure.\n2\nCoupled thermo-microstructure model\nThis section summarizes model equations. An emphasis is placed on details especially relevant to the efficient solution\nstrategy presented later in this article. We refer to the respective publications for the full details of the thermal [25] and\nmicrostructure [23] models.\n2\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\n2.1\nThermal model\nFirst, we briefly summarize the thermal part of the problem following [25]. The temperature field T is determined in\nthe domain Ω by solving the heat equation:\nρc∂T\n∂t = −∇ · q + qvol,\nq = −k(T)∇T\nin Ω,\n(1)\nHere, ρ is the density and c is the specific heat capacity of the material. The temperature and state-dependent heat\nconductivity k can be computed from the liquid fraction g(T), defined as\ng(T) =\n\n\n\n\n\n0,\nT < Ts,\nT −Ts\nTl−Ts ,\nTs ≤ T ≤ Tl\n1,\nT > Tl,\n(2)\nwhere Ts and Tl are the solidus and liquidus temperature. The time-dependent consolidated fraction\nrc(t) =\n(\n1,\nif rc(0) = 1 (i.e. initially consolidated)\nmax\n˜t<t g(T(˜t)),\nif rc(0) = 0 (i.e. initially powder)\n.\n(3)\ncaptures the irreversible powder-to-melt transition and allows setting the initial material state. From (2) and (3), the\nactual fractions of powder (p), melt (m) and solid (s) material are computed as\nrp(rc) = 1 − rc,\nrm(T) = g(T),\nrs(T, rc) = rc − g(T),\n(4)\nand finally, the temperature- and history-dependent heat conductivity k(T, rc) is found:\nk(T, rc) = rp(rc)kp + rm(T)km + rs(T, rc)ks,\n(5)\nwhere kp, ks and km are the parameters for a single state.\nA cylindrical volumetric heat source qvol formulated in a local coordinate system (ˆx, ˆy, ˆz) models the incident energy\nfrom a moving laser beam:\nqvol =\n(\n2Weff\nπR2hpowder exp\n\u0010\n−2(ˆx2+ˆy2)\nR2\n\u0011\n,\nif 0 < ˆz < −hpowder\n0,\notherwise\n,\n(6)\nHere, R is the effective beam radius of the incident energy beam, Weff is the effective power and hpowder is the powder\nlayer thickness.\nThe necessary initial and boundary conditions for the heat equation (1) are given as:\nT = T0\nin Ω for t = 0,\n(7)\nT = T0\non ΓD,\n(8)\nq · n = 0\non ΓN,\n(9)\nq · n = qrad + qevap\non ΓRE,\n(10)\nqrad = ϵσS(T 4 − T 4\n∞),\n(11)\nqevap = 0.82CP exp\n\u0014\n−CT\n\u0012 1\n[T] − 1\nTv\n\u0013\u0015 s\nCM\n[T] (hv + c([T] − Th,0)), if [T] > Tv.\n(12)\nAll material is initially pre-heated to a temperature T0. The material parameters required for the initial boundary value\nproblem are listed in Table 1. In addition, σS in (11) is the Stefan-Boltzmann constant. To avoid numerical challenges\narising from the strong nonlinearity in the evaporation term (12), the temperature [T] is limited to a maximum value\nTmax > Tv. In this study, we opt for Tmax = Tv + 1000 K, which ensures numerical stability without affecting the\noverall results.\n2.2\nMicrostructure model\nA phenomenological model for the microstructure evolution was presented in [23]. This model focuses on the three\nmost important phases2, β, αs and αm. While the thermal model needs to consider the powder material state, we can\n2Note that the word ‘phase’ refers to the microstructure phases αs, αm, and β. In contrast, when we distinguish material into\npowder, melt, and solid, we speak of the ‘state’ of the material.\n3\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\nTable 1: Thermal model parameters for Ti-6Al-4V.\nSymbol\nProperty\nValue\nUnit\nkms\nThermal conductivity in melt and solid phase\n28.6\nW m−1 K−1\nkp\nThermal conductivity in powder phase\n0.286\nW m−1 K−1\nρ\nDensity\n4090\nkg m−3\nc\nSpecific heat capacity\n1130\nJ kg−1 K−1\nTs\nSolidus temperature\n1878\nK\nTl\nLiquidus temperature\n1928\nK\nT∞\nAmbient temperature\n293\nK\nϵ\nEmissivity\n0.7\n–\nTv\nBoiling temperature\n3130\nK\nCP\nRecoil pressure factor\n54\nkPa\nCT\nRecoil pressure temperature factor\n5.07 × 104\nK\nCM\nHeat loss temperature factor\n9.15 × 10−4\nK s2 m−2\nM\nMolar mass\n0.0478\nkg mol−1\nhv\nLatent heat of evaporation\n8.84\nMJ kg−1\nTh,0\nEnthalpy reference temperature\n538\nK\nneglect it in the context of the microstructure model. We define phase fractions Xi ∈ [0; 1] for the microstructure\nphases along with elementary continuity constraints:\nXsol + Xliq = 1,\n(13)\nXα + Xβ = Xsol,\n(14)\nXαs + Xαm = Xα.\n(15)\nThe liquid phase fraction Xliq and, by virtue of (13), the solid phase fraction Xsol are again computed according to g(T)\n(2) as\nXliq = g(T),\nXsol = 1 − g(T).\n(16)\nWhile, for now, the definitions of Xsol and Xliq seem redundant to the state described in (4), they make for a cleaner\nnotation, and the duplicate definition allows us to treat them slightly differently in terms of numerics later on. Also,\nnote that the powder state is now implicitly part of the solid state. The transformation from solid to liquid state and vice\nversa is thus complete, and the remainder of this section focuses on the microstructure phase transformations.\nBefore the evolution equations for the phase fractions can be defined, we introduce two equilibrium phase fractions\nassociated with material cooling from a molten state to ambient temperature T∞. All newly solidified solid material\nconsists entirely of β-phase. On further cooling, the β-phase can transform into stable αs-phase. The fraction Xeq\nα (T)\ndetermines the amount of stable α-phase at a given temperature in thermodynamic equilibrium. It follows an exponential\nKoistinen-Marburger law:\nXeq\nα (T) =\n\n\n\n0.9\nfor T < Tαs,end,\n1 − exp[−keq\nα (Tαs,start − T)]\nfor Tαs,end ≤ T ≤ Tαs,start,\n0\nfor T > Tαs,start,\n(17)\nwhere the parameters keq\nα , Tαs,start and Tαs,end are obtained either directly from the literature or fitted to experimental\ndata in [23]. Their values are listed in Table 2. Notably, the actual fraction of stable α-phase Xαs at a given temperature\nis, in general, not identical to the equilibrium value in (17), which is only reached when the cooling rate is very low.\nInstead, the equilibrium value can be interpreted as the long-term solution for t → ∞. The formation of αs is driven\nby a diffusion process as detailed below. If the cooling rate is high, this diffusion process is inhibited, and metastable\nmartensite αm-phase forms instead. Again, we define a pseudo equilibrium phase fraction Xeq\nαm,0 for martensitic\nαm-phase for high cooling rates:\nXeq\nαm,0(T) =\n\n\n\n0.9\nfor T < T∞\n1 − exp[−keq\nαm(Tαm,start − T)]\nfor T∞ ≤ T ≤ Tαm,start\n0\nfor T > Tαs,start\n(18)\n4\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\nαs\nαm\nβ\ndiﬀusive\ninstantaneous\nFigure 1: Possible transformation paths between different microstructure phases.\nwith the parameters keq\nαm and Tαm,start listed in Table 2. Again, the actual fraction of martensitic αm-phase Xαm\nat a given temperature is not necessarily identical to the equilibrium value Xeq\nαm,0. Equations (17) and (18) for the\nequilibrium fractions are incompatible for specific temperature values, in the sense that, e.g., for T = T∞ their values\nsum to 1.8, which is larger than 1. The transformation from β-phase to αs-phase happens in a strictly higher temperature\ninterval than the transformation from β-phase to αm-phase for the material parameters listed in Table 2. For this reason,\nthe incompatibility is resolved by the introduction of the following effective pseudo-equilibrium phase fraction:\nXeq\nαm(T) = Xeq\nαm,0(T) · 0.9 − Xαs\n0.9\n.\n(19)\nThis means that the martensite equilibrium fraction Xeq\nαm is corrected based on the already formed fraction of stable\nαs-phase, with the effect that Xαs + Xeq\nαm ≤ 0.9. The formation and dissolution of the three phases αs, αm and β is\ngoverned by the following ordinary differential equations:\n˙Xαs = ˙Xβ→αs + ˙Xαm→αs − ˙Xαs→β,\n(20)\n˙Xαm = ˙Xβ→αm − ˙Xαm→αs − ˙Xαm→β,\n(21)\n˙Xβ = ˙Xαm→β + ˙Xαs→β − ˙Xβ→αm − ˙Xβ→αs,\n(22)\nwhere ˙Xi→j is the formation of phase j from phase i or, equivalently, the dissolution from phase i into phase j. Note\nthat ˙Xi→j ̸= ˙Xj→i, since the reverse transformation might not even exist (e.g., for the transformation from martensite\nto stable αs phase) or is governed by different kinetics. A graphical overview of the transformation processes is shown\nin Figure 1. The transformation αm ↔ β occurs on a much shorter time scale than αs ↔ β. Therefore, we treat the\nphase change αm ↔ β as instantaneous, while the transformations αs ↔ β and αm → αs are modeled as a diffusive\nprocess.\nFor T < Ts, the sum of (20)–(22) yields\n˙Xαs + ˙Xαm + ˙Xβ = 0\nif\nT < Ts,\n(23)\nallowing us to directly express the β-phase fractions as\nXβ = Xsol − Xαs − Xαm.\n(24)\nThis makes integration of (22) unnecessary.\nThe following set of logistic differential equations describes the diffusion-driven transformation processes:\n˙Xβ→αs =\n(\nkαs(T) (Xαs)\ncαs −1\ncαs\n\u0000Xeq\nα − Xα\n\u0001 cαs +1\ncαs\nif Xα < Xeq\nα ,\n0\notherwise\n(25)\n˙Xαm→αs =\n(\nkαs(T) (Xαs)\ncαs −1\ncαs\n(Xαm)\ncαs +1\ncαs\nif Xαm > 0,\n0\notherwise\n(26)\n˙Xαs→β =\n(\nkβ(T) (0.9 − Xα)\ncβ −1\ncβ\n\u0000Xα − Xeq\nα\n\u0001 cβ +1\ncβ\nif Xα > Xeq\nα ,\n0\notherwise\n(27)\nwhich are completed by temperature-dependent diffusion rates,\nkαs(T) =\nk1\n1 + exp[−k3(T − k2)]\nand\nkβ(T) = f · kαs(T).\n(28)\n5\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\nTable 2: Parameters of the microstructure evolution model. A detailed analysis and literature review of all parameters is\ngiven in [23].\nParameter\nDescription\nValue\nUnit\nTl\nLiquidus temperature\n1928\nK\nTs\nSolidus temperature\n1878\nK\nTαs,start\nUpper end of temperature range for β → αs transformation\n1273\nK\nTαs,end\nLower end of temperature range for β → αs transformation\n935\nK\nTαm,start\nUpper end of temperature range for β → αm transformation\n848\nK\nT∞\nAmbient temperature\n293\nK\nkeq\nα\nαs-phase equilibrium concentration constant\n0.0068\nK−1\nkeq\nαm\nαm-phase equilibrium concentration constant\n0.00415\nK−1\nTable 3: Fitted parameters of the microstructure evolution model. A detailed explanation of the calibration process is\ngiven in [23].\nParameter\nValue\nUnit\ncαs\n2.51\n–\ncβ\n11.0\n–\nk1\n0.294\ns−1\nk2\n850\nK\nk3\n0.0337\nK−1\nf\n3.8\n–\nIn total, six parameters, cαs, cβ, k1, k2, k3 and f, govern the diffusion process. Their values were determined by fitting\nexperimental data in [23] and are summarized in Table 3. When cooling down below Tαm,start the martensite phase\nfraction instantaneously follows the pseudo-equilibrium phase fraction:\nXαm = Xeq\nαm,\nif\nT < Tαm,start\n(29)\nwhich is already corrected according to (19) such that martensite only forms from β-phase if the αs-phase is below the\nequilibrium concentration. When heating material, the martensite phase fraction instantaneously dissolves into β-phase\naccording to:\nXαm = max(Xeq\nα − Xαs, 0),\nif\nXα > Xeq\nα\n(30)\nThis implies that no previously formed martensite remains when T > Tαs,start. To fully dissolve the stable αs-phase\nwhen further heating the material, we introduce a regularization,\nXαs = min\n\u0012\nXαs, 0.9Tαs,start + Tαs,reg − T\nTαs,reg\n\u0013\n,\nif\nTαs,start < T < Tαs,reg,\n(31)\nThus, the αs-phase fraction decreases linearly from a maximum of 0.9 to zero in the regularization interval\n[Tαs,start, Tαs,start + Tαs,reg]. In this contribution, we choose Tαs,reg = 100 K. The regularization has the effect\nthat no αs-phase but only β-phase remains once the solidus temperature Tsol is reached and material begins to melt.\nWithout the regularization, it would be possible to retain αs-phase until Tsol; however, in that case, one would need to\nmodel the melting of a mixture of two phases. Since the exact phase composition in the high-temperature region is not\nof interest and due to the lack of experimental data, we choose the outlined strategy for temperatures above Tαs,start.\n3\nNumerical methods and efficient implementation\nThe thermal problem is solved with an efficient FEM implementation [25] based on fast operator evaluation [15].\nImplementation is performed with the deal.II library [4]. Notably, we use an explicit scheme for the active laser phase\nwhere small time step sizes are necessary to obtain a continuous melt track. In the interlayer cool down phase after\nevery layer, we use an implicit scheme allowing larger time step sizes. This approach is extended to the microstructure\nmodel where we introduce a fast explicit and a more accurate and robust implicit scheme.\nThe microstructure model is integrated into the existing approach as a one-way coupled problem that is solved after the\nthermal model in every time step. Since the microstructure model does not explicitly depend on the spatial coordinate,\n6\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\nthe problem is fully decoupled in space. The ODEs can be solved independently at every point in space. It is sufficient\nto place the degrees of freedom (DoFs) of the microstructure model (phases Xβ, Xαs and Xαm) in the same spatial\npositions as the thermal DoFs (temperature T). This choice has the advantage that no communication and interpolation\nis necessary to obtain the temperature to evaluate the microstructure model.\nThe spatial discretization is realized as an adaptive mesh. When activating a new layer, more refined cells are placed\nin the highest active layer and a few layers beneath. The mesh can be coarsened at later stages when the material\nhistory allows for it. Previously, the only history variable that needed to be considered for the thermal model was the\nconsolidated fraction rc. In this contribution, the three microstructure phases also represent a material history that\nshould not be coarsened inadvertently. Therefore, an octant consisting of eight sibling cells of equal refinement level\nwill only be coarsened when, for every microstructure phase, all its values are sufficiently close to each other. For more\ngeneral details of the adaptive and growing mesh, the reader is referred to [25].\n3.1\nTime integration of microstructure model\nTo ease the notation, the unknown fractions of stable and martensitic α-phase are collected in a state vector m =\n[Xαs, Xαm]. The β-phase fractions can be processed for a given state and temperature as,\nXβ(m, T) = Xsol(T) − Xαs − Xαm.\n(32)\nThe right-hand side of the differential equations (20)–(21) is split into a diffusion-based and instantaneous contribution:\n˙m =\n\u0014 ˙Xαs\n˙Xαm\n\u0015\n=\n\u0014 ˙Xβ→αs + ˙Xαm→αs − ˙Xαs→β\n− ˙Xαm→αs\n\u0015\n|\n{z\n}\n=: ˙mdiff\n+\n\u0014\n0\n˙Xβ→αm − ˙Xαm→β\n\u0015\n|\n{z\n}\n=: ˙minst\n(33)\nIntegrating (33) from a point in time tn to a point in time tn+1 = tn + ∆t yields,\nmn+1 = mn +\nZ tn+1\ntn\n˙mdiff dt +\nZ tn+1\ntn\n˙minst dt\n(34)\nwhere the superscript indicates at which point in time a quantity is evaluated. The phase fractions mn and the\ntemperature T n+1 are known. A numerical time integration scheme will approximate the first integral over the diffusion-\ndriven contribution. Note that the second integral over the (non-differentiable) instantaneous change rate yields a finite\nvalue for the absolute change. These instantaneous changes are defined in (29) and (30).\nExplicit time integration\nWe split (34) into a two-stage process, where integration of the diffusion-based term is\nperformed with a forward Euler scheme towards an intermediate state ˜mn+1, followed by a correction step:\n˜mn+1 = mn + ∆t ˙mdiff(T n, mn),\n(35)\nmn+1 = g(T n+1, ˜mn+1).\n(36)\nHere, we define a correction function g(T, m), which contains the instantaneous changes for the martensite phase as\nwell as corrections that are necessary to satisfy the continuity constraints (13)–(15). Furthermore, if either Xαs or Xαm\nfalls below zero, it is instead set to zero. If Xα exceeds the maximum equilibrium fraction of 0.9, both, Xαs or Xαm\nare reduced while maintaining the ratio Xαs/Xαm.\nTwo exceptional cases become apparent when examining (25) and (27). Both equations pose a problem for the explicit\ntime integration scheme presented so far. Evaluating (25) for Xαs = 0, Xαm = 0, Xβ = 1.0 gives a rate of zero, which\nimplies that a solution computed with the explicit scheme can never evolve out of the initial state. Thus, we initiate\nthe diffusion process with the help of an approximate analytical solution described in more detail in [23]. The same\nstrategy can be applied to (27) which suffers from the same problem for Xαs = 0.9, Xαm = 0, Xβ = 0.1. Due to the\nnumeric values of the physical constants, the second case is prone to cancellation of significant digits. An appropriate\nreformulation can be found in Appendix A.\nThe presented explicit time integration scheme does not come with a stability limit due to the correction function\ng(T, m) being applied after every step. Therefore, the solution cannot grow arbitrarily large, and classical stability\nconsiderations do not apply to the specific scheme used here. Still, the time step size should be chosen within limits to\nobtain a sufficiently accurate solution.\n7\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\nImplicit time integration\nWe use a Crank-Nicolson time integration scheme for the diffusion-based term and reuse\nthe same correction function g as in the explicit case:\n˜mn+1 = mn + 1\n2∆t\n\u0000 ˙mdiff(T n+1, mn+1) + ˙mdiff(T n, mn)\n\u0001\n,\n(37)\nmn+1 = g(T n+1, ˜mn+1).\n(38)\nThe nonlinear equation (37) is solved employing a fixed-point iteration:\nmn+1\ni+1 = g\n\u0012\nT n+1, mn + 1\n2∆t\n\u0000 ˙mdiff(T n+1, mn+1\ni\n) + ˙mdiff(T n, mn)\n\u0001\n|\n{z\n}\n˜\nmn+1\ni+1\n\u0013\n,\n(39)\nmn+1\n0\n= mn,\n(40)\nuntil the weighted root-mean-square (WRMS) norm of the residual\nrn+1\ni+1 = mn+1\ni+1 −\n\u0012\nmn + 1\n2∆t\n\u0000 ˙mdiff(T n+1, mn+1\ni+1 ) + ˙mdiff(T n, mn)\n\u0001\u0013\n(41)\n= ∆t\n2\n\u0000 ˙mdiff(T n+1, mn+1\ni\n) − ˙mdiff(T n+1, mn+1\ni+1 )\n\u0001\n(42)\nfalls below a threshold. The WRMS norm is defined as\n||a||WRMS = 1\nN\nN\nX\nj=1\n(ajwj)2,\nwhere wj = (εabs + ¯ajεrel)−1\n(43)\nwith an absolute tolerance εabs = 1 × 10−10 and a relative tolerance εrel = 1 × 10−3. It can easily be verified that the\niteration scheme prescribed in (39) is a contraction on Xi ∈ (0, 0.9), and thus converges to a unique solution if the time\nstep size ∆t is sufficiently small. This proof holds for time step sizes up to around 0.001 s. However, we experimentally\nobserve fast and robust convergence for time step sizes up to 1 s. We use a subcycling scheme to achieve sufficient\naccuracy, where a large time step performed in the thermal model is subdivided into substeps not exceeding a maximum\nsize ∆tsub = 0.01 s.\n3.2\nVectorized computation\nModern CPUs support vector operations on specialized execution units that perform the same operation on a (small)\narray of different data, an idiom commonly called Single Instruction Multiple Data (SIMD). This small array has\nnlanes entries and will be referred to as a vectorized array. A useful C++ type VectorizedArray overloading basic\narithmetic operations is provided by the deal.II library. Similar data types are available in the experimental C++\nstandard implementation [1] or as stand-alone libraries [11]. The overloaded operations simultaneously perform the\narithmetic operation on all lanes by calling the respective, hardware-specific intrinsic functions. For instance, the\nlatest Intel AVX512 instruction set architecture supports eight concurrent double-precision operations. This capability\npromises to significantly speed up computation-heavy code paths by a factor of nlanes when fully utilized. Using\nSIMD operations demands contiguous data storage in memory for maximum performance benefits. Furthermore, the\nconcurrently processed data should be independent, i.e., the computation in one vector lane may not depend on a\ncomputation in another lane of the same vector.\nThe classical and automatic approach to vectorization is to look at inner loops or plain code and let the compiler\nidentify nearby operations of the same kind that could go to different lanes. The results of auto-vectorization are\npoor if the loop kernel contains code beyond basic arithmetic, e.g., conditional branches and transcendental function\ncalls. Therefore, we choose to vectorize the outer loop over all points in the mesh in batches of size nlanes and then\nsolve the microstructure ODEs on a batch of points stored in the different lanes. The different quantities on a batch of\npoints are loaded into the VectorizedArray data structure. This approach results in an array-of-struct-of-array layout,\nwith the inner array being a VectorizedArray, which allows a concise implementation without explicitly writing the\ninner-most vectorized loop. However, the numerous conditional branches in the microstructure model do not always\nallow the same operation to be performed on all lanes. From an implementation standpoint, three distinct scenarios for\nthe conditional branches of equations can be distinguished:\n1. All vector lanes require evaluation of an expression. In this case, the expression is evaluated for all vector lanes\nusing intrinsic functions.\n8\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\nnlanes\nload 5 vectors\nstore 4 vectors\nsome\nresults per\nbranch\nblended result\nall\nnone\ncondition\nmask\nupdate in place\nlocal working copy\nconditional\nevauation\ntime integration\n+\nsubcycling\n+\nﬁxed-point iteration\nMicrostructure algorithm\nXas\nXam\nXb\nTn\nTn+1\nFigure 2: Illustration of vectorized microstructure algorithm. The algorithm works simultaneously on a local working\ncopy of nlanes entries of the five global data vectors. Time integration, fixed-point iteration, and (optional) subcycling\nare all performed locally. All conditional computations are performed by blending the results of different conditional\nbranches based on the condition mask.\n2. None of the vector lanes require evaluation of an expression. In this case, the expression is not evaluated.\n3. Some but not all of the vector lanes require the evaluation of an expression. In this case, the expression is\nevaluated for all vector lanes, but the result is only stored in some vector lanes that require it. Note that\nthe unused additional computations do often not impact the evaluation time compared to an unvectorized\nimplementation.3\nA condition mask is computed for every branch to see which of the three scenarios is active. In the third case, the\nresults of different branches are combined by blending the results with the condition mask. The general strategy is also\nvisualized in Figure 2.\nThe strategy outlined above only makes sense when an efficient vectorized implementation of every required (mathemat-\nical) function is available. Although it is possible to fall back to compute expressions on the vector lanes sequentially,\ndoing this in the scenario of mixed operations can, in the worst case, lead to an increase in computation time on the\norder of O (nlanes) compared to an unvectorized implementation4.\nAlgorithm 1 outlines the overall vectorized solution procedure for the microstructure model. Starting from the solution\nvariables, Xn\nαs, Xn\nαm, Xn\nβ and T n, at the previous time tn, the solution after a time increment ∆t with temperature\nT n+1 is sought. We load a contiguous data slice from these five global vectors into vectorized arrays. Time integration\nis then performed on the vectorized arrays. Afterward, the results at time tn+1 are written back from the vectorized\narrays into the respective global vectors. Note that the update of the temperature vector T n+1 ← T n is also performed\nin this loop since the data is already loaded. Five load and four store operations must be performed for every evaluation\npoint, totaling 72 bytes of memory transfer per evaluation point or 24 bytes per DoF (3 DoFs per evaluation point).\nThe explicit time stepping is outlined in Algorithm 2. The function compute rates evaluates the diffusion-based\nrates (25) – (27), and the function instantaneuous corrections evaluates instantaneous transformations between\nαm- and β-phase. Only a few arithmetic operations are needed for every set of vectorized arrays. In contrast, the\nimplicit solution procedure shown in Algorithm 3 usually requires fixed-point iteration and, thus, at least twice as\n3Note that wider vectors might lead to slightly lower clock frequencies on some hardware and complicated functions, like\ndivisions or square roots, might have lower throughput when executed on wider vectors; nonetheless, the overwhelming share of\noperations has the same throughput for 1 or nlanes results.\n4If every lane requires a different kind of operation, O (nlanes) operations are necessary in the unvectorized case. However,\nwhen the computation is vectorized and every kind of operation is unnecessarily performed on all lanes, O\n\u0000n2\nlanes\n\u0001\noperations are\nnecessary.\n9\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\nAlgorithm 1: Time integration of microstructure model with vectorized data.\nData: ∆t, Global vectors Xn\nαs, Xn\nαm, Xn\nβ , T n, T n+1\nResult: Global vectors Xn+1\nαs , Xn+1\nαm , Xn+1\nβ\n, T n+1\ni ← 0\nwhile i < size(T n) do\n// Load into vectorized array\nˇXn\nαs ← Xn\nαs[i : i + nlanes]\nˇXn\nαm ← Xn\nαm[i : i + nlanes]\nˇXn\nβ ← Xn\nβ [i : i + nlanes]\nˇT n ← T n[i : i + nlanes]\nˇT n+1 ← T n+1[i : i + nlanes]\n// Solve local time integration problem\nˇXn+1\nαs , ˇXn+1\nαm , ˇXn+1\nβ\n← time integration( ˇXn\nαs, ˇXn\nαm, ˇXn\nβ , ˇT n, ˇT n+1, ∆t)\n// Store from vectorized array\nXn+1\nαs [i : i + nlanes] ← ˇXn+1\nαs\nXn+1\nαm [i : i + nlanes] ← ˇXn+1\nαm\nXn+1\nβ\n[i : i + nlanes] ← ˇXn+1\nβ\nT n+1[i : i + nlanes] ← ˇT n\ni ← i + v\nend\nAlgorithm 2: Local explicit time integration of microstructure model on vectorized data.\nData: ˇmn = [ ˇXn\nαs, ˇXn\nαm], ˇXn\nβ , ˇT n, ∆t\nResult: ˇXn+1\nαs , ˇXn+1\nαm , ˇXn+1\nβ\n˙ˇmn ← compute rates( ˇmn, ˇT n)\nˇmn+1 ← ˇmn + ∆t ˙ˇm\nˇmn+1, ˇXn+1\nβ\n← instantaneous corrections( ˇmn+1, ˇXn\nβ , ˇT n)\nAlgorithm 3: Local implicit time integration of microstructure model on vectorized data.\nData: ˇmn = [ ˇXn\nαs, ˇXn\nαm], ˇXn\nβ , ˇT n, ˇT n+1, ∆t\nResult: ˇXn+1\nαs , ˇXn+1\nαm , ˇXn+1\nβ\n˙ˇmn ← compute rates( ˇmn, ˇT n)\nˇmn+1\n0\n, ˇXn+1\nβ,0 ← instantaneous corrections( ˇmn, ˇXn\nβ , ˇT n+1)\n˙ˇmn+1\n0\n← compute rates( ˇmn+1\n0\n, ˇT n+1)\ni ← 0\nrepeat\nˇmn+1\ni+1 ← ˇmn + ∆t\n2 ( ˙ˇmn+1\ni\n+ ˙ˇmn)\nˇmn+1\ni+1 , ˇXn+1\nβ,i+1 ←instantaneous corrections( ˇmn+1\ni+1 , ˇXn+1\nβ,i , ˇT n+1)\n˙ˇmn+1\ni+1 ← compute rates( ˇmn+1\ni+1 , ˇT n+1)\ne ← weighted root mean square( ∆t\n2 ( ˙ˇmn+1\ni+1 − ˙ˇmn+1\ni\n))\ni ← i + 1\nuntil e < 1.0\n10\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\nmany arithmetic operations as the explicit step. However, the amount of loaded and stored data is equal. As we will\ndemonstrate in the examples, this typically leads to the explicit time integration scheme being memory-bound and the\nimplicit scheme being compute-bound.\n3.3\nEfficient approximation of transcendental functions\nThe evolution equations of the microstructure model contain a few terms that necessitate the computation of a (non-\ninteger) power or exponential function. Note that the power of a positive number can equivalently be written as\nax = exp(x ln a),\na > 0,\n(44)\nwhich allows to compute the power of a number via a natural logarithm and an exponential function. At the time\nof writing, the C++ standard did not offer an implementation of these functions that could leverage SIMD hardware\nsupport. While copying and adapting the sophisticated implementations from the standard library or wrapping an\nexisting library supporting vectorized data types would, in theory, be possible, we want to follow a different strategy\nhere. The C++ standard implementation and most other libraries [31] must deal with a wide range of applications and\nconsequently are implemented to be accurate up to machine precision. However, in the context of a numerical method,\nwe accept a much less accurate result than machine precision. The chosen strategy embeds this fact by allowing the\ndefinition of an approximation that is accurate enough while minimizing the number of arithmetic operations.\nThe strategy employed in this work assumes the ubiquitous IEEE-754 standard [3] to represent floating point numbers.\nIn this standard, a real number is represented as\n(−1)s2p−b(1 + m).\n(45)\nFor a 64-bit representation, i.e., the double data type in C/C++, the bias is set to b = 1023, the sign s consumes a\nsingle bit, the exponent p (an integer) consumes 11 bit, and the mantissa m (a binary fraction) consumes 52 bit. The\nidea of directly computing and manipulating the bitwise representation was initially brought up in [30]. Here, we follow\nthe refined implementation discussed in [18, 24]. Let us first find an approximation to the exponential function zexp by\nrewriting,\nzexp := exp(x) = 2x log2(e) = 2y = 2yi2yf ,\n(46)\nwhere yi = ⌊x log2(e)⌋ is an integer5, and yf = x log2(e) − yi ∈ [0, 1) is a rational number. By comparing (46) to\n(45), we find that\ns = 0,\n(47)\n2yi = 2p−b,\n(48)\n2yf = 1 + m.\n(49)\nThe sign bit is always zero, as expected for exponentiation. The exponent p can directly be computed from (48) as\np = yi + b.\n(50)\nBy rearranging (49) and introducing a correction function Kexp(yf), we write:\n2yf = 1 + m = 1 + yf − Kexp(yf),\nwith\nKexp(yf) = 1 + yf − 2yf ,\n(51)\nwhich leads to the mantissa\nm = yf − Kexp(yf).\n(52)\nThe correction function Kexp(yf) is replaced with a polynomial approximation to circumvent the need to compute a (non-\ninteger) power of 2. Note that this is the only approximation that is performed for the computation of the exponential\nfunction. The polynomial approximation can be tailored to the required accuracy by polynomial interpolation or\nregression. In this contribution, we use a least-squares fit of a polynomial of degree 7 to data sampled on 1000\nequidistant points in [0, 1). The resulting coefficients are listed in Table 4. Tests revealed that adding more sample\npoints does not increase the accuracy of the approximation in a relevant manner for our application. In contrast to\n[24], we do not consider the derivatives of Kexp(yf) in the computation of the coefficients as we found their impact\nnegligible.\nSince we determined the sign bit s = 0, the exact exponent p = yi+b, and the approximate mantissa m = yf −Kexp(yf)\nof zexp in (46), all that remains to be done is filling their bitwise representations into the IEEE754 conforming layout.\n5The floor function ⌊x⌋ returns the largest integer not exceeding x.\n11\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\nTable 4: Polynomial coefficients for the approximated correction functions Kexp(yf) and Kln(yf).\ni\nai in Kexp(yf) = Pn\ni=0 aiyi\nf\nbi in Kln(yf) = Pn\ni=0 biyi\nf\n0\n1.213 071 811 889 × 10−10\n1.847 756 720 962 93 × 10−10\n1\n3.068 528 102 657 × 10−1\n1.442 695 040 841 32\n2\n−2.402 263 423 993 59 × 10−1\n−0.721 347 520 143 005\n3\n−5.550 533 134 149 54 × 10−2\n0.480 898 345 526 187\n4\n−9.613 524 328 848 3 × 10−3\n−0.360 675 000 332 004\n5\n−1.342 884 759 630 84 × 10−3\n0.288 048 466 919 235\n6\n−1.431 317 444 835 89 × 10−4\n−0.235 306 287 368 882\n7\n−2.159 565 612 634 9 × 10−5\n0.183 102 904 829 435\n8\n−0.120 996 268 979 3\n9\n0.059 150 381 159 211 3\n10\n−0.018 114 949 248 998 9\n11\n0.002 544 886 756 057 43\n64-bit int\n64-bit double\nreinterpret bitwise representation\nconvert to equivalent\n64-bit int\n×252\n0\n64-bit int\n64-bit int\n64-bit double\n64-bit double\n64-bit double\nexponent p: integer\nmantissa m: rational number in [0,1)\npm\n0\n0\n0\n0\n0\n...\n0\n...\n0\n0\n0\npm+52\n0\np\nm\nbit mask\n0\n0\nbit mask\nadd\nadd\n×2-52\nconvert to equivalent\n×252\n×2-52\n...\nFigure 3: Following the arrows from top to bottom illustrates how to synthesize an IEEE754 double representation\nfrom a separate exponent p (blue) and mantissa m (red). Following the arrows from bottom to top shows the inverse\noperation, namely a decomposition of a double representation into exponent and mantissa.\nAn elegant way to achieve this can be derived by filling a 64-bit integer (int64) with the values of s, p, and m and then\ninterpreting the result as a (64-bit) double value. A graphical depiction of the approach is shown in Figure 3. The\nexponent p – an integer stored inside a double representation – is converted into the equivalent int64 format and then\nmultiplied with 252, shifting it 52 bits to the left. Multiplying the mantissa m < 1 by 252 shifts the decimal point behind\nthe last (binary) digit, thus making it an integer, which is then converted into the equivalent int64 format. In C++,\nthe conversion from double to int64 is achieved by a static cast<int64> operation. The two int64 numbers\nderived from p and m have no overlapping non-zero bits. They are added together to yield a combined int64 with the\nbitwise representation of zexp when reinterpreted as a double number( using reinterpret cast<double> in C++).\nProgrammatically speaking, this algorithm can be written as:\nzexp ← reinterpret cast<double>(252 × static cast<int64>(p) + static cast<int64>(252 × m))\n(53)\nFor an integer stored inside a double representation, we may flip the ordering of multiplication with another integer\nand a static cast<int64> to integer format. Thus, we can rewrite (53) as,\nzexp ← reinterpret cast<double>(static cast<int64>(252 × (p + m))),\n(54)\nand with (50) and (52) after rearranging as\ny ← x log2(e)\n(55)\nyf ← y − ⌊y⌋\n(56)\nzexp ← reinterpret cast<double>(static cast<int64>(A × (y − Kexp(yf)) + B))\n(57)\n12\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\nThe coefficients A = 252, B = 252 · 1023 and log2(e) can be precomputed. The operations required in (55)–(57) are\nmultiplication, addition, flooring, and type conversions. All of these are typically available in an instruction set for\nvector extensions. Thus, it is straightforward to implement (55)–(57) using SIMD in a given instruction set architecture.\nThe same ideas can be applied to derive a fast, vectorized approximation of the natural logarithm ln(x). We perform a\nchange of basis and insert the IEEE754 double representation (45) to obtain:\nzln = ln(x) = ln(2) log2(x) = ln(2) log2\n\u0002\n2p−b(1 + m)\n\u0003\n= ln(2)[(p − b)\n| {z }\nli\n+ log2(1 + m)\n|\n{z\n}\nlf\n].\n(58)\nAgain, we identify an integer part li and a fractional part lf. The integer part li is the exponent in the double\nrepresentation of x. The fractional part lf is once more replaced by a correction function Kln(m) ≈ log2(1 + m) which\ntakes the mantissa m of x as an argument. The exact form is replaced with an approximated polynomial of degree 10\ndetermined via a least-squares fit of 1000 sample points in the relevant interval m ∈ [0, 1). The coefficients are given in\nTable 4. The exponent p − b and the mantissa m are extracted from x by bit manipulations. Note that these operations\nare the inverse of the operations performed to synthesize a double, as shown in Figure 3 when following the arrows\nfrom the bottom to the top. Again, (58) is straightforward to implement with SIMD instructions.\nTo evaluate polynomials Kexp of degree 7 and Kln of degree 10, we make use of Estrin’s scheme [10]. Although this\nscheme requires more floating point operations than the classical Horner scheme, it is better suited for the two separate\nfused multiply-add (FMA) units typically available on modern hardware since it allows independent computation of\nterms, thus shortening dependency chains. Applying this technique to the polynomial approximation of the correction\nfunction Kexp yields,\nKexp(yf) = (((a7yf + a6)y2\nf + (a5yf + a4))y4\nf + ((a3yf + a2)y2\nf + (a1yf + a0))),\n(59)\nwhere pairs of parentheses group expressions that can be computed by an FMA instruction.\n4\nNumerical experiments\nThe experiments are run on compute nodes consisting of two Intel Xeon Gold 6230 CPUs (total of 40 cores per compute\nnode) running at 2.1 GHz with a measured peak performance of 2.5 TFlops/s and a DAXPY memory bandwidth of\n162 GB s−1. The DAXPY benchmark updates a vector y in place according to y ← y + αx, which, from a memory\naccess perspective, is close to the microstructure model. A second setup consists of compute nodes with two AMD\nEPYC 9354 CPUs (total of 64 cores per compute node) running at 3.25 GHz with a measured peak performance of\n3.75 TFlops/s and a DAXPY memory bandwidth of 617 GB s−1. All performance measurements are conducted and\nanalyzed with the LIKWID suite [32].\n4.1\nPerformance analysis\nAs a first numerical study, we investigate the microstructural model implementation in isolation. A significant challenge\nfor a vectorized implementation of the microstructure equations lies in the conditional branches. As outlined above, we\nrely on the fact that spatially close material points (in the physical domain) likely need the same treatment. Such points\nare often located next to each other in a global vector of unknowns arising from spatial discretization. Three different\nsynthetic sets of test data are used. The first test layout consists of alternating data, so neighboring entries in global\nvectors require different conditional branches in the microstructure model. The second consists of contiguous blocks of\n10 entries, and the third consists of contiguous blocks of 100 entries. The throughput, defined as the number of DoFs\ndivided by the solution time, is shown for these three block sizes and the explicit and implicit time integration scheme\nin Figure 4. Most importantly, the throughput increases for all block sizes when increasing the vectorization width.\nThis holds for explicit and implicit time integration schemes. This behavior is achieved by implementing the expensive\nexponential and power functions to exploit SIMD instructions. Without this implementation, one would observe\nincreased computation times and lower throughput for high vectorization widths at small block sizes. Due to unavoidable\nconditional computations in the case of block size 1, the performance improvement when increasing the vectorization\nwidth cannot scale perfectly here. For the Intel hardware, the flattening of the curve above 6 GDoF/s is in good\nagreement with the maximum theoretically possible throughput of (162 GByte/s)/(24 Byte/DoF) = 6.75 GDoF/s\nfor a fully memory-bound code.\nFigure 5 shows a roofline plot of the tested data layouts. For increasing vectorization width, data points move upwards\nand thus closer to the hardware limits. The explicit scheme quickly saturates the maximum memory bandwidth for\nlarger block sizes. This explains why no speedup is visible when increasing the vectorization width from four to eight\nin Figure 4: the implementation is memory-bound, and higher vectorization widths cannot speed up the computation\n13\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\n1\n2\n4\n8\nvectorization width [-]\n109\n1010\nthroughput [DoFs/s]\nIntel Xeon Gold 6230\nexplicit, block size 1\nexplicit, block size 10\nexplicit, block size 100\nimplicit, block size 1\nimplicit, block size 10\nimplicit, block size 100\n1\n2\n4\n8\nvectorization width [-]\n1010\nthroughput [DoFs/s]\nAMD EPYC 9354\nexplicit, block size 1\nexplicit, block size 10\nexplicit, block size 100\nimplicit, block size 1\nimplicit, block size 10\nimplicit, block size 100\nFigure 4: Impact of vectorization width on throughput of the microstructure model solved with an explicit or implicit\nscheme on Intel and AMD hardware.\n100\n101\narithmetic intensity [FLOPS/byte]\n1011\n1012\nperformance [FLOPS/s]\npeak\ninstruction mix\nw/o vectorization\nDAXPY memory bandwidth 162 GB/s\nIntel Xeon Gold 6230\nexplicit, block size 1\nexplicit, block size 10\nexplicit, block size 100\nimplicit, block size 1\nimplicit, block size 10\nimplicit, block size 100\n100\n101\narithmetic intensity [FLOPS/byte]\n1011\n1012\nperformance [FLOPS/s]\npeak\ninstruction mix\nw/o vectorization\nDAXPY memory bandwidth 617 GB/s\nAMD EPYC 9354\nexplicit, block size 1\nexplicit, block size 10\nexplicit, block size 100\nimplicit, block size 1\nimplicit, block size 10\nimplicit, block size 100\nFigure 5: Roofline plot of a single time step performed in the microstructure model with an explicit or implicit scheme\nat different data block sizes. Data points move upwards along the dashed lines for increasing vectorization widths.\nif memory transfer is the bottleneck. An improvement can only be expected if data transfer is minimized further\nor more work is performed for loaded data. One way to achieve this is subcycling, which performs multiple time\nsteps on the same loaded data in place and only stores the result of the last subcycle. However, in a practical setting,\nthe microstructure model already outperforms the thermal model by a significant factor, so further optimization in\nthat direction is not investigated here. For block size 1, we observe a growing arithmetic intensity for increasing\nvectorization width. In this case, multiple branches must be computed in all lanes, although the result is only stored in\nsome lanes. For larger block sizes, it becomes less likely to require different branch evaluations on a vectorized array,\nand thus, the number of (unproductive) arithmetic operations decreases.\nFurthermore, we analyzed the generated machine code for the implicit scheme with the machine code analyzer of the\nLLVM project [2]. Analyzing the instruction mix reveals that the achievable performance is limited by dependency\nchains and expensive instructions that occupy the same execution ports as the productive floating point operations. In\nparticular, executing the necessary instructions to compute diffusion from β to αs phase without any branching or\nload/store instructions reveals that only 43% of the work performed on the two relevant execution ports of the Intel\nhardware contributes to the floating point operation metric. For the AMD hardware, the equivalent factor is 57%.\nTherefore, we introduce an application-specific roofline into the roofline plots, where the (unrealistic) peak performance\n14\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\nTable 5: Processing parameters of cube example.\nParameter\nDescription\nValue\nUnit\nvscan\nLaser scan speed\n960\nmm s−1\ndh\nHatch spacing\n0.08\nmm\nWeff\nEffective laser power\n180\nW\nR\nLaser beam radius\n0.06\nmm\nhp\nPowder layer thickness\n0.05\nmm\nlayer 190\nlayer 195\nlayer 200\nﬁnal cool down\ntemperature [K]\nphase fraction αs [-]\nphase fraction αm [-]\nphase fraction β [-]\nx\nz\nFigure 6: Phase fractions and residual temperature after processing and cooling of layers 190, 195, 200, and after a final\ncool down of the cube geometry. Results are depicted in a slice at y = 5 mm and the base plate is cropped.\nis scaled down by the respective factor for the instruction mix. We achieve 58% of the instruction mix performance on\nIntel Gold hardware and 82% on AMD EPYC.\n4.2\nCube geometry\nIn this example, we simulate manufacturing a 1 × 1 × 1 cm3 cube from 200 powder layers with thickness 0.05 µm.\nThe cube is placed on a base plate of dimensions 1.2 × 1.2 × 1 cm3. The processing parameters are summarized in\nTable 5. A time step size of ∆tactive = 2 × 10−5 s is used in the active laser phase and after every layer, a cool down\nphase of 1 s is simulated. The first 2,000 steps of this phase are simulated with the same time step size as the active\nphase. Afterward, the macroscopic time step size is doubled after every ten time steps for the thermal model up to a\n15\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\nαs\nαm\nx\ny\n1\n2\n3\n4\nscan strategy\n1 cm\n1 cm\nFigure 7: Final phase fraction of stable αs and martensite αm for cube example in a horizontal slice at z = 8 cm. Two\ndifferent scan strategies are used to manufacture the cube: the first row shows the results for a continuous serpentine\ntrack extending over the cross-section. The second row shows the results for a scan path split into four islands, each\ncontaining a serpentine track.\nFigure 8: Final phase fraction of martensite αm for cube example with single island scan track. An octant is cut out\nto show the asymmetric distribution of martensite induced by the asymmetric scan track. An adaptively refined mesh\ncaptures the built geometry.\n16\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\n40\n80\n160\n320\n# cores\n10\n4\n10\n3\naverage time per step [s]\nideal\n40\n80\n160\n320\n# cores\n107\n108\nthroughput [dofs/s/core]\n40\n80\n160\n320\n# cores\n0.6\n0.7\n0.8\n0.9\n1.0\nparallel efficiency [-]\nActive phase\nlayer 1; 388,987 dofs\nlayer 20; 537,107 dofs\nlayer 100; 854,456 dofs\nlayer 200; 1,256,594 dofs\nMicrostructure\nThermal\n40\n80\n160\n320\n# cores\n10\n2\n10\n1\n100\naverage time per step [s]\nideal\n40\n80\n160\n320\n# cores\n105\n106\nthroughput [dofs/s/core]\n40\n80\n160\n320\n# cores\n0.6\n0.7\n0.8\n0.9\n1.0\nparallel efficiency [-]\nCool down phase\nlayer 1; 388,987 dofs\nlayer 20; 537,107 dofs\nlayer 100; 854,456 dofs\nlayer 200; 1,256,594 dofs\nMicrostructure\nThermal\nFigure 9: Strong scaling study of cuboid example with adaptive mesh coarsening. The first row shows the average\nsolution time per step, the throughput, and the parallel efficiency in the active laser phase; the second row shows the\nsame metrics in the cool down phase. Note that the reported time per step includes subcycling for the microstructure\nmodel in the later cool down steps. The number of DoFs is given for the thermal problem; the microstructure problem\ncarries three times this number.\nmaximum step size of 0.1 s. The microstructure model uses the identical time step size as the thermal model if the step\nsize is less than or equal to 1 × 10−2 s and, otherwise, uses the subcycling technique described earlier. After processing\nthe last layer, the geometry is cooled to room temperature over 100 s.\nAs a first example, every layer is processed as a single island consisting of a continuous serpentine track, where the\nlaser beam moves in y-direction and hatching proceeds in x-direction. The three phases and the residual temperature\nafter layers 190, 195, and 200 are processed are shown in Figure 6. A noticeable asymmetry can be seen in the higher\nlayers, where the accumulated heat produces a. Due to the long and continuous serpentine track, heat accumulates as\nthe track hatches progress in positive x-direction, leading to lower cooling rates and decreased martensite formation\nand, instead more stable αs phase formation in layers 170 to 190. This happens because the residual temperature only\nfalls slightly below the martensite start temperature in higher layers. The material is held at elevated temperatures,\ngiving enough time for the diffusion-driven formation of stable αs-phase. Due to the time required for a significant\nformation of αs-phase, the formation happens a few layers below the currently processed layer. Note that the final cool\ndown stage is essential to obtain the actual phase composition close to room temperature. During this stage, the already\nformed stable αs-phase remains. In the highest layers, the cooling rate is now large enough because no heat is added\nabove layer 200. Consequently, most of the β-phase remaining after processing of layer 200 transforms into αm-phase\nb. At room temperature, the β-phase fraction reaches its equilibrium value of 10%.\nThe cube test geometry is well-suited to study the effects of different scan strategies on the resulting microstructural\ncomposition. In addition to the single island scan track consisting of a continuous serpentine track, we investigate a\nscan track split into four disjoint islands, each consisting of a serpentine track. The tracks are shown in Figure 7 along\nwith the stable αs- and martensite αm-phase fractions after the final cool down in a horizontal slice at z = 8 cm. A\nstrong asymmetry is visible in the in-plane distribution of the αs- and αm-phase fractions for the single-island scan\nstrategy. On the other hand, the four-island scan strategy produces a more homogeneous distribution with a higher\naverage martensite fraction than the single-island scan. The different phase distribution is caused exclusively by the\nscan strategy, as all other parameters are identical. This observation again shows the need for scan-resolved models,\nsuch as the one presented in this work.\nFor a better idea of the different scales involved in a resolved part-scale simulation, a view of the adaptive mesh is\nshown in Figure 8. The smallest cells’ heights correspond to one powder layer thickness. To capture the geometry, the\nmesh is more refined close to the cube’s surface. One could employ a boundary-fitted mesh for this simple geometry to\nsave DoFs, as done in our previous work [25].\n17\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\nTable 6: Processing parameters of cantilever example.\nParameter\nDescription\nValue\nUnit\nvscan\nLaser scan speed\n960\nmm s−1\ndh\n(Approximate) hatch spacing\n0.11\nmm\nWeff\nEffective laser power\n180\nW\nR\nLaser beam radius\n0.06\nmm\nhp\nPowder layer thickness\n0.04\nmm\nbuild direction\nx\nz\ny\n75 mm\n5 mm\n12.48 mm\nhollow leg with\nthin walls\n45 degree\noverhang\n312 layers of 0.04 mm thickness\nTotal track length 853m\nFigure 10: NIST AMBench 2022 cantilever geometry.\nFinally, we also want to judge the performance of our implementation in this more practical example. The scenario with\nthe single-island scan strategy is simulated in a strong scaling study on 1, 2, 4, and 8 nodes of the Intel Gold hardware\nmentioned in the introduction to this section connected by an Infiniband FDR (56 Gbit/s) interconnect. The resulting\naverage time per time step, throughput, and parallel efficiency are shown in Figure 9 for the thermal and microstructure\nmodels separately. Here, parallel efficiency is defined as:\nparallel efficiency = reference compute time × reference number of cores\nscaled compute time × scaled number of cores\n(60)\nOverall, the explicit and implicit solution of the microstructure equations requires around 10% of the time of the\nrespective thermal model. Note that the microstructure problem carries three times the number of DoFs as the thermal\nproblem; thus, the throughput is further increased compared to the thermal problem. The microstructure implementation\nexhibits excellent parallel scalability, even in the first layer. This result is to be expected since no communication\nbetween processes is involved. The total wall time when running the example on eight Intel Gold nodes is 2.32 h.\n4.3\nCantilever\nAs a last example, we investigate the well-known NIST AMBench cantilever geometry [16]. The geometry, shown in\nFigure 10, features thin-walled legs and overhang regions, leading to different local cooling rates. The geometry is built\non a 10.56 mm high base plate section. To investigate the effect of different pre-heating temperatures, the bottom of the\nbase plate is constrained to a fixed temperature ˆT ∈ {293 K, 500 K, 550 K, 600 K}. The scan strategy is directly taken\nfrom [16]. The active scan phase in every layer is followed by a cool down phase of 1s, which uses identical time step\nsizes as described for the cube example. After simulating all 312 layers, a final cool down of 100 s is simulated, during\nwhich the temperature on the bottom of the baseplate is set to 293 K room temperature. The scan parameters are given\nin Table 6.\nThe case of ˆT = 293K leads to a fully martensitic microstructure and is not shown in more detail. Instead, we focus on\nthe results for higher pre-heating temperatures. Figure 11 shows the phase fractions and residual temperatures at various\npoints in time for a pre-heating temperature ˆT = 600 K. In the overhang regions and above the legs, a substantial\n18\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\ntemperature [K]\nphase fraction αs [-]\nphase fraction αm [-]\nphase fraction β [-]\nlayer 312 after ﬁnal cool down\nlayer 188\nlayer 234\nx\nz\nFigure 11: Phase fractions and residual temperature after processing and cooling of layers 188, 234, and 312 (including\nfinal cool down time). Results are depicted in the symmetry xz-plane of the cantilever geometry.\nphase fraction αs [-]\nlayer 200\npre-heating\ntemperature\nlayer 188\n600K\n550K\n500K\nFigure 12: Detailed view of αs-phase fractions for different preheating temperatures after processing and cooling of\nlayers 188 and 200. Results are depicted in the symmetry xz-plane of the cantilever geometry near the hollow leg\nstructure.\n19\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\nthermo 89%\nmicrostructure\n11%\nrelative time active\nactive 86%\ncool down\n11%\nother\n2%\ntotal time\nthermo 98%\nmicrostructure\n2%\nrelative time cool down\nFigure 13: Distribution of total solution time over different parts of the solution procedure.\namount of αs-phase forms over time due to the reduced cooling provided by the thin-walled legs. Again, the phase\nfraction αs increases visibly a few layers after initial processing. It keeps growing until reaching 90% stable αs-phase,\nthe equilibrium value. The highest layers are not held at an elevated temperature for a sufficient time, so almost no\nαs-phase forms here and the microstructure is fully martensitic after the final cooling step.\nWhile we varied the scan pattern in the last example, we now vary the pre-heating temperature and show the evolution\nof αs-phase for ˆT ∈ {500 K, 550 K, 600 K} in Figure 12. The final microstructure composition is sensitive to the\npre-heating temperature, the scan track, and the interlayer cool down time.\nThe full simulation of the case with ˆT = 293 K takes 52.3 h on four AMD Epyc nodes. Figure 13 breaks down the\ntotal solution time into active and cool down phase and the thermal and microstructure problem. Due to the high degree\nof optimization of the microstructure implementation, the coupled thermo-microstructure problem is obtained at only\nmarginally increased computation time compared to the thermal problem alone.\n5\nConclusion\nWe presented a highly efficient implementation of a coupled thermal-microstructure model. The proposed approach\nenables simulations on the scale of real parts with a scan-track resolved heat source. As demonstrated in the examples,\nconsidering the actual scan track is vital to capture variations in the microstructural composition caused by the scan\nstrategy rather than the geometry. Simulations with hundreds of layers are possible in a few hours to a few days,\ndepending on the build volume. While the investigated geometries are of a relevant scale, the presented methodology\nmay be combined with layer-wise heating approaches in areas where this simplification is applicable to tackle scales\nbeyond decimeters in future research.\nThe microstructure model equations contain conditional branches and computationally expensive mathematical functions.\nThrough special approximations and a careful data layout, the proposed methodology can utilize modern hardware\ncapabilities efficiently. The evaluation of the thermo-microstructure model comes with less than a 10% increase in run\ntime compared to the thermal model.\nIn future investigations, the current model may be refined to include homogenized information on the anisotropic\norientation of grains induced by the thermal gradients. The model can then serve as the basis for microstructure-informed\nsolid mechanics simulations.\nAcknowledgements\nThe authors thank Maximilian Bergbauer for valuable discussions about performance modeling. Furthermore, the\nauthors thank Neil Hodge, Jonas Nitzler, and Nils Much for their initial work on the microstructure model.\n20\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\nA\nAnalytical solution for initiating diffusion-based transformations\nWhen initiating the diffusion process αs → β from an initial state Xαs = 0.9, Xβ = 0.1, the rate form (27) cannot be\nused in combination with an explicit scheme since it always yields zero for the initial values. Instead, an approximate\nsolution is used for the initial time steps when diffusion starts.\nThe Crank-Nicolson integration scheme with a fixed point iteration would not face this issue if one were to perturb the\ninitial guess. However, for a unified implementation, the analytical solution is also used to initiate diffusion when using\nthe Crank-Nicolson scheme.\nTo derive the approximate analytical solution, we rewrite (27), with the help of (14) and the relations Xeq\nβ = 1 − Xeq\nα\nand ˜Xβ := Xβ − 0.1 as\n˙Xβ = kβ(T)(0.9 − Xα)\ncβ −1\ncβ (Xα − Xeq\nα )\ncβ +1\ncβ\n= kβ(T)( ˜Xβ)\ncβ −1\ncβ (Xeq\nβ − 0.1 − ˜Xβ)\ncβ +1\ncβ .\n(61)\nWe perform the substitution ξ := ˜Xβ/(Xeq\nβ − 0.1) and obtain\n˙ξ = (Xeq\n| β − 0.1)kβ(T)\n{z\n}\n˜k\n(ξ)\ncβ −1\ncβ (1 − ξ)\ncβ +1\ncβ ,\n(62)\nwhich, assuming that ˜k = const., has a known solution given in [5]. For an initial value ξn at tn, the solution in the next\nstep tn + ∆t can be found as:\n˜Xn+1\nβ\n= (Xeq\nβ − 0.1)\n\n1 +\n\n\n\ncβ\n(Xeq\nβ − 0.1)kβ(T)∆t + cβ\n\u0010\nξn\n1−ξn\n\u0011 1\ncβ\n\n\n\ncβ\n\n−1\n(63)\nFor numerical reasons, this solution is computed using a shifted fraction ˜Xβ, which has an equilibrium value of zero at\nroom temperature. Due to the careful formulation of (63), it is possible to accurately work on a small number below\nmachine precision ε(1) ≈ 1 × 10−16 without losing precision by adding to a numeric value on the order of 1. The\nanalytical solution (63) is evaluated in subsequent time steps until ˜Xn+1\nβ\n∆t > 1 × 10−15 which is an approximation for\nthe decrement in αs-fraction according to (27). This criterion ensures a sufficient change is noticeable in the α-fraction\nand allows to continue the evolution with (27). While using the approximate analytical solution, the fraction ˜Xβ is\ntracked independently and not computed from the continuity constraint (32). The applicability of this strategy has been\nverified for a constant temperature T = 1200 K as shown in Figure 14. The analytical approximation (63) is exact in\nthe case of a constant temperature.\nAn analytical approximation for the initial diffusion step from β → αs has already been discussed in [23]. In this case,\nthe values obtained from the analytical expression are large enough and significant digits are not absorbed.\nReferences\n[1] C++ SIMD library. https://en.cppreference.com/w/cpp/experimental/simd. Accessed: 2024-02-06.\n[2] llvm-mca – LLVM Machine Code Analyzer. https://llvm.org/docs/CommandGuide/llvm-mca.html.\nAccessed: 2024-02-26.\n[3] IEEE standard for floating-point arithmetic. IEEE Std 754-2019 (Revision of IEEE 754-2008), pages 1–84, 2019.\n[4] D. Arndt, W. Bangerth, M. Bergbauer, M. Feder, M. Fehling, J. Heinz, T. Heister, L. Heltai, M. Kronbichler,\nM. Maier, et al. The deal. ii library, version 9.5. Journal of Numerical Mathematics, 31(3):231–246, 2023.\n[5] I. Avramov and J. ˇSest´ak. Generalized kinetics of overall phase transition explicit to crystallization. Journal of\nThermal Analysis and Calorimetry, 118:1715–1720, 2014.\n[6] J. Berry, A. Perron, J.-L. Fattebert, J. D. Roehling, B. Vrancken, T. T. Roehling, D. L. Rosas, J. A. Turner, S. A.\nKhairallah, J. T. McKeown, et al. Toward multiscale simulations of tailored microstructure formation in metal\nadditive manufacturing. Materials Today, 51:65–86, 2021.\n21\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\n0\n5\n10\n15\n20\n25\n30\nt [s]\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nX  [-]\n19.2\n19.4\n19.6\n0.340\n0.345\n0.350\n0.355\n0.360\nanalytical\nexplicit\nCrank-Nicolson\nFigure 14: Comparison of analytical solution for transformation β → αs to explicit and Crank-Nicolson time integration.\nThe solution is computed for a constant temperature T = 1200 K and initial values Xαs = 0.9 and Xβ = 0.1.\n[7] Q. Chen, N. Ma, K. Wu, and Y. Wang. Quantitative phase field modeling of diffusion-controlled precipitate growth\nand dissolution in ti–al–v. Scripta Materialia, 50(4):471–476, 2004.\n[8] A. Crespo. Modelling of heat transfer and phase transformations in the rapid manufacturing of titanium\ncomponents. InTech, 2011.\n[9] R. Ding and Z. Guo. Microstructural evolution of a ti–6al–4v alloy during β-phase processing: experimental and\nsimulative investigations. Materials Science and Engineering: A, 365(1-2):172–179, 2004.\n[10] G. Estrin. Organization of computer systems: the fixed plus variable structure computer. In Papers presented at\nthe May 3-5, 1960, western joint IRE-AIEE-ACM computer conference, pages 33–40, 1960.\n[11] A. Fog. VCL – C++ vector class library manual. https://raw.githubusercontent.com/vectorclass/\nmanual/master/vcl_manual.pdf. Accessed: 2024-02-06.\n[12] D. Furrer and S. Semiatin. Introduction to fundamentals of modeling for metals processing. 2009.\n[13] X. Gong and K. Chou. Phase-field modeling of microstructure evolution in electron beam additive manufacturing.\nJom, 67:1176–1182, 2015.\n[14] J. Koepf, D. Soldner, M. Ramsperger, J. Mergheim, M. Markl, and C. K¨orner. Numerical microstructure prediction\nby a coupled finite element cellular automaton model for selective electron beam melting. Computational Materials\nScience, 162:148–155, 2019.\n[15] M. Kronbichler and K. Kormann. A generic interface for parallel cell-based finite element operator application.\nComputers & Fluids, 63:135–147, 2012.\n[16] B. Lane, L. Levine, D. Deisenroth, H. Yeung, V. Tondare, S. Mekhontsev, and J. Neira. AM Bench 2022 3D\nBuild Modeling Challenge Description Data (AMB2022-01). Technical report, National Institute of Standards\nand Technology, 2022.\n[17] L. Lindgren, A. Lundb¨ack, M. Fisk, R. Pederson, and J. Andersson. Simulation of additive manufacturing using\ncoupled constitutive and microstructure models. Additive Manufacturing, 12:144–158, 2016.\n[18] A. C. I. Malossi, Y. Ineichen, C. Bekas, and A. Curioni. Fast exponential computation on SIMD architectures.\nProc. of HIPEAC-WAPCO, Amsterdam NL, 56, 2015.\n[19] C. Meier, R. W. Penny, Y. Zou, J. S. Gibbs, and A. J. Hart. Thermophysical phenomena in metal additive\nmanufacturing by selective laser melting: fundamentals, modeling, simulation, and experimentation. Annual\nReview of Heat Transfer, 20, 2017.\n[20] J. Munk, E. Breitbarth, T. Siemer, N. Pirch, and C. H¨afner. Geometry effect on microstructure and mechanical\nproperties in laser powder bed fusion of ti-6al-4v. Metals, 12(3):482, 2022.\n[21] C. C. Murgau, R. Pederson, and L.-E. Lindgren. A model for Ti–6Al–4V microstructure evolution for arbitrary\ntemperature changes. Modelling and Simulation in Materials Science and Engineering, 20(5):055006, 2012.\n[22] P. Nie, O. Ojo, and Z. Li. Numerical modeling of microstructure evolution during laser additive manufacturing of\na nickel-based superalloy. Acta Materialia, 77:85–95, 2014.\n22\nHighly efficient computational approach for part-scale microstructure predictions in Ti-6Al-4V additive manufacturing\n[23] J. Nitzler, C. Meier, K. W. M¨uller, W. A. Wall, and N. E. Hodge. A novel physics-based and data-supported\nmicrostructure model for part-scale simulation of laser powder bed fusion of Ti-6Al-4V. Advanced Modeling and\nSimulation in Engineering Sciences, 8(1):16, 2021.\n[24] F. Perini and R. D. Reitz. Fast approximations of exponential and logarithm functions combined with efficient\nstorage/retrieval for combustion kinetics calculations. Combustion and Flame, 194:37–51, 2018.\n[25] S. D. Proell, P. Munch, M. Kronbichler, W. A. Wall, and C. Meier. A highly efficient computational approach\nfor fast scan-resolved simulations of metal additive manufacturing processes on the scale of real parts. Additive\nManufacturing, 79:103921, 2024.\n[26] P. Promoppatum, S.-C. Yao, P. C. Pistorius, A. D. Rollett, P. J. Coutts, F. Lia, and R. Martukanitz. Numerical\nmodeling and experimental validation of thermal history and microstructure for additive manufacturing of an\ninconel 718 product. Progress in Additive Manufacturing, 3:15–32, 2018.\n[27] A. Rai, M. Markl, and C. K¨orner. A coupled Cellular Automaton–Lattice Boltzmann model for grain structure\nsimulation during additive manufacturing. Computational Materials Science, 124:37–48, 2016.\n[28] M. Rolchigo, S. T. Reeve, B. Stump, G. L. Knapp, J. Coleman, A. Plotkowski, and J. Belak. Exaca: A performance\nportable exascale cellular automata application for alloy solidification modeling. Computational Materials Science,\n214:111692, 2022.\n[29] E. Salsi, M. Chiumenti, and M. Cervera. Modeling of microstructure evolution of ti6al4v for additive manufactur-\ning. Metals, 8(8):633, 2018.\n[30] N. N. Schraudolph. A fast, compact approximation of the exponential function. Neural Computation, 11(4):853–\n862, 1999.\n[31] N. Shibata and F. Petrogalli. Sleef: A portable vectorized library of c standard mathematical functions. IEEE\nTransactions on Parallel and Distributed Systems, 31(6):1316–1327, 2019.\n[32] J. Treibig, G. Hager, and G. Wellein. Likwid: A lightweight performance-oriented tool suite for x86 multicore\nenvironments. In 2010 39th international conference on parallel processing workshops, pages 207–216. IEEE,\n2010.\n[33] J. A. Turner, J. Belak, N. Barton, M. Bement, N. Carlson, R. Carson, S. DeWitt, J.-L. Fattebert, N. Hodge,\nZ. Jibben, et al. ExaAM: Metal additive manufacturing simulation at the fidelity of the microstructure. The\nInternational Journal of High Performance Computing Applications, 36(1):13–39, 2022.\n[34] J. Yang, H. Yu, J. Yin, M. Gao, Z. Wang, and X. Zeng. Formation and control of martensite in Ti-6Al-4V alloy\nproduced by selective laser melting. Materials & Design, 108:308–318, 2016.\n[35] Q. Zhang, J. Xie, Z. Gao, T. London, D. Griffiths, and V. Oancea. A metallurgical phase transformation framework\napplied to slm additive manufacturing processes. Materials & Design, 166:107618, 2019.\n23\n"
}