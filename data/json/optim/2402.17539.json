{
    "optim": "arXiv:2402.17539v1  [math.OC]  27 Feb 2024\nThe optimizing mode classiﬁcation stabilization of\nsampled stochastic jump systems via an improved\nhill-climbing algorithm based on Q-learning\nGuoliang Wang\nAbstract—This paper addresses the stabilization problem of\nstochastic jump systems (SJSs) closed by a generally sampled\ncontroller. Because of the controller’s switching and state both\nsampled, it is challenging to study its stabilization. A new\nstabilizing method deeply depending on the mode classiﬁcations\nis proposed to deal with the above sampling situation, whose\nquantity is equal to a Stirling number of the second kind. For\nthe sake of ﬁnding the best stabilization effect among all the\nclassiﬁcations, a convex optimization problem is developed, whose\nglobally solution is proved to be existent and can be computed by\nan augmented Lagrangian function. More importantly, in order\nto further reduce the computation complexity but retaining a\nbetter performance as much as possible, a novelly improved hill-\nclimbing algorithm is established by applying the Q-learning\ntechnique to provide an optimal attenuation coefﬁcient. A nu-\nmerical example is offered so as to verify the effectiveness and\nsuperiority of the methods proposed in this study.\nIndex Terms—Stochastic jump systems; sampled control;\nmode classiﬁcation and optimization; Lagrangian function; hill-\nclimbing algorithm; Q-learning.\nI. INTRODUCTION\nS\nIGNIFICANTLY different from deterministic systems,\nstochastic jump system (SJS) can represent physical sys-\ntems experiencing random structure changes. Due to this sys-\ntem with multiple structures or modes, it makes its stabilization\nproblems quite distinctive whose controller’s quantity is not\nunique. According to the designed controller depending on\nmode or not, the existing stabilization results are mainly\nclassiﬁed into two categories. The ﬁrst kind needs the mode\nof controller to keep pace with others and are usually called to\nbe mode-dependent control method such as [1]–[6]. Due to all\nthe modes synchronized with each other at the same time, the\neffect of stabilization effect will be the best and have the least\nconservatism. However, this advantage is also its disadvantage\nwhich will be limited in practice, since a lot of effort is\nneeded to keep this synchronization all the time. In theoretical\nresearch, an ideal assumption for all the mode information\navailable in real time is commonly acquiescent. The second\nkind is mentioned as mode-independent control approach [7]–\n[10], in which the mode information is totally removed even if\nThis work was supported by the Open Project of Key Field Alliance of\nLiaoning Province under Grant No. 2022-KF-11-03, the Educational Depart-\nment Foundation of Liaoning Province under Grant No. JYTMS20231435, the\nNational Natural Science Foundation of China under Grant No. 62073158.\nG. Wang is with School of Information and Control Engineering, Liaon-\ning Petrochemical University, Fushun 113001, Liaoning, China (e-mail:\nglwang@lnpu.edu.cn).\nit is available sometimes. Because the mode information is to-\ntally removed in controller, it can stabilize a system regardless\nof its mode accessible or not and naturally bring more con-\nservatism. In contrast to mode-dependent control being very\nideal, mode-independent control is excessively absolute due\nto mode information neglected completely. For the purpose\nof bridging the above methods and balancing their advantages\nand disadvantages, some improved controllers were developed,\nsuch as partially mode-dependent controller [11] and partial\ninformation controller [12]. However, the drawbacks of mode-\ndependent and -independent control methods have not been\npartly solved, and there are still some problems to be further\nstudied. For example, the quantity of controllers denoted as\nM in the above references is no less than number of modes\nreferred to be N. Consequently, an interesting problem about\nSJSs can be proposed such that whether one can stabilize an\nSJS using fewer controllers but more than one. In this situation,\nsome results were found, see, e.g., disordered or unmatched\ncontroller [13], [14], and scheduling controller [15], [16].\nThough the aim of fewer controllers stabilizing an SJS with\nmore subsystems was realized, it can be found from these\nreferences that for each subsystem or mode, at most total M\ncontrollers were added once, while the equipment cost and\nconservatism of stabilization realizing were both increased.\nThe main reason is that the developed controller in these ref-\nerences was designed on the whole modes without considering\nthem separately. When the controller is designed according to\nthe mode classiﬁcations, a quantity limited controller method\nwas in proposed in [17]. However, the mode classiﬁcation\nmethod for designing controllers is not fully studied, and many\ninteresting and signiﬁcant topics need to be further researched.\nFor example, whether there is an optimization classiﬁcation or\nnot and how to ﬁnd the best mode classiﬁcation will be the\nﬁrst problems, and more extensions based on optimizing mode\nclassiﬁcation method will also be meaningful.\nOn the other hand, it is well known that networked control\nsystem (NCS) is a control system whose components are con-\nnected through a communication network. Though NCS has\nsuch advantages, there is a precondition that all the transmitted\ndata should be ﬁrst sampled. Importantly, the appearance of\nsampled data complicates system analysis and synthesis and\ncauses many unpredictable problems. It can further bring some\nnegative effects such as communication delays, data packet\ndropouts and/or packet disordering, network attack, some of\nwhich are not easy. Thus, it is very important to research the\nsampling phenomenon scientiﬁcally. Particularly, when an SJS\nis connected by a network, some novel but hard issues will\nencounter such that not only state but also switching signal\nare sampled. Due to switching being stochastic, its sampling\nis speciﬁc and signiﬁcantly different from state sampled. Ac-\ncordingly, some interesting but challenging problems emerge.\nUp to now, very few results are found to study the stabilization\nof stochastic systems via a sampled-switching controller. On\nthe one hand, the author in [18] ﬁrst considered its stabi-\nlization problem by applying an auxiliary system approach.\nMore extensions [19], [20] were further obtained base in this\nmethod. Since the stabilization problem of original sampling\nsystem was transformed to study its auxiliary system without\nany sampling, it decided that the sampling bound should be\nvery small. On the other hand, based on an augmented system\nmethod, the stabilization of Markovian jump systems (MJSs)\nclosed by a sampled switching and state controller was studied\nin [21], whose sampling effect was modeled to be a time-\nvarying exponential matrix. Unfortunately, the convergency\nguaranteed by the reference was only asymptotically mean\nstable and was worse than the common stability concepts such\nas almost surely exponentially stable, globally asymptotically\nstable and so on. To summarize, it is necessary to further in-\nvestigate the stabilization problem of sampled stochastic jump\nsystems. Moreover, new approaches are expected to provide\nlarger sampling bounds and better convergency properties.\nMeanwhile, many difﬁculties will encounter in the research,\nsome of which are challenging. For example, how to establish\na quantized correlation between the original switching and\nits sampled value will be the ﬁrst difﬁculty to encounter,\nsince no more suitable models are available. Particularly, it\nwill be challenging to achieve the above expected objectives,\nbecause both switching and state are sampled simultaneously.\nEspecially so many possible combinations of switching and\nits sampled values will emerge and bring large difﬁculties in\nsystem analysis and synthesis.\nThe main contributions of this paper are as follows: 1) For\nthe aim of overcoming the control difﬁculties of sampling in\nboth state and switching signals, a new stabilizing controller\nis established to be very closed to the mode classiﬁcations.\nOn the one hand, the controller’s quantity is smaller than\nmode-dependent controllers, and its switching is not necessary\nsynchronous to the original one. On the other hand, the\nconservatism is smaller than mode-independent ones [7]–[10];\n2) So as to further improve the stabilization performance, a\nconvex optimization problem is presented to determine the\nbest classiﬁcation of sampled stabilization, which is better\nthan [17] without mode optimization. It can be shown that the\noptimal solution can exist and be obtained by computing some\nequations coming from an augmented Lagrangian function; 3)\nDue to the classiﬁcation quantity being a Stirling number of\nthe second kind and large, a novel method having less com-\nplexity but better control performance is proposed based on the\nhill-climbing algorithm by using the Q-learning technique to\nensure an optimal attenuation coefﬁcient. Particularly, not only\nthe monotonicity but also the convergency of method in this\npaper is guaranteed; 4) Compared with the existing auxiliary\nsystem approach [18] and augmented system method [21], the\ndeveloped method is less conservative and has larger sampling\nbounds. Moreover, the key idea in this paper can popularize in\nmany situations as long as the system switching experiences\na sampling or mismatching phenomenon.\nNotation R, R>0, R≥0 and N>0 represent the sets of real\nnumbers, positive real numbers, non-negative real numbers and\npositive integers respectively. Rn denotes the n-dimensional\nEuclidean space, and RN\n⪰0 is a set of vector whose each\nelement is non-negative. P (·) and E (·) are the probability and\nexpectation operators respectively. ∥·∥ refers to the Euclidean\nvector norm or spectral matrix norm. λmin(M) and λmax(M)\ndenote the smallest and largest eigenvalues of a square matrix\nM, χM ≜ λmax\n\u0010\nM+MT\n2\n\u0011\nand (M)⋆ ≜ M + M ⊤.\nII. PROBLEM FORMULATION\nConsider a stochastic jump system described as\n˙x(t) = Aη(t)x(t) + Bη(t)u(t)\n(1)\nwhere x(t) ∈ Rn, Aη(t) ∈ Rn×n and Bη(t) ∈ Rn×m and\nu(t) ∈ Rm. The stochastic switching process {η(t), t ≥ 0} is\na piecewise constant function and right-continuous. In detail,\nit is actual the semi-Markvoian switching and takes values\nfrom a set N ≜ {1, 2, . . . , N} such as η(t) = i ∈ N , ∀t ∈\n[Tn, Tn+1), n ∈ N, where switching instant Tn satisﬁes 0 =\nT0 < T1 < · · · < Tn < · · · . For simplicity, η(Tn) = i at the\nnth switching instant is simply denoted to be ηn = i.\nIn contrast to the usual controllers designed for stochastic\nsystems including (1), a general controller with sampling\nphenomenon is described to be\nu(t) = Kη(tk)x(tk), ∀t ∈ [tk, tk+1) , ∀k ∈ N\n(2)\nwhere Kη(tk) ∈ Rm×n is the control gain, tk is the sampling\ninstant such as 0 = t0 < t1 < · · · < tk < · · · , and\nsk ≜ tk −tk−1 is denoted as the sampling interval. Obviously,\nthe simultaneous existence of two instant sequences {Tn}n∈N\nand {tk}k∈N makes the system analysis and synthesis not\neasy. Especially, due to η(t) being sampled, it will bring large\ndifﬁculties and also complicates the closed-loop system. The\nﬁrst reason is that so many combinations about original signal\nη(t) and its sampled signal η(tk) encounter and inevitably\nresult in great complexity and large conservatism. The second\nreason, but not the last, is that the sampled state x(tk) existing\nsimultaneously also leads to negative effects such that the\ncorrelation between the original and sampled states on each\nsubinterval is hard to be done. In order to solve the above\nmentioned problems, the controller is developed as\nu(t) =\nN\nX\nℓ=1\nα[ν(η(tk))]\nℓ\n¯Kℓx(tk), ∀t ∈ [tk, tk+1) , ∀k ∈ N\n(3)\nwhere α[ν(η(tk))]\nℓ\n∈ R and ¯Kℓ ∈ Rm×n are to be designed.\nParticularly, the sampling instant tk of controller (3) is differ-\nent from (2). In detail, the sampling instant of (3) is event-\ntriggered such as\ntk+1 = min\nt≥tk {t : η(tk) ∈ Nh, η(t) /∈ Nh}\n(4)\nAccordingly, function ν (η(t)) on interval ∀t ∈ [tk, tk+1) with\nproperty (4) is deﬁned as ν (η(t)) ≡ ν (η(tk)) = h, when\nη(t) ∈ Nh. Meanwhile, set Nh is a newly constructed subset\nbased on N and deﬁned as\nN D = {N1, N2, . . . , NM}\n(5)\nwhere Nh ⊆ N , h ∈ M ≜ {1, 2, . . ., M}, and constant\nM is the quantity of elements of set N D and denoted as\nnum(N D) = M ∈ N>0. Moreover, all the elements of set\nN D are mutually exclusive such as\nNh\n\\\nNℓ = ∅, ∀h ̸= ℓ ∈ M\n(6)\nThen, it can be concluded that\nN =\nM\n[\nh=1\nNh and\nM\nX\nh=1\nnh = N\n(7)\nwhere nh ≜ num (Nh) ∈ N>0. Moreover, subset Nh can be\nfurther expressed as\nNh =\nn\ni[Nh]\n1\n, i[Nh]\n2\n, . . . , i[Nh]\nnh\no\n(8)\nwhere i[Nh]\nℓ\n∈ N , ℓ = 1, 2, . . ., nh. When the above men-\ntioned classiﬁcation and event-trigger scheme achieve, con-\ntroller (3) will be superior to (2), which can be realized easily\nand of larger signiﬁcance in theory and practice. Moreover, a\nmapping between M controllers and N subsystems or modes\nshould be introduced. In the next, it will be seen that this\nmapping can not only be used to design a new controller\nfor stochastic systems but also bridge the traditionally mode-\ndependent and -independent controllers very well.\nREMARK 1: It is noted that controller (3) includes some\nexisting controllers without any sampling signals as special\nsituations in which neither x(t) or η(t) is sampled. First of\nall, when M = N and Nh = {h}, ∀h ∈ N , in addition to\nPN\nℓ=1 α[h]\nℓ\n≡ 1 with α[h]\nℓ\n∈ {0, 1} but α[h]\nh ≡ 1, controller (3)\nwithout sampled state x(tk) but with x(t) will be simpliﬁed\nto the traditionally mode-dependent controller such as u(t) =\n¯Kη(t)x(t). Second, under a deterministic classiﬁcation same\nto the ﬁrst situation, and if PN\nℓ=1 α[h]\nℓ\n≡ 1 with α[h]\nℓ\n∈ (0, 1),\none could get a partial information controller similar to [12].\nMoreover, if α[h]\nℓ\ntakes discrete values such as α[h]\nℓ\n∈ {0, 1}, a\ndisordered controller similar to [13] will be obtained. Thirdly,\nwhen there is only one element in N D such as N1 = N ,\nthere will be only one element in M such as M = {1}. Then,\ncontroller (3) with x(tk) replaced by x(t) will reduce to be the\ntraditionally mode-independent controller u(t) = K1x(t) =\nPN\nℓ=1 αℓ ¯Kℓ. When αℓ is equal to the stationary distribution,\nthe mode-independent controller u(t) = PN\nℓ=1 αℓ ¯Kℓ will be\nan optimal estimation of ¯Kℓ similar to [17], [22].\nThough some existing controllers are included as special\nsituations of sampled controller (3), their methods cannot be\nused to deal with (3). Obviously, controller (3) deeply depends\non the mode classiﬁcation. Meanwhile, so many possible\ncombinations of the division about set N are involved whose\ndivision value is a positive natural number. Particularly, it can\nbe known from [23] that its value is equal to S2(N, M) which\nis a Stirling number of the second kind and described to be\nS2(N, M) = S2(N − 1, M − 1) + MS2(N − 1, M)\nIts detailed expansion [24] is given to be\nS2(N, M) =\n1\nM!\nM\nX\nv=0\n(−1)v\n\u0012\nM\nv\n\u0013\n(M − v)N\n(9)\nWhen the classiﬁcation of (3) is not given in advance, con-\ntroller (3) should deeply depend on the Stirling number of the\nsecond kind and be rewritten as\nu(t) =\nN\nX\nℓ=1\nα[ν(η(tk))]\nℓ\n(c) ¯Kℓx(tk), ∀t ∈ [tk, tk+1) , ∀k ∈ N\n(10)\nwhere c is selected to be only one value from c ∈ C ≜\n{1, 2, . . . , S2(N, M)}. Accordingly, the related symbols in\ndeﬁnitions (5)-(8) will change to be\nN D(c) = {N1(c), N2(c), . . . , NM(c)}\nNh(c) =\nn\ni[Nh(c)]\n1\n, i[Nh(c)]\n2\n, . . . , i[Nh(c)]\nnh(c)\no\nwhere nh(c) ≜ num (Nh(c)) ∈ N>0, whose properties (6)\nand (7) satisfy too.\nThen, two necessary but not easy problems are proposed as\nfollows:\nProblem 1: Whether does the best classiﬁcation of set N\nexist or not?\nProblem 2: How to ﬁnd the best classiﬁcation to design a\nsampled stabilizing controller such as (10)?\nFirst of all, a cost function is introduced to be\nJ(α(c)) =\nM\nX\nh=1\n\r\r\r\r\r\nN\nX\nℓ=1\nα[h]\nℓ (c) ¯Kℓ\n\r\r\r\r\r\n2\n(11)\nwhere matrix α(c) ≜\n\u0010\nα[h]\nℓ (c)\n\u0011\n∈ RM×N is composed of\nα[h]\nℓ (c) but depends on classiﬁcation parameter c. Then, the\nrelated optimization problem is to ﬁnd the optimal classiﬁca-\ntion and its related optimal classiﬁcation parameter α[h]\nℓ (c) of\nsampled controller (10) satisfying\nJ∗ = min\nc∈C\nmin\nα[h]\nℓ\n(c)∈R\nM\nX\nh=1\n\r\r\r\r\r\nN\nX\nℓ=1\nα[h]\nℓ (c) ¯Kℓ\n\r\r\r\r\r\n2\n= min\nc∈C\nM\nX\nh=1\nJ[h] \u0010\u0010\nα[h](c)\n\u0011∗\u0011\n= min\nc∈C J (α∗ (c))\n(12)\nwhere\nthe\noptimal\nsolution\nα∗ (c)\nsatisﬁes\nJ (α∗ (c))\n≜\nminα[h]\nℓ\n(c)∈R\nPM\nh=1\n\r\r\rPN\nℓ=1 α[h]\nℓ (c) ¯Kℓ\n\r\r\r\n2.\nSimilarly,\none\ncan\ndeﬁne\n\u0000α[h](c)\n\u0001∗\nsuch\nas\nJ[h] \u0010\u0000α[h](c)\n\u0001∗\u0011\n≜\nminα[h]\nℓ\n(c)∈R\n\r\r\rPN\nℓ=1 α[h]\nℓ (c) ¯Kℓ\n\r\r\r\n2,\nwhere J[h] \u0000\u0000α[h](c)\n\u0001\u0001\n≜\n\r\r\rPN\nℓ=1 α[h]\nℓ (c) ¯Kℓ\n\r\r\r\n2 > 0 means\nthere is always a controller added to each subsystem. It can\nbe seen from (12) that a normal method getting the solution\nto Problem 2 is to compute cost function (11) one by one\nwhose process will repeat S2(N, M) times. After doing that,\none can select the solution minimizing the value of (11) as the\nglobally optimal solution. Obviously, when N and M become\nlarge, the complexity of computation will be very large.\nThus, it is necessary to develop a new way which provides\na suboptimal solution nearing the globally optimal solution\nas much as possible but has smaller complexity without\ncomputing (11) one by one. In this paper, an improved hill-\nclimbing algorithm (HCA) based on the Q-learning technique\nwill be developed, which can not only avoid traversing all the\nclassiﬁcations but also guarantee the proposed algorithm some\ngood properties such as convergence and monotonicity. As a\nresult, the computation complexity will be largely reduced,\nwhile the cost function will also have an optimal value. Some\nfundamentally dealing processes should be established ﬁrstly.\nFirst of all, some constants about classiﬁcation set N D(c)\nare needed and important in designing the optimization method\nto be presented. In detail, each element Nh(c) of N D(c) is ar-\nranged by h such as N D(c) = {N1(c), N2(c), . . . , NM(c)}.\nMeanwhile, all the elements of Nh(c) are rewritten as an\nascending sequence such as i[Nh(c)]\n1\n(c) < i[Nh(c)]\n2\n(c) < · · · <\ni[Nh(c)]\nnh(c) (c), since they are natural numbers and distinct from\neach other. Then, two kind parameters referred to be ξ and\nζ about subset Nh(c) can be generated. On the one hand,\nparameter ξ is generated by arranging every nh(c) with h\nselecting 1, 2, . . . , M simultaneously and sequently such as\nξ = n1(c)n2(c) · · · nM(c). On the other hand, similar to ξ,\nparameter ζ is constructed by arranging all the elements of\nevery subset following an ascending sequence such as\nζ = i[N1(c)]\n1\ni[N1(c)]\n2\n· · · i[N1(c)]\nn1(c)\n· · · i[Nℓ(c)]\nnℓ(c)\n· · · i[NM(c)]\nnM(c)\nBased\non\nthese\nparameters,\nan\none-to-one\ncorrelation\nor\nmapping\nbetween\nsets\nD\n≜\n\b\nN D(1), N D(2), . . . , N D(S2(N, M))\n\t\nand\nC\ncan\nbe\nobtained by arranging the value of c orderly along with\nthe values of ξ and ζ increasing successively. To illustrate\nthe above process clear and vividly, an example about\nN\n= {1, 2, 3, 4, 5} and M = {1, 2, 3} is given in Table\nI. There, all the subset classiﬁcations about N = 5 and\nM = 3 with S2(5, 3) = 25 are listed followed by the above\nproposed process, while parameters ξ and ζ are computed too.\nWithout loss of generality, only two situations are discussed\nin detail. The ﬁrst situation is N1(c) = {1}, N2(c) = {2}\nand N3(c) = {3, 4, 5}. Obviously, one knows n1(c) = 1,\nn2(c) = 1 and n3(c) = 3, while ξ = 113 and ζ = 12345.\nBecause of ζ = 12345 being the smallest among ξ = 113, and\nbased on the proposed mapping principle, one should select\nc = 1. Similarly, c = 2 means the second-smallest value of\nζ among ξ = 113 such as ζ = 13245. The second situation\nis N1(c) = {1}, N2(c) = {2, 3} and N3(c) = {4, 5}. Then,\none knows n1(c) = 1, n2(c) = 2 and n3(c) = 2, such that\nξ = 122 and ζ = 12345. Though the values of ζ about the\ntwo situations are the same, the values of ξ are different. Due\nto 113 < 122, the values of parameter c are different and\nselected to be c = 1 and c = 11 respectively followed by the\nabove mapping. The other situations are all given in Table I,\nwhose detailed computation processes are omitted.\nTABLE I\nTHE CLASSIFICATION OF COMBINATIONS AND THEIR NUMBERS\nN1(c)\nN2(c)\nN3(c)\nξ\nζ\nc\n{1}\n{2}\n{3, 4, 5}\n113\n12345\n1\n{1}\n{3}\n{2, 4, 5}\n113\n13245\n2\n{1}\n{4}\n{2, 3, 5}\n113\n14235\n3\n{1}\n{5}\n{2, 3, 4}\n113\n15234\n4\n{2}\n{3}\n{1, 4, 5}\n113\n23145\n5\n{2}\n{4}\n{1, 3, 5}\n113\n24135\n6\n{2}\n{5}\n{1, 3, 4}\n113\n25134\n7\n{3}\n{4}\n{1, 2, 5}\n113\n34125\n8\n{3}\n{5}\n{1, 2, 4}\n113\n35124\n9\n{4}\n{5}\n{1, 2, 3}\n113\n45123\n10\n{1}\n{2, 3}\n{4, 5}\n122\n12345\n11\n{1}\n{2, 4}\n{3, 5}\n122\n12435\n12\n{1}\n{2, 5}\n{3, 4}\n122\n12534\n13\n{2}\n{1, 3}\n{4, 5}\n122\n21345\n14\n{2}\n{1, 4}\n{3, 5}\n122\n21435\n15\n{2}\n{1, 5}\n{3, 4}\n122\n21534\n16\n{3}\n{1, 2}\n{4, 5}\n122\n31245\n17\n{3}\n{1, 4}\n{2, 5}\n122\n31425\n18\n{3}\n{1, 5}\n{2, 4}\n122\n31524\n19\n{4}\n{1, 2}\n{3, 5}\n122\n41235\n20\n{4}\n{1, 3}\n{2, 5}\n122\n41325\n21\n{4}\n{1, 5}\n{2, 3}\n122\n41523\n22\n{5}\n{1, 2}\n{3, 4}\n122\n51234\n23\n{5}\n{1, 3}\n{2, 4}\n122\n51324\n24\n{5}\n{1, 4}\n{2, 3}\n122\n51423\n25\nSecondly, after introducing the mapping between sets D and\nC , an optimization algorithm based on a local search can be\nproposed and remain some advantages. In detail, on the one\nhand, a trajectory only using the selected partial nodes instead\nof exploiting all the division nodes is generated. In other\nwords, it can lead to a locally even globally optimal solution\nby an iterating method. On the other hand, a favorable con-\nvergence and monotonicity of the proposed algorithm should\nbe satisﬁed. Particularly, based on the proposed mapping, the\nnormal HCA can be used to realize the former requirement of\nlocally optimal solution. However, the other properties on the\nconvergence and monotonicity described in the latter are not\nguaranteed. In order to make a brief introduction to the HCA,\nsome deﬁnitions are needed to be clariﬁed, while the other\ndetails can be found in the existing similar references such\nas [25]. For convenience, in the following, we will mention\nthe detailed classiﬁcation set N D(c) by using scalar c equiva-\nlently. Then, the scalar parameter c in (11) will have a speciﬁc\nmeaning, which actually corresponds a detailed classiﬁcation\nN D(c) and makes it possible to get the optimal solution by\napplying the HCA. Unfortunately, at least two shortcomings\nare found in directly applying set C , when the HCA is to\nbe used. For one thing, the element of C has a clustering\nphenomenon. In other words, the clustering phenomenon will\nlikely lead to a worse locally optimal solution, when the search\ninterval radius of the traditionally HCA is not large enough.\nFor another, due to the element of C being a natural number,\na big range between two elements exists and complicates the\ncomputation of (11). In order to solve the problems coming\nfrom C , another set Ω referred to be “the nominal solution set”\nis deﬁned as Ω ≜ {ω(1), ω(2), . . . , ω (S2(N, M))}, where\nω(c), ∀c ∈ C , is an any real number in the interval (0, ǫ] with a\ngiven real ǫ ∈ R>0. Meanwhile, it is further required that ω(c),\n∀c ∈ C , is distinct such as ω(c) ̸= ω(j), ∀c, j ∈ C and c ̸= j.\nMore importantly, a corresponding correlation between sets C\nand Ω is denoted such that the value of ω(c) corresponds to\nthe classiﬁcation set N D(c), when the scalar c belongs to set\nC . After doing that, another discrete mapping between sets\nJ ≜ {J (α∗ (1)) , J (α∗ (2)) , . . . , J (α∗ (S2(N, M)))} and Ω\nis introduced to be\nf : Ω → J such as f(ω(c)) = J (α∗ (c)) , ∀c ∈ C\n(13)\nWhen some elements’ values of set J are equal, one just\nneeds to remain one and delete the other same values. Based\non the characteristic of mapping (13), it can be seen that the\ndeletion of the same values of set J has nothing to do with the\nconsidered problem in this paper. Without loss of generality,\nall the elements’ values of J are assumed to be distinct in the\nnext. Particularly, due to f(ω(c)) = J (α∗ (c)), ω(c) is said\nto be “the nominally optimal solution” to (11) with c ∈ D\ngiven in advance, whose optimization effect is the same as\nα∗ (c). After doing this, the problems mentioned can be done\nby applying set C directly. Finally, in order to exploit the HCA\nsuccessfully, another variable ˆω(k) ∈ Ω, k = 1, 2, . . . , kmax, is\nintroduced, where k is the a number of k-th iteration and kmax\nis the maximum number of iteration and obviously satisﬁes\nkmax ≤ S2(N, M). Because of ˆω(k) ∈ Ω, it is true that\nfor any iteration number k, there is always only one ω(c)\nsatisfying ˆω(k) = ω(c), ∃c ∈ C . Meanwhile, when the HCA\nis mentioned, variable ˆω(k) is normally simply said to be “a\nsolution” and selected as the k-th iteration value. For the sake\nof distinction and simplicity, it will be named as “nominal\nsolution” in the next. Then, a neighbour set Θ (ˆω(k)) about\nnominal solution ˆω(k) ∈ Ω is deﬁned as\nΘ (ˆω(k)) ≜\nn\nˆω′(k) ∈ Ω\n\f\f\f|ˆω′(k) − ˆω(k)| < L, ˆω′(k) ̸= ˆω(k)\no\n(14)\nwhere L > 0 is the radius of search interval. The neighborhood\nprobability mass function gˆω(k)(ˆω′(k)) is described as\ngˆω(k)(ˆω′(k)) ≜ P (ˆω′(k) ∈ Θ (ˆω(k))) =\n1\nnum (Θ (ˆω(k)))\n(15)\nMeanwhile, the update law of ˆω(k) is given by\nˆω(k + 1) = ˆω′(k), if f(ˆω′(k)) − f(ˆω(k)) < 0\n(16)\nIt is noted that the above algorithm only ensures the mono-\ntonicity of function such as f(ˆω(k+1)) < f (ˆω(k)) but not the\nconvergence of nominal solution ˆω(k) such as |eˆω(k + 1)| <\n|eˆω(k)| where eˆω(k) ≜ ˆω(k+1)−ˆω(k). Thus, the convergence\nspeed of nominal solution cannot be guaranteed.\nTo illustrate the utility of the above proposed algorithm,\nan example simulation about 100 distinct random points\nwill be given. In detail, their horizontal and vertical co-\nordinates referred to be ω(c) and f (ω(c)) respectively\nare randomly generated on interval (0, 20], which are fur-\nther denoted as Ω = {ω(1), ω(2), . . . , ω(100)} and J\n=\n{f (ω(1)) , f (ω(2)) , . . . , f (ω(100))}. First of all, some sim-\nulations are shown in Fig. 1, in which different search radius\nL such as L = 20, 10.71, 5.68 and 2.84 are given. On\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\na1: L = 20\na2: L = 10.71 a3: L = 5.68\na4: L = 2.84\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\nSubtitle\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\nb1: L = 20\nb2: L = 10.71\nb3: L = 5.68\nb4: L = 2.84\nFig. 1. The iteration effects of (14) under different constants L with different\ninitial points.\nthe one hand, the red point is the initial iteration point, and\nthe gray points are “useless” ones which are not used at\nall. Without loss of generality, two situations about differ-\nent initial iteration points such as Point 16 and Point 83\nare considered. Their horizontal and vertical coordinates are\nselected to be (ˆω(1), f (ˆω(1))) = (ω(16), f (ω(16))) and\n(ˆω(1), f (ˆω(1))) = (ω(83), f (ω(83))) respectively. On the\nother hand, the blue points are the failed ones during the iter-\nation, while the green ones are the successful ones satisfying\nthe update law (16). By investigating these simulations, it can\nbe found that the bigger the value L takes, the smaller the\nvalue f (ˆω(k)) arrives. However, the computation complexity\nwill be larger as L takes bigger values. To the contrary, when\nthe radius is selected to be small enough, it can be concluded\nfrom Fig. 1 that the computation complexity will be great\nreduced. However, the probability of the obtained optimal\nsolution being a locally optimal solution will be higher and\nhave a worse quality. Thus, how to select a suitable radius is\nalso one topic studied in this paper.\nThe search radius L of (14) is selected to be\nLk+1 ≜ δ · |ˆω(k + 1) − ˆω(k)| , k = 1, 2, . . .\n(17)\nwhere δ ∈ (0, 1] is a attenuation coefﬁcient. Particularly,\nthe initial search radius L1 is also deﬁned as L1 ≜ δ ·\n|ˆω(1) − ˆω(0)|, where ˆω(0) is given to be\nˆω(0) =\n(\n0,\nif ˆω(1) > ǫ\n2\nǫ,\notherwise\nThen, one can get a simulation Fig. 2 similar to Fig. 1, where\nthe values of δ about the initial radius are selected to be\nδ = 1, 0.7, 0.4 and 0.2 respectively. Accordingly, the values\nof initial radius L1 about initial value ˆω(1) = ω(16) based\non (17) are computed to be L1 = 15.3, 10.71, 6.12 and 3.06\nrespectively. Meanwhile, the values of initial radius L1 about\ninitial value ˆω(1) = ω(82) are computed to be L1 = 14.2,\n9.94, 5.68 and 2.84 respectively. On the one hand, by the\nsimulations of Fig. 2 presented in rows respectively, it can be\nconcluded that the computation complexity is usually reduced\nalong with δ decreasing under the same initial condition. On\nthe other hand, in order to make some comparisons between\nFig. 1 based on (14) and Fig. 2 based on (17), it had better\nto compare them under the same conditions such as the same\nˆω(1) and L1. Thus, only a part but not all the subgraphs are\nnecessary to make comparisons such as the comparisons on\nsubgraphs ai, i = 1, 2, and bi, i = 1, 3, 4 between Fig. 1\nand Fig. 2 respectively. In detail, not only the fewer iteration\ntimes but also the fewer failed points are presented in Fig.\n2. More importantly, the convergence of nominal solution\nˆω(k) is guaranteed in Fig. 2, which is not satisﬁed in Fig. 1.\nHowever, there is also a negative effect that the gaps among\nthe locally optimal solutions obtained in Fig. 2 are bigger,\nsome of which are farther away from the globally optimal\nsolution to subgraphs ai and bi of Fig. 1. Thus, it is necessary\nto further study the effect of variable radius in order to give\nan optimal variation of radius Lk.\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\na1\na2\na3\na4\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\nb1\nb2\nb3\nb4\nFig. 2. The iteration effects of (17) under different constants L with different\ninitial points.\nFor another, based on (17), it can be known that δ plays an\nimportant role in generating variable Lk. In order to realize\nan optimization to radius Lk, expression (17) is revised to be\nLk+1 ≜ δk+1 · |ˆω(k + 1) − ˆω(k)| , k = 1, 2, . . .\n(18)\nwhere δk ∈ (0, 1]. Similar to the deﬁnition L1 in (17),\nit is deﬁned as L1 ≜ δ1 · |ˆω(1) − ˆω(0)|. Then, similar to\nFig. 2, similar simulations under (18) are given in Fig. 3.\nParticularly, the initial values of parameters δk and Lk of\nsubgraphs in Fig. 3 are given such as a1 : δ1 = 1, L1 = 15.3;\na2 : δ1 = 0.7, L1 = 10.71; a3 : δ1 = 0.4, L1 = 6.12;\na4 : δ1 = 0.2, L1 = 3.06; b1 : δ1 = 1, L1 = 14.2;\nb2 : δ1 = 0.7, L1 = 9.94; b3 : δ1 = 0.4, L1 = 5.68 and\nb4 : δ1 = 0.2, L1 = 2.84. By making the comparisons of all\nthe subgraphs between Figs. 2 and 3, it can be found that\nless computation complexity of (18) is presented in Fig. 3,\nwhose iteration time is fewer too. Moreover, the minimum\nvalue of f (ˆω(k)) obtained in Fig. 2 based on (17) is larger\nthan one in Fig. 3 by applying (18). In other words, it is\nnecessary and important to study how to select the detailed\nvalue during every iteration to gain a better performance such\nas smaller value of (12), less computation complexity, but\nbetter monotonicity and convergence. All these problems will\nbe considered and ﬁnally solved in this paper.\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\na1\na2\na3\na4\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\nb1\nb2\nb3\nb4\nFig. 3. The iteration effects of (18) under different constants L with different\ninitial points..\nDEFINITION 1: A control update sequence {tk, k ∈ N} is\nsaid to have the ﬁnite sampling rate property if there exists a\nscalar s such that sk ≥ s > 0, k ∈ N>0.\nAssumption 1: It is assumed that the event-triggered sam-\npling interval sk, k ∈ N>0, has an upper bound such as\nsk ≤ min {¯τ1, ¯τ2, . . . , ¯τM}, where ¯τh = P\nℓ∈Nh ˆτℓ, ∀h ∈ M ,\nand ˆτℓ ≜ E [τℓ(n)], ∀ℓ ∈ Nh, ∀n ∈ N>0.\nDEFINITION 2: System (1) closed by controller (3) is\nglobally asymptotically stable almost surely (GAS a.s.), if the\nfollowing conditions hold simultaneously.\n(C1)\nFor any ǫ ∈ (0, 1), there is a δ = δ(ǫ) > 0 such that\nP\n\u0000supt≥0 ∥x(t)∥ < ǫ\n\u0001\n> 1 − ǫ, when ∥x0∥ < δ.\n(C2)\nFor\nany\nγ\n>\n0\nand\nξ\n>\n0,\nthere\nis\na\npositive\nrandom\nvariable\nϕ(γ, ξ)\nsuch\nthat\nP\n\u0010\nsupt≥ϕ(γ,ξ) ∥x(t)∥ < ξ\n\u0011\n= 1, when ∥x0∥ < γ.\nIII. MAIN RESULTS\nTHEOREM 1: Consider the system composed of (1) and (3),\nwhere the detailed classiﬁcation of controller (3) is assumed\nto be given in advance such that N D is given beforehand,\nso do the α[h]\nℓ\nand ¯Kℓ, ∀h ∈ M , ∀ℓ ∈ N . Then, the related\nclosed-loop system is GAS a.s., if given parameters λi ∈ R,\nµi > 1 and σh ∈ R>0, there exists a matrix Pi > 0 satisfying\n\u0010\nPi ¯A[h]\ni\n\u0011⋆\n+2σh∥PiBi\nN\nX\nℓ=1\nα[h]\nℓ\n¯Kℓ∥I ≤ λiPi, ∀h ∈ M , ∀i ∈ Nh\n(19)\nPi ≤ µiPj, ∀i, j ∈ N\n(20)\nN\nX\ni=1\nπi\n\u0012\nλi + ln µi\nˆτi\n\u0013\n< 0\n(21)\nwhere ¯A[h]\ni\n= Ai + Bi\nPN\nℓ=1 α[h]\nℓ\n¯Kℓ, πi =\n¯πiˆτi\nPN\nj=1 ¯πj ˆτj , and\n¯πi, ∀i ∈ N , is the stationary distribution of the embedded\nchain of semi-Markov process. Meanwhile, the upper sampling\nbound ¯τh is computed by\n¯τh =\n\n\n\n\n\n\n\n\n\n1\n∥ ˆAh∥\nσh\n1 + σh\n,\nif ˆχh ≤ 0\n1\nˆχh\nlog\n \nˆ\nσhχh\n∥ ˆAh∥(1 + σh)\n+ 1\n!\n,\nif ˆχh > 0\n, ∀h ∈ M\n(22)\nwhere\n∥ ˆAh∥\n=\nmaxℓ∈Nh\nn\n∥ ¯A[h]\nℓ ∥\no\nand\nˆχh\n=\nmaxℓ∈Nh {χAℓ}.\nProof The proof is given in Appendix A. □\nNext, Problems 1 and 2 will be considered. Before dis-\ncussing them, a convex optimization problem with some\nconstraints should be proposed ﬁrst. On the one hand, from Ex-\nample 3.11 of [27] on Page 82, it is clear that J[h] \u0000\u0000α[h](c)\n\u0001\u0001\n,\n∀h ∈ M but given c ∈ C , is convex. Moreover, function\nJ(α(c)) = PM\nh=1 J[h] \u0000\u0000α[h](c)\n\u0001\u0001\nis also convex. On the other\nhand, even if the set classiﬁcation of controllers is ﬁxed, the\ngiven conditions of Theorem 1 to be as constraints will be hard\nto be solved in the optimization problems, since parameters\n¯Kℓ and Pi are vector and matrix variables respectively. As\na result, different from Theorem 1, not only ¯Kℓ satisfying\nKh ≜ PN\nℓ=1 α[h]\nℓ\n¯Kℓ but also Pi here is given beforehand.\nWithout loss of generality, they will be calculated by following\nLMIs\n\n\n(Ai + BiYi)⋆ − λiXi\nBiYi\nXi\n∗\n−2Xi + I\n0\n∗\n∗\n−σ−2I\n\n ≤ 0, ∀i ∈ N\n(23)\n\u0014 −µiXj\nXj\n∗\n−Xi\n\u0015\n< 0, ∀i, j ∈ N\n(24)\nand (21), where λi ∈ R, σ ∈ R>0 and µi > 1 are given\nscalars, and Xi ≜ P −1\ni\nand Yi ≜ ¯KiXi are variables to be\ncomputed by solving the above LMIs. Due to page limitation,\nthe detailed calculation process is omitted here.\nREMARK 2: It is worth mentioning that the computation\nway for ¯Kℓ and Pi described in (21), (23) and (24) is not\nunique. In other words, they can be computed in advance by\nother ways, as long as the corresponding conditions described\nby (19)-(21) with given ¯Kℓ and Pi satisfy. Naturally, there\nexist inevitable differences among the different techniques\nproviding different parameters’ values. However, such differ-\nences will not lead to essential distinctions to the optimization\nproblems in this paper and will not discuss in detail.\nSince the parameters of Theorem 1 such as λi ∈ R, µi > 1,\nσh ∈ R>0, ¯Kℓ and Pi are given beforehand, conditions (20)\nand (21) are known and always satisﬁed. In detail, parameters\nλi ∈ R, µi > 1, ¯Kℓ and Pi are deﬁned by (21), (23) and (24),\nwhile σh ∈ R>0 is a new given parameter and only deﬁned in\n(19). Then, the constraints described by conditions (19)-(21)\nare equivalently simpliﬁed to be\ns.t.\nHi (α(c)) ≤ 0, ∀i ∈ Nh(c), c ∈ C\n(25)\nwhere\nHi (α(c)) ≜\nM\nX\nh=1\n(\"\nPi\n \nAi + Bi\nN\nX\nℓ=1\nα[h]\nℓ (c) ¯Kℓ\n!#⋆\n− λiPi + 2σh\n\r\r\r\r\rPiBi\nN\nX\nℓ=1\nα[h]\nℓ (c) ¯Kℓ\n\r\r\r\r\r I\n)\nAccording to Example 2.10 on Page 38 and Example 3.11 on\nPage 82 of [27], it is clear that constraint (25) is a convex\nset. Then, a convex optimization problem described by cost\nfunction (11) with constraint (25) is successfully proposed.\nAccording to Example 3.10 of [27] on Page 82, it can be\nconcluded that function λmax\nHi(α(c)) is also convex. Thus, the\nfeasible domain of (25) is equivalently rewritten to be\ns.t.\nλmax\nHi(α(c)) ≤ 0, ∀i ∈ Nh, c ∈ C\n(26)\nSince (26) being inequalities, a slack variable such as ςi(c) is\nintroduced to change (26) be an equation constraint such as\ns.t.\nλmax\nHi(α(c)) + (ςi(c))2 = 0, ∀i ∈ Nh, c ∈ C\n(27)\nBased on the given results of [28] on Pages 98 and 99, it\ncan be known that such slack variables do not bring any\nnegative effects to (26) but make the equivalent constraint (27)\nsolved easily. Moreover, it can be concluded that constraint\n(27) is convex. Thus, the original convex optimization problem\nis transformed into convex cost function (11) with convex\nconstraint (27). In order to solve this convex optimization\nproblem, an augmented Lagrangian function is constructed as\nL (α(c), γ(c), ς(c), φ) ≜ J ((α(c))) + L1 (α(c), γ(c), ς(c))\n+ L2(α(c), ς(c), φ)\n(28)\nwhere\nL1(α(c), γ(c), ς(c)) ≜\nN\nX\ni=1\nγi(c)Ei(α(c)), ςi(c))\nL2(α(c), ς(c), φ) ≜ φ\n2\nN\nX\ni=1\nE2\ni (α(c), ςi(c))\nEi(α(c), ςi(c)) ≜ λmax\nHi(α(c)) + (ςi(c))2\nγ(c) ≜\n\u0002 γ1(c)\nγ2(c)\n· · ·\nγN(c) \u0003⊤ ∈ RN\n⪰0\nς(c) ≜\n\u0002 ς1(c)\nς2(c)\n· · ·\nςN(c) \u0003⊤ ∈ RN\n⪰0\nand penalty factor φ ∈ R>0. Here, ς(c) is the slack variable\nand γ(c) is the multiplier. Because (11) and (27) are both\nconvex, it is obvious that function (28) is convex too.\nMeanwhile, it is obvious that the above computation process\nof the globally optimal value J∗ should be repeated by\nselecting every c ∈ C . Based on the above illustrations and\nsimulations about mode classiﬁcation, the repetition number of\ncomputation will equal to the Stirling number of the second\nkind. Obviously, the computation complexity will be very large\nespecially N and M increase big. In order to deal with this\nproblem and motivated by the phenomena discovered in Figs.\n1-3, an optimization algorithm based on an improved HCA\nwill be developed, which can generate an iteration sequence of\nsolution {ˆω(k)}kmax\nk=1 and so does the corresponding sequence\nof objective function {f(ˆω(k))}kmax\nk=1 . Moreover, the locally\noptimal solution ˆω∗ and its value f ∗ ≜ f(ˆω∗) can be reached\nsuch as ˆω∗ = ˆω(kmax). Moreover, one can conclude from\nFigs. 1-3 that strategy (18) will be the best if its dynamically\nattenuation coefﬁcient δk is suitably adjusted. In detail, it\nnot only ensures all the advantages of strategy (17) but also\nimproves the iteration speed and the quality of optimal solution\nˆω∗. How to dynamically adjust the attenuation coefﬁcient δk\nto make (18) work optimally is an open problem. Here, we\nwill use the Q-learning algorithm to dynamically adjust δk, so\nas to dynamically change the radius of search interval Lk and\nlead to an improvement in performance. Meanwhile, it is very\nnecessary and important to analyze its mathematical model,\nwhich includes the state, action, and reward function.\nState: The state Sk is a feedback of the agent at the kth step\nand denotes the impact of its taking action on the environment.\nHere, Sk described as the produced solution ˆω(k) ∈ Ω at step\nk such as Sk ≜ ˆω(k). Meanwhile, a termination state Send\nshould be given beforehand but does not belong to the solution\nset Ω. Its aim is to end the current training round when the\nstate Sk arrives at the termination state Send. Finally, the state\nspace S is composed of the solution set Ω of HCA and the\ntermination state Send such as S = Ω S {Send}.\nAction: The action Ak is a description of the agent’s\nbehavior at the kth step. Here, it is the speciﬁc value of δk\nof HCA at the kth iteration step such as Ak ≜ δk, which\ncan change the neighborhood set Θ (ˆω(k)) and affect the\ngeneration of the next solution. As a result, all values of δk\nor Ak constitute the action space A.\nReward: The reward Rk+1 is a feedback of the environ-\nment in which the agent has taken the action Ak in state Sk.\nHere, it is described by\nRk+1 =\n\n\n\nf(ˆω(k)) − f(ˆω′(k))\n|ˆω′(k) − ˆω(k)|\n,\nif num (Θ (ˆω(k))) ̸= 0\n− f(ˆω(k)),\notherwise\n(29)\nwhere function f(·) has been deﬁned in (13). In detail, two\nsituations will be found if condition num (Θ (ˆω(k))) ̸= 0 is\nsatisﬁed. On the one hand, the agent will be penalized and\nreceive a negative reward, if the agent takes an action Ak\nin state Sk such that the solution ˆω′(k) satisﬁes f(ˆω′(k)) ≥\nf(ˆω(k)). On the other hand, the agent will be encouraged\nand receive a positive reward, if the solution ˆω′(k) satisﬁes\nf(ˆω′(k)) < f(ˆω(k)). In other words, if the agent wants to\nobtain a larger positive reward, the solution ˆω′(k) should\nsatisfy not only f(ˆω(k)) is larger than f(ˆω′(k)) as much as\npossible, but also the distance between ˆω′(k) and ˆω(k) is\nas small as possible. To the contrary, num (Θ (ˆω(k))) = 0\nmeans the neighbor set Θ (ˆω(k)) of ˆω(k) is the empty set. It\nalso means that no solution within Θ (ˆω(k)) whose objective\nfunction value is smaller than f(ˆω(k)). In this situation,\nthe agent is still penalized but receives a negative reward\n−f(ˆω(k)). Then, according to [29] on Page 70, it is well\nknown that the Q-learning effect of taking action Ak in state\nSk can be depicted by the Q-value, i.e. it can make an\nevaluation about the variation of δk. Accordingly, a speciﬁc\ndeﬁnition of Q-value similar to (3.11) in [29] is given as\nQ̟ (s, a) ≜ E̟\n ∞\nX\nq=0\nγqRk+q+1\n\f\f\fSk = s, Ak = a\n!\n(30)\nwhere Q̟(s, a) is the Q-value and quantizes the effect of\ntaking action Ak = a followed by the policy ̟ in state Sk =\ns, and γ ∈ [0, 1] is a given discount factor. Particularly, policy\n̟ is a mapping from each state s ∈ S and action a ∈ A to\nthe probability P (a|s) of taking action a when in state s. As\na result, a different taking action Ak = a can be generated\nby a different strategy ̟ in state Sk = s and will lead to\na different Q̟(s, a). In detail, when the Q-value is larger,\nthe taking action will be better. To the contrary, the action\nselection will be worse.\nTHEOREM 2: Consider a convex optimization problem\ndescribed by (11) and (25), where the parameters ¯Kℓ and Pi\nare computed by solving conditions (21), (23) and (24), and\nparameters λi ∈ R, σ ∈ R>0, σh ∈ R>0 and µi > 1 are also\ngiven in advance. The optimization problem (11) constrained\non (25) will have a globally optimal solution, if the following\nconditions are satisﬁed\n∇α(c)L (α(c), γ(c), ς(c), φ) = 0, ∀c ∈ C\n(31)\n∇ς(c)L (α(c), γ(c), ς(c), φ) = 0, ∀c ∈ C\n(32)\n∇γ(c)L (α(c), γ(c), ς(c), φ) = 0, ∀c ∈ C\n(33)\nThen, the globally optimal value of (11) is obtained by\nJ∗ ≜ J (α∗) = min\nc∈C J (α∗ (c)) = min\nc∈C L (α∗(c), γ∗(c), ς∗(c), φ)\n(34)\nMeanwhile, the globally optimal solution is computed by\nα∗ ≜ arg min\nc∈C J (α∗ (c)) = arg min\nc∈C L (α∗(c), γ∗(c), ς∗(c), φ)\n(35)\nParticularly, in order to get an optimal solution to convex\nproblem (11) with (25) without computing c ∈ C one by\none, an improved HCA based on Q-learning (Q-HCA) is\nproposed, whose searching radius iteration rule is given in\n(18). Meanwhile, δk is obtained by the Q-learning with state\nSk = s, action Ak = a and reward Rk+1 presented in (29).\nThen, an iteration rule for estimating Q-value (30) is given as\nQk+1(Sk, Ak) =\n\n\n\n\n\n\n\n\n\n\n\n\n\nQk (Sk, Ak) − β [Qk(Sk, Ak) − (Rk+1\n+ γ\nmax\nˆa∈A(Sk+1) Qk(Sk+1, ˆa)\n\u0013\u0015\n,\nif (Sk, Ak) = (s, a);\nQk (Sk, Ak) , otherwise\n(36)\nwhere β ∈ [0, 1] is the given learning rate, and A(Sk+1) is\nthe set of taking actions in state Sk+1. As a result, an optimal\nattenuation coefﬁcient δ∗\nk is obtained. Moreover, under any\ninitial condition ∀ˆω(1) ∈ Ω with ˆω(0) similarly deﬁned in\n(17), a preferably nominal solution sequence {ˆωpre(k)}kmax\nk=1\nwith ˆωpre(1) = ˆω(1) can be developed by following rules (36)\nand (18), where kmax is a maximum value of iteration. Thus,\na locally optimal solution to convex problem (11) with (25)\nsatisfying a part of C is computed by\nˆωpre(k) → ˆω∗ ≜ ˆωpre(kmax)\n(37)\nMeanwhile, the corresponding value of (11) is also locally\noptimal such as J∗ ≤ f ∗ and described to be\nf ∗ = f (ˆω∗) = f (ˆωpre(kmax)) <\n· · · < f (ˆωpre(1))\n(38)\nMore importantly, both convergence and monotonicity proper-\nties of Q-HCA are ensured. Finally, the upper sampling bound\n¯τh of the related optimal controllers is also computed by (22).\nProof The proof is given in Appendix B. □\nSpecially, when controller (3) has no sampling phenomenon,\nit will reduce to be\nu(t) =\nN\nX\nℓ=1\nα[ν(η(t))]\nℓ\n¯Kℓx(t), ∀t ∈ [Tn, Tn+1) , ∀n ∈ N\n(39)\nwhere α[ν(η(tk))]\nℓ\n∈ R and ¯Kℓ ∈ Rm×n are similar to (3), and\nfunction ν (η(t)) also has the similar deﬁnition but on interval\n∀t ∈ [Tn, Tn+1). Then, one has the following corollaries.\nCOROLLARY 1: Consider the system composed of (1) and\n(39) with mode classiﬁcation N D and α[h]\nℓ\ngiven beforehand.\nThen, the related closed-loop system is GAS a.s., if given\nparameters λi ∈ R and µi > 1, there exist Xi > 0, ¯Yℓ and W\nsatisfying LMIs (21), (24) and\n\u0014\nΓ[h]\ni1\nΓ[h]\ni2\n∗\n(−W)⋆\n\u0015\n< 0, ∀h ∈ M , ∀i ∈ Nh\n(40)\nwhere Γ[h]\ni1 =\n\u0010\nAiW + Bi\nPN\nℓ=1 α[h]\nℓ ¯Yℓ\n\u0011⋆\n− λiXi and Γ[h]\ni2 =\nAiW + Bi\nPN\nℓ=1 α[h]\nℓ ¯Yℓ + Xi − W ⊤. Then, the control gains\ncan be computed by\n¯Kℓ = ¯YℓW −1\n(41)\nProof The proof is established by Theorem 1 and omitted. □\nREMARK 3: When parameter α[h]\nℓ\nof controller (39) is\nselected to be special values such as α[h]\nℓ\n=\nπℓ\nP\nj∈Nh πj , if\nℓ ∈ Nh; α[h]\nℓ\n= 0, otherwise. Accordingly, controller (39) can\nbe simply rewritten as u(t) = P\nℓ∈Nh\nπℓ\nP\nj∈Nh πj ¯Kℓx(t) and\nsimilar to [17] which is related to the stationary distribution\nprobability. In this situation, similar results can be obtained\nand omitted for page limitation. Particularly, if all the values\nof PN\nℓ=1 α[h]\nℓ ¯Yℓ are equal such as ¯Y = PN\nℓ=1 α[h]\nℓ ¯Yℓ, ∀h ∈ N\nand M = N , a mode-independent controller u(t) = Kx(t)\nwith ¯K = ¯Y W −1 will be obtained and similar to [17], [22].\nIn other words, Corollary 1 contains some existing results as\nspecial situations, which is more general and less conservative.\nAccordingly, when the mode classiﬁcation is not given in\nadvance and similar to (10), controller (39) is described as\nu(t) =\nN\nX\nℓ=1\nα[ν(η(t))]\nℓ\n(c) ¯Kℓ(c)x(t), ∀t ∈ [Tn, Tn+1)\n(42)\nAfter giving parameters λi ∈ R and µi > 1, one can compute\n¯Kℓ and Pi by solving conditions (21), (24) and\n(Ai + BiYi)⋆ − λiXi ≤ 0, ∀i ∈ N\n(43)\nThen, similar to constraint (25), the constraint of the above\nconditions is equivalently simpliﬁed to be\ns.t.\n¯Hi (α(c)) ≤ 0, ∀i ∈ Nh(c), c ∈ C\n(44)\nwhere\n¯Hi (α(c)) ≜\nM\nX\nh=1\n(\"\nPi\n \nAi + Bi\nN\nX\nℓ=1\nα[h]\nℓ (c) ¯Kℓ\n!#⋆\n− λiPi\n)\nA similar augmented Lagrangian function is constructed as\n¯\nL (α(c), γ(c), ς(c), φ) ≜ J ((α(c))) + T1 (α(c), γ(c), ς(c))\n+ T2(α(c), ς(c), φ)\n(45)\nwhere\nT1(α(c), γ(c), ς(c)) ≜\nN\nX\ni=1\nγi(c) ¯Ei(α(c)), ςi(c))\nT2(α(c), ς(c), φ) ≜ φ\n2\nN\nX\ni=1\n¯E2\ni (α(c), ςi(c))\n¯Ei(α(c), ςi(c)) ≜ λmax\n¯\nHi(α(c)) + (ςi(c))2\nand parameers γ(c) and ς(c) are deﬁned in (28). Then, one\ncan obtain the following corollary.\nCOROLLARY 2: Consider a convex optimization problem\ndescribed by (11) and (44), where the parameters ¯Kℓ and\nPi are computed by solving conditions (21), (24) and (43)\nunder giving parameters λi ∈ R and µi > 1. The optimization\nproblem (11) constrained on (44) will have a globally optimal\nsolution, if the following conditions are satisﬁed\n∇α(c) ¯\nL (α(c), γ(c), ς(c), φ) = 0, ∀c ∈ C\n(46)\n∇ς(c) ¯\nL (α(c), γ(c), ς(c), φ) = 0, ∀c ∈ C\n(47)\n∇γ(c) ¯\nL (α(c), γ(c), ς(c), φ) = 0, ∀c ∈ C\n(48)\nThen, the globally optimal value of (11) is obtained by\nJ∗ = min\nc∈C\n¯\nL (α∗(c), γ∗(c), ς∗(c), φ)\n(49)\nMeanwhile, the globally optimal solution is computed by\nα∗ = arg min\nc∈C\n¯\nL (α∗(c), γ∗(c), ς∗(c), φ)\n(50)\nMoreover, based on the developed Q-HCA algorithm, one also\ngets a locally optimal solution and its locally optimal value\nsuch as (37) and (38) without computing c ∈ C one by one.\nProof Its proof is similar to Theorem 2 and omitted. □\nREMARK 4: It can be seen that some parameters such\nas ¯Kℓ and Pi in main results need to be given in advance.\nParticularly, in order to give them easily and directly, they\nare solved by some LMIs such as (23) and (24). It is worth\nnoted that these convenient techniques will lead to some\nconservatism in terms of some of constraints such as (25)\nunsatisﬁed. In this situation, some possible ways may be used\nto deal with them, and only two possible ways are mentioned\nhere. On the one hand, one can select different values of\nthe scalars given in the presented LMIs time and time again,\nuntil the dissatisﬁed constraints hold. On the other hand, other\ndifferent conditions providing ¯Kℓ and Pi in advance can be\ndeveloped so as to make the dissatisﬁed constraints satisfying.\nIV. NUMERICAL EXAMPLE\nExample 1: Considering a system of form (1) with N =\n{1, 2, 3, 4, 5} whose matrices are described as\nA1 =\n\u0014 −2\n2\n0.1\n0.14\n\u0015\n, B1 =\n\u0014 0.32\n−1.7\n\u0015\n; A2 =\n\u0014 −3.6\n0.2\n1\n0.2\n\u0015\nB2 =\n\u0014 0.32\n−2\n\u0015\n; A3 =\n\u0014 −0.7\n2\n0\n0.32\n\u0015\n, B3 =\n\u0014\n0.25\n−0.45\n\u0015\n;\nA4 =\n\u0014\n−3.3\n0.1\n0.8\n0.03\n\u0015\n, B4 =\n\u0014\n0.22\n−0.61\n\u0015\n;\nA5 =\n\u0014 −2.5\n0\n0.1\n0.95\n\u0015\n, B5 =\n\u0014\n0.12\n−0.53\n\u0015\nThe transition probabilities of the embodied chain is given as\nP =\n\n\n0\n0.1\n0.25\n0.25\n0.4\n0.1\n0\n0.2\n0.4\n0.3\n0.2\n0.35\n0\n0.3\n0.15\n0.15\n0.3\n0.2\n0\n0.35\n0.3\n0.15\n0.25\n0.3\n0\n\n\nIt has a unique stationary distribution computed as ¯π =\n[0.21 0.19 0.2 0.15 0.25]. In addition, the expectations of\nsojourn time for modes are given to be ˆτ1 = 0.03, ˆτ2 = 0.05,\nˆτ3 = 0.04, ˆτ4 = 0.09 and ˆτ5 = 0.07. Firstly, based on\nconditions (23) and (24), after letting λ1 = −0.8, λ2 =\n−0.9, λ3 = −0.5, λ4 = −0.6, λ5 = 0.4, µ1 = 1.005,\nµ2 = 1.001, µ3 = 1.009, µ4 = 1.002, µ5 = 1.001 and\nσ = 0.069, one can obtain that PN\ni=1 πi\n\u0010\nλi + ln µi\nˆτi\n\u0011\n=\n−0.2549 < 0, and the control gains are computed such\nas ¯K1 =\n\u0002 0.1921\n0.1857 \u0003\n, ¯K2 =\n\u0002 0.2087\n0.9061 \u0003\n,\n¯K3 =\n\u0002 1.0049\n4.9363 \u0003\n, ¯K4 =\n\u0002 0.6863\n3.1342 \u0003\nand\n¯K5 =\n\u0002\n0.2835\n3.7523\n\u0003\n, while matrix Pi is computed as\nP1 =\n\u0014\n0.0047\n0.0034\n0.0034\n0.0236\n\u0015\n, P2 =\n\u0014\n0.0047\n0.0033\n0.0033\n0.0235\n\u0015\n,\nP3 =\n\u0014\n0.0047\n0.0034\n0.0034\n0.0236\n\u0015\nP4 =\n\u0014\n0.0047\n0.0033\n0.0033\n0.0235\n\u0015\n,\nP5 =\n\u0014\n0.0047\n0.0033\n0.0033\n0.0235\n\u0015\nAs we know, based on the commonly mode-dependent\nmethods, see, e.g., [1]–[4], [6], there will be 5 controllers since\nthe mode quantity of this example is 5. More importantly, an\nideal assumption that the switching signals between controller\nand other system matrices should be synchronous is also\nneeded. To the contrary, the method in this paper can provide\nfewer effective controllers whose modes are not necessary\nsynchronous to system matrices’, which has larger application\nscope. Without loss of generality, set N\nis separated into\n3 classes such as M = {1, 2, 3}. Consequently, it can be\ncomputed that S2(5, 3) = 25 with N = 5 and M = 3, and\nthe classiﬁcation parameter c is the same to Table I. Then,\nafter applying the above designed controllers in addition to\nsome related parameters, the optimal value J (α∗ (c)) with\nits optimal solution α∗ (c) of each classiﬁcation is given\nin Table II, where ¯τ = minh∈M {¯τh} is denoted as the\nultimate upper sampling bound. It can be seen from this table\nthat there is no optimal solution to some classiﬁcations. The\nreason is that the given parameters\n¯Kℓ and Pi computed\nby (23) and (24) dissatisfy constraint (25), whose possibly\nsolvable algorithms are presented in Remark 4. Moreover,\nsome comparisons between this paper and some similar ex-\nisting references can be done in the next. In references [18]–\n[20], a method based on an auxiliary system approach was\nfound and can be used to discuss stochastic systems having\na sampling phenomenon in either state or switching or both\nof them. Since their methods about sampling are the same,\nwithout loss of generality, only comparisons between this\npaper and [18] are enough. Under the above given parameters\nand by using the method in [18], the maximum sampling\nupper bound can be computed as ¯τ = 0.000047. It is far\nless than ¯τ = 0.0174 which results from the globally optimal\nsolution such as α∗\n1 = 0.4581, α∗\n2 = 0.4668, α∗\n3 = −0.0713,\nα∗\n4 = 1.6570, α∗\n5 = −0.6935 and J∗ = 3.3820 and also\ncorresponds to the situation of Table II with c = 1. It can\nbe further seen from Table II, all the upper sampling bounds\nare larger than 0.000047, so long as there exists a suitable\nsolution. Based on these comparisons, it can be concluded that\nthe developed mode classiﬁcation and optimization method is\nsuperior to the above auxiliary system approach for providing\na larger sampling interval and improving the efﬁciency of\ncommunication network. Moreover, under the initial condition\nx0 =\n\u0002\n2\n−2\n\u0003⊤ and selecting any effective classiﬁcation\nsuch as N1 = {1}, N2 = {2, 3}, N3 = {4, 5}, corresponding\nto c = 11 in Table II, one can compute its controller such\nas KN1 =\n\u0002\n0.0880\n0.5432\n\u0003\n, KN2 =\n\u0002\n0.8654\n2.2401\n\u0003\nand KN3 =\n\u0002 −0.2397\n1.5940 \u0003\n. Then, the state curves\nof the closed-loop system are shown in Fig. 4 (a), and the\nschematic diagram of mode signals is displayed in Fig. 4\n(b). Although both state and mode are sampled, the presented\ncontroller is still useful in stabilizing a stochastic system.\n0\n0.2\n0.4\n0.6\n0.8\n1\n(b) Time(s)\n2\n4\n6\nMode\n(t)\n(tk)\n0\n5\n10\n15\n(a) Time(s)\n-2\n-1\n0\n1\n2\nx(t)\nx1(t)\nx2(t)\nFig. 4.\n(a) The state responds of the closed-loop system by controller (3).\n(b) The simulations of signals η(t) and η(tk).\nFurthermore, based on the developed Q-HCA in Theorem\n2, a suboptimal solution or even an optimal solution can be\nobtained. In detailed, the iteration processes under different\ninitial points are shown in Fig. 5 with ǫ = 10, where\nTABLE II\nTHE OPTIMIZATION RESULTS OF THEOREM 2 FOR DIFFERENT MODE\nCLASSIFICATIONS.\nc\nα∗\n1(c)\nα∗\n2(c)\nα∗\n3(c)\nα∗\n4(c)\nα∗\n5(c)\nJ(α∗(c))\n¯τ\n1\n0.46\n0.47\n-0.07\n1.66\n-0.69\n3.3820\n0.0174\n2\n–\n–\n–\n–\n–\n–\n–\n3\n0.46\n2.70\n0.05\n0.24\n-0.12\n3.5891\n0.0146\n4\n0.46\n1.50\n-0.18\n0.57\n0.45\n4.5422\n0.0142\n5\n–\n–\n–\n–\n–\n–\n–\n6\n0\n11.83\n-1.70\n0.24\n0.45\n4.8947\n0.0136\n7\n0.68\n0.47\n-0.09\n1.23\n0.45\n6.4733\n0.0123\n8\n–\n–\n–\n–\n–\n–\n–\n9\n–\n–\n–\n–\n–\n–\n–\n10\n0\n11.83\n-1.70\n0.24\n0.45\n4.8947\n0.0137\n11\n0.46\n16.92\n-2.65\n-0.80\n1.09\n4.5637\n0.0146\n12\n0.46\n-4.97\n1.08\n1.68\n-0.82\n3.7408\n0.0172\n13\n0.46\n-0.51\n0.10\n0.75\n0.57\n5.1091\n0.0153\n14\n-1.88\n0.47\n0.99\n-0.80\n1.09\n9.2897\n0.0123\n15\n0\n0.47\n0.67\n0.24\n-0.18\n3.9675\n0.0174\n16\n0\n0.47\n-0.08\n1.01\n0.45\n4.9755\n0.0161\n17\n–\n–\n–\n–\n–\n–\n–\n18\n–\n–\n–\n–\n–\n–\n–\n19\n–\n–\n–\n–\n–\n–\n–\n20\n0.40\n0.08\n0.67\n0.24\n-0.18\n4.0838\n0.0173\n21\n-1.88\n-4.01\n0.99\n0.24\n1.39\n9.4961\n0.0123\n22\n0\n16.92\n-2.65\n0.24\n0.45\n4.8516\n0.0146\n23\n0\n0.59\n-0.10\n1.06\n0.45\n5.0880\n0.0174\n24\n-1.88\n-1.43\n0.99\n0.65\n0.45\n9.6922\n0.0091\n25\n0\n16.92\n-2.65\n0.26\n0.45\n4.8516\n0.0146\nthe points in the horizontal axis denote as infeasible points.\nParticularly, the infeasible points in blue means that they have\nbeen selected to participate in calculation, while the black ones\nare only infeasible points but without being selected during the\niteration. Moreover, from this simulation, it can be seen that\nwhen the initial points are Points 24 and 7 respectively, the\nﬁnal point is Point 12 corresponding to c = 12 in Table II,\nwhose cost function is computed as f ∗ = 3.7408. Similarly,\none can further know that when the initial point is Point 14, the\nﬁnal point is Point 3 with f ∗ = 3.5891. And when the initial\npoint is Point 7, the ﬁnal point is Point 1. Especially, in this\nsituation, its cost function is computed as f ∗ = 3.3820 and\nequals to the globally optimal value J∗ = 3.3820. Obviously,\nby comparing Table II and Fig. 5, one can obtain that the\ncomputation complexity and time of Fig. 5 by the Q-HCA\nmethod is both largely reduced and without computing mode\nclassiﬁcation one by one. Moreover, it also can be seen from\nFig. 5 that the convergence of the Q-HCA method is also\nensured, which is asymptotically convergent. In a word, all\nthe statements about the effectiveness and superiority of the\ndeveloped method in this paper have been shown by the\nsimulations and comparisons.\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\nInitial : 24\nInitial : 14\nInitial : 21\nInitial : 7\nFig. 5. The effects of Q-HCA in Theorem 2 under different initial points.\nNext, some simulations and comparison about Corollary 2\nwill be done, where set N is also separated into 3 classes\nsuch as M = {1, 2, 3}. First, letting λ1 = −0.8, λ2 = −0.9,\nλ3 = −0.5, λ4 = −0.6, λ5 = 0.4, µ1 = 1.005, µ2 = 1.001,\nµ3 = 1.009, µ4 = 1.002 and µ5 = 1.001, it can be known\nfrom Corollary 2 that PN\ni=1 πi\n\u0010\nλi + ln µi\nˆτi\n\u0011\n= −0.2549 < 0.\nMeanwhile, the control gains computed by conditions (24)\nand (43) are listed as follows: ¯K1 =\n\u0002\n1.9651\n1.6991\n\u0003\n,\n¯K2\n=\n\u0002 1.8758\n1.1729 \u0003\n,\n¯K3\n=\n\u0002 4.6357\n4.8861 \u0003\n,\n¯K4 =\n\u0002 6.0120\n4.4209 \u0003\nand ¯K5 =\n\u0002 4.7489\n5.3510 \u0003\n.\nNow, more comparisons will be done. In reference [17], a\nquantity-limited controller was proposed based on mode sep-\naration. However, the optimization problem about such mode\nseparation was not considered in the reference. Moreover, it\nhas been shown there that the method in [17] is less conser-\nvative than mode-independent ones [7]–[10]. In this situation,\nonly comparisons between Corollary 2 and [17] will be done.\nBased on [17], it is assumed that modes {1} and {2} are\nknown, and the rest modes are unknown. In this situation, the\nabove assumption is the same as the following mode classiﬁca-\ntion such as N1 = {1}, N2 = {2} and N3 = {3, 4, 5}. Then,\nby using the method in [17], one can obtain the control gains\nas K1 =\n\u0002 1.7897\n2.0866 \u0003\n, K2 =\n\u0002 2.1638\n4.7343 \u0003\nand K =\n\u0002\n−0.1417\n−9.2833\n\u0003\n, and the same cost function\n(11) about the above designed controllers of [17] is equal to\nJ = ∥K1∥ + ∥K2∥ + ∥K∥ = 17.2387. Investigating all the\noptimal function value J∗ computed similar to Table II and\nomitted due to page limiation, it can be seen that the global\ncost function value after optimization is much smaller and less\nconservative. In order to further illustrate the superiority, more\ncomparisons are done such that a positive perturbation ∆ is\nonly added in block (1,1) of matrix A1 such as −2 + ∆, and\nthe others remain unchanged. Then, the respective maximum\nallowable bound about Corollary 2 and [17] under the same λ1\nis given in Table III, which is denoted as ∆max. It is obvious\nthat Corollary 2 by optimizing the mode classiﬁcations is less\nconservative than [17]. Similar to Fig. 5, some simulations\nabout Q-HCA of Corollary 2 under different initial points are\ngiven in Fig. 6 with ǫ = 10. It can be found that when the\ninitial points are Points 21, 22 and 23 respectively, the ﬁnal\npoint is Point 2 corresponding to c = 2 similar to Table\nII, whose cost function is computed as f ∗ = 6.7184 and\nequals to the globally optimal value J∗ = 6.7184. Also, when\nthe initial point is Point 10, the ﬁnal point is Point 1 with\nf ∗ = 7.1112 which is a locally optimal value. As a result,\nsimilar conclusions about the given Q-HCA in this paper can\nbe obtained and omitted here.\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n6.5\n7\n7.5\n8\n8.5\n9\n9.5\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n6.5\n7\n7.5\n8\n8.5\n9\n9.5\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n6.5\n7\n7.5\n8\n8.5\n9\n9.5\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n6.5\n7\n7.5\n8\n8.5\n9\n9.5\nSelection Process\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\nInitial : 21\nInitial : 22\nInitial : 10\nInitial : 23\nFig. 6. The effects of Q-HCA in Corollary 2 under different initial points.\nFinally, more comparisons will be done to further demon-\nTABLE III\nTHE MAXIMUM ALLOWABLE BOUND ∆max UNDER λ1 TAKING DIFFERENT\nVALUES.\nλ1\n-0.1\n-0.2\n-0.3\n-0.4\n-0.5\nCorollary 2\n5.595\n5.562\n5.529\n5.496\n5.463\n[17]\n4.341\n4.302\n4.263\n4.224\n4.185\n-0.6\n-0.7\n-0.8\n-0.9\n-1\n5.430\n5.397\n5.364\n5.331\n5.298\n4.146\n4.108\n4.069\n4.030\n3.991\nstrate the advantages of the method proposed here. As we\nknow, a sampled system can be discussed by transforming\nthe sampled term into a time-varying delay term. Similarly,\nwhen both state and switching are sampled, a input delay\napproach was used in [33]. Unfortunately, its method has some\nlimits such that it cannot be used to stabilize an MJS having\nnon-negative eigenvalues. Meanwhile, an augmented system\napproach was presented in [21] and can be used to deal with\nMJSs with sampled state and switching simultaneously. Due\nto it considering about MJSs instead of semi-Markovian jump\nsystems (SMJSs) and in order to make some comparisons, it\nis assumed that the related system in this example is reduced\nto be an MJS. In detail, all the system parameters are the same\nas the above SMJS, except the transition rate matrix of MJSs\nis given as\nΛ =\n\n\n−3\n1\n0.5\n0.2\n1.3\n1\n−3\n0.5\n1.3\n0.2\n1\n0.5\n−2\n0.25\n0.25\n1.5\n0.2\n0.9\n−4\n1.4\n0.4\n0.3\n0.2\n0.1\n−1\n\n\nThen, based on [21] with given control gains such as\nK1\n=\n\u0002 0.1710\n1.1218 \u0003\n, K2\n=\n\u0002 0.1853\n0.8848 \u0003\n,\nK3 =\n\u0002 0.9524\n4.8487 \u0003\n, K4 =\n\u0002 0.6209\n2.8994 \u0003\nand\nK5 =\n\u0002 0.2302\n3.7272 \u0003\n, one can get the upper sampling\nbound is ¯τ = 0.0028. On the other hand, it can be known\nthat similar results about MJSs can be easily obtained from\nthe results about SMJSs. Thus, under the same control gains\ngiven above, and selecting α1 = 0.335, α2 = 29.5068,\nα3 = −4.8934, α4 = −0.6157 and α5 = 0.9425 with a\nspeciﬁc mode classiﬁcation such as N1 = {1}, N2 = {2, 3}\nand N3\n=\n{4, 5}, the upper sampling bound based on\nTheorem 1 without any optimization is equal to ¯τ = 0.01324.\nIt showns that the method in this paper can provide a larger\nsampling bound and is less conservative than [21].\nV. CONCLUSIONS\nIn this study, the sampled stabilization for stochastic jump\nsystems has been investigated by a mode classiﬁcation opti-\nmization method. A new mode-classiﬁcation-based controller\nhas been proposed to handle the general sampling situation\nthat both controller’s state and switching are sampled. So as\nto ﬁnd the best classiﬁcation for stabilization, an optimization\nproblem has been proposed to provide a globally optimal\nsolution among such classiﬁcations. An Q-HCA algorithm has\nbeen established to provide an optimal attenuation coefﬁcient,\nwhose monotonicity and convergency have been both satisﬁed.\nFinally, the utility and advantage of this paper have been\nobviously illustrated and shown by a numerical example.\nREFERENCES\n[1] H. Zhang, J. Wang, Z. Wang and H. Liang, “Mode-dependent stochastic\nsynchronization for Markovian coupled neural networks with time-\nvarying mode-delays,” IEEE Transactions on Neural Networks and\nLearning Systems, vol. 26, no. 11, pp. 2621-2634, 2015.\n[2] G. Zhuang, Q. Ma, B. Zhang, S. Xu and J. Xia, “Admissibility and\nstabilization of stochastic singular Markovian jump systems with time\ndelays,” Systems and Control Letters, vol. 114, pp.1-10, 2018.\n[3] B. Cai, L. Zhang and Y. Shi, “Observed-mode-dependent state estimation\nof hidden semi-Markov jump linear systems,” IEEE Transactions on\nAutomatic Control, vol. 65, no. 1, pp. 442-449, 2019.\n[4] K. Ding and Q. Zhu, “Extended dissipative anti-disturbance control for\ndelayed switched singular semi-Markovian jump systems with multi-\ndisturbance via disturbance observer,” Automatica, vol. 128, pp. 109556,\n2021.\n[5] W. Qi, Y. Zhou, L. Zhang, J. Cao and J. Cheng, “Non-fragile H∞ SMC\nfor Markovian jump systems in a ﬁnite-time,” Journal of the Franklin\nInstitute, vol. 358, no. 9, pp. 4721-4740, 2021.\n[6] R. Zhang, H. Wang, J. H. Park, K. Shi and P. He, “Mode-\ndependent adaptive event-triggered control for stabilization of Marko-\nvian memristor-based reaction-diffusion neural networks,” IEEE Trans-\nactions on Neural Networks and Learning Systems, vol. 34, no. 8, pp.\n3939-3951, 2023.\n[7] C. E. de. Souza, A. Troﬁno and K. A. Barbosa, “Mode-independent\nH∞ ﬁlters for Markovian jump linear systems,” IEEE Transactions on\nAutomatic Control, vol. 51, no. 11, pp. 1837-1841, 2006.\n[8] H. N. Wu, and K. Y. Cai, “Mode-independent robust stabilization for\nuncertain Markovian jump nonlinear systems via fuzzy control,” IEEE\nTransactions on Systems Man and Cybernetics Part B-Cybernetics, vol.\n36, no. 3, pp. 509-519, 2005.\n[9] P. H. Liu, D. W. C. Ho and F. C. Sun, “Design of H∞ ﬁlter for\nMarkov jumping linear systems with non-accessible mode information,”\nAutomatica, vol. 44, no, 10, pp. 2655-2660, 2008.\n[10] X. Li, W. Zhang and D. Lu, “Robust asynchronous output-feedback\ncontroller design for Markovian jump systems with output quantization,”\nIEEE Transactions on Systems, Man, and Cybernetics: Systems, vol. 52,\nno. 2, pp. 1214-1223, 2022.\n[11] G. L. Wang, B. Y. Li, Q. L. Zhang and C. Y. Yang, “A partially delay-\ndependent and disordered controller design for discrete-time delayed\nsystems,” Interational Journal of Robust Nonlinear Control, vol. 27, no.\n16, pp. 2646-2668, 2017.\n[12] O. L. V. Costa, M. D. Fragoso and M. G. Todorov, “A detector-based\napproach for the H2 control of Markov jump linear systems with partial\ninformation,” IEEE Transactions on Automatic Control, vol. 60, no. 5,\npp. 1219-1234, 2014.\n[13] G. L. Wang, Q. L. Zhang and C. Y. Yang, “Fault-tolerant control of\nMarkovian jump systems via a partially mode-available but unmatched\ncontroller,” Journal of the Franklin Institute, vol. 354, no. 17, pp. 7717-\n7731, 2017.\n[14] G. L. Wang and L. Xu, “Almost sure stability and stabilization of\nMarkovian jump systems with stochastic switching,” IEEE Transactions\non Automatic Control, vol. 67, no. 3, pp. 1529-1536, 2022.\n[15] G. L. Wang and Y. Y. Sun, “Almost sure stabilization of continuous-\ntime jump linear systems via a stochastic scheduled controller,” IEEE\nTransactions on Cybernetics, vol. 52, no. 5, pp. 2712-2724, 2022.\n[16] G. L. Wang, Y. S. Ren and Z. Q. Li, “Almost Sure Stabilization of\nContinuous-Time Semi-Markov Jump Systems via an Earliest Deadline\nFirst Scheduling Controller,” IEEE Transactions on Systems, Man, and\nCybernetics: Systems, vol. 54, no. 1, pp. 656-667, 2024.\n[17] G. L. Wang, “Stabilization of semi-Markovian jump systems via a\nquantity limited controller,” Nonlinear Analysis: Hybrid Systems, vol.\n42, Artical: 101085, 2021.\n[18] X. Mao, “Stabilization of continuous-time hybrid stochastic differential\nequations by discrete-time feedback control,” Automatica, vol. 49, no.\n12, pp. 3677-3681, 2013.\n[19] X. Mao, “Almost sure exponential stabilization by discrete-time stochas-\ntic feedback control,” IEEE Transactions on Automatic Control, vol. 61,\npp. 1619-1624, 2015.\n[20] G. F. Song, Z. Y. Lu, B. C. Zheng and et al, “Almost sure stabilization of\nhybrid systems by feedback control based on discrete-time observations\nof mode and state,” Science China Information Sciences, vol. 61, pp.\n70213, 2018.\n[21] G. L. Wang, Y. S. Ren and C. Huang, “Stabilizing control of Markovian\njump systems with sampled switching and state signals and applica-\ntions,” Interational Journal of Robust Nonlinear Control, vol. 33, no.\n10, pp. 5198-5228, 2023.\n[22] G. L. Wang, “Mode-independent control of singular Markovian jump\nsystems: A stochastic optimization viewpoint,” Applied Mathematics and\nComputation, vol. 286, pp. 155-170, 2016.\n[23] B. C. Rennie and A. J. Dobson, “On stirling numbers of the second\nkind,” Journal of Combinatorial Theory, vol. 7, no. 2, pp. 116-121,\n1969.\n[24] K. N. Boyadzhiev, “Close encounters with the Stirling numbers of the\nsecond kind,” Mathematics Magazine, vol. 85, no. 4, pp. 252-266, 2012.\n[25] S. H. Jacobson and E. Y¨ucesan, “Analyzing the performance of gen-\neralized hill climbing algorithms,” Journal of Heuristics, vol. 10, pp.\n387-405, 2004.\n[26] X. T. Wu, Y. Tang, J. D. Cao and X. R. Mao, “Stability analysis for\ncontinuous-time switched systems with stochastic switching signals,”\nIEEE Transactions on Automatic Control, vol. 63, no. 9, pp. 3083-3090,\n2017.\n[27] S. P. Boyd and L. Vandenberghe, Convex optimization. Cambridge\nuniversity press, 2004.\n[28] F. S. Hillier, Introduction to operations research. McGrawHill, 2001.\n[29] R. S. Sutton and A. G. Barto, Reinforcement learning: An introduction.\nMIT press, 2018.\n[30] Y. J. Wang and Z. A. Liang, Optimization of the basic theory and\nmethods. Fudan University Press, 2011.\n[31] D. P. Bertsekas, Constrained optimization and Lagrange multiplier\nmethods. Academic press, 2014.\n[32] C. J. C. H. Watkins and P. Dayan, “Q-learning,” Machine learning, vol.\n8, pp. 279-292, 1992.\n[33] G. L. Wang and Y. S. Ren, “Stability analysis of delayed Markovian\njump systems with delay switching and state signals and applications,”\nInterational Journal of Robust Nonlinear Control, vol. 32, no. 9, pp.\n5141-5163, 2022.\nVI. APPENDIX\nA.\nProof of Theorem 1\nFirst of all, Nη(t0, t), ∀t ≥ 0, is deﬁned to be the switching\nquantity of η(t) on interval [t0, t]. For any Nη(t0, t) =\nn, ∀t\n≥\n0 and n\n∈\nN, one concludes that [t0, t]\n=\nSn−1\ni=0 [Ti, Ti+1) S [Tn, t] and t ∈ [Tn, Tn+1). Consequently,\none gets [t0, t] = Sk−1\nj=0 [tj, tj+1) S [tk, t] and t ∈ [tk, tk+1),\nk\n∈\nN, from event-triggered mechanism (4) under As-\nsumption 1. Moreover, one can further obtain k ≤ n such\nthat every subinterval of Sn−1\ni=0 [Ti, Ti+1) S [Tn, t] such as\n[Ti, Ti+1) or [Tn, t] certainly belongs to one subinterval of\nSk−1\nj=0 [tj, tj+1) S [tk, t] such as [tj, tj+1) or [tk, t] uniquely.\nAlternatively, {tk}k∈N established based on principle (4) is\na subsequence of {Tn}n∈N. As a result, and without loss of\ngenerality, it is assumed that\n[tj, tj+1) =\nNη(tj,tj+1)−1\n[\nq=0\n\u0002\nTNη(t0,tj)+q, TNη(t0,tj)+q+1\n\u0001\n(51)\nwhere tj = TNη(t0,tj) and tj+1 = TNη(t0,tj+1). Particularly,\n[tk, t] is denoted as\n[tk, t] =\nNη(tk,t)−1\n[\nq=0\n\u0002\nTNη(t0,tk)+q, TNη(t0,tk)+q+1\n\u0001\n[ \u0002\nTNη(t0,t), t\n\u0003\n(52)\nIn addition, for ∀t ∈ [tk, tk+1) , ∀k ∈ N, one can conclude that\nη(t) ∈ Nη(tk), if η(tk) ∈ M . Then, after applying (3), the\nsystem (1) closed by an event-triggered controller described\nby (3)-(8) is equal to\n\n\n\n\n\n˙x(t) = Aη(t)x(t) + Bη(t)\nN\nX\nℓ=1\nα[ν(η(tk))]\nℓ\n¯Kℓx(tk)\nx(tk) = x(t−\nk )\n(53)\nAccordingly, choose the Lyapunov function as V (x(t), η(t)) =\nxT (t)Pη(t)x(t) and based on (51)-(53) and condition (20), for\nany t ∈\n\u0002\nTNη(t0,t), TNη(t0,t)+1\n\u0001\n, one gets that\nV\n\u0000x(TNη(t0,tk)+1), ηNη(t0,tk)\n\u0001\n× e\n−ληNη(t0,tk)\n\u0010\nTNη(t0,tk)+1−TNη(t0,tk)\n\u0011\n= V\n\u0000x\n\u0000TNη(t0,tk)\n\u0001\n, ηNη(t0,tk)\n\u0001\n+\nZ TNη(t0,tk)+1\nTNη(t0,tk)\nd\n\u0000V\n\u0000x(s), ηNη(t0,tk)\n\u0001\n×e\n−ληNη(t0,tk)\n\u0010\ns−TNη(t0,tk)\n\u0011\u0013\n≤ V\n\u0000x\n\u0000TNη(t0,tk)\n\u0001\n, ηNη(t0,tk)\n\u0001\n≤ µηNη(t0,tk)−1V\n\u0000x\n\u0000TNη(t0,tk)\n\u0001\n, ηNη(t0,tk)−1\n\u0001\n(54)\n...\nV\n\u0000x(TNη(t0,t)), ηNη(t0,t)−1\n\u0001\n× e\n−ληNη(t0,t)−1(TNη(t0,t)−TNη(t0,t)−1)\n= V\n\u0000x\n\u0000TNη(t0,t)−1\n\u0001\n, ηNη(t0,t)−1\n\u0001\n+\nZ TNη(t0,t)\nTNη(t0,t)−1\nd\n\u0000V\n\u0000x(s), ηNη(t0,t)−1\n\u0001\n×e\n−ληNη(t0,t)−1(s−TNη(t0,t)−1)\n\u0013\n≤ V\n\u0000x\n\u0000TNη(t0,t)−1\n\u0001\n, ηNη(t0,t)−1\n\u0001\n≤ µηNη(t0,t)−2V\n\u0000x\n\u0000TNη(t0,t)−1\n\u0001\n, ηNη(t0,t)−2\n\u0001\n(55)\nV\n\u0000x(t), ηNη(t0,t)\n\u0001\ne\n−ληNη(t0,t)(t−TNη(t0,t))\n= V\n\u0000x\n\u0000TNη(t0,t)\n\u0001\n, ηNη(t0,t)\n\u0001\n+\nZ t\nTNη(t0,t)\nd\n\u0012\nV\n\u0000x(s), ηNη(t0,t)\n\u0001\ne\n−ληNη(t0,t)(s−TNη(t0,t))\n\u0013\n≤ V\n\u0000x\n\u0000TNη(t0,t)\n\u0001\n, ηNη(t0,t)\n\u0001\n≤ µηNη(t0,t)−1V\n\u0000x\n\u0000TNη(t0,t)\n\u0001\n, ηNη(t0,t)−1\n\u0001\n(56)\nParticularly, the above inequalities holding also need the\nfollowing condition\n\"\nx⊤(t)Pη(t)\n \nAη(t)x(t) + Bη(t)\nN\nX\nℓ=1\nα[h]\nℓ\n¯Kℓx(tk)\n!#⋆\n≤ λη(t)x⊤(t)Pη(t)x(t)\n(57)\nwhere ∀t ∈ [tk, tk+1), η(tk) = h ∈ M and η(t) ∈ Nh. On\nthe other hand, let δ(t) = x(t) − x(tk), ∀t ∈ [tk, tk+1), it can\nbe concluded from (53) that\n( ˙δ(t) = Aη(t)δ(t) + ¯A[h]\nη(t)x(tk)\nδ(tk) = 0\n, ∀t ∈ [tk, tk+1) , ∀k ∈ N\n(58)\nIts solution is computed as\nδ(t) = e\nR t\ntk Aη(s)dsδ(tk) +\nZ t\ntk\ne\nR t\nθ Aη(s)ds ¯A[h]\nη(θ)x(tk)dθ\n(59)\nwhich implies\n∥δ(t)∥ ≤\nZ t\ntk\n∥e\nR t\nθ Aη(s)ds∥∥ ¯A[h]\nη(θ)∥∥x(tk)∥dθ\n≤ max\nℓ∈Nh\nn\n∥ ¯A[h]\nℓ ∥\no\n∥x(tk)∥\nZ t\ntk\nemaxℓ∈Nh{χAℓ}(t−θ)dθ\n= ∥ ˆAh∥\nZ t\ntk\neˆχh(t−θ)dθ∥x(tk)∥\n(60)\nIt can be known that function ζh(t − tk) ≜\nR t\ntk eˆχh(t−θ)dθ,\n∀t ∈ [tk, tk+1) , ∀k ∈ N, is monotonically increasing with t\nand ζ(0) = 0. Based on Assumption 1, one has\nζh(t − tk) ≤ ζh(sk+1) ≤ ζh(¯τh)\n(61)\nThen, one obtains that\n∥δ(t)∥ ≤ ∥ ˆAh∥ζh(¯τh) (∥δ(t)∥ + ∥x(t)∥)\n(62)\nWhen function ζh(¯τh) satisﬁes\nζh(¯τh) ≤\n1\n∥ ˆAh∥\nσh\n1 + σh\n(63)\nwhere σh > 0 is a suitable design parameter, inequality (62)\nbecomes to be\n∥δ(t)∥ ≤ σh∥x(t)∥, ∀t ∈ [tk, tk+1) , ∀k ∈ N, η(tk) = h ∈ M\n(64)\nUnder condition x(tk) = x(t) − δ(t), inequality (57) is\nequivalent to\nxT (t)\nh\u0010\nPη(t) ¯A[h]\nη(t)\n\u0011⋆\n− λη(t)Pη(t)\ni\nx(t)\n− 2x⊤(t)Pη(t)Bη(t)\nN\nX\nℓ=1\nα[ν(η(tk))]\nℓ\n¯Kℓδ(t) ≤ 0\n(65)\nBased on condition (19) and (64), inequality (65) is guaran-\nteed. Thus, conditions (54)-(56) are satisﬁed. They ﬁnally yield\nthat for ∀t ≥ 0,\nV (x(t), η(t)) ≤ µηNη(t0,t)−1V\n\u0000x\n\u0000TNη(t0,t)\n\u0001\n, ηNη(t0,t)−1\n\u0001\n× e\nληNη(t0,t)(t−TNη(t0,t))\n≤ µηNη(t0,t)−2µηNη(t0,t)−1\n× V\n\u0000x\n\u0000TNη(t0,t)−1\n\u0001\n, ηNη(t0,t)−2\n\u0001\n× e\nληNη(t0,t)(t−TNη(t0,t))\n× e\nληNη(t0,t)−1(TNη(t0,t)−TNη(t0,t)−1)\n...\n≤ V (x0, η0)\nNη(t0,t)\nY\nk=1\nµηke\nR t\n0 λη(s)ds\n= V (x0, η0)\nN\nY\ni=1\nµNi(t0,t)\ni\ne\nR t\n0 λη(s)ds\n(66)\nThen, one could obtain that\n∥x(t)∥ ≤ maxi∈N {λmax (Pi)}\nmini∈N {λmin (Pi)} ∥x0∥\nN\nY\ni=1\nµNi(t0,t)\ni\ne\nR t\n0 λη(s)ds\n(67)\nIt is obvious from (21) that there is always a scalar ǫ1 > 0\nsuch that\nN\nX\ni=1\nπiλi +\nN\nX\ni=1\n\u0012πi\nˆτi\n+ ǫ1\n\u0013\nln µi < 0\n(68)\nThen, similar to the proof of Theorem 1 in [26], one knows\nthat if ∀i ∈ N and ǫ1 deﬁned in (68), there exists a positive\nconstant H (ǫ1) such that if t ≥ H (ǫ1), then\nNi(t0, t) ≤\n\u0012πi\nˆτi\n+ ǫ1\n\u0013\nt, a.s.\n(69)\nAccordingly, for t ≥ H (ǫ1), one has\nN\nY\ni=1\nµNi(t0,t)\ni\ne\nR t\n0 λη(s)ds = e\nPN\ni=1 Ni(t0,t) ln µi+R t\n0 λη(s)ds\n≤ e\nPN\ni=1\n\u0010 πi\nˆτi +ǫ1\n\u0011\n(ln µi)t+\nR t\n0 λη(s)ds, a.s.\n(70)\nBased on the strong law of large numbers, one obtains that\nlim\nt→∞\n1\nt\nZ t\n0\nλη(s)ds =\nN\nX\ni=1\nλiπi, a.s.\n(71)\nThen, it can be concluded from (21) that\nlim\nt→∞\nN\nX\ni=1\n\u0012πi\nˆτi\n+ ǫ1\n\u0013\n(ln µi) t +\nZ t\n0\nλη(s)ds = −∞,\na.s.\n(72)\nConsequently, one gets that\nN\nY\ni=1\nµNi(t0,t)\ni\ne\nR t\n0 λη(s)ds = 0, a.s.\n(73)\nBased on the above equation, it can be known that for any\ngiven scalars γ > 0 and ξ > 0, there exits a random variable\nϕ (γ, ξ) such that\nP\n \nsup\nt≥ϕ(γ,ξ)\n N\nY\ni=1\nµNi(t0,t)\ni\ne\nR t\n0 λη(s)ds\n!\n< mini∈N {λmin (Pi)}\nmaxi∈N {λmax (Pi)}\nξ\nγ\n\u0013\n= 1\n(74)\nThen, for any ∥x0∥ < γ and combing conditions (67) and (74),\none can conclude condition C2. Moreover, it can be concluded\nfrom (74) that\nsup\nt≥0\n N\nY\ni=1\nµNi(t0,t)\ni\ne\nR t\n0 λη(s)ds\n!\n< ∞,\na.s.\n(75)\nObviously, for any ǫ ∈ (0, 1), there is always ρ > 0 such that\nP\n \nsup\nt≥0\n N\nY\ni=1\nµNi(t0,t)\ni\ne\nR t\n0 λη(s)ds\n!\n< ρ\n!\n> 1 − ǫ.\n(76)\nBy selecting δ =\nmini∈N {λmin(Pi)}\nmaxi∈N {λmax(Pi)}\nǫ\nρ and letting ∥x0∥ < δ,\nand considering inequality (67) under condition (76), one has\nP\n\u0012\nsup\nt≥0\n∥x(t)∥ ≤ maxi∈N {λmax (Pi)}\nmini∈N {λmin (Pi)} ∥x0∥\n× sup\nt≥0\n N\nY\ni=1\nµNi(t0,t)\ni\ne\nR t\n0 λη(s)ds\n!\n<\nǫ\nρ sup\nt≥0\n N\nY\ni=1\nµNi(t0,t)\ni\ne\nR t\n0 λη(s)ds\n!\n< ǫ\n!\n> 1 − ǫ\n(77)\nwhich implies condition C1. Due to conditions C1 and C2 both\nsatisfying, the resulting closed-loop system is ﬁnally GAS a.s..\nAs for condition (63) with η(tk) = h ∈ M , ∀t ∈ [tk, tk+1),\nit is implied by\nZ t\ntk\neˆχh(t−θ)dθ ≤\n1\n∥ ˆAh∥\nσh\n1 + σh\n(78)\nWhen ˆχh ≤ 0, it could be guaranteed by\nsk ≤ ¯τh ≤\n1\n∥ ˆAh∥\nσh\n1 + σh\n(79)\nwhich is actually the former condition of (22). To the contrary,\ncondition (63) under ˆχh > 0 is ensured by\n1\nˆχh\neˆχh(t−s)|tk\nt ≤ 1\nˆχh\n\u0000eˆχh¯τh − 1\n\u0001\n≤\n1\n∥ ˆAh∥\nσh\n1 + σh\n(80)\nIt is equivalent to the latter condition of (22). This completes\nthe proof. □\nB.\nProof of Theorem 2\nOn the one hand, ﬁrst of all, it is obvious that the augmented\nLagrangian function (28) is convex. Then, based on the\nresult given in [30] on Page 108, it can be concluded that\nthere exists a globally optimal solution (α∗(c), γ∗(c), ς∗(c))\nto (28) which can be computed by solving conditions\n(31)-(33)\nand\ndeﬁned\nas\nL (α∗(c), γ∗(c), ς∗(c), φ)\n≜\nminα(c),γ(c),ς(c) L (α(c), γ(c), ς(c), φ). Particularly, it can\nbe seen that (28) is strictly convex about α(c) such as\n∇2\nα(c)L (α(c), γ(c), ς(c), φ) > 0. In other words, there is\nonly one globally optimal solution α∗(c) satisfying (31)-(33).\nMeanwhile, according to reference [31] on Page 97, it can be\nknown that the optimization problem (11) constrained by (27)\nhas the same optimal value as the optimization problem (28).\nThat is\nJ (α∗(c)) = L (α∗(c), γ∗(c), ς∗(c), φ)\n(81)\nFinally, one can easily obtain the globally optimal value of (11)\nwith constraint (27) described by (34), whose corresponding\noptimal solution is obviously computed by (35).\nOn the other hand, it has been shown in [32] that Qk(s, a)\ngenerated by (36) can theoretically converge to Q∗(s, a) with\nprobability 1 when k → ∞. As a result, an optimal taking\naction A∗\nk, k = 1, 2, . . ., maximizing Q-value (30) can be es-\ntablished, which is actually an optimal attenuation coefﬁcient\nδ∗\nk. Then, a preferable searching radius Lpre\nk , k = 1, 2, . . .,\ncan be gotten based on the iterative update rule (18), while\nthe initial condition ˆω(1) is given to be ∀ˆω(1) ∈ Ω but\nˆω(0) should be given such as one deﬁned in (17). Based on\nthe obtained Lpre\nk , a preferably nominal solution referred as\nˆωpre(k), k = 2, 3, . . ., can be gotten by using HCA. Finally,\nby repeating the above process along with iteration number\nk having a maximum value kmax, two optimal sequences\n{A∗\nk}kmax\nk=1\nand {δ∗\nk}kmax\nk=1\ncan be established based on (36),\nwhile two preferable sequence {L∗\nk}kmax\nk=1 and {ˆωpre(k)}kmax\nk=1\nwith ˆωpre(1) = ˆω(1) can also be developed by (18). The\ndetailed repeating process is given as follows:\nˆω(1) → δ∗\n1\nˆω(1)\n−−−→\nˆω(0) L1 → ˆω(2) → · · · →\nˆω(kmax) → δ∗\nkmax\nˆω(kmax)\n−−−−−−−→\nˆω(kmax−1) Lkmax\nConsequently, based on the characteristics of Q-HCA, it can\nbe obviously known that sequence {ˆωpre(k)}kmax\nk=1\nwill have\na good convergence characteristic such as (37). Meanwhile,\nthe monotonicity of (38) can be guaranteed. Moreover, since\nall the elements of {ˆωpre(k)}kmax\nk=1 belong to Ω but is only a\npart of Ω, it is obviously concluded that the obtained optimal\nvalue f ∗ will be no less than J∗ obtained by (34). In this\nsituation, it can be said that the above obtained ˆω∗ is only a\nlocally optimal solution. Finally, the iteration process of the\ndeveloped Q-HCA is given below:\nAlgorithm 1: Improved hill climbing algorithm based on Q-learning\nInitial Q-values with Q-HCA, parameter ǫ, iterative index k = 1,\nSelect a starting state S1 = ˆω(1), calculate L1 by the parameter ǫ\nwhile (k ≤ maximum number of iterations)\nwhile Sk is not a termination state Send\nChoose Ak according to the max Q(Sk)\nTake action Ak\nReturn reward Rk+1 by the equation (29)\nUpdate Q-value by the equation (36)\nUpdate Lk by the equation (19)\nUpdate Θ(ˆω(k)) of ˆω(k) corresponding to Sk\nby the equation (14)\nif Θ(ˆω(k)) is not empty set\nGenerate a new state by gˆω(k)(ˆω′(k)) of ˆω(k)\ncorresponding to Sk\nMove to new state\nelse if Θ(ˆω(k)) is empty set\nMove to the termination state Send\nend if\nend while\nend while\nThis completes the proof. □\n"
}