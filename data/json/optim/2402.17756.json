{
    "optim": "Robustly Learning Single-Index Models via Alignment Sharpness Nikos Zarifis∗‖ UW Madison zarifis@wisc.edu Puqian Wang†‖ UW Madison pwang333@wisc.edu Ilias Diakonikolas‡ UW Madison ilias@cs.wisc.edu Jelena Diakonikolas§ UW Madison jelena@cs.wisc.edu Abstract We study the problem of learning Single-Index Models under the L2 2 loss in the agnostic model. We give an efficient learning algorithm, achieving a constant factor approximation to the optimal loss, that succeeds under a range of distributions (including log-concave distributions) and a broad class of monotone and Lipschitz link functions. This is the first efficient constant factor approximate agnostic learner, even for Gaussian data and for any nontrivial class of link functions. Prior work for the case of unknown link function either works in the realizable setting or does not attain constant factor approximation. The main technical ingredient enabling our algorithm and analysis is a novel notion of a local error bound in optimization that we term alignment sharpness and that may be of broader interest. ∗Supported in part by NSF Medium Award CCF-2107079 and NSF award 2023239. †Supported in part by NSF Award CCF-2007757. ‡Supported by NSF Medium Award CCF-2107079 and a DARPA Learning with Less Labels (LwLL) grant. §Supported by NSF Award CCF-2007757 and by the U. S. Office of Naval Research under award number N00014- 22-1-2348. ‖Equal contribution. arXiv:2402.17756v1  [cs.LG]  27 Feb 2024 1 Introduction Single-index models (SIMs) [Ich93, HJS01, HMS+04, DJS08, KS09, KKSK11, DH18] are a classical supervised learning model extensively studied in statistics and machine learning. SIMs capture the common assumption that the target function f depends on an unknown direction w, i.e., f(x) = u(w · x) for some link (a.k.a. activation) function u : R 7→ R and w ∈ Rd. In most settings, the link function is unknown and is assumed to satisfy certain regularity properties. Classical works [KS09, KKSK11] studied the efficient learnability of SIMs for monotone and Lipschitz link functions and data distributed on the unit ball. These early algorithmic results succeed in the realizable setting (i.e., with clean labels) or in the presence of zero-mean label noise. The focus of this work is on learning SIMs in the challenging agnostic (or adversarial label noise) model [Hau92, KSS94], where no assumptions are made on the labels of the examples and the goal is to compute a hypothesis that is competitive with the best-fit function in the class. Importantly, as will be formalized below, we will not assume a priori knowledge of the link function. In more detail, let D be a distribution on labeled examples (x, y) ∈ Rd × R and L2(h) = E(x,y)∼D[(h(x) − y)2] be the squared loss of the hypothesis h : Rd → R with respect to D. Given i.i.d. samples from D, the goal of the learner is to output a hypothesis h with squared error competitive with OPT, where OPT = inff∈C L2(f) is the best attainable error by any function in the target class C. In the context of this paper, the class C above is the class of SIMs, i.e., all functions of the form f(x) = u(w · x) where both the weight vector w and the link function u are unknown. For this task to be even information-theoretically solvable, one requires some assumptions on the vector w and the link function u. We will assume, as is standard, that the ℓ2-norm of w is bounded by a parameter W. We will similarly assume that the link function lies in a family of well-behaved functions that are monotone and satisfy certain Lipschitz properties (see Definition 1.3). For a weight vector w and link function u, the L2 2 loss of the SIM hypothesis u(w · x) (defined by u and w) is L2(w; u) = E(x,y)∼D[(u(w · x) − y)2]. Our problem of robustly learning SIMs is defined as follows. Problem 1.1 (Robustly Learning Single-Index Models). Fix a class of distributions G on Rd and a class of link functions1 F. Let D be a distribution of labeled examples (x, y) ∈ Rd × R such that its x-marginal Dx belongs to G. We say that an algorithm is a C-approximate proper SIM learner, for some C ≥ 1, if given ϵ > 0, W > 0, and i.i.d. samples from D, the algorithm outputs a link function ˆu ∈ F and a vector bw ∈ Rd such that with high probability it holds L2(bw; ˆu) ≤ C OPT + ϵ, where OPT ≜ min∥w∥2≤W,u∈F L2(w; u). Throughout this paper, we use u∗(w∗ · x) to denote a fixed (but arbitrary) optimal solution to the above learning problem, i.e., one satisfying L2(w∗; u∗) = OPT. Some comments are in order. First, Problem 1.1 does not make realizability assumptions on the distribution D. That is, the labels are allowed to be arbitrary and the goal is to be competitive against the best-fit function in the class C = {u(w · x) | w ∈ Rd, ∥w∥2 ≤ W, u ∈ F} . Second, our focus is on obtaining efficient learners that achieve a constant factor approximation to the optimum loss, i.e., where C in Problem 1.1 is a universal constant — independent of the dimension d and the radius W of the weight space. Ideally, one would like an efficient learner that succeeds for all marginal distributions and achieves optimal error of OPT + ϵ (corresponding to C = 1). Unfortunately, known computational hardness results rule out this possibility. Even for the very special case that the marginal distribution is Gaussian and the link function is known (e.g., a ReLU), there is strong evidence that any algorithm 1Throughout this paper, we will use the terms “link function” and “activation” interchangeably. 1 achieving error OPT+ϵ requires dpoly(1/ϵ) time [DKZ20, GGK20, DKPZ21, DKR23]. Moreover, even if we relax our goal to constant factor approximation (i.e., C = O(1)), distributional assumptions are required both for proper [Sím02, MR18] and improper learning [DKMR22]. As a consequence, algorithmic research in this area has focused on constant factor approximate learners that succeed under mild distributional assumptions. Recent works [DGK+20, DKTZ22, ATV23, WZDD23] gave efficient, constant factor approximate learners, under natural distributional assumptions, for the special case of Problem 1.1 where the link function is known a priori (see also [FCG20]). For the general setting, the only prior algorithmic result was recently obtained in [GGKS23]. Specifically, [GGKS23] gave an efficient algorithm that succeeds for the class of monotone 1-Lipschitz link functions and any marginal distribution with second moment bounded by λ. Their algorithm achieves L2 2 error O(W √ λ √ OPT) + ϵ (1) under the assumption that the labels are bounded in [0, 1]. The error guarantee (1) is substantially weaker — both qualitatively and quantitatively — from the goal of this paper. Firstly, the dependence on OPT scales with its square root, as opposed to linearly. Secondly, and arguably more importantly, the multiplicative factor inside the big-O scales (linearly) with the diameter of the space W. Interestingly, [GGKS23] showed — via a hardness construction from [DKMR22] — that, under their distributional assumptions, a multiplicative dependence on W (in the error guarantee) is inherent for efficient algorithms. That is, to obtain an efficient constant factor approximation, it is necessary to restrict ourselves to distributions with additional structural properties. This discussion raises the following question: Can we obtain efficient constant factor learners for Problem 1.1 under mild distributional assumptions? The natural goal here is to match the guarantees of known algorithmic results for the special case of known link function [DKTZ22, WZDD23]. As our main contribution, we answer this question in the affirmative. That is, we give the first efficient constant-factor approximate learner that succeeds for natural and broad families of distributions (including log-concave distributions) and a broad class of link functions. We emphasize that this is the first polynomial-time constant factor approximate learner even for Gaussian marginals and for any nontrivial class of link functions. Roughly speaking, our distributional assumptions require concentration and (anti)-anti-concentration (see Definition 1.2). 1.1 Overview of Results We start by stating the distributional assumptions and defining the family of link functions for which our algorithm succeeds. Distributional Assumptions Our algorithm succeeds for the following class of structured distributions. Definition 1.2 (Well-Behaved Distributions). Let L, R > 0. Let V be any subspace in Rd of dimension at most 2. A distribution Dx on Rd is called (L, R)-well-behaved if for any projection (Dx)V of Dx onto subspace V , the corresponding pdf γV on R2 satisfies the following: • For all xV ∈ V such that ∥xV ∥∞ ≤ R, γV (xV ) ≥ L (anti-anti-concentration). • For all xV ∈ V , γV (xV ) ≤ (1/L)(e−L∥xV ∥2) (anti-concentration and concentration). 2 As a consequence of sub-exponential concentration, we can assume without loss of generality that the operator norm of Ex∼Dx[xx⊤] is bounded above by an absolute constant. For simplicity, we take Ex∼Dx[xx⊤] ≼ I, which can be ensured by simple rescaling of the data. The distribution class of Definition 1.2 was introduced in [DKTZ20], in the context of learning linear separators with noise, and has since been used in a number of prior works — including for robustly learning SIMs with known link function [DKTZ22]. The parameters L, R in Definition 1.2 are viewed as universal constants, i.e., L, R = O(1). Indeed, it is known that many natural distributions, most importantly isotropic log-concave distributions, fall in this category; see, e.g., [DKTZ20]. Unbounded Activations Our algorithm succeeds for a broad class of link functions that con- tains many well-studied activations, including ReLUs. This class, defined in [DKTZ22] and used in [WZDD23], requires the link function to be monotone, Lipschitz-continuous and strictly increasing in the positive region. Definition 1.3 (Unbounded Activations). Let u : R 7→ R. Given a, b ∈ R such that 0 < a ≤ b, we say that u(z) is (a, b)-unbounded if u(0) = 0 and u(z) is non-decreasing, b-Lipschitz-continuous, and u(z) − u(z′) ≥ a(z − z′) for all z ≥ z′ ≥ 0. We denote this function class by U(a,b). A simplified version of our main algorithmic result is as follows (see Theorem 4.2 for a more detailed statement): Theorem 1.4 (Main Algorithmic Result, Informal). Given Problem 1.1, where G is the class of (L, R)-well behaved distributions with L, R = O(1) and F = U(a,b) such that (1/a), b = O(1), there is an algorithm that draws N = poly(W) ˜O(d/ϵ2) samples from D, runs in poly(N, d) time, and outputs a hypothesis ˆu(bw · x) with ˆu ∈ U(a,b), ∥bw∥2 ≤ W such that L2(bw; ˆu) = C OPT + ϵ with high probability, where C > 0 is an absolute constant. We reiterate that the approximation factor C in Theorem 1.4 is a universal constant, independent of the dimension and the diameter of the space. That is, our main result provides the first efficient learning algorithm achieving a constant factor approximation, even for the most basic case of Gaussian data and any non-trivial class of link functions. 1.2 Technical Overview When it comes to learning SIMs in the agnostic model with target error COPT + ϵ, to the best of our knowledge, all prior work that achieves such a guarantee with C being an absolute constant only applies to the special case of known link function u∗. Such results are established by proving growth conditions (local error bounds) that relate either the L2 2 loss or a surrogate loss to (squared) distance to the set of target solutions, using assumptions about the link function and the data distribution, such as concentration and (anti-)anti-concentration [DGK+20, DKTZ22, WZDD23]. Among these, most relevant to our work is [WZDD23], which proved a “sharpness” property for the convex surrogate function defined by Lsur(w; u) = E (x,y)∼D \u0014 Z w·x 0 (u(r) − y) dr \u0015 , (2) based on certain assumptions about the link function (that are the same as ours) and distributional assumptions (that are somewhat weaker but comparable to ours). Their sharpness result corresponds to guaranteeing that for vectors w that are not already O(OPT) + ϵ accurate solutions, the following holds: ∇Lsur(w; u∗) · (w − w∗) ≳ ∥w − w∗∥2 2, (3) 3 where w∗ is a vector that achieves error O(OPT) + ϵ and u∗ is the (a priori known) link function. One may hope that the sharpness result of [WZDD23] can be generalized to the case of unknown link function and leveraged to obtain constant factor robust learners in this more general setting. However, as we discuss below, such direct generalizations are not possible and there are several technical challenges that had to be overcome in our work. To illustrate some of the intricacies, consider first the following example. Example 1.5. Let x ∼ N(0, I) and w = (1/2)w∗, where w∗ is an arbitrary but fixed target unit vector. Let b > 2a. Suppose that the link function at hand is u(z) = bz and the target link function is u∗(z) = az. Observe that both u, u∗ ∈ U(a,b), as required by our model. Furthermore, suppose there is no label noise, in which case OPT = 0. Note that the L2 2 error of u(w · x) in this case is L2(w; u) = E x∼N(0,I)[(u(w · x) − u∗(w∗ · x))2] = E z∼N(0,1)[(b/2 − a)2z2] = (b/2 − a)2 = Θ(1). However, the gradient of the surrogate loss, ∇Lsur(w; u) = E[(u(w · x) − u∗(w∗ · x))x], is negatively correlated with w − w∗, i.e., ∇Lsur(w; u) · (w − w∗) < 0, contrary to what we would hope for if a sharpness property as in [WZDD23] were to hold. Thus, although w and u are both still far away from the target parameters w∗ and u∗, the gradient of the surrogate loss cannot provide useful information about the direction in which to update w. What Example 1.5 demonstrates is that we cannot hope for the surrogate loss to satisfy a local error bound for an arbitrary parameter pair (u, w) that would guide the convergence of an algorithm toward a target parameter pair (u∗, w∗). This seemingly insurmountable obstacle is surpassed by observing that we do not, in fact, need the surrogate loss to contain a “signal” that would guide us toward target parameters for an arbitrary pair (u, w). Instead, we can restrict our attention to pairs (u, w) satisfying that u is a “reasonably good” link function for the vector w. Ideally, we would like to only consider link functions u that minimize the L2 2 loss — considering that u∗ must minimize the L2 2 loss for a given, fixed w∗ — but it is unclear how to achieve that in a statistically and computationally efficient manner. As a natural approach, we consider link functions that are the best fitting functions in an empirical distribution sense. In particular, given a sample set S = {(x(i), y(i))}m i=1 and a parameter w, we select a function ˆuw that solves the following (convex) optimization problem: ˆuw ∈ argmin u∈U(a,b) 1 m m X i=1 (u(w · x(i)) − y(i))2. (P) For notational simplicity, we drop the parameter wt from ˆuwt and use ˆut instead. It is worth pointing out here that in general the problem of finding the best function that minimizes the L2 2 error fails under the category of non-parametric regression, which unfortunately requires exponentially many samples (namely, Ω(1/ϵd)). Fortunately, in our setting, we are looking for the best function that lies in a one-dimensional space. Therefore, instead of looking at all possible directions, we can project all the points of the sample set S to the direction w and find the best fitting link function efficiently. We provide the full details for efficiently solving the optimization problem (P) in Appendix E. Having set on the “best-fit” link functions in the sense of the problem (P), the next obstacle one encounters when trying to prove a “sharpness-like” result is that neither the L2 2 loss nor its surrogate convey information about the scale of w and w∗. This is because models determined by u, w and u/c, cw for some parameter c > 0 can have the same value of both loss functions. Thus, it seems unlikely that a more traditional local error bound, as in (3), can be established in general, 4 for either the surrogate loss or the original L2 2 loss. Instead, we prove a weaker property that establishes strong correlation between the gradient of the empirical surrogate loss ∇ bLsur(wt; ˆut) = (1/m) Pm i=1(ˆut(wt · x(i)) − y(i))x(i) and the direction wt − w∗ that holds whenever wt is not an O(OPT) + ϵ error solution and which is independent of the scale of wt. This constitutes our key structural result, stated as Proposition 3.1 and discussed in detail in Section 3. We further discuss how this result relates to classical and recent local error bounds in Appendix B. In addition to this weaker version of a sharpness property, we further prove in Corollary 3.4 that given a parameter wt and a dataset of m samples from D, the activation ˆut(wt · x) generated by optimizing the empirical risk on the dataset as in (P) satisfies Ex∼Dx[(ˆut(wt · x) − u∗(w∗ · x))2] ≲ b2∥wt − w∗∥2 2 with high probability. As a result, we can guarantee that when ∥wt − w∗∥2 decreases, the L2 2 distance between ˆut and u∗ diminishes as well. This is crucial, since without such a coupling we would not be able to argue about convergence over both model parameters u, w. Leveraging these results, we arrive at an algorithm that alternates between “gradient descent-style” updates for w and best-fit updates for u. We note in passing that similar alternating updates have been used in classical work on SIM learning in the less challenging, non-agnostic setting [KKSK11]. In more detail, our algorithm fixes the scale β of ∥wt∥2 and alternates between taking a Riemannian gradient descent step on a sphere for wt with respect to the empirical surrogate loss and solving (P). The unknown scale for the true parameter vector w∗ is resolved by applying this approach using β chosen from a sufficiently fine grid of the interval [0, W] and employing a testing procedure at the end to select the best parameter vector. Although the idea is simple, the proof of correctness is quite technical, as it requires ensuring that the entire process does not accumulate spurious errors arising from the stochastic nature of the problem, adversarial labels, and approximate minimization of the surrogate loss, and, as a result, that it converges to the target error. Technical Comparison to [GGKS23] The only prior work addressing SIM learning (with unknown link functions) in the agnostic model is [GGKS23], thus here we provide a technical comparison. While both [GGKS23] and our work make use of the surrogate loss function from (2), on a technical level the two works are completely disjoint. [GGKS23] uses a framework of omnipredictors to minimize the surrogate loss and then relates this result to the L2 2 loss. Although they handle more general distributions and activations, their learner outputs a hypothesis with error that cannot be considered constant factor approximation (see (1)) and is improper. By contrast, our work does not seek to minimize the surrogate loss. Instead, our main insight is that the gradient of the surrogate loss at a vector w conveys information about the direction of a target vector w∗, for a fixed link function that minimizes the L2 2 loss. We leverage this property to construct a proper learner achieving constant factor approximation. 2 Preliminaries Basic Notation For n ∈ Z+, let [n] := {1, . . . , n}. We use lowercase boldface characters for vectors. We use x · y for the inner product of x, y ∈ Rd and θ(x, y) for the angle between x, y. For x ∈ Rd and k ∈ [d], xk denotes the kth coordinate of x, and ∥x∥2 denotes the ℓ2-norm of x. We use 1A = 1{A} to denote the characteristic function of the set A. For vectors v, u ∈ Rd, we denote by v⊥u the projection of v onto the subspace orthogonal to u, i.e., v⊥u := v − ((v · u)u)/∥u∥2 2. We use B(r) to denote the ℓ2 ball in Rd of radius r, centered at the origin. Asymptotic Notation We use the standard O(·), Θ(·), Ω(·) asymptotic notation. We use eO(·) to omit polylogarithmic factors in the argument. We use Op(·) to suppress polynomial dependence 5 on p, i.e., Op(ω) = O(poly(p)ω). Θp(·) and Ωp(·) are defined similarly. We write E ≳ F for two non-negative expressions E and F to denote that there exists some positive universal constant c > 0 (independent of the variables or parameters on which E and F depend) such that E ≥ c F. The notation ≲ is defined similarly. Probability Notation We use EX∼D[X] for the expectation of a random variable X according to the distribution D and Pr[E] for the probability of event E. For simplicity of notation, we omit the distribution when it is clear from the context. For (x, y) distributed according to D, we use Dx to denote the marginal distribution of x. Organization In Section 3, we establish our main structural result of alignment sharpness. In Section 4, we describe and analyze our constant factor approximate SIM learner. We conclude the paper in Section 5. Some of the proofs and technical details are deferred to the Appendix. 3 Main Structural Result: Alignment Sharpness of Surrogate Loss In this section, we establish our main structural result (Proposition 3.1), which is what crucially enables us to obtain the target O(OPT)+ϵ error for the studied problem. Proposition 3.1 states that the empirical gradient of the surrogate loss (2) positively correlates with the direction of wt − w∗ whenever wt does not correspond to an O(OPT) + ϵ error solution; and, moreover, the correlation is proportional to the quantity ∥(w∗)⊥wt∥2 2. This is a key property that is leveraged in our algorithmic result (Theorem 4.2), both in obtaining an O(OPT) + ϵ error result, and in arguing about the convergence and computational efficiency of our algorithm. Intuitively, what Proposition 3.1 allows us to argue is that as long as the angle between wt and w∗ is not close to zero, we can update wt to better align it with w∗ (in the sense that we reduce the angle between these two vectors). To understand this statement better, note that when ∥wt∥2 ≈ ∥w∗∥2, we also have ∥(w∗)⊥wt∥2 ≈ ∥wt − w∗∥2. Additionally, ∥wt − w∗∥2 = O(OPT + ϵ) implies that the L2 2 error of the hypothesis defined by ˆut, wt is O(OPT + ϵ) (see Claim 4.4). Thus, for a sufficiently good guess of the value of ∥w∗∥2, Proposition 3.1 provides a local error bound of the form ∇ bLsur(wt; ˆut) · (wt − w∗) ≳ µ∥wt − w∗∥2 2 that holds outside of the set of O(OPT + ϵ) error solutions, allowing us to contract the distance to this set. Proposition 3.1 (Alignment Sharpness of the Convex Surrogate). Suppose that Dx is (L, R)-well- behaved, U(a,b) is as in Definition 1.3, and ϵ, δ > 0. Let µ ≳ a2LR4/b. Given any wt ∈ B(W), denote by ˆut the optimal solution to (P) with respect to wt and the sample set S = {(x(i), y(i))}m i=1 drawn i.i.d. from D. If m satisfies m ≳ dW 9/2b4L−4 log4(d/(ϵδ))(1/ϵ3/2 + 1/(ϵδ)) , then, with probability at least 1 − δ, ∇ bLsur(wt; ˆut) · (wt − w∗) ≥ µ∥(w∗)⊥wt∥2 2 − 2(OPT + ϵ)/b − 2( √ OPT + √ϵ)∥wt − w∗∥2 . To prove Proposition 3.1, we rely on the following key ingredients. In Section 3.1, we prove our main technical lemma (Lemma 3.2), which states that the L2 2 distance between the hypothesis u(w·x) and the target u∗(w∗ · x) is bounded below by the misalignment of wt and w∗, i.e., the squared norm of the component of w∗ that is orthogonal to wt, ∥(w∗)⊥wt∥2 2. As will become apparent in the proof of Proposition 3.1, the inner product ∇ bLsur(wt; ˆut) · (wt − w∗) can be bounded below as 6 a function of the empirical L2 2 error for wt and a different (but related) activation ˆu∗t, which can in turn be argued to be close to the population L2 2 error for a sufficiently large sample size, using concentration. Thus, Lemma 3.2 can be leveraged to obtain a term scaling with ∥(w∗)⊥wt∥2 2 in the lower bound on ∇ bLsur(wt; ˆut) · (wt − w∗). In Section 3.2, we characterize structural properties of the population-optimal link functions ut and u∗t (see (EP) and (EP*)), which play a crucial role in the proof of Proposition 3.1. Specifically, we show that the activation ut is close to the idealized activation u∗t (the optimal activation without noise, given wt) in L2 2 distance (Lemma 3.3). Since by standard uniform convergence results we have that ˆut and ˆu∗t are close to their population counterparts ut and u∗t, respectively, Lemma 3.3 certifies that ˆut is not far from ˆu∗t. This property enables us to replace ˆut by (the idealized) ˆu∗t in the empirical surrogate gradient ∇ bLsur(wt; ˆut), which is easier to analyze, since ˆu∗t is defined with respect to the “ideal” dataset (with uncorrupted labels). Finally, as a simple corollary of Lemma 3.3, we obtain Corollary 3.4, which gives a clear explanation of why our algorithm, which alternates between updating wt and ˆut, works: we show that the L2 2 loss between the hypothesis generated by our algorithm ˆut(wt · x) and the underlying optimal hypothesis u∗(w∗ · x) is bounded above by the distance between wt and w∗. Since our structural sharpness result (Proposition 3.1) enables us to decrease ∥wt −w∗∥2, Corollary 3.4 certifies that choosing the empirically-optimal activation leads to convergence of the hypothesis ˆut(wt · x). Equipped with these technical lemmas, we prove our main structural result (Proposition 3.1) in Section 3.3. 3.1 L2 2 Error and Misalignment Our first key result is Lemma 3.2 below, which plays a critical role in the proof of Proposition 3.1. As discussed in Section 1.2, for two different activations u and u∗ and parameters w and w∗ such that w and w∗ are parallel, even when the L2 2 error is Ω(1), the gradient ∇Lsur(w; u) might not significantly align with the direction of w−w∗, and thus cannot provide sufficient information about the direction to decrease ∥w − w∗∥2. Intuitively, the following lemma shows that this is the only thing that can go wrong, and it happens when w and w∗ are parallel. In particular, Lemma 3.2 shows that for any square integrable link function f, we can relate the L2 2 distance Ex∼Dx[(f(w · x) − u∗(w∗ · x))2] to the magnitude of the component of w∗ that is orthogonal to w. Although its proof is quite technical, this lemma is the main supporting result allowing us to prove Proposition 3.1, thus we provide its full proof below. It is however possible to follow the rest of this section by only relying on its statement. Lemma 3.2 (Lower Bound on L2 2 Error by Misalignment). Let u∗ ∈ U(a,b), Dx be (L, R)-well-behaved, and f : R 7→ R be square-integrable with respect to the measure of the distribution Dx. Then, for any w, w∗ ∈ Rd, E x∼Dx[(f(w · x) − u∗(w∗ · x))2] ≳ a2LR4∥(w∗)⊥w∥2 2 . Proof. The statement holds trivially if w is parallel to w∗, so assume this is not the case. Let v = (w∗)⊥w = w∗ − (w∗ · w)w/∥w∥2 2. Suppose first that w · w∗ ≥ 0. Then w∗ = αw + v, for some α > 0. Let V be the subspace spanned by w, v. Then, E x∼Dx[(f(w·x)−u∗(w∗·x))2] = E x∼Dx[(f(w·xV )−u∗(w∗·xV ))2] ≥ E x∼Dx[(f(w·xV )−u∗(w∗·xV ))21{xV ∈ A}] , for any A ⊆ Rd. For ease of notation, we drop the subscript V , and we assume that all x are projected to the subspace V . We denote by ˜w = w/∥w∥2 (resp. ˜v = v/∥v∥2) the unit vector in the direction of w (resp. v). We choose A = {x ∈ Rd : w · x ≥ 0, ˜v · x ∈ (R/16, R/8) ∪ (3R/8, R/2)}. 7 The idea of the proof is to utilize the non-decreasing property of u∗ and the fact that the marginal distribution Dx is anti-concentrated on the subspace V . In short, for any x such that |˜v · x| ≤ R, by the non-decreasing property of u∗ we know that f(w · x) falls into one of the following four intervals: (−∞, u∗(αw · x + ∥v∥2R/32)] , (u∗(αw · x + ∥v∥2R/32), u∗(αw · x + ∥v∥2R/4)] , (u∗(αw · x + ∥v∥2R/4), u∗(αw · x + ∥v∥2R)] , (u∗(αw · x + ∥v∥2R), +∞) . When f(w·x) belongs to any of the intervals above, we can show that with some constant probability, the difference between w∗ · x and w · x is proportional to ∥v∥2, and hence u∗(w∗ · x) is far from f(w · x) (due to the well-behaved property of the marginal Dx). To indicate that f(w · x) belongs to one of the intervals above, denote I1(x) = f(w · x) − u∗(αw · x + ∥v∥2R/32) , I2(x) = f(w · x) − u∗(αw · x + ∥v∥2R/4) , I3(x) = f(w · x) − u∗(αw · x + ∥v∥2R) . For any x ∈ Rd, using the assumption that u∗ is non-decreasing, we have that I1(x) ≥ I2(x) ≥ I3(x); as a consequence, it must be that I1(x)I2(x) ≥ 0 or I2(x)I3(x) ≥ 0. Figure 1: Under the assumption that ˜v · x ∈ (R/16, R/8), and I1(x) ≥ 0, I2(x) ≥ 0, the distance between f(w · x) and u∗(w∗ · x) is at least |u∗(αw · x + ∥v∥2R/4) − u∗(w∗ · x)| ≥ a∥v∥2R/8. Case 1: f(w · x) ∈ (u∗(αw · x + ∥v∥2R/4), ∞). Then I1(x) ≥ I2(x) ≥ 0. Let B := {x ∈ Rd : w · x ≥ 0, ˜v · x ∈ (R/16, R/8)} and notice that B ⊆ A. We have that when x ∈ B, u∗(w∗ · x) = u∗(αw · x + ∥v∥2˜v · x) ∈ (u∗(αw · x + ∥v∥2R/16), u∗(αw · x + ∥v∥2R/8)), thus we can conclude that (f(w · x) − u∗(w∗ · x))21{x ∈ B} = \u0000{f(w · x) − u∗(αw · x + ∥v∥2R/4)} + {u∗(αw · x + ∥v∥2R/4) − u∗(w∗ · x)} \u000121{x ∈ B} ≥ (u∗(αw · x + ∥v∥2R/4) − u∗(w∗ · x))21{x ∈ B} , where in the last inequality we used that I2(x) = f(w · x) − u∗(αw · x + ∥v∥2R/4) ≥ 0 and u∗(αw · x + ∥v∥2R/4) − u∗(w∗ · x) ≥ 0 by the non-decreasing property of u∗, and the elementary inequality (a + b)2 ≥ max(a, b)2 for a, b ≥ 0. Further, using u∗(t) − u∗(t′) ≥ a(t − t′) for t ≥ t′ ≥ 0 (which holds by assumption) and w∗ = αw + v, we have (u∗(αw · x + ∥v∥2R/4) − u∗(w∗ · x))21{x ∈ B} ≥ a2(∥v∥2R/4 − v · x)21{x ∈ B} ≥ a2∥v∥2 2(R/8)21{x ∈ B} , 8 where in the last inequality we used that 0 ≤ ˜v · x ≤ R/8 (by the definition of the event B). A visual illustration of the argument above is given in Figure 1. Case 2: f(w · x) ∈ (−∞, u∗(αw · x + ∥v∥2R/32)). Then 0 ≥ I1(x) ≥ I2(x). We follow a similar argument as in the previous case. In particular, we begin with (f(w · x) − u∗(w∗ · x))21{x ∈ B} = \u0000{f(w · x) − u∗(αw · x + ∥v∥2R/32)} + {u∗(αw · x + ∥v∥2R/32) − u∗(w∗ · x)} \u000121{x ∈ B}. (4) Note that I1(x) ≤ 0 and u∗(w∗ · x) = u∗(αw · x + ∥v∥2˜v · x) ≥ u∗(αw · x + ∥v∥2R/32) since ˜v · x ≥ R/16 ≥ R/32 for x ∈ B; thus, the two terms in curly brackets in (4) have the same sign and we further have: (f(w · x) − u∗(w∗ · x))21{x ∈ B} ≥ (u∗(αw · x + ∥v∥2R/32) − u∗(w∗ · x))21{x ∈ B} ≥ a2∥v∥2 2(R/32)21{x ∈ B} , where in the first inequality we used the fact that (a + b)2 ≥ max{a2, b2} when both a, b ≤ 0. By the analysis of Case 1 and Case 2, we can conclude that when I1(x)I2(x) ≥ 0, it must be: (f(w · x) − u∗(w∗ · x))21{x ∈ B} ≥ a2∥v∥2 2R2/2101{x ∈ B} . (5) Case 3: f(w · x) ∈ (u∗(αw · x + ∥v∥2R), +∞). Then I2(x) ≥ I3(x) ≥ 0 and we choose B′ = {x ∈ Rd : w · x ≥ 0, ˜v · x ∈ (3R/8, R/2)} . Following the same reasoning as in the previous two cases, we have (f(w · x) − u∗(w∗ · x))21{x ∈ B′} = \u0000{f(w · x) − u∗(αw · x + ∥v∥2R)} + {u∗(αw · x + ∥v∥2R) − u∗(w∗ · x)} \u000121{x ∈ B′} ≥ (u∗(αw · x + ∥v∥2R) − u∗(w∗ · x))21{x ∈ B′} ≥ a2∥v∥2 2(R/2)21{x ∈ B′} . Case 4: f(w · x) ∈ (−∞, u∗(αw · x + ∥v∥2R/4)). Then 0 ≥ I2(x) ≥ I3(x). It follows that (f(w · x) − u(w∗ · x))21{x ∈ B′} = \u0000{f(w · x) − u∗(αw · x + ∥v∥2R/4)} + {u∗(αw · x + ∥v∥2R/4) − u(w∗ · x)} \u000121{x ∈ B′} ≥ a2∥v∥2 2(R/8)21{x ∈ B′} . Thus, from the analysis of Case 3 and Case 4, we conclude that when I2(x)I3(x) ≥ 0, we have (f(w · x) − u∗(w∗ · x))21{x ∈ B′} ≥ a2∥v∥2 2(R2/64)1{x ∈ B′} . (6) Recall that for any x, at least one of the inequalities I1(x)I2(x) ≥ 0 or I2(x)I3(x) ≥ 0 happens, thus, 1{I1(x)I2(x) ≥ 0} ≥ 1 − 1{I2(x)I3(x) ≥ 0}. Therefore, the probability mass of the region (B ∩ {I1(x)I2(x) ≥ 0}) ∪ (B′ ∩ {I2(x)I3(x) ≥ 0}) 9 can be bounded below by: Pr \u0014 x ∈ (B ∩ {I1(x)I2(x) ≥ 0}) ∪ (B′ ∩ {I2(x)I3(x) ≥ 0}) \u0015 = Z V \u0012 1{x ∈ B}1{I1(x)I2(x) ≥ 0} + 1{x ∈ B′}1{I2(x)I3(x) ≥ 0} \u0013 γ(x) dx ≥ Z V,∥x∥∞≤R \u0012 1{x ∈ B}1{I1(x)I2(x) ≥ 0} + 1{x ∈ B′}1{I2(x)I3(x) ≥ 0} \u0013 L dx ≥ L Z V,∥x∥∞≤R \u0012 1{x ∈ B} + (1{x ∈ B′} − 1{x ∈ B})1{I2(x)I3(x) ≥ 0} \u0013 dx , (7) where in the first inequality we used the assumption that Dx is (L, R)- well-behaved. As a visual illustration of the lower bound argument above, the reader is referred to Figure 2. Figure 2: On the 2-dimensional space V spanned by (xv, xw), at each point x ∈ B ∪ B′, it must be that I1(x)I2(x) ≥ 0 or I2(x)I3(x) ≥ 0. Γ1 denotes the interval of xw = w · x such that f(w ·x) ≥ u∗(αw ·x+∥v∥2R), hence both I1(x)I2(x) ≥ 0, I2(x)I3(x) ≥ 0; Γ2 denotes the interval of xw such that f(w·x) ∈ (u∗(αw·x+∥v∥2R/32), u∗(αw·x+∥v∥2R/4)), hence I2(x)I3(x) ≥ 0; finally, Γ3 denotes the interval of xw such that f(w · x) ∈ (u∗(αw · x + ∥v∥2R/4), u∗(αw · x + ∥v∥2R/)), hence I1(x)I2(x) ≥ 0. The area of the union of the red and blue regions is the lower bound on the probability in (7). As displayed in the figure, the sum of the blue and red region is lower bounded by 1{x ∈ B} + (1{x ∈ B′} − 1{x ∈ B})1{I2(x)I3(x) ≥ 0}. To finish bounding below the probability in (7), it remains to bound the integral from its final inequality, which now does not involve the probability density function anymore, as we used the anti- concentration property of Dx to uniformly bound below γ(x). Recall that by definition, I1(x), I2(x), I3(x) are functions of w · x that do not depend on ˜v · x. Denote the projection of x on 10 the standard basis of space V by x ˜w = ˜w · x and x˜v = ˜v · x. Then, we have: Z V,∥x∥∞≤R \u0012 1{x ∈ B′} − 1{x ∈ B} \u0013 1{I2(x)I3(x) ≥ 0} dx = Z |x ˜ w|≤R Z |x˜v|≤R \u0012 1 \u001a x˜v ∈ \u00123R 8 , R 2 \u0013\u001b − 1 \u001a x˜v ∈ \u0012 R 16, R 8 \u0013\u001b\u0013 dx˜v1{x ˜w ≥ 0, I2(x)I3(x) ≥ 0} dx ˜w = Z |x ˜ w|≤R 1{x ˜w ≥ 0, I2(x)I3(x) ≥ 0} dx ˜w Z |x˜v|≤R \u0012 1 \u001a x˜v ∈ \u00123R 8 , R 2 \u0013\u001b − 1 \u001a x˜v ∈ \u0012 R 16, R 8 \u0013\u001b\u0013 dx˜v ≥ 0 . Plugging the inequality above back into (7), we get: Pr \u0014 x ∈ \u0000B ∩ {I1(x)I2(x) ≥ 0} \u0001 ∪ \u0000B′ ∩ {I2(x)I3(x) ≥ 0} \u0001\u0015 ≥ L Z V,∥x∥∞≤R 1{w · x ≥ 0, ˜v · x ∈ (R/16, R/8)} dx = L ZZ (1{x ˜w ∈ (0, R)} dx ˜w)1{x˜v ∈ (R/16, R/8)} dx˜v = LR2/16 . (8) We are now ready to provide a lower bound on the L2 2 distance between f(w · x) and u∗(w∗ · x). Combining the inequalities from (5) and (6), we get E x∼Dx[(f(w · x) − u∗(w∗ · x))2] ≥ E x∼Dx[(f(w · xV ) − u∗(w∗ · xV ))21{xV ∈ A}] ≥ a2(R2/1024)∥v∥2 2 E x∼Dx[1 \b {xV ∈ B ∩ {I1(x)I2(x) ≥ 0}} ∪ {B′ ∩ {I2(x)I3(x) ≥ 0}} \t ] ≥ a2(R4/213)L∥v∥2 2 , where we used (8) in the last inequality. Now for the case where w · w∗ ≤ 0, it holds w∗ = αw + v with α ≤ 0. Considering instead A = {x ∈ Rd : w · x ≤ 0, ˜v · x ∈ (R/16, R/8) ∪ (3R/8, R/2)} and similarly B = {x ∈ Rd : w · x ≤ 0, ˜v · x ∈ (R/16, R/8)}, B′ = {x ∈ Rd : w · x ≤ 0, ˜v · x ∈ (R/3, R/2)}, then all the steps above remains valid without modification. This completes the proof of Lemma 3.2. 3.2 Closeness of Idealized and Attainable Activations In this section, we bound the contribution of the error incurred from working with attainable link functions ˆut in the iterations of the algorithm. The error incurred is due to both the arbitrary noise in the labels and due to using a finite sample set. In bounding the error, for analysis purposes, we introduce auxiliary population-level link functions. Concretely, given w ∈ B(W), a population-optimal activation is a solution to the following stochastic convex program: uw ∈ argmin u∈U(a,b) E (x,y)∼D[(u(w · x) − y)2]. (EP) We further introduce auxiliary “idealized, noiseless” activations, which, given noiseless labels y∗ = u∗(w∗ · x) and a parameter weight vector w, are defined via u∗ w ∈ argmin u∈U(a,b) E (x,y)∼D[(u(w · x) − y∗)2]. (EP*) 11 Below we relate ut := uwt and u∗t := u∗ wt and show that their L2 2 error for the parameter vector wt is bounded by OPT. The proof of Lemma 3.3 is deferred to Appendix C.1. Lemma 3.3 (Closeness of Population-Optimal Activations). Let wt ∈ B(W) and let u∗t, ut be defined as solutions to (EP*), (EP), respectively. Then, E x∼Dx[(ut(wt · x) − u∗t(wt · x))2] ≤ OPT. As a consequence of the lemma above, we are able to relate ˆut to the “noiseless” labels y∗ = u∗(w∗ · x) by showing that the L2 2 distance between u∗(w∗ · x) and the sample-optimal activation ˆut(wt·x) is bounded by ∥wt−w∗∥2 2. Although Corollary 3.4 is not used in the proof of Proposition 3.1, we still present it here as it justifies the mechanism of our approach alternating between updates for wt and ˆut. The proof of Corollary 3.4 can be found in Appendix C.2. Corollary 3.4 (Closeness of Idealized and Attainable Activations). Let ϵ, δ > 0. Given a parameter wt ∈ B(W) and m ≳ d log4(d/(ϵδ))(b2W 3/(L2ϵ))3/2 samples from D, let ˆut be the sample-optimal activation on these samples given wt, as defined in (P). Then, with probability at least 1 − δ, E x∼Dx[(ˆut(wt · x) − u∗(w∗ · x))2] ≤ 3(ϵ + OPT + b2∥wt − w∗∥2 2) . 3.3 Proof of Proposition 3.1 We are now ready to prove our main structural result. We focus here on the main argument, while the proofs of supporting technical claims are deferred to Appendix C. Proof of Proposition 3.1. Given any weight parameter wt ∈ B(W) and ˆut chosen as its corresponding sample-optimal solution to problem (P), let ut be the population-optimal activation, as defined by Problem (EP). Given a sample set S = {(x(i), y(i))}m i=1, consider an idealized, “noise-free” set S∗ that assigns realizable labels to data vectors from S, i.e., S∗ = {(x(i), y∗(i))}m i=1, y∗(i) = u∗(w∗ · x(i)). Further define idealized sample-optimal activations by ˆu∗ w ∈ argmin u∈U(a,b) 1 m m X i=1 (u(w · x(i)) − y∗(i))2. (P*) For a parameter wt, denote ˆu∗t := ˆu∗ wt, for simplicity, and recall that the population version of ˆu∗t was defined by (EP*). To prove Proposition 3.1, we decompose ∇ bLsur(wt; ˆut) · (wt − w∗) into three summation terms: ∇ bLsur(wt; ˆut) · (wt − w∗) = 1 m m X i=1 (ˆut(wt · x(i)) − y(i))(wt − w∗) · x(i) = 1 m m X i=1 (ˆut(wt · x(i) − ˆu∗t(wt · x(i)))(wt − w∗) · x(i) | {z } Q1 + 1 m m X i=1 (ˆu∗t(wt · x(i)) − y∗(i))(wt − w∗) · x(i) | {z } Q2 + 1 m m X i=1 (y∗(i) − y(i))(wt · x(i) − w∗ · x(i)) | {z } Q3 . (9) 12 We tackle each term Q1 to Q3 in (9) separately, using the following arguments relying on three auxiliary claims. Because the proofs of these claims are technical, we defer them to Appendix C. The first claim states that Q1 is of the order (√ϵ + √ OPT)∥wt − w∗∥2 + (OPT + ϵ)/b with high probability. Claim 3.5. Let S = {(x(i), y(i))}m i=1 be i.i.d. samples from D where m is as specified in the statement of Proposition 3.1. Let ˆut be the solution of optimization problem (P) given wt ∈ B(W) and S. Furthermore, denote the idealized version of S by S∗ = {(x(i), y∗(i))}m i=1, where y∗(i) = u∗(w∗ · x(i)). Let ˆu∗t be the solution of problem (P*). Then, with probability at least 1 − δ, Q1 = 1 m m X i=1 ((ˆut(wt·x(i))−ˆu∗t(wt·x(i)))(wt−w∗)·x(i) ≥ −(√ϵ+ √ OPT)∥wt−w∗∥2−(ϵ+OPT)/b . The proof of Claim 3.5 is based on the following argument: first, standard concentration arguments ensure that ˆut and ˆu∗t are close to their population counterparts, ut and u∗t, in L2 2 distance (see Appendix F). Therefore, applying Chebyshev’s inequality, we are able to swap the sample-optimal activations in (9) by their population-optimal counterparts with high probability and focus on bounding 1 m m X i=1 (ut(wt · x(i)) − u∗t(wt · x(i)))(wt − w∗) · x(i) . To bound this quantity, we leverage the result from Lemma 3.3, namely that Ex∼Dx[(ut(wt · x) − u∗t(wt · x))2] ≤ OPT. The second claim leverages the misalignment lemma (Lemma 3.2) and shows that, up to small errors, Q2 is a constant multiple of ∥(w∗)⊥wt∥2 2. Claim 3.6. Let S∗ = {(x(i), y∗(i))}m i=1 be a sample set such that x(i)’s are i.i.d. samples from Dx and y∗(i) = u∗(w∗ · x(i)) for each i. Let m be the value specified in the statement of Proposition 3.1. Then, given a parameter wt ∈ B(W), with probability at least 1 − δ, Q2 = 1 m m X i=1 (ˆu∗t(wt · x(i)) − y∗(i))(wt − w∗) · x(i) ≥ Ca2LR4 b ∥(w∗)⊥wt∥2 2 − √ϵ∥wt − w∗∥2 − ϵ/b , where C is an absolute constant. The proof of Claim 3.6 is rather technical. We first define an ‘empirical inverse’ of the activation u∗, and denote it by ˆf. Note that u∗(z) ∈ U(a,b) is not necessarily strictly increasing when z ≤ 0, therefore (u∗)−1 is not defined everywhere on R, and the introduction of this ‘empirical inverse’ function ˆf is needed. Then, adding and subtracting ˆf(ˆu∗t(wt · x(i))) in the wt · x(i) − w∗ · x(i) term, we get 1 m m X i=1 (ˆu∗t(wt · x(i)) − u∗(w∗ · x(i)))(wt − w∗) · x(i) = 1 m m X i=1 (ˆu∗t(wt · x(i)) − u∗(w∗ · x(i)))(wt · x(i) − ˆf(ˆu∗t(wt · x(i)))) + 1 m m X i=1 (ˆu∗t(wt · x(i)) − u∗(w∗ · x(i)))( ˆf(ˆu∗t(wt · x(i))) − w∗ · x(i)) . 13 Analyzing the KKT conditions of the optimization problem (P*), we argue that the first term in the equation above is always positive. Then, we argue that our definition of the empirical inverse ˆf ensures that the second term can be bounded below by 1 bm Pm i=1(ˆu∗t(wt · x(i)) − u∗(w∗ · x(i)))2. Using standard concentration arguments, the quantity above concentrates around its expectation Ex∼Dx[(ˆu∗t(wt · x) − u∗(w∗ · x))2], hence we complete the proof applying Lemma 3.2. Similar to Claim 3.5, the last claim shows that Q3 is of the order √ OPT∥w∗ − wt∥2, which is small compared to the positive term in Claim 3.6 outside the set of O(OPT) + ϵ error solutions. Claim 3.7. Let S = {(x(i), y(i))}m i=1 be i.i.d. samples from D, and denote by S∗ = {(x(i), y∗(i))}m i=1 the idealized version of S, where y∗(i) = u∗(w∗ · x(i)). Under the condition of Proposition 3.1, given a parameter wt ∈ B(W), with probability at least 1 − δ, Q3 = 1 m m X i=1 (y∗(i) − y(i))(wt · x(i) − w∗ · x(i)) ≥ − √ OPT∥w∗ − wt∥2 − (OPT + ϵ)/b . The proof of Claim 3.7 follows via similar arguments as the proof of Claim 3.5. Plugging the bounds from Claim 3.5, Claim 3.6, and Claim 3.7 back into (9) and using a union bound, we get that with probability at least 1 − 3δ, ∇ bLsur(wt; ˆut) · (wt − w∗) ≥ Ca2LR4 b ∥(w∗)⊥wt∥2 2 − 2( √ OPT + √ϵ)∥wt − w∗∥2 − 2(OPT + ϵ)/b, for some absolute constant C, completing the proof. 4 Robust SIM Learning via Alignment Sharpness As discussed in Section 1.2, our algorithm can be viewed as employing an alternating procedure: taking a Riemannian gradient descent step on a sphere with respect to the empirical surrogate, given an estimate of the activation, and optimizing the activation function on the sample set for a given parameter weight vector. This procedure is performed using a fine grid of guesses of the scale of ∥w∗∥2. For this process to converge with the desired linear rate (even for a known value of ∥w∗∥2), the algorithm needs to be properly initialized to ensure that the initial weight vector has a nontrivial alignment with the optimal vector w∗. The initialization process is handled in the following subsection. 4.1 Initialization We begin by showing that the Initialization subroutine stated in Algorithm 1 returns a point ¯w0 that has a sufficient alignment with w∗. As will become apparent later in the proof of Theorem 4.2, this property of the initial point is critical for Algorithm 2 to converge at a linear rate. Lemma 4.1 (Initialization). Let µ = Ca2LR4/b for an absolute constant C > 0 and let ϵ, δ > 0. Choose the step size η = µ3/(27b4) in Algorithm 1. Then, drawing m0 i.i.d. samples from D at each iteration such that m0 ≳ W 9/2b10d log4(d/(ϵδ)) L4µ6δϵ3/2 , ensures that within t0 ≲ b6 log(b/µ)/µ6 iterations, the initialization subroutine Algorithm 1 generates a list of size t0 that contains a point ¯w0 such that ∥(w∗)⊥ ¯ w0∥2 ≤ max{µ∥w∗∥2/(4b), 64b2/µ3( √ OPT + √ϵ)}, with probability at least 1 − δ. The total number of samples required for Algorithm 1 is N0 = t0m0. 14 Algorithm 1 Initialization 1: Input: w0 = 0; ϵ, δ > 0; positive parameters a, b, L, R, W; µ ≲ a2LR4/b, step size η = µ3/(27b4), number of iterations t0 ≲ (b/µ)6 log(b/µ); 2: for t = 0 to t0 do 3: Draw m0 ≳ W 9/2b10d log4(d/(ϵδ))/(L4µ6δϵ3/2) i.i.d. samples from D 4: ˆut = argmin u∈U(a,b) 1 m0 m0 P i=1 (u(wt · x(i)) − y(i))2. 5: ∇ bLsur(wt; ˆut) = 1 m0 m0 P i=1 (ˆut(wt · x(i)) − y(i))x(i). 6: wt+1 = wt − η∇ bLsur(wt; ˆut). 7: end for 8: Return: {w0, . . . , wt0} Proof. Consider first the case that ∥w∗∥2 ≤ 64b2/µ3( √ OPT + √ϵ). Then, for the parameter vector w0 = 0, we have ∥(w∗)⊥w0∥2 = ∥w∗∥2 ≤ 64b2/µ3( √ OPT + √ϵ) and the claimed statement holds trivially. Thus, in the rest of the proof we assume ∥w∗∥2 ≥ 64b2/µ3( √ OPT + √ϵ). Let vt denote the component of w∗ that is orthogonal to wt; i.e., vt = w∗ − (w∗ · wt)wt/∥wt∥2 2 = (w∗)⊥wt, where wt is defined in Algorithm 1. Our goal is to show that when ∥vt∥2 ≥ µ∥w∗∥2/(4b) at iteration t, the distance between wt+1 and w∗ contracts by a constant factor 1 − c for some c < 1, i.e., ∥wt+1 − w∗∥2 ≤ (1 − c)∥wt − w∗∥2. This implies that when ∥vt∥2 is greater than µ∥w∗∥2/(4b), ∥wt+1 − wt∥2 contracts until ∥vt∥2 ≥ µ∥w∗∥2/(4b) is violated at step t0; this wt0 is exactly the initial point we are seeking to initialize the optimization subroutine. Applying Proposition 3.1, we get that under our choice of batch size m, with probability at least 1 − δ, at each iteration it holds ∇ bLsur(wt; ˆut) · (wt − w∗) ≥ Ca2LR4 b ∥(w∗)⊥wt∥2 2 − 2( √ OPT + √ϵ)∥wt − w∗∥2 − 2(OPT + ϵ)/b . We now study the distance between wt+1 and w∗, where wt+1 is updated from wt according to Algorithm 1. ∥wt+1 − w∗∥2 2 = ∥wt − η∇ bLsur(wt; ˆut) − w∗∥2 2 = ∥wt − w∗∥2 2 + η2∥∇ bLsur(wt; ˆut)∥2 2 − 2η∇ bLsur(wt; ˆut) · (wt − w∗) . (10) Applying Lemma 4.3 to (10), and plugging in Proposition 3.1, we get that under our choice of batch size m it holds that with probability at least 1 − δ, ∥wt+1 − w∗∥2 2 ≤ ∥wt − w∗∥2 2 + η2(10(OPT + ϵ) + 4b2∥wt − w∗∥2 2) + 2η(2(OPT + ϵ)/b + 2( √ OPT + √ϵ)∥wt − w∗∥2 − µ∥vt∥2 2) ≤ (1 + 4b2η2)∥wt − w∗∥2 2 + 2η(2( √ OPT + √ϵ)∥wt − w∗∥2 − µ∥vt∥2 2) + 5η(OPT + ϵ) , (11) where µ = Ca2LR4/b and C is an absolute constant. Note that in the last inequality we used that η ≤ 1/10, hence 10η2 ≤ η, and that b ≥ 1. 15 When t = 0, v0 = w∗, hence we have ∥v0∥2 ≥ µ∥w∗∥2/(4b). Suppose that at iteration t, ∥vt∥2 ≥ µ∥w∗∥2/(4b) is still valid. Then, (11) is transformed to: ∥wt+1 − w∗∥2 2 ≤ (1 + 4b2η2)∥wt − w∗∥2 2 + 5η(OPT + ϵ) + 2η((µ3/(32b2))∥wt − w∗∥2∥w∗∥2 − (µ3/(16b2))∥w∗∥2 2) . (12) We use an inductive argument to show that at iteration t, ∥wt−w∗∥2 ≤ ∥w∗∥2, which must eventually yield a contraction ∥wt+1 − w∗∥2 2 ≤ (1 − c)∥wt − w∗∥2 2 for some constant c < 1. This condition ∥wt − w∗∥2 ≤ ∥w∗∥2 certainly holds for the base case t = 0 as w0 = 0, hence ∥w0 − w∗∥2 = ∥w∗∥2. Now, suppose ∥wt − w∗∥2 ≤ ∥w∗∥2 holds for all the iterations from 0 to t. Then, plugging η = µ3/(27b4) into (12), we get: ∥wt+1 − w∗∥2 2 ≤ (1 + 4b2η2)∥wt − w∗∥2 2 + 2η((µ3/(32b2)) − (µ3/(16b2)))∥wt − w∗∥2∥w∗∥2 + 5η(OPT + ϵ) ≤ (1 + 4η2b2 − 2ηµ3/(32b2))∥wt − w∗∥2 2 + 5µ3/(27b4)(OPT + ϵ) ≤ (1 − µ6/(211b6))∥wt − w∗∥2 2 + 5µ3/(27b4)(OPT + ϵ) . Since we have assumed √ OPT+√ϵ ≤ µ3/(64b2)∥w∗∥2, it holds ∥wt−w∗∥2 ≥ ∥vt∥2 ≥ µ∥w∗∥2/(4b) ≥ (16b/µ2)( √ OPT + √ϵ), thus, we have (noting that µ ≤ 1): 5µ3/(27b4)(OPT + ϵ) ≤ 5µ3/(27b4)( √ OPT + √ϵ)2 ≤ µ6/(212b6)∥wt − w∗∥2 . Therefore, combining the results above, we get: ∥wt+1 − w∗∥2 2 ≤ (1 − µ6/(212b6))∥wt − w∗∥2 2 , for any iteration t such that ∥vt∥2 ≥ µ∥w∗∥2/(4b) holds. This validates the induction argument that ∥wt − w∗∥2 ≤ ∥w∗∥2 for every t = 0, . . . , t0 and at the same time yields the desired contraction property of the sequence ∥wt−w∗∥2, t = 0, . . . , t0. Now, since ∥w0−w∗∥2 = ∥w∗∥2 and ∥wt−w∗∥2 ≥ ∥vt∥2, we have ∥vt+1∥2 2 ≤ (1 − µ6/(212b6))t∥w∗∥2 2 ≤ exp(−tµ6/(212b6))∥w∗∥2 2 . Thus, after at most t0 = 212b6 log(4b/µ)/µ6 iterations, it must hold that among all those vectors v1, . . . , vt0, there exists a vector vt∗ 0 such that ∥vt∗ 0∥2 ≤ µ∥w∗∥2/(4b). Since there are only a constant number of candidates, we can feed each one as the initialized input to the optimization subroutine Algorithm 2. This will only result in a constant factor increase in the runtime and sample complexity. Finally, recall that we need to draw m ≳ W 9/2b4 log4(d/(ϵδ)) L4 \u0012 1 ϵ3/2 + 1 ϵδ \u0013 new samples at each iteration for (11) to hold with probability 1 − δ, and the total number of iterations is t0. Thus, applying a union bound, we know that the probability that (11) holds for all t0 is 1 − t0δ. Hence, choosing δ ← δt0, and noting that t0 ≈ b6/µ6 log(b/µ), it follows that setting the batch size to be m0 = Θ \u0012W 9/2b4 log4(d/(ϵδ)) L4 \u0012 1 ϵ3/2 + b6 log(b/µ) µ6ϵδ \u0013\u0013 = Θ \u0012W 9/2b10d log4(d/(ϵδ)) L4µ6δϵ3/2 \u0013 , suffices and the total number of samples required for the initialization process is t0m0. 16 4.2 Optimization Our main optimization algorithm is summarized in Algorithm 2 (see Algorithm 4 for a more detailed version). We now provide intuition for how guessing the value of ∥w∗∥2 is used in the convergence analysis. Let wt = ∥w∗∥2 ¯wt/∥ ¯wt∥2 so that ∥wt∥2 = ∥w∗∥2 and let vt := (w∗)⊥wt. Observe that ∥vt∥2 = ∥wt − w∗∥2 cos(θ(wt, w∗)/2). Applying Proposition 3.1, it can be shown that ∥ ¯wt+1 − w∗∥2 2 ≤ ∥wt − w∗∥2 2 − C∥vt∥2 2 for some constant C. Thus, as long as the angle between wt and w∗ is not too large (ensured by initialization), ∥wt − w∗∥2 ≈ ∥vt∥2. Hence, we can argue that ∥wt − w∗∥2 contracts in each iteration, by observing that ∥wt − w∗∥2 2 ≈ ∥vt+1∥2 2 ≤ ∥ ¯wt+1 − w∗∥2 2. Algorithm 2 Optimization 1: Input: wini = 0; ϵ > 0; positive parameters: a, b, L, R, W, µ; step size η 2: {wini 0 , . . . , wini t0 } = Initialization[wini] (Algorithm 1) 3: P = {(w = 0; u(z) = 0)} 4: for k = 0 to t0 ≲ (b/µ)6 log(b/µ) do 5: for j = 1 to J = W/(η√ϵ) do 6: ¯w0 j,k = wini k , βj = jη√ϵ 7: for t = 0 to T = O((b/µ)2 log(1/ϵ)) do 8: bwt j,k = βj( ¯wt j,k/∥ ¯wt j,k∥2) 9: Draw m = ˜ΘW,b,1/L,1/µ(d/ϵ3/2) new samples 10: ˆut j,k = argmin u∈U(a,b) 1 m m P i=1 (u(bwt j,k · x(i)) − y(i))2 11: ¯wt+1 j,k = bwt j,k − η∇ bLsur(bwt j,k; ˆut j,k) 12: end for 13: P ← P ∪ {(bwT j,k; ˆuT j,k)} 14: end for 15: end for 16: (bw; ˆu) = Test[(w; u) ∈ P] (Algorithm 3) 17: Return: (bw; ˆu) Our main result is the following theorem (see Theorem D.1 for a more detailed statement and proof in Appendix D.1): Theorem 4.2 (Main Result). Let D be a distribution in Rd × R and suppose that Dx is (L, R)- well-behaved. Let U(a,b) be as in Definition 1.3 and let ϵ > 0. Then, Algorithm 2 uses N = ˜OW,b,1/L,1/µ(d/ϵ2) samples, it runs for ˜OW,b,1/µ(1/√ϵ) iterations, and, with probability at least 2/3, re- turns a hypothesis (ˆu, bw), where ˆu ∈ U(a,b) and bw ∈ B(W), such that L2(bw; ˆu) = O1/L,1/R,b/a(OPT)+ ϵ . To prove Theorem 4.2, we make use of two technical results stated below. First, Lemma 4.3 provides an upper bound on the norm of the empirical gradient of the surrogate loss. The proof of the lemma relies on concentration properties of (L, R)-well behaved distributions Dx, and leverages the uniform convergence of the empirically-optimal activations ˆut. A more detailed statement (Lemma D.5) and the proof of Lemma 4.3 is deferred to Appendix D.2. Lemma 4.3 (Bound on Empirical Gradient Norm). Let S be a set of i.i.d. samples from D of size m = ˜ΘW,b,1/L(d/ϵ3/2 + d/(ϵδ)). Given any wt ∈ B(W), let ˆut ∈ U(a,b) be the solution of optimization problem (P) with respect to wt and sample set S. Then, with probability at least 1 − δ, ∥∇ bLsur(wt; ˆut)∥2 2 ≤ 4b2∥wt − w∗∥2 2 + 10(OPT + ϵ) . 17 The following claim bounds the L2 2 error of a hypothesis ˆuw(w · x) by the distance between w and w∗. We defer a more detailed statement (Claim D.6) and the proof to Appendix D.3. Claim 4.4. Let w ∈ B(W) be any fixed vector. Let ˆuw be defined by (P) given w and a sample set of size m = ˜ΘW,b,1/L(d/ϵ3/2). Then, E(x,y)∼D[(ˆuw(w · x) − y)2] ≤ 8(OPT + ϵ) + 4b2∥w − w∗∥2 2. Proof Sketch of Theorem 4.2. For this sketch, we consider the case ∥w∗∥2 ≳ b3/µ4( √ OPT + √ϵ) so that the initialization subroutine generates a point wini k∗ ∈ {wini k }t0 k=1 such that ∥(w∗) ⊥wini k∗ ∥2 ≤ µ∥w∗∥2/(4b), by Lemma 4.1. Fix this initialized parameter ¯w0 j,k∗ = wini k∗ at step k∗ and drop the subscript k∗ for simplicity. Since we constructed a grid with width η√ϵ, there exists an index j∗ such that |βj∗ − ∥w∗∥2| ≤ η√ϵ. We consider the intermediate for-loop at this iteration j∗, and show that the inner loop with normalization factor βj∗ outputs a solution with error O(OPT) + ϵ. This solution can be selected using standard testing procedures. We now focus on the iteration j∗, and drop the subscript j∗ for notational simplicity. Let wt = ∥w∗∥2( ¯wt/∥ ¯wt∥2) and denote vt := (w∗)⊥ b wt. Expanding ∥ ¯wt+1 − w∗∥2 2 and applying Proposition 3.1 and Lemma 4.3, we get ∥ ¯wt+1 − w∗∥2 2 = ∥bwt − η∇ bLsur(bwt; ˆut) − w∗∥2 2 = ∥bwt − w∗∥2 2 + η2∥∇ bLsur(bwt; ˆut)∥2 2 − 2η∇ bLsur(bwt; ˆut) · (bwt − w∗) ≤ ∥bwt − w∗∥2 2 + η2(10(OPT + ϵ) + 4b2∥bwt − w∗∥2 2) + 2η(2( √ OPT + √ϵ)∥bwt − w∗∥2 − µ∥vt∥2 2) + 4η(OPT + ϵ)/b ≤ (1 + 4η2b2)∥wt − w∗∥2 2 + (24η2 + 4η/b)(OPT + ϵ) + 2η(2( √ OPT + √ϵ)∥wt − w∗∥2 − µ∥vt∥2 2), (13) where in the last inequality we used ∥bwt − wt∥2 = |βj∗ − ∥w∗∥2| ≤ η√ϵ. Since wt and w∗ are on the same sphere, ∥wt − w∗∥2 ≤ ∥vt∥2. In particular, letting ρt = ∥vt∥2/∥w∗∥2, we have ∥wt − w∗∥2 2 ≤ (1 + ρ2 t )∥vt∥2 2 ≤ 2∥vt∥2 2. Recall that the algorithm is initialized from ¯w0 that satisfies ρ0 ≤ µ/(4b). If ρt ≤ µ/(4b), then ∥wt − w∗∥2 2 ≤ (1 + (µ/(4b))2)∥vt∥2 2. Assuming in addition that ∥vt∥2 ≳ (1/µ)( √ OPT + √ϵ), and choosing the step-size η = µ/(4b2), (13) implies that ∥vt+1∥2 2 ≤ ∥ ¯wt+1 − w∗∥2 2 ≤ (1 − µ2/(32b2))∥vt∥2 2 , and thus, in addition, ρt+1 ≤ µ/(4b). Therefore, by an inductive argument, we show that as long as wt is still far from w∗, i.e., ∥vt∥2 ≳ (1/µ)( √ OPT + √ϵ), we have ∥vt+1∥2 2 ≤ (1 − µ2/(32b2))∥vt∥2 2 and ρt+1 ≤ µ/(4b) . Hence, after T = O((b2/µ2) log(1/ϵ)) iterations, it must be ∥vT ∥2 ≲ (1/µ)( √ OPT + √ϵ), which implies ∥wT − w∗∥2 2 ≤ 2∥vT ∥2 2 = O(OPT) + ϵ . Finally, by Claim 4.4, hypothesis ˆuT (bwT · x) achieves L2 2-error O(OPT) + ϵ, which completes the proof. 4.3 Testing We now briefly discuss the testing procedure, which allows our algorithm to select a hypothesis with minimum empirical error while maintaining validity of the claims. This part relies on standard arguments and is provided for completeness. Concretely, we rely on the following claim, whose proof can be found in Appendix D.4. 18 Algorithm 3 Testing 1: Input: ϵ > 0; positive parameters: a, b, L, R, W; list of solutions P; let r ≳ 1 L log(bW/(Lϵ) log2(1/ϵ)) 2: Draw m′ ≳ (bW/L)4 log5(1/ϵ)/ϵ2 new i.i.d. samples from D. 3: (bw; ˆu) = argmin(w;u)∈P{ 1 m′ Pm′ i=1(u(w · x(i)) − y(i))21{|w · x(i)| ≤ Wr} }. 4: Return: (bw; ˆu) Claim 4.5. Let µ, ϵ1, δ ∈ (0, 1) be fixed. Let r = 1 L log( Cb4W 4 L6ϵ2 1 log2( bW ϵ1 )), where C is a sufficiently large absolute constant. Given a set of parameter-activation pairs P = {(wj; uj)}t0J j=1 such that wj ∈ B(W) and uj ∈ U(a,b) for j ∈ [t0J], where t0J = 4b9W/(µ8√ϵ1), we have that using m′ = Θ \u0012b4W 4 log(1/δ) L4ϵ2 1 log5 \u0012 bW Lµϵ1 \u0013\u0013 , i.i.d. samples from D, for any (wj; uj) ∈ P it holds with probability at least 1 − δ, \f\f\f\f 1 m′ m′ X i=1 (uj(wj · x(i)) − y(i))21{|wj · x(i)| ≤ Wr} − E (x,y)∼D[(uj(wj · x) − y)2] \f\f\f\f ≤ 2ϵ1. Therefore, Claim 4.5 guarantees that selecting a hypothesis using the provided testing procedure introduces an error at most 2ϵ1, with high probability. 5 Conclusion We presented the first constant-factor approximate SIM learner in the agnostic model, for the class of (a, b)-unbounded link functions under mild distributional assumptions. Immediate questions for future research involve extending these results to other classes of link functions. More specifically, our results require that b/a is bounded by a constant. It is an open question whether the constant-factor approximation result in the agnostic model can be extended to all b-Lipschitz functions (with a = 0). This question is open in full generality, even when the link function is known to the learner. References [ATV23] P. Awasthi, A. Tang, and A. Vijayaraghavan. Agnostic learning of general ReLU activation using gradient descent. In The Eleventh International Conference on Learning Representations, ICLR, 2023. [BNPS17] J. Bolte, T. P. Nguyen, J. Peypouquet, and B. W. Suter. From error bounds to the complexity of first-order descent methods for convex functions. Mathematical Programming, 165(2):471–507, 2017. [BNS16] S. Bhojanapalli, B. Neyshabur, and N. Srebro. Global optimality of local search for low rank matrix recovery. Advances in Neural Information Processing Systems, 29, 2016. [DGK+20] I. Diakonikolas, S. Goel, S. Karmalkar, A. R. Klivans, and M. Soltanolkotabi. Approxi- mation schemes for ReLU regression. In Conference on Learning Theory, COLT, volume 125 of Proceedings of Machine Learning Research, pages 1452–1485. PMLR, 2020. 19 [DH18] R. Dudeja and D. Hsu. Learning single-index models in Gaussian space. In Conference on Learning Theory, COLT, volume 75 of Proceedings of Machine Learning Research, pages 1887–1930. PMLR, 2018. [DJS08] A. S. Dalalyan, A. Juditsky, and V. Spokoiny. A new algorithm for estimating the effective dimension-reduction subspace. The Journal of Machine Learning Research, 9:1647–1678, 2008. [DKMR22] I. Diakonikolas, D. Kane, P. Manurangsi, and L. Ren. Hardness of learning a single neuron with adversarial label noise. In Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS), 2022. [DKPZ21] I. Diakonikolas, D. M. Kane, T. Pittas, and N. Zarifis. The optimality of polynomial regression for agnostic learning under Gaussian marginals in the SQ model. In Proceedings of The 34th Conference on Learning Theory, COLT, 2021. [DKR23] I. Diakonikolas, D. M. Kane, and L. Ren. Near-optimal cryptographic hardness of agnostically learning halfspaces and ReLU regression under Gaussian marginals. In ICML, 2023. [DKTZ20] I. Diakonikolas, V. Kontonis, C. Tzamos, and N. Zarifis. Learning halfspaces with massart noise under structured distributions. In Conference on Learning Theory, COLT, 2020. [DKTZ22] I. Diakonikolas, V. Kontonis, C. Tzamos, and N. Zarifis. Learning a single neuron with adversarial label noise via gradient descent. In Conference on Learning Theory (COLT), pages 4313–4361, 2022. [DKZ20] I. Diakonikolas, D. M. Kane, and N. Zarifis. Near-optimal SQ lower bounds for agnosti- cally learning halfspaces and ReLUs under Gaussian marginals. In Advances in Neural Information Processing Systems, NeurIPS, 2020. [FCG20] S. Frei, Y. Cao, and Q. Gu. Agnostic learning of a single neuron with gradient descent. In Advances in Neural Information Processing Systems, NeurIPS, 2020. [FP03] F. Facchinei and J-S. Pang. Finite-dimensional variational inequalities and complemen- tarity problems. Springer, 2003. [GGK20] S. Goel, A. Gollakota, and A. R. Klivans. Statistical-query lower bounds via functional gradients. In Advances in Neural Information Processing Systems, NeurIPS, 2020. [GGKS23] A. Gollakota, P. Gopalan, A. R. Klivans, and K. Stavropoulos. Agnostically learning single-index models using omnipredictors. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. [Hau92] D. Haussler. Decision theoretic generalizations of the PAC model for neural net and other learning applications. Information and Computation, 100:78–150, 1992. [HJS01] M. Hristache, A. Juditsky, and V. Spokoiny. Direct estimation of the index coefficient in a single-index model. Annals of Statistics, pages 595–623, 2001. [HMS+04] W. Härdle, M. Müller, S. Sperlich, A. Werwatz, et al. Nonparametric and semiparametric models, volume 1. Springer, 2004. 20 [Hof52] A. J. Hoffman. On approximate solutions of systems of linear inequalities. Journal of Research of the National Bureau of Standards, 49:263–265, 1952. [Ich93] H. Ichimura. Semiparametric least squares (SLS) and weighted SLS estimation of single-index models. Journal of econometrics, 58(1-2):71–120, 1993. [JGN+17] C. Jin, R. Ge, P. Netrapalli, S. Kakade, and M. Jordan. How to escape saddle points efficiently. In International conference on machine learning, pages 1724–1732. PMLR, 2017. [KKSK11] S. M Kakade, V. Kanade, O. Shamir, and A. Kalai. Efficient learning of generalized linear and single index models with isotonic regression. Advances in Neural Information Processing Systems, 24, 2011. [KNS16] H. Karimi, J. Nutini, and M. Schmidt. Linear convergence of gradient and proximal- gradient methods under the Polyak-łojasiewicz condition. In Joint European conference on machine learning and knowledge discovery in databases, pages 795–811, 2016. [KS09] A. T. Kalai and R. Sastry. The isotron algorithm: High-dimensional isotonic regression. In COLT, 2009. [KSS94] M. Kearns, R. Schapire, and L. Sellie. Toward efficient agnostic learning. Machine Learning, 17(2/3):115–141, 1994. [LCP22] J. Liu, Y. Cui, and J-S. Pang. Solving nonsmooth and nonconvex compound stochastic programs with applications to risk measure minimization. Mathematics of Operations Research, 2022. [LH22] C. Lu and D. S. Hochbaum. A unified approach for a 1D generalized total variation problem. Mathematical Programming, 194(1-2):415–442, 2022. [Łoj63] S. Łojasiewicz. Une propriété topologique des sous-ensembles analytiques réels. Les équations aux dérivées partielles, 117:87–89, 1963. [Łoj93] S. Łojasiewicz. Sur la géométrie semi-et sous-analytique. In Annales de l’institut Fourier, volume 43, pages 1575–1595, 1993. [MR18] P. Manurangsi and D. Reichman. The computational complexity of training ReLU(s). arXiv preprint arXiv:1810.04207, 2018. [Rd17] V. Roulet and A. d’Aspremont. Sharpness, restart and acceleration. Advances in Neural Information Processing Systems, 30, 2017. [Sím02] J. Síma. Training a single sigmoidal neuron is hard. Neural Computation, 14(11):2709– 2728, 2002. [WZDD23] P. Wang, N. Zarifis, I. Diakonikolas, and J. Diakonikolas. Robustly learning a single neuron via sharpness. 40th International Conference on Machine Learning, 2023. [ZL16] Q. Zheng and J. Lafferty. Convergence analysis for rectangular matrix completion using Burer-Monteiro factorization and gradient descent. arXiv preprint arXiv:1605.07051, 2016. [ZY13] H. Zhang and W. Yin. Gradient methods for convex minimization: better rates under weaker conditions. arXiv preprint arXiv:1303.4645, 2013. 21 Appendix Organization The appendix is organized as follows. In Appendix A, we highlight some useful properties about the distribution class and the activation class. Appendix B reviews local error bounds and discussed their relation to our alignment sharpness structural result. In Appendix C, we provide detailed proofs omitted from Section 3, and in Appendix D we complete the proofs omitted from Section 4. In Appendix E, we provide a detailed discussion about computing the sample-optimal activation. Finally, in Appendix F we state and prove standard uniform convergence results that are used throughout the paper. A Remarks about the Distribution Class and the Activation Class In this section, we show that without the loss of generality we can assume that the parameters L, R in the distributional assumptions (Definition 1.2) can be taken less than 1, while the parameters a, b of the activations functions (see Definition 1.3) can be taken as a, 1/b ≤ 1. Remark A.1 (Distribution/Activation Parameters, (Definition 1.2 & Definition 1.3)). We observe that if a distribution Dx is (L, R)-well-behaved, then it is also (L′, R′)-well-behaved for any 0 < L′ ≤ L, 0 < R′ ≤ R. Hence, it is without loss of generality to assume that L, R ∈ (0, 1]. Similarly, if an activation is (a, b)-unbounded, it is also an (a, b′)-unbounded activation with b′ ≥ b. Thus, we assume that b ≥ 1. We can similarly assume a ≤ 1. In addition, we remark that the (L, R)-well behaved distributions are sub-exponential. Remark A.2 (Sub-exponential Tails of Well-Behaved Distributions, Definition 1.2). Definition 1.2 might seem abstract, but to put it plain it implies that the random variable x has a (1/L)-sub- exponential tail, and that the pdf of the projected random variable xV onto the space V is lower bounded by L. To see the first statement, given any unit vector p, let xp be the projection of x onto the one-dimensional linear space Vp = {z ∈ Rd : z = tp, t ∈ R}, i.e., xp = p · x ∈ Vp. Then, by the anti-concentration and concentration property, we have Pr[|p · x| ≥ r] = Pr[|xp| ≥ r] ≤ Z |x|≥r γ(x) dx ≤ 2 Z ∞ r 1 L exp(−Lx) dx = 2 L2 exp(−Lr), which implies that x possesses a sub-exponential tail. B Local Error Bounds and Alignment Sharpness Given a generic optimization problem minw f(w) and a non-negative residual function r(w) measuring the approximation error of the optimization problem, we say that the problem satisfies a local error bound if in some neighborhood of “test” (typically optimal) solutions W∗ we have that r(w) ≥ (µ/ν) dist(w, W∗)ν. (14) In other words, low value of the residual function implies that w must be close to the test set W∗. Local error bounds have been studied in the optimization literature for decades, starting with the seminal works of [Hof52, Łoj63]; see, e.g., Chapter 6 in [FP03] for an overview of classical results and [BNPS17, KNS16, Rd17, LCP22] and references therein for a more cotemporary overview. While local error bounds can be shown to hold generically under fairly minimal assumptions on f and for 22 r(w) = f(w) − minw′ f(w′) [Łoj63, Łoj93], it is rarely the case that they can be ensured to hold with a parameter µ that is not trivially small. On the other hand, learning problems often possess very strong structural properties that can lead to stronger local error bounds. There are two main such examples we are aware of, where local error bounds can be shown to hold with ν = 2 and an absolute constant µ > 0. The first example are low-rank matrix problems such as matrix completion and matrix sensing, which are unrelated to our work [BNS16, ZL16, JGN+17]. More relevant to our work is the recent result in [WZDD23], which proved a local error bound of the form r(w) ≥ µ 2 dist(w, W∗)2 (15) for the more restricted problem than ours (with a known activation function) but under somewhat more general distributional assumptions. In [WZDD23], the residual function was defined by r(wt) = ∇ bLsur(wt; u∗) · (wt − w∗), where ∇ bLsur(wt; u∗) is the gradient of an empirical surrogate loss, and the resulting local error bound referred to as “sharpness.”2 Our structural result can be seen as a weak notion of a local error bound, where the residual function for the empirical surrogate loss expressed as r(wt, ˆut) = ∇ bLsur(wt; ˆut)·(wt−w∗) is bounded below as a function of the magnitude of the component of w∗ that is orthogonal to wt. Compared to more traditional local error bounds and the bound from [WZDD23], which bound below the residual error function as a function of the distance to W∗, this is a much weaker local error bound since it does not distinguish between vectors of varying magnitudes along the direction of w∗. Since our lower bound is related to the “sharpness” notion studied in [WZDD23], we refer to it as the “alignment sharpness” to emphasize that it only relates the misalignment (as opposed to the distance) of vectors wt and w∗ to the residual error. To the best of our knowledge, such a form of a local error bound, which only bounds the alignment of vectors as opposed to their distance, is novel. We expect it to find a more broader use in learning theory and optimization. C Omitted Proofs from Section 3 This section provides full technical details for results omitted from Section 3. C.1 Proof of Lemma 3.3 To prove Lemma 3.3, we first prove the following auxiliary claim, which is inspired by [KKSK11, Lemma 9]. Claim C.1. Let wt ∈ B(W) and let u∗t, ut be defined as solutions to (EP*), (EP), respectively. Then, E (x,y)∼D[(ut(wt · x) − v(wt · x))(y − ut(wt · x))] ≥ 0, ∀ ∈ U(a,b). Similarly, E (x,y)∼D[(u∗t(wt · x) − v′(wt · x))(y∗ − u∗t(wt · x))] ≥ 0, ∀v′ ∈ U(a,b). Proof of Claim C.1. Denote by Ft the set of functions of the form f(x) = u(wt · x), where u ∈ U(a,b) and wt is a fixed vector in B(W). We first argue that Ft is a convex set, using the definition of 2A local error utilizing the same type of a residual was introduced in [ZY13] under the name “restricted secant inequality.” 23 convexity. In particular, for any α ∈ (0, 1) and any f1, f2 ∈ Ft such that f1(x) = u1(wt · x), f2 = u2(wt · x), let u3(·) = αu1(·) + (1 − α)u2(·). Then: αf1(x) + (1 − α)f2(x) = αu1(wt · x) + (1 − α)u2(wt · x) = u3(wt · x). It is immediate that u3 is also (a, b)-bounded, non-decreasing, and u3(0) = 0, hence u3 ∈ U(a,b) and f3(x) = u3(wt · x) ∈ Ft. Thus, Ft is convex. Since Ft is a convex set of functions, we can regard ut(wt · x) as the orthogonal projection of y (which is a function of x) onto the convex set Ft. Classic inequalities for orthogonal projections can then be applied to our case. In particular, below we prove that E (x,y)∼D[(ut(wt · x) − v(wt · x))(y − ut(wt · x))] ≥ 0, ∀v ∈ U(a,b). (16) To prove (16), note first that fu(x) = ut(wt · x) ∈ Ft and fv(x) = v(wt · x) ∈ Ft since ut, v ∈ U(a,b). Thus, for any α ∈ (0, 1), we have αfv(x) + (1 − α)fu(x) ∈ Ft. Furthermore, by definition of ut, ∀f ∈ Ft we have E(x,y)∼D[(ut(wt · x) − y)2] ≤ E(x,y)∼D[(f(x) − y)2], therefore, it holds: 0 ≤ 1 α E (x,y)∼D[(αfv(x) + (1 − α)fu(x) − y)2] − 1 α E (x,y)∼D[(ut(wt · x) − y)2] = 1 α E (x,y)∼D[(ut(wt · x) − y + α(v(wt · x) − ut(wt · x)))2 − (ut(wt · x) − y)2] = E (x,y)∼D[2(ut(wt · x) − y)(v(wt · x) − ut(wt · x)) + α(v(wt · x) − ut(wt · x))2]. Let α ↓ 0, and note that Ex∼Dx[(v(wt · x) − ut(wt · x))2] < +∞, we thus have E (x,y)∼D[(ut(wt · x) − v(wt · x))(y − ut(wt · x))] ≥ 0, proving the claim. The second claim can be proved following the same argument and is omitted for brevity. We now proceed to the proof of Lemma 3.3. Lemma 3.3 (Closeness of Population-Optimal Activations). Let wt ∈ B(W) and let u∗t, ut be defined as solutions to (EP*), (EP), respectively. Then, E x∼Dx[(ut(wt · x) − u∗t(wt · x))2] ≤ OPT. Proof. Summing up the first and second statement of Claim C.1 with v = u∗t ∈ U(a,b) in (16) and v′ = ut ∈ U(a,b), we get: 0 ≤ E (x,y)∼D[(ut(wt · x) − u∗t(wt · x))(y − ut(wt · x)) + (u∗t(wt · x) − ut(wt · x))(y∗ − u∗t(wt · x))] = E (x,y)∼D[(ut(wt · x) − u∗t(wt · x))(y − y∗ + u∗t(wt · x) − ut(wt · x))] = E (x,y)∼D[(ut(wt · x) − u∗t(wt · x))(y − y∗)] − E x∼Dx[(ut(wt · x) − u∗t(wt · x))2] Rearranging and applying the Cauchy-Schwarz inequality, we have E x∼Dx[(ut(wt · x) − u∗t(wt · x))2] ≤ E (x,y)∼D[(ut(wt · x) − u∗t(wt · x))(y − y∗)] ≤ r E x∼Dx[(ut(wt · x) − u∗t(wt · x))2] E[(y − y∗)2]. To complete the proof, it remains to recall that E[(y − y∗)2] = OPT and rearrange the last inequality. 24 C.2 Proof of Corollary 3.4 Corollary 3.4 (Closeness of Idealized and Attainable Activations). Let ϵ, δ > 0. Given a parameter wt ∈ B(W) and m ≳ d log4(d/(ϵδ))(b2W 3/(L2ϵ))3/2 samples from D, let ˆut be the sample-optimal activation on these samples given wt, as defined in (P). Then, with probability at least 1 − δ, E x∼Dx[(ˆut(wt · x) − u∗(w∗ · x))2] ≤ 3(ϵ + OPT + b2∥wt − w∗∥2 2) . Proof. The corollary follows directly from the combination of Lemma F.4 and Lemma 3.3, as we have: E x∼Dx[(ˆut(wt · x) − u∗(w∗ · x))2] = E x∼Dx[(ˆut(wt · x) − ut(wt · x) + ut(wt · x) − u∗t(wt · x) + u∗t(wt · x) − u∗(w∗ · x))2] ≤ 3( E x∼Dx[(ˆut(wt · x) − ut(wt · x))2] + E x∼Dx[(ut(wt · x) − u∗t(wt · x))2]) + 3 E x∼Dx[(u∗t(wt · x) − u∗(w∗ · x))2] ≤ 3(ϵ + OPT + b2∥wt − w∗∥2 2), where we used that because u∗t ∈ argminu∈U(a,b) Ex∼Dx[(u(wt·x)−u∗(w∗·x))2], we have Ex∼Dx[(u∗t(wt· x) − u∗(w∗ · x))2] ≤ Ex∼Dx[(u∗(wt · x) − u∗(w∗ · x))2] ≤ b2∥wt − w∗∥2 2, with the last inequality following from the fact that u∗ ∈ U(a,b). C.3 Proof of Claim 3.5 In this subsection, we prove Claim 3.5 that appeared in Section 3.3, the proof of Proposition 3.1. Claim 3.5. Let S = {(x(i), y(i))}m i=1 be i.i.d. samples from D where m is as specified in the statement of Proposition 3.1. Let ˆut be the solution of optimization problem (P) given wt ∈ B(W) and S. Furthermore, denote the idealized version of S by S∗ = {(x(i), y∗(i))}m i=1, where y∗(i) = u∗(w∗ · x(i)). Let ˆu∗t be the solution of problem (P*). Then, with probability at least 1 − δ, Q1 = 1 m m X i=1 ((ˆut(wt·x(i))−ˆu∗t(wt·x(i)))(wt−w∗)·x(i) ≥ −(√ϵ+ √ OPT)∥wt−w∗∥2−(ϵ+OPT)/b . Proof. Adding and subtracting ut(wt · x(i)) and u∗t(wt · x(i)), we have 1 m m X i=1 ((ˆut(wt · x(i)) − ˆu∗t(wt · x(i)))(wt − w∗) · x(i) = 1 m m X i=1 (ˆut(wt · x(i)) − ut(wt · x(i)))(wt − w∗) · x(i) + 1 m m X i=1 (u∗t(wt · x(i)) − ˆu∗t(wt · x(i)))(wt − w∗) · x(i) + 1 m m X i=1 (ut(wt · x(i)) − u∗t(wt · x(i)))(wt − w∗) · x(i). (17) To proceed, we use that both ˆu∗t(z) and ˆut(z) are close to their population counterparts ut(z) and u∗t(z), respectively. In particular, in Lemma F.4 and Lemma F.2, we show that using a dataset S of m samples such that m ≳ d log4(d/(ϵδ)) \u0012b2W 3 L2ϵ \u00133/2 , 25 we have that with probability at least 1 − δ, for all wt, w∗ ∈ B(W) it holds E x∼Dx[(ˆut(wt · x) − ut(wt · x))2] ≤ ϵ, E x∼Dx[(ˆu∗t(wt · x) − u∗t(wt · x))2] ≤ ϵ. (18) Now suppose that the inequalities in (18) hold for the given wt ∈ B(W) (which happens with probability at least 1 − δ). Applying Chebyshev’s inequality to the first summation term in (17), we get: Pr \u0014\f\f\f\f 1 m m X i=1 (ˆut(wt · x(i)) − ut(wt · x(i)))(wt − w∗) · x(i) − E x∼Dx[(ˆut(wt · x) − ut(wt · x))(wt − w∗) · x] \f\f\f\f ≥ s \u0015 ≤ 1 ms2 E x∼Dx[(ˆut(wt · x) − ut(wt · x))2(wt · x − w∗ · x)2], (19) since x(i) are i.i.d. random variables. The next step is to bound the variance. Note that Dx possesses a 1/L-sub-exponential tail, thus we have Pr[|(wt − w∗) · x| ≥ ∥wt − w∗∥2r] ≤ (2/L2) exp(−Lr). Choose r = 2W L log(2/(L2ϵ′)); then, we have Pr[|(wt − w∗) · x| ≥ r] ≤ ϵ′. Now we separate the variance under the event A = {x : |(wt − w∗) · x| ≤ r} and its complement. E x∼Dx[(ˆut(wt · x) − ut(wt · x))2(wt · x − w∗ · x)2] = E x∼Dx[(ˆut(wt · x) − ut(wt · x))2(wt · x − w∗ · x)21{A}] + E x∼Dx[(ˆut(wt · x) − ut(wt · x))2(wt · x − w∗ · x)2(1 − 1{A})]. (20) Using that Ex∼Dx[(ˆut(wt · x) − ut(wt · x))2] ≤ ϵ, the first term in (20) can be bounded as follows: E x∼Dx[(ˆut(wt · x) − ut(wt · x))2(wt · x − w∗ · x)21{A}] ≤ r2 E x∼Dx[(ˆut(wt · x) − ut(wt · x))2] ≤ r2ϵ = 4W 2ϵ L2 log2(2/(L2ϵ′)). (21) The second term in (20) can be bounded using that both ˆut and ut are non-decreasing b-Lipschitz and vanish at zero (thus |ˆut(wt ·x)| ≤ b|wt ·x| and |ut(wt ·x)| ≤ b|wt ·x|, with their signs determined by the sign of wt · x), and then applying Young’s inequality: E x∼Dx[(ˆut(wt · x) − ut(wt · x))2(wt · x − w∗ · x)2(1 − 1{A})] ≤ b2 E x∼Dx[(wt · x)2(wt · x − w∗ · x)2(1 − 1{A})] ≤ 2b2 E x∼Dx[((wt · x)4 + (wt · x)2(w∗ · x)2)(1 − 1{A})] . Since Dx is sub-exponential, we have E[(v · x)8] ≤ c2/L8 for some absolute constant c, hence E x∼Dx[(wt · x)4(1 − 1{A})] ≤ r E x∼Dx[W 8((wt/∥wt∥2) · x)8] Pr[|wt · x| ≥ r] ≤ cW 4√ ϵ′/L4. Similarly, for E[(wt · x)2(w∗ · x)2(1 − 1{A})], we have: E x∼Dx[(wt · x)2(w∗ · x)2(1 − 1{A})] ≤ 2 E x∼Dx[((wt · x)4 + (w∗ · x)4)(1 − 1{A})] ≤ 2c(W/L)4√ ϵ′. 26 Combining the inequalities above with (21), we get the final upper bound on the variance in (20): E x∼Dx[(ˆut(wt · x) − ut(wt · x))2(wt · x − w∗ · x)2] ≤ 4W 2ϵ L2 log2(2/(L2ϵ′)) + 6cb2(W/L)4√ ϵ′. Thus, choosing s = ϵ/b in (19), ϵ′ = ϵ2, and using m ≳ W 4b4 log2(1/ϵ)/(ϵδL4) samples we get 1 ms2 \u00124W 2ϵ L2 log2(2/(Lϵ′)) + 12cb2W 4√ ϵ′ L4 \u0013 ≲ b2L4ϵδ ϵ2W 4b4 log2(1/ϵ) \u0012W 2ϵ L2 log2 \u0012 1 Lϵ \u0013 + b2W 4ϵ L4 \u0013 ≤ δ . Plugging the inequality above back into (19) and recalling that Ex∼Dx[(ˆut(wt · x) − ut(wt · x))2] ≤ ϵ (from (18)), we finally have with probability at least 1 − δ, 1 m m X i=1 (ˆut(wt · x(i)) − ut(wt · x(i)))(wt − w∗) · x(i) ≥ E x∼Dx[(ˆut(wt · x) − ut(wt · x))(wt − w∗) · x] − ϵ/b ≥ − r E x∼Dx[(ˆut(wt · x) − ut(wt · x))2] E x∼Dx[(wt · x − w∗ · x)2] − ϵ/b ≥ −√ϵ∥wt − w∗∥2 − ϵ/b, where in the second inequality we used the Cauchy-Schwarz inequality and in the last inequality we used the assumption that Ex∼Dx[xx⊤] ≼ I. Finally, noting that (18) holds with probability at least 1 − δ, applying a union bound we get that with probability at least 1 − 2δ, we have 1 m m X i=1 (ˆut(wt · x(i)) − ut(wt · x(i)))(wt − w∗) · x(i) ≥ −√ϵ∥wt − w∗∥2 − ϵ/b . In summary, to guarantee that the inequality above remains valid, we need the batch size to be: m ≳ dW 9/2b4 log4(d/(ϵδ) L4 \u0012 1 ϵ3/2 + 1 ϵδ \u0013 . (22) We finished bounding the first term in (17). Since the same statements hold for the relationship between ˆu∗t and u∗t as they do for ˆut and ut, using the same argument we also get that with probability at least 1 − 2δ, 1 m m X i=1 (ˆu∗t(wt · x(i)) − u∗t(wt · x(i)))(wt − w∗) · x(i) ≥ −√ϵ∥wt − w∗∥2 − ϵ/b, which is the lower bound for the second term in (17). Lastly, for the third term in (17), since in Lemma 3.3 we showed that for any wt it always holds: E x∼Dx[(ut(wt · x) − u∗t(wt · x))2] ≤ OPT, the only change of the previous steps is at the right-hand side of (21), where instead of having the upper bound of r2ϵ, we have E x∼Dx[(ut(wt · x) − u∗t(wt · x))2(wt · x − w∗ · x)21{A}] ≤ r2OPT = 4W 2OPT L2 log2(2/(L2ϵ′)). 27 By the same token, we have E x∼Dx[(ut(wt · x) − u∗t(wt · x))2(wt · x − w∗ · x)2(1 − 1{A})] ≤ 6cb2(W/L)4√ ϵ′. As a result, Chebyshev’s inequality yields: Pr \u0014\f\f\f\f 1 m m X i=1 (ut(wt · x(i)) − u∗t(wt · x(i)))(wt − w∗) · x(i) − E x∼Dx[(ut(wt · x) − u∗t(wt · x))(wt − w∗) · x] \f\f\f\f ≥ s \u0015 ≤ 1 ms2 E x∼Dx[(ut(wt · x) − u∗t(wt · x))2(wt · x − w∗ · x)2] ≤ 1 ms2 \u00124W 2OPT L2 log2(2/(L2ϵ′)) + 6cb2W 4√ ϵ′ L4 \u0013 . Now instead of choosing s = ϵ, we let s = (OPT + ϵ)/b and keep ϵ′ as ϵ2 to get 1 ms2 \u00124W 2OPT L2 log2 \u0012 2 L2ϵ′ \u0013 + 12cb2W √ ϵ′ L4 \u0013 ≲ b2L4ϵδ dW 9/2b4 log4(d/(ϵδ))(OPT + ϵ)2 \u0012W 2OPT L2 log2 \u0012 1 Lϵ \u0013 + b2W 4ϵ L4 \u0013 ≤ δ, under our choice of m as specified in (22). Thus, we have that with probability at least 1−δ, it holds 1 m m X i=1 (ut(wt · x(i)) − u∗t(wt · x(i)))(wt − w∗) · x(i) ≥ E x∼Dx[(ut(wt · x) − u∗t(wt · x))(wt − w∗) · x] − (OPT + ϵ)/b ≥ − √ OPT∥wt − w∗∥2 − (OPT + ϵ)/b, where in the last inequality we used the fact that | E x∼Dx[(ut(wt · x) − u∗t(wt · x))(wt − w∗) · x]| ≤ r E x∼Dx[(ut(wt · x) − u∗t(wt · x))2] E x∼Dx[((wt − w∗) · x)2] ≤ √ OPT∥wt − w∗∥2, since Ex∼Dx[(ut(wt · x) − u∗t(wt · x))2] ≤ OPT by Lemma 3.3. Therefore, combining the upper bounds on the three terms in (17), we get that with probability at least 1 − 5δ, it holds: 1 m m X i=1 ((ˆut(wt·x(i))−ˆu∗t(wt·x(i)))(wt−w∗)·x(i) ≥ −(2√ϵ+ √ OPT)∥wt−w∗∥2−(3ϵ+OPT)/b. (23) Since (23) was proved using arbitrary ϵ, δ > 0, it remains to replace δ ← δ/5 and ϵ ← ϵ/4 to complete the proof of Claim 3.5. C.4 Proof of Claim 3.6 In this subsection, we prove Claim 3.6 that appeared in the proof of Proposition 3.1 in Section 3.3. 28 Claim 3.6. Let S∗ = {(x(i), y∗(i))}m i=1 be a sample set such that x(i)’s are i.i.d. samples from Dx and y∗(i) = u∗(w∗ · x(i)) for each i. Let m be the value specified in the statement of Proposition 3.1. Then, given a parameter wt ∈ B(W), with probability at least 1 − δ, Q2 = 1 m m X i=1 (ˆu∗t(wt · x(i)) − y∗(i))(wt − w∗) · x(i) ≥ Ca2LR4 b ∥(w∗)⊥wt∥2 2 − √ϵ∥wt − w∗∥2 − ϵ/b , where C is an absolute constant. Proof. Before we proceed to the proof of the claim, let us consider first the inverse of u∗. Since u∗(z) ∈ U(a,b) is strictly increasing when z ≥ 0, (u∗)−1(α) exists for α ≥ 0. However, when z ≤ 0, u∗(z) could be constant on some intervals, hence (u∗)−1(α) might not exist for every α ≤ 0. We consider instead an ‘empirical’ version of (u∗)−1(α) based on S∗, which is defined on every α ∈ R. Given a sample set S∗ = {(x(i), y∗(i))} where y∗(i) = u∗(w∗ · x(i)), let us sort the index i in the increasing order of w∗ · x(i), i.e., w∗ · x(1) ≤ · · · ≤ w∗ · x(m). Since u∗ is a monotone function, this implies y∗(i)’s are also in increasing order, i.e., we have y∗(1) ≤ · · · ≤ y∗(m). We then partition the set {y∗(i)}m i=1 into blocks ∆s = {y∗(ks−1+1), . . . , y∗(ks)}, s.t. y∗(ks−1+1) = · · · = y∗(ks) = τs, for s = 1, . . . , s′. Since {y∗(i)} is sorted in increasing order, we have τs−1 < τs for s = 2, . . . , s′. Note that since u∗(z) is strictly increasing when z ≥ 0 and as u∗(0) = 0, ∆s is a singleton set whenever τs > 0. Furthermore, let us denote by s∗ the largest index among 1, . . . , s′ such that τs∗ ≤ 0. Suppose first that τs∗ < 0 and define a function ˆf : R → R in the following way: ˆf(α) =                (u∗)−1(α), α > 0 w∗ · x(ks∗) + α−τs∗ τs∗ (w∗ · x(ks∗)), α ∈ [τs∗, 0] w∗ · x(ks), α = τs, s = 1, . . . , s∗ − 1 w∗ · x(ks−1) + α−τs−1 τs−τs−1 (w∗ · x(ks−1+1) − w∗ · x(ks−1)), α ∈ (τs−1, τs), s = 2, . . . , s∗ w∗ · x(1) + 1 b(α − τ1) . α ∈ (−∞, τ1) (24) When τs∗ = 0, we define (0 − τs∗)/τs∗ = −1, and hence ˆf(0) = 0. The rest remains unchanged. A visualization of ˆf with respect to the ReLU activation is presented in Figure 3. The function ˆf has the following properties. First, ˆf(α) satisfies ˆf(0) = 0, (α1 − α2)/a ≥ ˆf(α1) − ˆf(α2), for all α1 ≥ α2 ≥ 0, since ˆf(α) = (u∗)−1(α) when α > 0 and u∗ ∈ U(a,b). Second, ˆf(α1)− ˆf(α2) ≥ (α1 −α2)/b for all α1, α2 ∈ R, α1 ≥ α2. This is because each segment of ˆf has slope at least 1/b. Third, for any α ≥ u∗(w∗ · x(i)), it holds that ˆf(α) − w∗ · x(i) ≥ (α − u∗(w∗ · x(i)))/b. To see this, suppose u∗(w∗ · x(i)) ∈ ∆s. Then for any α ≥ τs, we have ˆf(α) − w∗ · x(i) ≥ ˆf(α) − w∗ · x(ks) = ˆf(α) − ˆf(τs) = ˆf(α) − ˆf(u∗(w∗ · x(i))) ≥ (α − u∗(w∗ · x(i)))/b, using that the slope of ˆf(α) is at least 1/b. On the other hand, when α < u∗(w∗ · x(i)), we have w∗ · x(i) − ˆf(α) ≥ (u∗(w∗ · x(i)) − α)/b. This can be seen similarly from the construction of ˆf. Finally, suppose u∗(w∗ · x(i)) ∈ ∆s. Then for any α < τs, we have w∗·x(i)− ˆf(α) ≥ w∗·x(ks−1+1)− ˆf(α) = ˆf(τs)− ˆf(α) = ˆf(u∗(w∗·x(i)))− ˆf(α) ≥ (u∗(w∗·x(i))−α)/b. Again, we used the fact that ˆf(α1) − ˆf(α2) ≥ (α1 − α2)/b for all α1, α2 ∈ R, α1 ≥ α2 in the last inequality. 29 Figure 3: An illustration of ˆf for u∗(z) = max{0, z} and a dataset S∗ = {(x(1), u∗(w∗ · x(1))), . . . , (x(6), u∗(w∗ · x(6)))} where w∗ · x(1) < w∗ · x(2) < w∗ · x(3) < 0. Now we turn to the summation displayed in the statement of the claim. To proceed, we add and subtract ˆf(ˆu∗t(wt · x)) in the second component in the inner product, which yields: 1 m m X i=1 (ˆu∗t(wt · x(i)) − u∗(w∗ · x(i)))(wt − w∗) · x(i) = 1 m m X i=1 (ˆu∗t(wt · x(i)) − u∗(w∗ · x(i)))(wt · x(i) − ˆf(ˆu∗t(wt · x(i)))) + 1 m m X i=1 (ˆu∗t(wt · x(i)) − u∗(w∗ · x(i)))( ˆf(ˆu∗t(wt · x(i))) − w∗ · x(i)). (25) To bound below the first term in (25), we make use of the following fact, whose proof can be found in Appendix C.5. Fact C.2. Let wt ∈ B(W). Given m samples S = {(x(1), y∗(1)), · · · , (x(m), y∗(m))}, let ˆu∗t be one of the solutions to the optimization problem (P*) , i.e., ˆu∗t ∈ argminu∈U(a,b)(1/m) Pm i=1(u(wt · x(i)) − y∗(i))2. Then m X i=1 (ˆu∗t(wt · x(i)) − y∗(i))(wt · x(i) − f(ˆu∗t(wt · x(i)))) ≥ 0, for any function f : R → R such that f(0) = 0, (α1 − α2)/a ≥ f(α1) − f(α2) for all α1 ≥ α2 ≥ 0, and f(α1) − f(α2) ≥ (α1 − α2)/b, ∀α1, α2 ∈ R, α1 ≥ α2. As we have already argued, ˆf satisfies the assumptions of Fact C.2, hence 1 m m X i=1 (ˆu∗t(wt ·x(i))−y∗(i))(wt −w∗)·x(i) ≥ 1 m m X i=1 (ˆu∗t(wt ·x(i))−y∗(i))( ˆf(ˆu∗t(wt ·x(i)))−w∗ ·x(i)). (26) Recall that we have shown the function ˆf satisfies ˆf(α) − w∗ · x(i) ≥ (α − u∗(w∗ · x(i)))/b ≥ 0 whenever α ≥ u∗(w∗ · x(i)), and moreover, w∗ · x(i) − ˆf(α) ≥ (u∗(w∗ · x(i)) − α)/b ≥ 0 when 30 α < u∗(w∗ · x(i)). Therefore, letting α = ˆu∗t(wt · x(i)) and combining these results we get (ˆu∗t(wt · x(i)) − u∗(w∗ · x(i)))(f(ˆu∗t(wt · x(i))) − w∗ · x(i)) ≥ 1 b(ˆu∗t(wt · x(i)) − u∗(w∗ · x(i)))2. Plugging the inequality above back into (26) we then get 1 m m X i=1 (ˆu∗t(wt · x(i)) − y∗(i))(wt − w∗) · x(i) ≥ 1 mb m X i=1 (ˆu∗t(wt · x(i)) − y∗(i))2 . (27) The goal now is to bound below the right-hand side of (27) by E[(ˆu∗t(wt · x) − y∗)2] and some small error terms using Chebyshev inequality as we did in Claim 3.5. Plugging in Lemma 3.2, we can further lower bound E[(ˆu∗t(wt · x) − y∗)2] by ∥(w∗)⊥wt∥2 2 and then we are done with the proof of this claim. Note that Chebyshev’s inequality yields Pr \u0014\f\f\f\f 1 m m X i=1 (ˆu∗t(wt · x(i)) − y∗(i))2 − E x∼Dx[(ˆu∗t(wt · x) − y∗)2] \f\f\f\f ≥ s \u0015 ≤ 1 ms2 E x∼Dx[(ˆu∗t(wt · x) − y∗)4]. (28) We now bound Ex∼Dx[(ˆu∗t(wt · x) − y∗)4]. Observe that E x∼Dx[(ˆu∗t(wt · x) − y∗)4] = E x∼Dx[(ˆu∗t(wt · x) − u∗t(wt · x) + u∗t(wt · x) − y∗)2(ˆu∗t(wt · x) − y∗)2] ≤ 4 E x∼Dx[(ˆu∗t(wt · x) − u∗t(wt · x))2((ˆu∗t(wt · x))2 + (y∗)2)] + 4 E x∼Dx[(u∗t(wt · x) − y∗)2((ˆu∗t(wt · x))2 + (y∗)2)]. (29) We focus on the two terms in (29) separately. Again, choosing r = 2W L log(2/(L2ϵ′)), then by the L-sub-exponential tail bound of Dx, it holds Pr[|wt · x| ≥ r] ≤ ϵ′, Pr[|w∗ · x| ≥ r] ≤ ϵ′. Since y∗ = u∗(w∗ · x) and both u∗ and ˆu∗t are non-decreasing b-Lipschitz, it holds: E x∼Dx[(ˆu∗t(wt · x) − u∗t(wt · x))2((ˆu∗t(wt · x))2 + (y∗)2)] ≤ b2 E x∼Dx[(ˆu∗t(wt · x) − u∗t(wt · x))2((wt · x)2 + (w∗ · x)2)] = b2 E x∼Dx[(ˆu∗t(wt · x) − u∗t(wt · x))2((wt · x)2 + (w∗ · x)2)1{|wt · x| ≤ r, |w∗ · x| ≤ r}] + b2 E x∼Dx[(ˆu∗t(wt · x) − u∗t(wt · x))2((wt · x)2 + (w∗ · x)2)1{|wt · x| ≥ r or |w∗ · x| ≥ r}] ≤ 2b2r2 E x∼Dx[(ˆu∗t(wt · x) − u∗t(wt · x))2] + 2b4 E x∼Dx[2(wt · x)2((wt · x)2 + (w∗ · x)2)1{|wt · x| ≥ r or |w∗ · x| ≥ r}]. (30) The first term in (30) can be upper bounded using Lemma F.2, which states that when m ≳ d log(1/δ)(b2W 3 log2(d/ϵ)/(L2ϵ))3/2), with probability at least 1 − δ it holds Ex∼Dx[(ˆu∗t(wt · x) − u∗t(wt · x))2] ≤ ϵ for all wt ∈ B(W). Now suppose this inequality is valid given wt ∈ B(W) (which happens with probability at least 1 − δ). For the second term in (30), note that for any unit vector a it holds Ex∼Dx[(a · x)8] ≤ c2/L8 31 for some absolute constant c > 0, and furthermore, the magnitude of r ensures that Pr[|wt · x| ≥ r or |w∗ · x| ≥ r] ≤ 2ϵ′; therefore, combining these bounds, we get: E x∼Dx[2(wt · x)2((wt · x)2 + (w∗ · x)2)1{|wt · x| ≥ r or |w∗ · x| ≥ r}] ≤ 2 r E x∼Dx[(wt · x)8] Pr[|wt · x| ≥ r or |w∗ · x| ≥ r] + 2 r 2( E x∼Dx[(wt · x)8] + E x∼Dx[(w∗ · x)8]) Pr[|wt · x| ≥ r or |w∗ · x| ≥ r] ≤ 24c(W/L)4√ ϵ′. Plugging back into (30), we have E x∼Dx[(ˆu∗t(wt · x) − u∗t(wt · x))2((ˆu∗t(wt · x))2 + (y∗)2)] ≤ 2b2r2ϵ + 48c(bW/L)4√ ϵ′, which is the upper bound on the first term of (29). For the second term in (29), since by definition we have u∗t ∈ argminu∈U(a,b) Ex∼Dx[(u(wt · x) − y∗)2], it holds that E x∼Dx[(u∗t(wt·x)−y∗)2] ≤ E x∼Dx[(u∗(wt·x)−u∗(w∗·x))2] ≤ b2 E x∼Dx[((wt−w∗)·x)2] ≤ b2∥wt−w∗∥2 2, noting in addition that Ex∼Dx[xx⊤] ≼ I. Thus, using similar steps as in (30), we have E x∼Dx[(u∗t(wt · x) − y∗)2((ˆu∗t(wt · x))2 + (y∗)2)] ≤ 2b2r2 E x∼Dx[(u(wt · x) − y∗)2] + 2b4 E x∼Dx[2((wt · x)2 + (w∗ · x)2)21{|wt · x| ≥ r or |w∗ · x| ≥ r}] ≤ 2b4r2∥wt − w∗∥2 2 + 48c(bW/L)4√ϵ. In summary, combining all the results and plugging them back into (29), we finally get the upper bound for the variance: E x∼Dx[(ˆu∗t(wt · x) − y∗)4] ≤ 32b2W 2 L2 log2(2/(L2ϵ′))(b2∥wt − w∗∥2 2 + ϵ) + 384c(bW/L)4√ ϵ′. Let s = b√ϵ∥wt − w∗∥2 + ϵ/b and plug the last inequality back into (28) to get: Pr \u0014\f\f\f\f 1 m m X i=1 (ˆu∗t(wt · x(i)) − y∗(i))2 − E x∼Dx[(ˆu∗t(wt · x) − y∗)2] \f\f\f\f ≥ b√ϵ∥wt − w∗∥2 + ϵ/b \u0015 ≤ 1 m(ϵb2∥wt − w∗∥2 2 + ϵ2/b2) \u001232b2W 2 L2 log2 \u0012 2 L2ϵ′ \u0013 (b2∥wt − w∗∥2 2 + ϵ) + 384c(bW/L)4√ ϵ′ \u0013 . Choosing ϵ′ = ϵ2/b4 and using similar arguments as in Claim 3.5, we get that the right-hand side of the inequality above is bounded by δ, given our choice of m ≳ db4W 9/2 log4(d/(ϵδ))(1/ϵ3/2 + 1/(ϵδ)) as specified in the statement of Proposition 3.1. In summary, after a union bound on the probability above and the event that Ex∼Dx[(ˆu∗t(wt · x) − u∗t(wt · x))2] ≤ ϵ, we have with probability at least 1 − 2δ, 1 m m X i=1 (ˆu∗t(wt · x(i)) − y∗(i))2 ≥ E x∼Dx[(ˆu∗t(wt · x) − y∗)2] − √ϵb∥wt − w∗∥2 − ϵ/b. 32 Recall that in Lemma 3.2 we showed that Ex∼Dx[(ˆu∗t(wt · x) − u∗(w∗ · x))2] ≥ Ca2LR4∥(w∗)⊥wt∥2 2 for an absolute constant C; thus, our final result is that with probability at least 1 − δ, 1 m m X i=1 (ˆu∗t(wt · x(i)) − y∗(i))(wt − w∗) · x(i) ≥ 1 mb m X i=1 (ˆu∗t(wt · x(i)) − y∗(i))2 ≥ Ca2LR4 b ∥(w∗)⊥wt∥2 2 − √ϵ∥wt − w∗∥2 − ϵ/b. This completes the proof of Claim 3.6. C.5 Proof of Fact C.2 We prove a modified version of Lemma 1 [KKSK11], presented as the statement below. The statement considers a smaller activation class and a function f with different properties compared to [KKSK11], and the proof is based on a rigorous KKT argument. Fact C.2. Let wt ∈ B(W). Given m samples S = {(x(1), y∗(1)), · · · , (x(m), y∗(m))}, let ˆu∗t be one of the solutions to the optimization problem (P*) , i.e., ˆu∗t ∈ argminu∈U(a,b)(1/m) Pm i=1(u(wt · x(i)) − y∗(i))2. Then m X i=1 (ˆu∗t(wt · x(i)) − y∗(i))(wt · x(i) − f(ˆu∗t(wt · x(i)))) ≥ 0, for any function f : R → R such that f(0) = 0, (α1 − α2)/a ≥ f(α1) − f(α2) for all α1 ≥ α2 ≥ 0, and f(α1) − f(α2) ≥ (α1 − α2)/b, ∀α1, α2 ∈ R, α1 ≥ α2. Proof. We transform the optimization problem (P*) to a quadratic optimization problem with linear constraints. To guarantee that the solution of this quadratic problem corresponds to a function that is (a, b)-unbounded, we add a sample (x(k), y∗(k)) = (0, 0) to the sample set. Let zi = wt · x(i) such that (after sorting the indices) z1 ≤ z2 ≤ · · · ≤ zm and zk = 0. We solve the following optimization problem: min ˜y(i),i∈[m] m X i=1 (˜y(i) − y∗(i))2 s.t. 0 ≤ ˜y(i+1) − ˜y(i), 1 ≤ i ≤ k − 1 , a(zi+1 − zi) ≤ ˜y(i+1) − ˜y(i), k ≤ i ≤ m − 1 , ˜y(i+1) − ˜y(i) ≤ b(zi+1 − zi), 1 ≤ i ≤ m − 1 , ˜y(k) = 0 . (31) Denote the solution of (31) as ˆy∗(i), i = 1, · · · , m. Let ˆu∗t(z) be the linear interpolation function of (zi, ˆy∗(i)), then ˆu∗t ∈ U(a,b) since ˆu∗t(0) = ˆu∗t(zk) = ˆy∗(k) = 0, ˆu∗t is b-Lipschitz and ˆu∗t(z)− ˆu∗t(z′) ≥ a(z − z′) for all z ≥ z′ ≥ 0. In other words, finding a solution of (P*) is equivalent to solving (31). Now observe that the summation Pm i=1(ˆy∗(i) − y∗(i))(zi − f(ˆy∗(i))) can be transformed into the following: m X i=1 (ˆy∗(i) − y∗(i))(zi − f(ˆy∗(i))) = m X i=1 \u0012 i X j=1 (ˆy∗(j) − y∗(j)) \u0013 (zi − f(ˆy∗(i)) − (zi+1 − f(ˆy∗(i+1)))), (32) where we let zm+1 = 0, ˆy∗ m+1 = 0 (and hence f(ˆy∗ m+1) = 0 as f(0) = 0). 33 To utilize the information that ˆy∗(i) is the minimizer of the optimization problem (31), we write down the KKT conditions for the optimization problem (31) described above: ˆy∗(i) = y∗(i) + (λ′ i − λ′ i−1)/2 − (λi − λi−1)/2 − (νk/2)1{i = k}, i = 1, · · · , m; (33) − λi(ˆy∗(i+1) − ˆy∗(i)) = 0, i = 1, · · · , k − 1; (34) λi(a(zi+1 − zi) − (ˆy∗(i+1) − ˆy∗(i))) = 0, i = k, · · · , m − 1; (35) λ′ i((ˆy∗(i+1) − ˆy∗(i)) − b(zi+1 − zi)) = 0, i = 1, · · · , m − 1; (36) νkˆy∗(k) = 0 , (37) where λi, λ′ i ≥ 0, for i = 1, . . . , m − 1, and νk ∈ R are dual variables, and we let λ0 = λ′ 0 = 0 for the convenience of presenting (33). Summing up (33) recursively, we immediately get that i X j=1 (ˆy∗(i) − y∗(i)) = 1 2((λ′ i − λi) − νk1{i ≥ k}). Plugging the equality above back into (32), we have m X i=1 (ˆy∗(i) − y∗(i))(zi − f(ˆy∗(i))) = 1 2 m X i=1 (λ′ i − λi)(zi − f(ˆy∗(i)) − (zi+1 − f(ˆy∗(i+1)))) + 1 2 m X i=k νk(zi − f(ˆy∗(i)) − (zi+1 − f(ˆy∗(i+1)))) = 1 2 m X i=1 (λ′ i − λi)(zi − f(ˆy∗(i)) − (zi+1 − f(ˆy∗(i+1)))) + νk(zk − f(ˆy∗(k)) − (zm+1 − f(ˆy∗(m+1)))). (38) Since by definition, zm+1 = f(ˆy∗(m+1)) = 0, zk = 0, and as ˆy∗(i), i ∈ [m], is a feasible solution of (31), it holds ˆy∗(k) = 0, we thus have νk(zk − f(ˆy∗(k)) − (zm+1 − f(ˆy∗(m+1)))) = 0. Plugging this back into (38), we get m X i=1 (ˆy∗(i) − y∗(i))(zi − f(ˆy∗(i))) = 1 2 m X i=1 (λ′ i − λi)(zi − f(ˆy∗(i)) − (zi+1 − f(ˆy∗(i+1)))) = 1 2 k−1 X i=1 (λ′ i − λi)(zi − f(ˆy∗(i)) − (zi+1 − f(ˆy∗(i+1)))) | {z } S1 + 1 2 m X i=k (λ′ i − λi)(zi − f(ˆy∗(i)) − (zi+1 − f(ˆy∗(i+1)))) | {z } S2 . (39) Consider first S1. Suppose that for some i ∈ {1, . . . , k−1} we have λ′ i, λi > 0. Then, according to the complementary slackness condition (34) and (35), it holds that 0 = ˆy∗(i+1) − ˆy∗(i) = b(zi+1 − zi). Therefore, (λ′ i − λi)(zi − f(ˆy∗(i)) − (zi+1 − f(ˆy∗(i+1)))) ≥ 0. 34 Suppose now that for some i ∈ {1, . . . , k − 1}, it holds λ′ i > 0, λ = 0. Then, it must be the case that ˆy∗(i+1) − ˆy∗(i) = b(zi+1 − zi) ≥ 0, according to the KKT condition (36). Since f(ˆy∗(i+1)) − f(ˆy∗(i)) ≥ (ˆy∗(i+1) − ˆy∗(i))/b by assumption on f, we thus have (zi − f(ˆy∗(i)) − (zi+1 − f(ˆy∗(i+1)))) ≥ 0. Finally, if λi > 0, λ′ = 0, then (34) indicates that 0 = ˆy∗(i+1) − ˆy∗(i). Therefore, as zi+1 ≥ zi, the ith summand is also positive. In summary, S1 ≥ 0. Now consider S2. Observe that if for some i ∈ {k, . . . , m} it holds λi > 0 and λ′ i > 0 at the same time, then KKT conditions (35) and (36) imply that a(zi+1 − zi) = ˆy∗(i+1) − ˆy∗(i) = b(zi+1 − zi), as a < b and it has to be zi+1 − zi = ˆy∗(i+1) − ˆy∗(i) = 0, which indicates that the ith summand in the second term must be 0, i.e., (λ′ i − λi)(zi − f(ˆy∗(i)) − (zi+1 − f(ˆy∗(i+1)))) = 0. Now suppose for some i ∈ {1, . . . , m}, λ′ i > 0 and λi = 0. Then by the complementary slackness conditions (35) and (36), it must be that ˆy∗(i+1) − ˆy∗(i) = b(zi+1 − zi) ≥ 0. Again, since f satisfies f(ˆy∗(i+1)) − f(ˆy∗(i)) ≥ (ˆy∗(i+1) − ˆy∗(i))/b for any ˆy∗(i+1) ≥ ˆy∗(i), we thus have zi − zi+1 + (f(ˆy∗(i+1)) − f(ˆy∗(i))) ≥ 0. Thus, it holds that (λ′ i − λi)(zi − f(ˆy∗(i)) − (zi+1 − f(ˆy∗(i+1)))) ≥ 0. On the other hand, if λ′ i = 0 and λi > 0, then complementary slackness implies that ˆy∗(i+1) − ˆy∗(i) = a(zi+1 − zi) ≥ 0. Furthermore, since ˆy∗(i) ≥ ˆy∗(k) ≥ 0 when i ≥ k, using the assumption that (α1 − α2)/a ≥ f(α1) − f(α2) when α1 ≥ α2 ≥ 0, we get zi − zi+1 + (f(ˆy∗(i+1)) − f(ˆy∗(i))) ≤ 0, and hence (λ′ i − λi)(zi − f(ˆy∗(i)) − (zi+1 − f(ˆy∗(i+1)))) ≥ 0 holds as well. Thus we conclude that S2 ≥ 0. In summary, since each summand in (39) is non-negative, we finally get that m X i=1 (ˆy∗(i) − y∗(i))(zi − f(ˆy∗(i))) = m X i=1 \u0012 i X j=1 (ˆy∗(j) − y∗(j)) \u0013 (zi − f(ˆy∗(i)) − (zi+1 − f(ˆy∗(i+1)))) ≥ 0. This completes the proof of Fact C.2. 35 C.6 Proof of Claim 3.7 We restate and prove Claim 3.7 that appeared in the proof of Proposition 3.1 in Section 3.3. Claim 3.7. Let S = {(x(i), y(i))}m i=1 be i.i.d. samples from D, and denote by S∗ = {(x(i), y∗(i))}m i=1 the idealized version of S, where y∗(i) = u∗(w∗ · x(i)). Under the condition of Proposition 3.1, given a parameter wt ∈ B(W), with probability at least 1 − δ, Q3 = 1 m m X i=1 (y∗(i) − y(i))(wt · x(i) − w∗ · x(i)) ≥ − √ OPT∥w∗ − wt∥2 − (OPT + ϵ)/b . Proof. By Chebyshev’s inequality, we can write Pr \u0014\f\f\f\f 1 m m X i=1 (y∗(i) − y(i))(wt · x(i) − w∗ · x(i)) − E (x,y)∼D[(y∗ − y)(wt − w∗) · x] \f\f\f\f ≥ s \u0015 ≤ E(x,y)∼D[(y∗ − y)2(wt · x − w∗ · x)2] ms2 . Let r = 2W L log(2/(L2ϵ′)), then by the fact that Dx is sub-exponential, we have Pr[|(wt − w∗) · x| ≥ r] ≤ ϵ′. Furthermore, since |y| ≤ M where M = bW L log(16b4W 4/ϵ2), as stated in Fact F.3, the variance can be bounded as follows: E (x,y)∼D[(y∗ − y)2(wt · x − w∗ · x)2] ≤ E (x,y)∼D[(y∗ − y)2(wt · x − w∗ · x)21{|(wt − w∗) · x| ≤ r}] + E (x,y)∼D[(y∗ − y)2(wt · x − w∗ · x)21{|(wt − w∗) · x| ≥ r}] ≤ r2 E (x,y)∼D[(u∗(w∗ · x) − y)2] + E (x,y)∼D[(2(u∗(w∗ · x))2 + y2)(wt · x − w∗ · x)21{|(wt − w∗) · x| ≥ r}] ≤ r2OPT + E x∼Dx[2(b2(wt · x)2 + M2)(wt · x − w∗ · x)21{|(wt − w∗) · x| ≥ r}]. Since for any unit vectors a, b we have Ex∼Dx[(a · x)4] ≤ c2/L4 and Ex∼Dx[(a · x)4(b · x)4] ≤ c2/L8, we have: 2b2 E x∼Dx[(wt · x)2(wt · x − w∗ · x2)21{|(wt − w∗) · x| ≥ r}] ≤ 4b2(W/L)4r E x∼Dx[((wt/∥wt∥2) · x)4(((wt − w∗)/∥wt − w∗∥2) · x)4] Pr[|(wt − w∗) · x| ≥ r] ≤ 4cb2(W/L)4√ ϵ′, and in addition, E x∼Dx[M2((wt − w∗) · x)21{|(wt − w∗) · x| ≥ r}] ≤ 2M2W 2r E x∼Dx[((wt − w∗) · x)4] Pr[|(wt − w∗) · x| ≥ r] ≤ cM2(W/L)2√ ϵ′. 36 Let s = (OPT + ϵ)/b, ϵ′ = ϵ2, under our choice of m ≳ db4W 9/2 log4(d/(ϵδ))(1/ϵ3/2 + 1/(ϵδ)), it holds that 1 ms2 \u00124W 2 log2(1/(L2ϵ′))OPT L2 + (4cb2(W/L)4 + cM2(W/L)2) √ ϵ′ \u0013 ≤ δ. Thus, with probability at least 1 − δ it holds that 1 m m X i=1 (y∗(i) − y(i))(wt · x(i) − w∗ · x(i)) ≥ E (x,y)∼D[(y − y∗)(wt − w∗) · x] − (OPT + ϵ)/b. Since \f\f\f\f E (x,y)∼D[(y − y∗)(wt − w∗) · x] \f\f\f\f ≤ r E (x,y)∼D[(y − y∗)2] E x∼Dx[((wt − w∗) · x)2] ≤ √ OPT∥w∗ − wt∥2, we finally have 1 m m X i=1 (y∗(i) − y(i))(wt · x(i) − w∗ · x(i)) ≥ − √ OPT∥w∗ − wt∥2 − (OPT + ϵ)/b, completing the proof of Claim 3.7. D Omitted Proofs from Section 4 D.1 Proof of Theorem 4.2 In this subsection, we restate and prove our main theorem Theorem 4.2. The full version of the optimization algorithm as well as the main theorem Theorem 4.2 is displayed below: Theorem D.1 (Main Result). Let D be a distribution in Rd × R and suppose that Dx is (L, R)- well-behaved. Furthermore, let U(a,b) be as in Definition 1.3, and ϵ > 0. Let µ = Ca2LR4/b, where C is an absolute constant. Running Algorithm 4 with the following parameters: step size η = µ/(4b2), batch size to be m ≳ dW 11/2b17 log5(d/ϵ)/(L4µ12ϵ3/2) and the total number of iterations to be T ′ = t0JT = O(Wb11/(µ10√ϵ) log(1/ϵ)), where T = O((b/µ)2 log(1/ϵ)), then with probability at least 2/3, Algorithm 4 returns a hypothesis (ˆu, bw) where ˆu ∈ U(a,b) and bw ∈ B(W) such that L2(bw; ˆu) = O \u0012 b4 a4L2R8 \u0013 OPT + ϵ , using N = O(T ′m) = ˜O(dW 13/2b28/(L4µ22ϵ2)) samples. Proof. As proved in Lemma 4.1, the initialization subroutine Algorithm 1 outputs a list of points {wini k }t0 k=1 that contains a point wini k∗ such that ∥(w∗) ⊥wini k∗ ∥2 ≤ max{µ∥w∗∥2/(4b), 64b2/µ3( √ OPT + √ϵ)}. Suppose first that µ∥w∗∥2/(4b) ≤ 64b2/µ3( √ OPT + √ϵ). Then this implies that ∥w∗∥2 ≤ 256b3/µ4( √ OPT + √ϵ). Therefore, applying Claim 4.4 we immediately get that the trivial hy- pothesis (w = 0, u(z) = 0) works as a constant approximate solution, as in this case L2(w; u) ≤ 8(OPT + ϵ) + 4b2∥w∗∥2 = O((b/µ)8)OPT + ϵ. 37 Algorithm 4 Optimization 1: Input: wini = 0; ϵ > 0; positive parameters: a, b, L, R, W; let µ ≲ a2LR4/b; step size η = µ/(4b2), number of iterations T = O((b/µ)2 log(1/ϵ)). 2: {wini 0 , . . . , wini t0 } = Initialization[wini] (Algorithm 1) 3: for k = 0 to t0 ≲ (b/µ)6 log(b/µ) do 4: Pk = {} 5: for j = 1 to J = W/(η√ϵ) do 6: ¯w0 j,k = wini k . 7: βj = jη√ϵ. ▷ find an η√ϵ approximation of ∥w∗∥2 8: for t = 0 to T − 1 do 9: bwt j,k = βj( ¯wt j,k/∥ ¯wt j,k∥2). ▷ normalize ¯w 10: Draw m ≳ W 11/2b17 log5(d/ϵ)d/(L4µ12ϵ3/2) new i.i.d. samples from D 11: ˆut j,k = argminu∈U(a,b)(1/m) Pm i=1(u(bwt j,k · x(i)) − y(i))2. 12: ∇ bLsur(bwt j,k; ˆut j,k) = (1/m) Pm i=1(ˆut j,k(bwt j,k · x(i)) − y(i))x(i). 13: ¯wt+1 j,k = bwt j,k − η∇ bLsur(bwt j,k; ˆut j,k) 14: end for 15: Pk ← Pk ∪ {(bwT j,k; ˆuT j,k)}. 16: end for 17: P = ∪t0 k=1Pk ∪ {(w = 0; u(z) = 0)} 18: end for 19: (bw; ˆu) = Test[(w; u) ∈ P] (Algorithm 3) ▷ testing 20: Return: (bw; ˆu) This hypothesis (w = 0, u(z) = 0) is contained in our solution set P (see Algorithm 4) and tested in Algorithm 3. Thus, in the rest of the proof we assume that wini k∗ satisfies ∥(w∗) ⊥wini k∗ ∥2 ≤ µ∥w∗∥2/(4b). Let us consider this initialized parameter at k∗ step in the outer loop (line 4), ¯w0 j,k∗ = wini k∗ . In the rest of the proof we drop the subscript k∗ since the context is clear. Since we constructed a grid with grid width η√ϵ from 0 to W to find the (approximate) value of ∥w∗∥2, there must exist an index j∗ such that the value of βj∗ is η√ϵ close to ∥w∗∥2, i.e., |βj∗ − ∥w∗∥2| ≤ η√ϵ. We now consider this j∗th outer loop and ignore the subscript j∗ for simplicity. Let wt = ∥w∗∥2( ¯wt/∥ ¯wt∥2), which is the true normalized vector of ¯wt that has no error. We study the squared distance between ¯wt+1 and w∗: ∥ ¯wt+1 − w∗∥2 2 = ∥bwt − η∇ bLsur(bwt; ˆut) − w∗∥2 2 = ∥bwt − w∗∥2 2 + η2∥∇ bLsur(bwt; ˆut)∥2 2 − 2η∇ bLsur(bwt; ˆut) · (bwt − w∗). (40) Applying Lemma 4.3 to (40), and plugging in Proposition 3.1, we get that when drawing m ≳ dW 9/2b4 log4(d/(ϵδ)) L4 \u0012 1 ϵ3/2 + 1 ϵδ \u0013 , (41) samples from the distribution, it holds with probability at least 1 − δ that: ∥ ¯wt+1 − w∗∥2 2 ≤ ∥bwt − w∗∥2 2 + η2(10(OPT + ϵ) + 4b2∥bwt − w∗∥2 2) + 2η(2(OPT + ϵ)/b + 2( √ OPT + √ϵ)∥bwt − w∗∥2 − µ∥vt∥2 2), (42) 38 where µ = Ca2LR4/b with C being an absolute constant, and where vt is the component of w∗ that is orthogonal to bwt, i.e., vt = w∗ − (w∗ · bwt)bwt/∥bwt∥2 2 = (w∗)⊥ b wt. Note that ∥vt∥2 is invariant to the rescaling of bwt, in other words, w∗ has the same orthogonal component vt for all ¯wt, wt and bwt. Since ∥bwt − wt∥2 ≤ η√ϵ, we have ∥bwt − w∗∥2 2 = ∥bwt − wt + wt − w∗∥2 2 ≤ ∥wt − w∗∥2 2 + η2ϵ + 2η√ϵ∥wt − w∗∥2. (43) In addition, by triangle inequality we have ∥bwt − w∗∥2 ≤ ∥wt − w∗∥2 + η√ϵ. Therefore, substituting wt with bwt in (42), we get: ∥ ¯wt+1 − w∗∥2 2 ≤ ∥wt − w∗∥2 2 + η2ϵ + 2η√ϵ∥wt − w∗∥2 + η2(10(OPT + ϵ) + 4b2∥wt − w∗∥2 2 + 4b2η2ϵ + 8b2η√ϵ∥wt − w∗∥2) + 2η(2(OPT + ϵ)/b + 2( √ OPT + √ϵ)(∥wt − w∗∥2 + η√ϵ) − µ∥vt∥2 2) ≤ ∥wt − w∗∥2 2 + η2(24(OPT + ϵ) + 4b2∥wt − w∗∥2 2) + 2η(2(OPT + ϵ)/b + 4( √ OPT + √ϵ)∥wt − w∗∥2 − µ∥vt∥2 2), (44) where we used 4b2η2 ≤ 1, which holds because η = µ/(4b2). Our goal is to show that ∥vt+1∥2 2 ≤ ∥ ¯wt+1 − w∗∥2 2 ≤ (1 − c)∥vt∥2 2 + ϵ, where c ∈ (0, 1) is a constant and ϵ is a small error parameter. However, this linear contraction can only be obtained when ∥vt∥2 is relatively small compared to ∥w∗∥2. Specifically, as will be manifested in Claim D.2 and the proceeding proof, the linear contraction is achieved only when ∥vt∥2 ≤ µ∥w∗∥2/(4b). Luckily, we can start with a v0 such that this condition is satisfied, due to the initialization subroutine Algorithm 1, as proved in Lemma 4.1. We prove the following claim. Claim D.2. Let η = µ/(4b2). Then, under the assumptions of Theorem 4.2, with probability at least 1 − δ, we have ∥ ¯wt+1 − w∗∥2 2 ≤ \u0012 1 − µ2 32b2 \u0013 ∥vt∥2 2, whenever ∥vt∥2 ≥ (96/µ)( √ OPT + √ϵ). Proof of Claim D.2. Since the norm of wt is normalized to w∗, the quantity ∥wt −w∗∥2 is controlled by ∥vt∥2 2. In particular, let w∗ = αtwt+vt. Then, since vt ⊥ wt, we have ∥w∗∥2 2 = α2 t ∥wt∥2 2+∥vt∥2 2 = α2 t ∥w∗∥2 2 + ∥vt∥2 2, thus, α2 t = 1 − ∥vt∥2 2/∥w∗∥2 2, and ∥vt∥2 2 = (1 − α2 t )∥w∗∥2 2. In addition, ∥wt − w∗∥2 2 can be expressed as a function of αt and w∗, as ∥wt − w∗∥2 2 = (1 − αt)2∥w∗∥2 2 + ∥vt∥2 2 = 2(1 − αt)∥w∗∥2 2. (45) Note that since αt = p 1 − ∥vt∥2 2/∥w∗∥2 2, denoting ρt = ∥vt∥2/∥w∗∥2, we further have: 1 − αt = 1 − q 1 − ∥vt∥2 2/∥w∗∥2 2 = 1 − q 1 − ρ2 t ≤ 1 2ρ2 t + 1 2ρ4 t ≤ ρ2 t , ∀ρt ∈ [0, 1]. (46) 39 Therefore, plugging (45) and (46) back into (44), we get: ∥ ¯wt+1 − w∗∥2 2 ≤ 2(1 − αt)∥w∗∥2 2 + 4b2η2(2(1 − αt)∥w∗∥2 2) + 8η( √ OPT + √ϵ) p 2(1 − αt)∥w∗∥2 − 2ηµ∥vt∥2 2 + 24η2(OPT + ϵ) + 4η(OPT + ϵ)/b ≤ (ρ2 t + ρ4 t )∥w∗∥2 2 + 4b2η2(ρ2 t + ρ4 t )∥w∗∥2 2 + 8 √ 2η( √ OPT + √ϵ)ρt∥w∗∥2 − 2ηµ∥vt∥2 2 + 24η2(OPT + ϵ) + 4η(OPT + ϵ)/b = (1 + ρ2 t + 4b2η2(1 + ρ2 t ))∥vt∥2 2 + 12η( √ OPT + √ϵ)∥vt∥2 − 2ηµ∥vt∥2 2 + 4(6η2 + η/b)(OPT + ϵ) ≤ (1 + ρ2 t + 4b2η2(1 + ρ2 t ))∥vt∥2 2 + 12η( √ OPT + √ϵ)∥vt∥2 − 2ηµ∥vt∥2 2 + 5η(OPT + ϵ), (47) where in the last inequality we observed that since η = µ 4b2 , it holds that 24η ≤ 1, as µ is small and b ≥ 1. Note that we have assumed that ∥vt∥2 ≥ (96/µ)( √ OPT + √ϵ), which indicates 12η( √ OPT + √ϵ)∥vt∥2 ≤ 1 8ηµ∥vt∥2 2, since b ≥ 1 was assumed without loss of generality. Furthermore, when ∥vt∥2 ≥ (96/µ)( √ OPT+√ϵ), it also holds that 1 8ηµ∥vt∥2 2 ≥ (96)2 8µ2 ηµ(OPT + ϵ) ≥ 5η(OPT + ϵ), since we have assumed µ = Ca2LR4/b ≤ 1 without loss of generality. Finally, as we will show in the rest of the proof, it holds that ∥vt+1∥2 ≤ ∥vt∥2 for t = 0, 1, . . . , T, thus as η = µ/(4b2), we have ∥vt∥2 ≤ √ηµ∥w∗∥2/2 = µ∥w∗∥2/(4b), since ∥v0∥2 ≤ √ηµ∥w∗∥2/2. This condition guarantees that ρ2 t = ∥vt∥2 2/∥w∗∥2 2 ≤ 1 4ηµ. Plugging these conditions back into (47), it is then simplified as (note that 1+ρ2 t ≤ 1+(1/4)ηµ ≤ 9/8 for ηµ ≤ 1/2): ∥ ¯wt+1 − w∗∥2 2 ≤ \u0012 1 + 9 2b2η2 − 3 2ηµ \u0013 ∥vt∥2 2. Therefore, when η = µ/(4b2) we have ∥ ¯wt+1 − w∗∥2 2 ≤ \u0012 1 − µ2 32b2 \u0013 ∥vt∥2 2, completing the proof. We proceed first under the condition that ∥vt∥2 ≥ (96/µ)( √ OPT + √ϵ) holds for t = 0, . . . , T and show that after some certain number of iterations T this condition must be violated. Observe that if ∥vt∥2 ≤ (96/µ)( √ OPT + √ϵ), then it holds ∥wt − w∗∥2 2 ≲ (1/µ2)(OPT + ϵ), implying that ˆut(wt · x) is a hypothesis achieving constant approximation error according to Claim 4.4, hence the algorithm can be terminated. However, note that T only works as an upper bound for the iteration complexity of our algorithm, and it is possible that the condition ∥vt∥2 ≥ (96/µ)( √ OPT + √ϵ) is violated at some step t∗ < T. However, as we show later, the value of ∥vT ∥2 cannot be larger than c∥vt∗∥2, where c is an absolute constant. We observe that: vt+1 = w∗ − (w∗ · wt+1)wt+1/∥wt+1∥2 2 = w∗ − (w∗ · ¯wt+1) ¯wt+1/∥ ¯wt+1∥2 2 = (w∗)⊥ ¯ wt+1, 40 therefore, ∥vt+1∥2 2 ≤ ∥ ¯wt+1 − w∗∥2 2, which, combined with Claim D.2, yields ∥vt+1∥2 2 ≤ \u0012 1 − µ2 32b2 \u0013 ∥vt∥2 2 ≤ \u0012 1 − µ2 32b2 \u0013t ∥v0∥2 2 ≤ exp \u0012 − µ2t 32b2 \u0013 2W 2. The above contraction only holds when ∥vt∥2 ≥ (96/µ)( √ OPT + √ϵ). Hence, after at most T = O \u0012 b2 µ2 log \u0012µW ϵ \u0013\u0013 inner iterations, the algorithm outputs a vector wt∗ with ∥vt∗∥2 ≤ 96 µ ( √ OPT + √ϵ), where t∗ ∈ [T]. Now suppose that at step t∗ < T it holds that ∥vt∗∥2 ≤ 96( √ OPT + √ϵ)/µ but at the next iteration ∥vt∗+1∥2 ≥ 96( √ OPT + √ϵ)/µ. Recall first that in Lemma 4.3 we showed that ∥∇ bLsur(bwt; ˆut)∥2 2 ≤ 4b2∥bwt − w∗∥2 2 + 10(OPT + ϵ). Therefore, revisiting the updating scheme of the algorithm we have ∥vt∗+1∥2 2 ≤ ∥ ¯wt∗+1 − w∗∥2 2 = ∥bwt∗ − η∇ bLsur(bwt∗; ˆut∗) − w∗∥2 2 ≤ 2∥bwt∗ − w∗∥2 2 + 2η2∥∇ bLsur(bwt∗; ˆut∗)∥2 2 ≤ (2 + 8b2η2)∥bwt∗ − w∗∥2 2 + 20η2(OPT + ϵ) ≤ 3∥bwt∗ − w∗∥2 2 + (OPT + ϵ), where in the last inequality we plugged in the value of η = µ/(4b2), and used the assumption that µ ≤ 1 and b ≥ 1, hence 20η2 ≤ 1 and 8b2η2 ≤ 1. Furthermore, recall that by the construction of the grid, ∥bwt∗ − wt∥2 ≤ η√ϵ, implying that ∥bwt∗ − w∗∥2 2 ≤ 2∥wt∗ − w∗∥2 2 + 2η2ϵ by triangle inequality. Therefore, going back to the inequality of ∥vt∗+1∥2 2 above, we get ∥vt∗+1∥2 2 ≤ 6∥wt∗ − w∗∥2 2 + 6η2ϵ + OPT + ϵ ≤ 6∥wt∗ − w∗∥2 2 + 2(OPT + ϵ). Finally, observe that since ∥wt∗∥2 = ∥w∗∥2, it holds ∥wt∗ − w∗∥2 ≤ √ 2∥vt∗∥2, hence, we get ∥vt∗+1∥2 2 ≤ 12∥vt∗∥2 2 + 2(OPT + ϵ). Now since ∥vt∗+1∥2 ≥ 96( √ OPT+√ϵ)/µ, the value of ∥vt∥2 2 will start to decrease again for t ≥ t∗+1. This implies that the value of ∥vT ∥2 satisfies ∥vT ∥2 ≤ √ 12∥vt∗∥2 + √ 2( √ OPT + √ϵ) ≤ 384 µ ( √ OPT + √ϵ). Combining Claim 4.4 and Lemma F.4, as we have guaranteed that ∥vT ∥2 ≤ (384/µ)( √ OPT+√ϵ), the hypothesis ˆuT (bwT · x) has the L2 2 error that can be bounded as: L2(bwT ; ˆuT ) ≤ 6OPT + 3b2(4∥vT ∥2 2 + η2ϵ) + ϵ = O \u0012 b2 µ2 (OPT + ϵ) \u0013 . For any ϵ1 > 0, setting ϵ = C′(µ2/b2)ϵ1 with C′ being some small universal absolute constant, we finally get L2(bwT ; ˆuT ) ≤ O((b2/µ2)OPT) + ϵ1. It still remains to determine the batch size as drawing a sample set of size m as displayed in (41) only guarantees that the contraction of ∥vt∥2 at step t holds with probability 1−δ. Applying a union bound on all t0JT = O( Wb10 µ9√ϵ log(1/ϵ)) = O( Wb11 µ10√ϵ1 log(1/ϵ1)) iterations yields that the contraction 41 holds at every step with probability at least 1 − t0JTδ. Therefore, setting δ ← δ(t0JT) and bringing the value of δ back to (41), we get that it suffices to choose the batch size as: m = Θ \u0012dW 9/2b4 log4(d/(ϵδ)) L4 \u0012 1 ϵ3/2 + Wb10 µ9ϵ3/2δ \u0013\u0013 = Θ \u0012dW 11/2b17 log5(d/(ϵ1δ)) L4µ12δϵ3/2 1 \u0013 , to guarantee that we get an O(OPT) + ϵ1-solution with probability at least 1 − δ. Note that we have set ϵ = C′(µ2/b2)ϵ1 in the last equality above. The argument above justifies the claim that among all t0J = Wb7 log(b/µ)/(ηµ7√ϵ1) hypotheses in P = {(bwT j ; ˆuT j )}t0J j=1, there exists at least one hypothesis that achieves L2 2 error O(OPT) + ϵ1. To select the correct hypothesis from the set P, one only needs to draw a new batch of m′ = ˜Θ(b4W 4 log(1/δ)/(L4ϵ2 1)) i.i.d. samples from D, and choose the hypothesis from P that achieves the minimal empirical error defined in Algorithm 4. As discussed in Section 4.3, this procedure introduces an error at most ϵ1. In conclusion, it holds by a union bound that Algorithm 4 delivers a solution with O(OPT) + ϵ1 error with probability at least 1 − 2δ. The total sample complexity of our algorithm is N = t0JTm+m′ = Θ \u0012W 13/2b28d log5(d/(ϵ1δ)) L4µ22δϵ2 1 +b4W 4 log(1/δ) log5(1/ϵ1) L4ϵ2 1 \u0013 = Θ \u0012W 13/2b28d log6(d/(ϵ1δ)) L4µ22δϵ2 1 \u0013 . Choosing δ = 1/6 above we get that the Algorithm 4 succeeds to generate an O(OPT) + ϵ1- solution for any ϵ1 > 0 with probability at least 1 − 2δ = 2/3, hence replacing ϵ1 with ϵ completes the proof of Theorem D.1. D.2 Proof of Lemma 4.3 This subsection is devoted to the proof of Lemma 4.3. To this aim, we first show the following lemmas that bound from above the norm of the population gradient ∇Lsur(wt; ˆut) and the difference between the population gradient and the empirical gradient ∇ bLsur(wt; ˆut). Lemma D.3. Let S be a sample set of m i.i.d. samples of size at least m ≳ d log4(d/(ϵδ))(b2W 3/L2ϵ)3/2. Furthermore, given wt ∈ B(W), let ˆut be defined as in (P). Then, it holds that with probability at least 1 − δ, ∥∇Lsur(wt; ˆut)∥2 2 ≤ 8(OPT + ϵ) + 2b2∥wt − w∗∥2 2. Proof. By the definition of ℓ2 norms, we have: ∥∇Lsur(wt; ˆut)∥2 = max ∥v∥2=1 ∇Lsur(wt; ˆut) · v = max ∥v∥2=1 E (x,y)∼D[(ˆut(wt · x) − y)v · x] = max ∥v∥2=1 \u001a E (x,y)∼D[(ˆut(wt · x) − ut(wt · x) + ut(wt · x) − u∗t(wt · x))(v · x)] + E (x,y)∼D[(u∗t(wt · x) − u∗(w∗ · x) + u∗(w∗ · x) − y)(v · x)] \u001b . 42 By the Cauchy-Schwarz inequality, we further have: ∥∇Lsur(wt; ˆut)∥2 ≤ max ∥v∥2=1 \u001ar E x∼Dx[(ˆut(wt · x) − ut(wt · x))2] E x∼Dx[(v · x)2] + r E x∼Dx[(ut(wt · x) − u∗t(wt · x))2] E x∼Dx[(v · x)2] + r E x∼Dx[(u∗t(wt · x) − u∗(w∗ · x))2] E x∼Dx[(v · x)2] + r E x∼Dx[(u∗(w∗ · x) − y)2] E x∼Dx[(v · x)2] \u001b ≤ r E x∼Dx[(ˆut(wt · x) − ut(wt · x))2] | {z } T1 + r E x∼Dx[(ut(wt · x) − u∗t(wt · x))2] | {z } T2 + r E x∼Dx[(u∗t(wt · x) − u∗(w∗ · x))2] | {z } T3 + r E x∼Dx[(u∗(w∗ · x) − y)2] | {z } T4 , where in the last inequality we used the assumption that Ex∼Dx[xx⊤] ≼ I, hence Ex∼Dx[(v ·x)2] ≤ 1. It remains to bound T1 − T4. Observe first that T1 ≤ √ϵ for every wt ∈ B(W), with probability at least 1 − δ, due to Lemma F.4. By definition, T4 = √ OPT. Recall that in Lemma 3.3 we showed the following T 2 2 = Ex∼Dx[(ut(wt · x) − u∗t(wt · x))2] ≤ OPT. For T3, note that u∗t ∈ argminu∈U(a,b) Ex∼Dx[(u(wt · x) − u∗(w∗ · x))2], therefore, since u∗ ∈ U(a,b), we have T 2 3 = E x∼Dx[(u∗t(wt · x) − u∗(w∗ · x))2] ≤ E x∼Dx[(u∗(wt · x) − u∗(w∗ · x))2] ≤ b2∥wt − w∗∥2 2, after applying the assumption that u∗ is b-Lipschitz. Thus, in conclusion, we have ∥∇Lsur(wt; ˆut)∥2 ≤ 2 √ OPT + √ϵ + b∥wt − w∗∥2. Furthermore, since (a + b)2 ≤ 2a2 + 2b2 for any a, b ∈ R, we get with probability at least 1 − δ: ∥∇Lsur(wt; ˆut)∥2 2 ≤ 8OPT + 8ϵ + 2b2∥wt − w∗∥2 2, completing the proof of Lemma D.3. We now prove that the distance between ∇Lsur(wt; ˆut) and ∇ bLsur(wt; ˆut) is bounded by b2∥wt − w∗∥2 2 + OPT + ϵ with high probability. Lemma D.4. Let S be a sample set of m ≳ (dW 9/2b4 log4(d/(ϵδ))/L4)(1/ϵ3/2+1/(ϵδ)) i.i.d. samples. Given a vector wt ∈ B(W), it holds that with probability at least 1 − δ, ∥∇ bLsur(wt; ˆut) − ∇Lsur(wt; ˆut)∥2 ≤ q b2∥wt − w∗∥2 2 + OPT + ϵ. Proof. Since for any zero-mean independent random variable zj, we have E[|| P j zj||2 2] = P j E[∥zj∥2 2], by Chebyshev’s inequality: Pr[∥∇ bLsur(wt; ˆut) − ∇Lsur(wt; ˆut)∥2 ≥ s] ≤ 1 ms2 E (x,y)∼D[∥(ˆut(wt · x) − y)x∥2 2] . (48) By linearity of expectation, we have: E (x,y)∼D[∥(ˆut(wt · x) − y)x∥2 2] = d X k=1 E (x,y)∼D[(ˆut(wt · x) − y)2(xk)2], 43 where xk = ek · x and ek is the kth unit basis of Rd. Let r = O(W/L log(1/(Lϵ′))), then it holds Pr[|xk| ≥ r] ≤ ϵ′. Then, the variance above can be decomposed into the following parts: E (x,y)∼D[(ˆut(wt · x) − y)2x2 k] = E (x,y)∼D[(ˆut(wt · x) − y)2x2 k1{|xk| ≥ r}] + E (x,y)∼D[(ˆut(wt · x) − y)2x2 k1{|xk| ≤ r}]. Since |y| ≤ M = O(bW/L log(bW/ϵ)), and Ex∼Dx[(wt · x)4x4 k] ≤ W 4c2/L8, Ex∼Dx[x4 k] ≤ c2/L4 for Dx is L-sub-exponential, we have E (x,y)∼D[(ˆut(wt · x) − y)2x2 k1{|xk| ≥ r}] ≤ 2 E (x,y)∼D[(ˆut(wt · x))2 + y2)x2 k1{|xk| ≥ r}] ≤ 2 E (x,y)∼D[(b(wt · x))2 + y2)x2 k1{|xk| ≥ r}] ≤ 2b2 r E x∼Dx[((wt · x)4x4 k] Pr[|xk| ≥ r] + 2M2 r E x∼Dx[x4 k] Pr[|xk| ≥ r] ≤ (2cb2W 2/L4) √ ϵ′ + (2cM2/L2) √ ϵ′ ≤ (4cM2/L2) √ ϵ′. (49) In addition, (ˆut(wt · x) − y)2 can be decomposed as the following: E (x,y)∼D[(ˆut(wt · x) − y)2] ≤ 4 E x∼Dx[(ˆut(wt · x) − ut(wt · x))2] + 4 E x∼Dx[(ut(wt · x) − u∗t(wt · x))2] + 4 E x∼Dx[(u∗t(wt · x) − u∗(w∗ · x))2] + 4 E (x,y)∼D[(u∗(w∗ · x) − y)2]. The first term is bounded above by 4ϵ with probability at least 1 − δ for every wt ∈ B(W) whenever m ≳ d log4(d/(ϵδ))(b2W 3/L2ϵ)3/2, as proved in Lemma F.4. The second term is smaller than 4OPT, which is shown in Lemma 3.3. The third term can be bounded above using again the definition of u∗t = argminu∈U(a,b) Ex∼Dx[(u(wt · x) − y∗)2], as 4 E x∼Dx[(u∗t(wt · x) − u∗(w∗ · x))2] ≤ 4 E x∼Dx[(u∗(wt · x) − u∗(w∗ · x))2] ≤ 4b2∥wt − w∗∥2 2, using the fact that u∗ is b-Lipschitz and Ex∼Dx[xx⊤] ≼ I. Lastly, the fourth term is bounded by 4OPT by the definition of u∗(w∗ · x). In summary, we have E (x,y)∼D[(ˆut(wt · x) − y)2x2 k1{|xk| ≤ r}] ≤ r2 E (x,y)∼D[(ˆut(wt · x) − y)2] ≤ 4r2(b2∥wt − w∗∥2 2 + 2OPT + ϵ), which, combining with (49), implies that the expectation E(x,y)∼D[(ˆut(wt · x) − y)2x2 k] is bounded by: E (x,y)∼D[(ˆut(wt · x) − y)2x2 k] ≤ 4r2b2∥wt − w∗∥2 2 + 4r2(2OPT + 2ϵ) ≤ CW 2 L2 log2 \u0012 b Lϵ \u0013 (b2∥wt − w∗∥2 2 + OPT + ϵ), 44 where C is a large absolute constant. Note to get the inequality above we chose ϵ′ = Cϵ2(L/b)4, which then indicates that 4c(M/L)2√ ϵ′ ≤ r2ϵ. Summing the inequality above from k = 1 to d delivers the final upper bound on the variance: E (x,y)∼D[∥(ˆut(wt · x) − y)x∥2 2] ≤ dCW 2 L2 log2 \u0012 b Lϵ \u0013 (b2∥wt − w∗∥2 2 + OPT + ϵ). Thus, plugging the upper bound on the variance above back to (48), as long as m ≳ (dW 2/L2) log2(b/(Lϵ))/δ, we get with probability at least 1 − δ, ∥∇ bLsur(wt; ˆut) − ∇Lsur(wt; ˆut)∥2 ≤ q b2∥wt − w∗∥2 2 + OPT + ϵ. Noting that m ≳ (dW 9/2b4 log4(d/(ϵδ))/L4)(1/ϵ3/2 + 1/(ϵδ)) certainly satisfies the condition on m above as m ≳ (dW 2/L2) log2(b/(Lϵ))/δ, thus, we completed the proof of Lemma D.4 We can now proceed to the proof of Lemma 4.3 (detailed statement in Lemma D.5 below), which can be derived directly from the preceding lemmas. Lemma D.5 (Upper Bound on Empirical Gradient Norm). Let S be a set of i.i.d. samples of size m ≳ (dW 9/2b4 log4(d/(ϵδ))/L4)(1/ϵ3/2 + 1/(ϵδ)). Given any wt ∈ B(W), let ˆut ∈ U(a,b) be the solution of optimization problem (P) with respect to wt and sample set S. Then, with probability at least 1 − δ, we have that ∥∇ bLsur(wt; ˆut)∥2 2 ≤ 4b2∥wt − w∗∥2 2 + 10(OPT + ϵ). Proof. The lemma follows directly by combining Lemma D.3, Lemma D.4 and the triangle inequality. D.3 Proof of Claim 4.4 We restate (providing a more detailed statement for the sample size) and prove Claim 4.4. Claim D.6. Let w be any vector from B. Let ˆuw be a solution to (P) for a fixed parameter vector w ∈ Rd with sample size m ≳ d log4(d/(ϵδ))(b2W 3/(L2ϵ))3/2. Then E (x,y)∼D[(ˆuw(w · x) − y)2] ≤ 8(OPT + ϵ) + 4b2∥w − w∗∥2 2. Proof. Let u∗ w, uw be the optimal activations for problems (EP*) and (EP) under parameter w, respectively. Then, a direct calculation gives: E (x,y)∼D[(ˆuw − y)2] = E (x,y)∼D[(ˆuw(w · x) − uw(w · x) + uw(w · x) − u∗ w(w · x) + u∗ w(w · x) − u∗(w∗ · x) + u∗(w∗ · x) − y)2] ≤ 4 E x∼Dx[(ˆuw(w · x) − uw(w · x))2] + 4 E x∼Dx[(uw(w · x) − u∗ w(w · x))2] + 4 E x∼Dx[(u∗ w(w · x) − u∗(w∗ · x))2] + 4OPT ≤ 8(OPT + ϵ) + 4b2∥w − w∗∥2 2, (50) where in the second inequality we used the results from Lemma 3.3, Lemma F.4 and we applied the observation that: E x∼Dx[(u∗ w(w · x) − u∗(w∗ · x))2] ≤ E x∼Dx[(u∗(w · x) − u∗(w∗ · x))2] ≤ b2∥w − w∗∥2 2, by the definition of u∗ w. 45 D.4 Proof of Claim 4.5 We restate Claim 4.5 and show the number of samples needed for the testing subroutine Algorithm 3. Claim 4.5. Let µ, ϵ1, δ ∈ (0, 1) be fixed. Let r = 1 L log( Cb4W 4 L6ϵ2 1 log2( bW ϵ1 )), where C is a sufficiently large absolute constant. Given a set of parameter-activation pairs P = {(wj; uj)}t0J j=1 such that wj ∈ B(W) and uj ∈ U(a,b) for j ∈ [t0J], where t0J = 4b9W/(µ8√ϵ1), we have that using m′ = Θ \u0012b4W 4 log(1/δ) L4ϵ2 1 log5 \u0012 bW Lµϵ1 \u0013\u0013 , i.i.d. samples from D, for any (wj; uj) ∈ P it holds with probability at least 1 − δ, \f\f\f\f 1 m′ m′ X i=1 (uj(wj · x(i)) − y(i))21{|wj · x(i)| ≤ Wr} − E (x,y)∼D[(uj(wj · x) − y)2] \f\f\f\f ≤ 2ϵ1. Proof. Fix (wj, uj) ∈ P. Since Dx is sub-exponential, we have Pr[|wj ·x| ≥ ∥wj∥2r] ≤ 1 L2 exp(−Lr). Consider random variables Zi,j = (uj(wj ·x(i))−y(i))21{|w ·x(i)| ≤ r}, i = 1, · · · , m, j = 1, · · · , t0J, where (x(i), y(i)) are independent random variables drawn from D. Using Fact F.3 (Appendix F), we can truncate the labels y such that |y| ≤ M, where M = C(bW/L) log(bW/ϵ1) for some large absolute constant C. Hence, |Zi,j| ≤ 2(u2 j(wj · x(i)) + (y(i))2)1{|wj · x(i)| ≤ Wr} ≤ 2(b2W 2r2 + M2), where we used the assumption that u is b-Lipschitz in the last inequality. Therefore, applying Hoeffding’s inequality to Zi,j we get: Pr \u0014\f\f\f\f m′ X i=1 (Zi,j − E[Zi,j]) \f\f\f\f ≥ m′t \u0015 ≤ 2 exp \u0012 − m′t2 8(b2W 2r2 + M2)2 \u0013 . Since there are t0J = Wb7/(µ7η√ϵ1) = 4b9W/(µ8√ϵ1) elements in the set P, applying a union bound leads to: Pr \u0014\f\f\f\f m′ X i=1 Zi,j − E[Zi,j] \f\f\f\f ≥ m′t, ∀j ∈ [J] \u0015 ≤ 2 exp \u0012 − m′t2 8(b2W 2r2 + M2)2 + log(4b9W/(µ8√ϵ1)) \u0013 . Therefore, when m′ ≥ 8(b2W 2r2 + M2)2 ϵ2 1 \u0012 log \u0012 4b9W µ8√ϵ1 \u0013 + log(2/δ) \u0013 , (51) we have that with probability at least 1 − δ: \f\f\f\f 1 m′ m′ X i=1 (uj(wj·x(i))−y(i))21{|wj·x(i)| ≤ Wr}− E (x,y)∼D[(uj(wj·x)−y)21{|wj·x| ≤ Wr}] \f\f\f\f ≤ ϵ1, (52) for any (wj, uj) ∈ P. In addition, as Pr[|wj · x| ≥ Wr] ≤ Pr[|wj · x| ≥ ∥wj∥2r] ≤ 2 L2 exp(−Lr), letting ϵ′ = 2 L2 exp(−Lr), we further have: E (x,y)∼D[(uj(wj · x) − y)21{|wj · x| ≥ Wr}] ≤ 2 E x∼Dx[((uj(wj · x))2 + M2)1{|wj · x| ≥ Wr}] ≤ 2b2r E x∼Dx[(wj · x)4] Pr[|wj · x| ≥ Wr] + M2 Pr[|wj · x| ≥ Wr] ≤ 2cb2(W/L)2√ ϵ′ + M2ϵ′ ≤ (2cb2(W/L)2 + M2) √ ϵ′, 46 where in the second inequality we used Cauchy-Schwarz inequality and in the last inequality we used the property that for any unit vector a it holds E[(a · x)4] ≤ c2/L4 for some absolute constant c as x possesses a 1 L-sub-exponential tail. Therefore, choosing r = 1 L log( C2b4W 4 L6ϵ2 1 log2( bW ϵ1 )) = ˜O( 1 L log( bW Lϵ1 )) for some large absolute constant C renders √ ϵ′ ≤ ϵ1/(2Cb2(W/L)2 log2(bW/ϵ1)), and we have E (x,y)∼D[(uj(wj · x) − y)21{|wj · x| ≥ Wr}] ≤ ϵ1. Observe that as E(x,y)∼D[(uj(wj · x) − y)2] is the sum of E(x,y)∼D[(uj(wj · x) − y)21{|wj · x| ≥ Wr}] and E(x,y)∼D[(uj(wj · x) − y)21{|wj · x| ≤ Wr}], we have 0 ≤ E (x,y)∼D[(uj(wj · x) − y)2] − E (x,y)∼D[(uj(wj · x) − y)21{|wj · x| ≤ Wr}] ≤ E (x,y)∼D[(uj(wj · x) − y)21{|wj · x| ≥ Wr}] ≤ ϵ1. Plugging the choice of r back into (51), we get that it is sufficient to choose m′ as m′ = C log(log(1/ϵ1)) ϵ2 1 \u0012 b2 \u0012W L \u00132 log2 \u0012bW Lϵ2 1 \u0013\u00132\u0012 log \u0012 4b9W µ8√ϵ1 \u0013 +log(1/δ) \u0013 = ˜Θ \u0012b4W 4 log(1/δ) L4ϵ2 1 log5 \u0012 bW Lµϵ1 \u0013\u0013 . Therefore, using m′ = ˜Ω(b4W 4/(L4ϵ2 1)) samples, (52) indicates that with probability at least 1 − δ, for any (wj, uj) ∈ P it holds \f\f\f\f 1 m′ m′ X i=1 (uj(wj · x(i)) − y(i))21{|wj · x(i)| ≤ Wr} − E (x,y)∼D[(uj(wj · x) − y)2] \f\f\f\f ≤ \f\f\f\f 1 m′ m′ X i=1 (uj(wj · x(i)) − y(i))21{|wj · x(i)| ≤ Wr} − E (x,y)∼D[(uj(wj · x) − y)21{|wj · x| ≤ Wr}] \f\f\f\f + \f\f\f\f E (x,y)∼D[(uj(wj · x) − y)2] − E (x,y)∼D[(uj(wj · x) − y)21{|wj · x| ≤ Wr}] \f\f\f\f ≤ 2ϵ1, thus completing the proof of Claim 4.5. E Efficiently Computing the Optimal Empirical Activation In this section, we show that the optimization problem (P) can be solved efficiently, following the framework from [LH22] with minor modifications. We show that, for any ϵ > 0, there is an efficient algorithm that runs in ˜O(m2 log(1/ϵ)) time and outputs a solution ˆvt(z) such that ∥ˆvt(z) − ˆut(z)∥∞ ≤ ϵ. We then argue that using such approximate solutions to the optimization problem (P) does not negatively impact our error guarantee, sample complexity, or runtime (up to constant factors). Proposition E.1 (Approximating the Optimal Empirical Activation). Let ϵ > 0, and Dx be (L, R)- well behaved. Let ˆut ∈ U(a,b) be the optimal solution of the optimization problem (P) given a sample set S of size m drawn from D and a parameter wt ∈ B(W). There exists an algorithm that produces an activation ˆvt ∈ U(a,b) such that ∥ˆvt − ˆut∥∞ ≤ ϵ, with runtime ˜O(m2 log(bW/(Lϵ))). To prove Proposition E.1, we leverage the following result: 47 Lemma E.2 (Section 5 [LH22]). Let fi(y) and hi(y) be any convex lower semi-continuous functions for i = 1, . . . , m. Consider the following convex optimization problem (ˆy1, . . . , ˆym) = argmin y1,...,ym m X i=1 fi(yi) + m−1 X i=1 hi(yi − yi+1), (53) where yi ∈ [−U, U] for all i = 1, . . . , m for some positive constant U. Then, for any ϵ > 0, there exists an algorithm (the cc-algorithm [LH22]) that outputs an ϵ-close solution {y1, . . . , ym} such that |yi − ˆyi| ≤ ϵ for all i ∈ [m] with runtime O(m2 log(U/ϵ)). Proof of Proposition E.1. We first reformulate problem (P) as a quadratic optimization problem with linear constraints. To guarantee that ˆut is an element in U(a,b) that satisfies ˆut(0) = 0, we add a zero point (x(0), y(0)) = (0, 0) to the data set S if S does not contain (0, 0) in the first place. We can thus assume without loss of generality that the data set contains (0, 0). Denote zi = w · x(i) such that z1 ≤ z2 ≤ · · · ≤ zm after rearranging the order of (x(i), y(i))’s, and suppose zk = w · x0 = 0 for a k ∈ [m]. Then (P) is equivalent to the following optimization problem: (ˆy(1), · · · , ˆy(m)) = argmin ˜y(i),i∈[m] m X i=1 (˜y(i) − y(i))2 s.t. 0 ≤ ˜y(i+1) − ˜y(i), 1 ≤ i ≤ k − 1, a(zi+1 − zi) ≤ ˜y(i+1) − ˜y(i), 1 ≤ i ≤ k − 1, ˜y(i+1) − ˜y(i) ≤ b(zi+1 − zi), 1 ≤ i ≤ m − 1, ˜y(k) = 0. Define hi(y) = I[−b(zi+1−zi),0](y) for i = 1 . . . , k − 1, hi(y) = I[−b(zi+1−zi),−a(zi+1−zi)](y) for i = k . . . , m − 1, where IY(y) is the indicator function of a convex set Y, i.e., IY(y) = 0 if y ∈ Y and IY(y) = +∞ otherwise. It is known that hi’s are convex and sub-differentiable on their domain Yi. In addition, let fi(y) = 1 2(y − y(i))2 for i ̸= k and fk(y) = I{0}(y). Then, we have the following formulation for problem (P): (ˆy(1), · · · , ˆy(m)) = argmin ˜y(i),i=1,...,m m X i=1 fi(˜y(i)) + m−1 X i=1 hi(˜y(i) − ˜y(i+1)) (P1) Note that the functions fi and hi we defined above satisfy the conditions of Lemma E.2. Thus, it only remains to find the bounds on the variables ˜y(i). This is easy to achieve as all ˜y(i) must satisfy |˜y(i)| ≤ b|zi| = b|w · x(i)| and we know that x(i) are sub-exponential random variables. Therefore, following the same idea from the proof of Lemma F.2, we know that for U = 2W L log(m/(Lδ)), it holds that with probability at least 1−δ, |˜y(i)| ≤ b|w·x(i)| ≤ bU for all i ∈ [m]. Hence, applying Lemma E.2 to problem (P1), we get that it can be solved within ϵ-error in runtime ˜O(m2 log(bW/(Lϵ))). The effect of approximation error in (P) Since the solution ˆvt is ϵ-close to ˆut, this approximated solution will only result in an ϵ-additive error in the sharpness result Proposition 3.1 and the gradient norm concentration Lemma 4.3. In more detail, for the result of Proposition 3.1, we have \f\f\f\f(∇ bLsur(wt; ˆvt) − ∇ bLsur(wt; ˆut)) · (wt − w∗) \f\f\f\f = \f\f\f\f 1 m m X i=1 (ˆvt(wt · x(i)) − ˆut(wt · x(i)))(wt − w∗) · x(i) \f\f\f\f ≤ ϵ m m X i=1 \f\f(wt − w∗) · x(i)\f\f ≤ 2ϵU, 48 since |wt · x(i)| ≤ U and |w∗ · x(i)| ≤ U with probability at least 1 − δ. Therefore, choosing ϵ′ = ϵ/U we have that Proposition 3.1 holds for approximate activations ˆvt with an additional ϵ error. Observe that this does not affect the approximation factor in our final O(OPT) + ϵ result, while the value of ϵ only needs to be rescaled by a constant factor, effectively increasing the sample size and the runtime by constant factors. Let us denote the unit ball by B. For the gradient norm concentration lemma Lemma 4.3, note that at any iteration t, it always holds that ∥∇ bLsur(wt; ˆvt) − ∇ bLsur(wt; ˆut)∥2 = max v∈B 1 m m X i=1 (ˆvt(wt · x(i)) − ˆut(wt · x(i)))x(i) · v ≤ max v∈B ϵ m m X i=1 |x(i) · v|. Since Ex∼Dx[xx⊤] ≼ I and v ∈ B, we have Ex∼Dx[|x · v|] ≤ p E[(x · v)2] ≤ 1. Now since |x(i) · v| are independent 1/L-sub-exponential random variables, applying Bernstein’s inequality it holds that for any v ∈ B and an absolute constant c, Pr \u0014\f\f\f\f 1 m m X i=1 |x(i) · v| − E x∼Dx[|x · v|] \f\f\f\f ≥ s \u0015 ≤ 2 exp \u0012 − c min \u001a m2s2 m/L2 , ms 1/L \u001b\u0013 = 2 exp(−cmL2s2). Let N(B, ϵ; ℓ2) be the ϵ-net of the unit ball B. Note that the cover number of these v ∈ B is of order (1/ϵ)O(d), therefore, applying a union bound on N(B, ϵ; ℓ2) and for all t0JT = O(log(1/ϵ)/√ϵ) iterations, and setting s = 1, it holds Pr \u0014 ∀v ∈ N(B, ϵ; ℓ2), \f\f\f\f 1 m m X i=1 |x(i) · v| − E x∼Dx[|x · v|] \f\f\f\f ≥ 1 \u0015 ≤ 2 exp(−cmL2 + c′d log(1/ϵ)) ≤ δ, where the last inequality comes from the fact that we have m ≳ W 9/2b14d log(1/δ) log4(d/ϵ)/(L4µ9δϵ3/2) as the batch size. Let v∗ = argmaxv∈B Pm i=1 |x(i) · v|. Then there exists a v′ ∈ N(B, ϵ; ℓ2) such that ∥v′ − v∗∥2 ≤ ϵ and hence, 1 m m X i=1 |x(i) · v∗| ≤ 1 m m X i=1 |x(i) · (v∗ − v′)| + 1 m m X i=1 |x(i) · v′| = ϵ m m X i=1 |x(i) · v∗ − v′ ϵ | + 1 m m X i=1 |x(i) · v′| ≤ ϵ m m X i=1 |x(i) · v∗| + 1 m m X i=1 |x(i) · v′|, where the last inequality comes from the observation that as (v∗ − v′)/ϵ ≤ B, it holds Pm i=1 |x(i) · ((v∗ − v′)/ϵ)| ≤ Pm i=1 |x(i) · v∗|, by the definition of v∗. Therefore, with probability at least 1 − δ we have 1 m m X i=1 |x(i) · v∗| ≤ 1 1 − ϵ 1 m m X i=1 |x(i) · v′| ≤ 2(1 + E x∼Dx[|v · x|]) ≤ 4. This implies that ∥∇ bLsur(wt; ˆvt)∥2 ≤ ∥∇ bLsur(wt; ˆut)∥2 + 4ϵ for all iterations with probability at least 1 − δ. Therefore, Lemma 4.3 continues to hold for the ϵ-approximate activation ˆvt. Thus, we have that the inequalities (40) and (42) in the proof of Theorem 4.2 remain valid for ϵ-approximate ˆvt, and hence the results in Theorem 4.2 are unchanged. 49 F Uniform Convergence of Activations In this section, we review and provide standard uniform convergence results showing that the sample-optimal activations concentrate around their population-optimal counterparts. We first bound the L2 2 distance between the sample-optimal and population-optimal activations under wt. To do so, we build on Lemma 8 in [KKSK11]. Note that Lemma 8 from [KKSK11] only works for bounded 1-Lipschitz activations u : R 7→ [0, 1], hence it is not directly applicable to our case. Fortunately, since Dx has a sub-exponential tail (see Definition 1.2), we are able to bound the range of u(w · x) for u ∈ U(a,b) and w ∈ B(W) with high probability. Concretely, we prove the following lemma. Note that in the lemma statement, ˆu∗t is a random variable defined w.r.t. the (random) dataset S∗, and thus the probabilistic statement is for this random variable. We make use of the following fact from [KKSK11]: Fact F.1 (Lemma 8 [KKSK11]). Let V be the set of non-deceasing 1-Lipschitz functions such that v : R → [0, 1], ∀v ∈ V. Given Sm = {(x(i), y(i))}m i=1, where (x(i), y(i)) are sampled i.i.d. from some distribution D′, let ˆvw ∈ argmin v∈V 1 m m X i=1 (v(w · x(i)) − y(i))2. Then, with probability at least 1−δ over the random dataset Sm, for any w ∈ B(W) it holds uniformly that E (x,y)∼D′[(ˆvw(w · x) − y)2] − inf v∈V E (x,y)∼D′[(v(w · x) − y)2] = O \u0012 W \u0012d log(Wm/δ) m \u00132/3\u0013 . The first lemma states that with sufficient many of samples, the idealized sample-optimal activation ˆu∗t defined as the optimal solution of (P*) is close to its population counterpart u∗t, the optimal solution of (EP*). Lemma F.2 (Approximating Population-Optimal Noiseless Activation by Sample-Optimal). Let Dx be (L, R)-well behaved and let wt ∈ B(W). Provided a dataset S∗ = {(x(i), y∗(i))}, where x(i) are i.i.d. samples from Dx and y∗(i) = u∗(w∗ · x(i)), let ˆu∗t be the sample-optimal activation on S∗ as defined in (P*). In addition, let u∗t be the corresponding population-optimal activation, following the definition in (EP*). Then, for any ϵ, δ > 0, if the size m of the dataset S∗ is sufficiently large m ≳ d log4(d/(ϵδ)) \u0012b2W 3 L2ϵ \u00133/2 , we have that with probability at least 1 − δ, for any wt ∈ B(W): E x∼Dx[(ˆu∗t(wt · x) − u∗(w∗ · x))2] ≤ E x∼Dx[(u∗t(wt · x) − u∗(w∗ · x))2] + ϵ , and, furthermore, E x∼Dx[(ˆu∗t(wt · x) − u∗t(wt · x))2] ≤ ϵ. Proof. Our goal is to show that with high probability, the sample-optimal activation ˆu∗t ∈ U(a,b) and the population optimal activation u∗t ∈ U(a,b) can be scaled to 1-Lipschitz functions mapping R to [0, 1], then, Fact F.1 can be applied. Since x possesses a sub-exponential tail, for any w ∈ B(W) we have Pr[|w · x| ≥ ∥w∥2r] ≤ 2 L2 exp(−Lr). Therefore, with probability at least 1 − (δ1/m)2 it holds |w · x| ≤ 2W L log(m/(Lδ1)). 50 Since we have m samples, a union bound on these m samples yields that with probability at least 1 − δ2 1/m it holds |w · x(i)| ≤ 2W L log(m/(Lδ1)), for any given w ∈ B(W). Let r = 2W L log(m/(Lδ1)). In the remainder of the proof, we assume that wt · x(i) ≤ r holds for every x(i) in the dataset S∗, which happens with probability at least 1 − δ2 1/m ≥ 1 − δ1. Let V be the set of non-decreasing 1-Lipschitz functions v : R → [0, 1] such that v(0) = 1/2, and v(z1) − v(z2) ≥ (a/(2br))(z1 − z2) for all z1 ≥ z2 ≥ 0. We observe that restricted on the interval |z| ≤ r, (ˆu∗t(z)/(2br) + 1/2)||z|≤r is 1-Lipschitz, non-decreasing and bounded in the interval [0, 1]. Thus, (ˆu∗t(z)/(2br) + 1/2)||z|≤r = ˆv∗t(z)||z|≤r, for some ˆv∗t ∈ V. Furthermore, under the condition that |wt · x(i)| ≤ r, since (ˆu∗t(z)/(2br) + 1/2)||z|≤r = ˆv∗t(z)||z|≤r, we observe that v∗t(z) is the optimal activation in the function space V, given the dataset S∗ and parameter wt, i.e., ˆv∗t ∈ argmin v∈V 1 m m X i=1 (v(wt · x(i)) − (u∗(w∗ · x(i))/(2br) + 1/2))2. In other words, ˆu∗t(z)/(2br) + 1/2 is the sample-optimal activation in the function class V when restricted to the interval |z| ≤ r. Consider x ∼ Dx. Then Pr[|wt · x| ≥ r] ≤ (δ1/m)2 and for any wt ∈ B(W), the expectation Ex∼Dx[(ˆu∗t(wt · x) − u∗(w∗ · x))2] can be decomposed into the following terms E x∼Dx[(ˆu∗t(wt · x) − u∗(w∗ · x))2] = E x∼Dx[(ˆu∗t(wt · x) − u∗(w∗ · x))21{|wt · x| ≤ r}] + E x∼Dx[(ˆu∗t(wt · x) − u∗(w∗ · x))21{|wt · x| > r}] ≤ E x∼Dx[(ˆu∗t(wt · x) − u∗(w∗ · x))21{|wt · x| ≤ r}] + 2 E x∼Dx[(ˆu∗t(wt · x))2 + (u∗(w∗ · x))21{|wt · x| > r}] . (54) Since both ˆu∗t and u∗ are (a, b)-unbounded functions such that ˆu∗t(0) = u∗(0) = 0, we have (ˆu∗t(wt · x))2 ≤ b2W 2((wt/∥wt∥2) · x)2 and similarly, (u∗(w∗ · x))2 ≤ b2W 2((w∗/∥w∗∥2) · x)2. Furthermore, since for any unit vector a, the random variable a · x follows a (1/L)-sub-exponential distribution as Dx is (L, R)-well behaved, thus, it holds that Ex∼Dx[(a·x)4] ≤ c/L4 for some absolute constant c. Therefore, after applying Cauchy-Schwarz inequality to E[(ˆu∗t(wt · x))21{|wt · x| ≥ r}], we get E[(ˆu∗t(wt · x))21{|wt · x| ≥ r}] ≤ b2W 2r E x∼Dx[((wt/∥wt∥2) · x)4] Pr[|wt · x| ≥ r] ≤ cb2W 2δ1/(L2m), (55) and similarly, E[(u∗(w∗ · x))21{|wt · x| ≥ r}] ≤ cb2W 2δ1/(L2m). Thus, plugging these inequalities back into (54), we get E x∼Dx[(ˆu∗t(wt · x) − u∗(w∗ · x))2] ≤ E x∼Dx[(ˆu∗t(wt · x) − u∗(w∗ · x))21{|wt · x| ≤ r}] + 2cb2W 2δ1/(L2m). We are now ready to apply Fact F.1 (note that V is a smaller function class compared to the class of 1-Lipschitz functions described Fact F.1, hence Fact F.1 applies). Denote A = {x : |wt · x| ≤ r}. Let y′ = y∗/(2br) + 1/2, y∗ = u∗(w∗ · x). Since conditioning on A, ˆu∗t(z)/(2br) + 1/2 is the 51 sample-optimal activation, applying Fact F.1 we get that with probability at least 1 − δ2: E x∼Dx[(ˆu∗t(wt · x)/(2br) + 1/2 − (u∗(w∗ · x)/(2br) + 1/2))2|A] = E x∼Dx[(ˆv∗t(wt · x) − y′)2|A] ≤ inf v∈V E x∼Dx[(v(wt · x) − y′)2|A] + ˜O(W(d log(m/δ2)/m)2/3). Let V||z|≤r and U(a,b)||z|≤r be the functions from V and U(a,b) restricted on the interval |z| ≤ r, respectively. It is not hard to see that by the definition of U(a,b) and V, (U(a,b)||z|≤r)/(2br) + 1/2 ⊂ V||z|≤r. Therefore, inf v∈V E x∼Dx[(v(wt · x) − y′)2|A] ≤ inf u∈U E x∼Dx[(u(wt · x)/(2br) + 1/2 − y′)2|A] ≤ 1 4b2r2 inf u∈U E x∼Dx[(u(wt · x) − y∗)2|A]. Hence, with probability at least 1 − δ2, E x∼Dx[(ˆu∗t(wt · x) − u∗(w∗ · x))21{A}] = 4b2r2 E x∼Dx[(ˆv∗t(wt · x) − y′)2|A] Pr[A] ≤ 4b2r2 inf v∈V E x∼Dx[(v(wt · x) − y′)2|A] Pr[A] + ˜O(b2r2W(d log(m/δ2)/m)2/3) Pr[A] ≤ inf u∈U E x∼Dx[(u(wt · x) − u∗(w∗ · x))21{A}] + ˜O(b2r2W(d log(m/δ2)/m)2/3) ≤ inf u∈U E x∼Dx[(u(wt · x) − u∗(w∗ · x))2] + ˜O(b2r2W(d log(m/δ2)/m)2/3) . Setting δ1 = δ2 = δ/2 and plugging everything back into (56), we finally get that with probability at least 1 − δ, E x∼Dx[(ˆu∗t(wt · x) − u∗(w∗ · x))2] ≤ inf u∈U E x∼Dx[(u(wt · x) − u∗(w∗ · x))2] + O \u0012b2W 3 L2 log2 \u0012 m Lδ \u0013\u0012d log(m/δ) m \u00132/3\u0013 . To complete the first part of the claim, it remains to choose m as the following value m = Θ \u0012 d log4(d/(ϵδ)) \u0012b2W 3 L2ϵ \u00133/2\u0013 . For the second part of the claim, note that U(a,b) is a closed convex set of functions, and that the infimum infu∈U Ex∼Dx[(u(wt · x) − u∗(w∗ · x))2] is attained by u∗t(z). Observe that we have shown that with the sample size m specified above, with probability at least 1 − δ, it holds ϵ ≥ E x∼Dx[(ˆu∗t(wt · x) − u∗(w∗ · x))2 − (u∗t(wt · x) − u∗(w∗ · x))2] = E x∼Dx[(ˆu∗t(wt · x) − u∗t(wt · x))(ˆu∗t(wt · x) + u∗t(wt · x) − 2u∗(w∗ · x))] = E x∼Dx[(ˆu∗t(wt · x) − u∗t(wt · x))2] + 2 E x∼Dx[(ˆu∗t(wt · x) − u∗t(wt · x))(u∗t(wt · x) − u∗(w∗ · x))]. 52 Since ˆu∗t(z) ∈ U(a,b), applying the second part of Claim C.1 with v′ = ˆu∗t we get E x∼Dx[(u∗t(wt · x) − ˆu∗t(wt · x))(u∗(w∗ · x) − u∗t(wt · x))] ≥ 0. Thus, we have: E x∼Dx[(ˆu∗t(wt · x) − u∗t(wt · x))2] ≤ ϵ. This completes the proof of Lemma F.2. To prove a similar uniform convergence result for the attainable activations ˆut, we make use of the following fact from prior literature, which shows that we can without loss of generality take the noisy labels to be bounded by M = O( bW L log(bW/ϵ)), due to Dx being (L, R)-well behaved. Fact F.3 (Lemma D.8 [WZDD23]). Let y′ = sign(y) min(|y|, M) for M = bW L log( 16b4W 4 ϵ2 ). Then: E (x,y)∼D[(u∗(w∗ · x) − y′)2] = OPT + ϵ. In other words, we can assume |y| ≤ M without loss of generality by truncating labels that are larger than M. Under this assumption, as stated in Lemma F.4 below, we bound the L2 2 distance between ˆut and ut using similar arguments as in Lemma F.2. Lemma F.4 (Approximating Population-Optimal Activation by Sample-Optimal). Let wt ∈ B(W). Given a distribution D whose marginal Dx is (L, R)-well behaved, let S = {(x(i), y(i))}m i=1, where (x(i), y(i)) for i ∈ [m] are i.i.d. samples from D. Let ˆut be a sample-optimal activation for the dataset S and parameter vector wt, as defined in (P). In addition, let ut be the corresponding population-optimal activation, as defined in (EP). Then, for any ϵ, δ > 0, choosing a sufficiently large m ≳ d log4(d/(ϵδ)) \u0012b2W 3 L2ϵ \u00133/2 , we have that for any wt ∈ B(W), with probability at least 1 − δ over the dataset S: E (x,y)∼D[(ˆut(wt · x) − y)2] ≤ E (x,y)∼D[(ut(wt · x) − y)2] + ϵ , and, furthermore, E x∼Dx[(ˆut(wt · x) − ut(wt · x))2] ≤ ϵ. Proof. As in the proof of Lemma F.2, we choose r = 2cW L log(m/(Lδ1)) so that |wt · x(i)| ≤ r for all x(i)’s from the dataset with probability at least 1 − δ2 1/m ≥ 1 − δ1. We now condition on the event that |wt · x(i)| ≤ r for all i = 1, . . . , m. Let V be the set of non-decreasing 1-Lipschitz functions such that ∀v ∈ V, v(0) = 1/2, and v(z1) − v(z2) ≥ (a/(2br))(z1 − z2) for all z1 ≥ z2 ≥ 0. Then, conditioned on this event, we similarly have that (ˆut(z)/(2br) + 1/2)||z|≤r = ˆvt(z) ∈ V, and ˆvt(z) satisfies: ˆvt(z) ∈ argmin v∈V 1 m m X i=1 (v(wt · x(i)) − y(i))2. Again, studying the L2 2 distance between ˆut(z) and ut(z), we have: E (x,y)∼D[(ˆut(wt · x) − y)2] = E (x,y)∼D[(ˆut(wt · x) − y)21{|wt · x| ≤ r}] + E (x,y)∼D[(ˆut(wt · x) − y)21{|wt · x| > r}]. 53 The probability of |wt · x| > r is small due to the fact that Dx possesses sub-exponential tail: Pr[|wt · x| > r] ≤ (δ1/m)2. Now note that |y| ≤ M and Ex∼Dx[((wt/∥wt∥2) · x)4] ≤ c/L4 by the sub-exponential property of Dx, we thus have: E (x,y)∼D[(ˆut(wt · x) − y)21{|wt · x| > r}] ≤ 2 E (x,y)∼D[((ˆut(wt · x))2 + y2)1{|wt · x| > r}] ≤ 2 E x∼Dx[b2W 2((wt/∥wt∥2) · x)21{|wt · x| > r}] + 2M2 Pr[|wt · x| > r] ≤ 2b2W 2r E x∼Dx[((wt/∥wt∥2) · x)4] Pr[|wt · x| > r] + 2M2 Pr[|wt · x| > r] ≤ 2cb2W 2δ1/(L2m) + 2M2(δ1/m)2, where in the second inequality we used the fact that ˆut is b-Lipschitz and wt ∈ B(W), and in the third inequality we applied Cauchy-Schwarz. Since M = bW L log( 16b4W 4 ϵ2 ), we have M2(δ1/m) ≲ cb2W 2/L2 for m ≳ log(bW/ϵ), thus, we get E (x,y)∼D[(ˆut(wt · x) − y)21{|wt · x| > r}] ≤ 4c(bW/L)2δ1/m, (56) for some absolute constant c. The rest remains the same as in the proof of Lemma F.2. Let A = {x : |wt · x| ≤ r}. Let y′ = y/(2br) + 1/2. As ˆvt(z) = ˆut(z)/(2br) + 1/2 is the sample-optimal activation in V given wt (conditioned on A), applying Fact F.1 we have that with probability at least 1 − δ: E (x,y)∼D[((ˆut(wt · x)/(2br) + 1/2) − y′)2|A] = E (x,y)∼D[(ˆvt(wt · x) − y′)2|A] ≤ inf v∈V E (x,y)∼D[(v(wt · x) − y′)2|A] + ˜O(W(d log(m/δ2)/m)2/3). Since U(a,b)||z|≤r/(2br) + 1/2 ⊂ V||z|≤r, we further have inf v∈V E (x,y)∼D[(v(wt · x) − y′)2|A] ≤ inf u∈U(a,b) E (x,y)∼D[(u(wt · x)/(2br) + 1/2 − y′)2|A] ≤ 1 4b2r2 inf u∈U(a,b) E (x,y)∼D[(u(wt · x) − y)2|A]. Therefore, E(x,y)∼D[(ˆut(wt · x) − y)21{A}] can be bounded from above by E (x,y)∼D[(ˆut(wt · x) − y)21{A}] = 4b2r2 E (x,y)∼D[(ˆvt(wt · x) − y′)2|A] Pr[A] ≤ 4b2r2 inf v∈V E (x,y)∼D[(v(wt · x) − y′)2|A] Pr[A] + ˜O(b2r2W(d log(m/δ2)/m)2/3) ≤ inf u∈U(a,b) E (x,y)∼D[(u(wt · x) − y)21{A}] + ˜O(b2r2W(d log(m/δ2)/m)2/3) ≤ inf u∈U(a,b) E (x,y)∼D[(u(wt · x) − y)2] + ˜O(b2r2W(d log(m/δ2)/m)2/3). Thus, combining with (56), we get that with probability at least 1 − δ1 − δ2, E (x,y)∼D[(ˆut(wt · x) − y)2] ≤ E (x,y)∼D[(ut(wt · x) − y)2] + ˜O \u0012 Wb2r2 \u0012d log(m/δ2) m \u00132/3\u0013 + \u0012bW L \u00132 δ1 m. 54 Choosing the size of the sample set to be: m = Θ \u0012 d log4(d/(ϵδ)) \u0012b2W 3 L2ϵ \u00133/2\u0013 , and recalling that r = 2cW L log(m/(Lδ1)), we finally have E (x,y)∼D[(ˆut(wt · x) − y)2] ≤ E (x,y)∼D[(ut(wt · x) − y)2] + ϵ, with probability at least 1 − δ, after choosing δ1 = δ2 = δ/2. To prove the final claim of the lemma, we follow the same argument as in the proof of Lemma F.2. Since we have just shown that with probability at least 1 − δ, it holds ϵ ≥ E x∼Dx[(ˆut(wt · x) − y)2 − (ut(wt · x) − y)2] = E x∼Dx[(ˆut(wt · x) − ut(wt · x))2] + 2 E x∼Dx[(ˆut(wt · x) − ut(wt · x))(ut(wt · x) − y)], applying the first statement in Claim C.1 completes the proof. 55 "
}