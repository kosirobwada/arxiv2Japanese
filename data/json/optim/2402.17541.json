{
    "optim": "arXiv:2402.17541v1  [math.PR]  27 Feb 2024\nOptimal Stopping of BSDEs with Constrained Jumps and Related\nDouble Obstacle PDEs\nMagnus Perninge∗\nFebruary 28, 2024\nAbstract\nWe consider partial diﬀerential equations (PDEs) characterized by an upper barrier that depends\non the solution itself and a ﬁxed lower barrier, while accommodating a non-local driver. First, we\nshow a Feynman-Kac representation for the PDE when the driver is local.\nSpeciﬁcally, we relate\nthe non-linear Snell envelope for an optimal stopping problem, where the underlying process is the\nﬁrst component in the solution to a stopped backward stochastic diﬀerential equation (BSDE) with\njumps and a constraint on the jumps process, to a viscosity solution for the PDE. Leveraging this\nFeynman-Kac representation, we subsequently prove existence and uniqueness of viscosity solutions\nin the non-local setting by employing a contraction argument. In addition, the contraction argument\nyields existence of a new type of non-linear Snell envelope and extends the theory of probabilistic\nrepresentation for PDEs.\n1\nIntroduction\nWe consider partial diﬀerential equations (PDEs) of the type\n\n\n\n\n\nmin{v(t, x) − h(t, x), max{v(t, x) − Mv(t, x), −vt(t, x) − Lv(t, x)\n−f(t, x, v(t, ·), σ⊤(t, x)∇xv(t, x))}} = 0,\n∀(t, x) ∈ [0, T) × Rd\nv(T, x) = ψ(x),\n(1.1)\nwhere for each (t, x, z) ∈ [0, T] × Rd × Rd, the map g 7→ f(t, x, g, z) : C(Rd → R) → R is a functional,\nMv(t, x) := infe∈E{v(t, x + γ(t, x, e)) + χ(t, x, e)} and\nL :=\nd\nX\nj=1\naj(t, x) ∂\n∂xj\n+ 1\n2\nd\nX\ni,j=1\n(σσ⊤(t, x))i,j\n∂2\n∂xi∂xj\n(1.2)\nis the inﬁnitesimal generator related to the stochastic diﬀerential equation (SDE)\nˇXs = x +\nZ s\n0\na(r, ˇXr)dr +\nZ s\n0\nσ(r, ˇ\nXr)dWr.\nWe establish existence and uniqueness (within the set of continuous functions of polynomial growth)\nof viscosity solutions to the above PDE by relating v(t, x) to Y t,x\nt\n, where\nY t,x\ns\n= ess sup\nτ∈Ts\nY t,x,τ\ns\n(1.3)\n∗M. Perninge is with the Department of Physics and Electrical Engineering, Linnaeus University, V¨axj¨o, Sweden. e-mail:\nmagnus.perninge@lnu.se.\n1\nand for each stopping time τ ≥ t, the process the Y t,x,τ is the ﬁrst component in the quadruple of processes\n(Y t,x,τ, Zt,x,τ, V t,x,τ, Kt,x,τ) that is the unique maximal solution to the backward stochastic diﬀerential\nequation (BSDE), driven by the above mentioned Brownian motion and an independent Poisson random\nmeasure µ with intensity λ, that has a constraint on the jump component\n\n\n\n\n\nY t,x,τ\ns\n= Ψ(τ, Xt,x\nτ ) +\nR τ\ns f(r, Xt,x\nr , ¯Y (r, ·), Zt,x,τ\nr\n)dr −\nR τ\ns Zt,x,τ\nr\ndWr −\nR τ\ns\nR\nE V t,x,τ\nr\n(e)µ(dr, de)\n−(K−,t,x,τ\nτ\n− K−,t,x,τ\ns\n),\n∀s ∈ [t, τ],\nV t,x,τ\ns\n(e) ≥ −χ(s, Xt,x\ns−, e),\ndP ⊗ ds ⊗ λ(de) − a.e.\n(1.4)\nHere, Ψ(t, x) :=\n1[t<T]h(t, x) +\n1[t=T]ψ(t, x), the process Xt,x is the unique solution to the forward SDE\nXt,x\ns\n= x +\nZ s\nt\na(r, Xt,x\nr )dr +\nZ s\nt\nσ(r, Xt,x\nr )dWr +\nZ s\nt\nZ\nE\nγ(r, Xt,x\nr−, e)µ(dr, de)\n(1.5)\nand the driver at time t ∈ [0, T] depends on the solution to the optimal stopping problem through the\nmap (t, x) 7→ ¯Y (t, x) := Y t,x\nt\n.\nOur contribution is twofold in the sense that our approach implicitly\nprovides existence of a unique solution to the optimal stopping problem (1.3)-(1.5).\nRelated literature Partial diﬀerential equations featuring non-local drivers, wherein the mapping\ng 7→ f(t, x, g, z) adopts the structure of an integral, are commonly referred to as integro-partial diﬀerential\nequations (IPDEs). A branch of the literature that relates BSDEs with jumps to IPDEs have focused on\nthe setting where the driver takes the form\nf(t, x, g, z) = ¯f(t, x, g(x), z,\nZ\nE\nθ(t, x, e)(g(x + ζ(t, x, e)) − g(x))λ(de)),\nfor a Lipschitz function ¯f. In particular, [3] and [8] both assume that ¯f is non-decreasing in the last\nvariable and that θ ≥ 0, the former considering the relation between regular BSDEs with jumps and\nIPDEs whereas the latter prove a relation between the reﬂected BSDEs with jumps considered in [21]\nand IPDEs with one-sided obstacles. These results where later extended in [13] to the setting when ¯f is\na general Lipschitz function and ζ may be negative. We also mention the work in [11], where a system\nof IPDEs with interconnected obstacles are treated.\nWhen the lower barrier h is absent, the PDE described in (1.1) is termed a quasi-variational inequality\n(QVI). It is well known that, under suitable conditions on the involved parameters, value functions to\nimpulse control problems are solutions (in viscosity sense) to standard QVIs when the driving noise\nprocess is a Brownian motion (see the seminal work in [4]) and to so called quasi-integrovariational\ninequalities when the driving noise is a general L´evy process [16]. Employing a contraction argument\nakin to the one delineated in the present study, quasi-variational inequalities (QVIs) featuring general\nnon-local drivers were investigated in [19]. Speciﬁcally, [19] establishes a Feynman-Kac representation of\nsuch QVIs by linking their solutions to systems of reﬂected BSDEs (RBSDEs).\nAn alternative Feynman-Kac representation for solutions to standard QVIs was proposed in [14] (see\nalso [5]), where the solution to a QVI is related to the minimal solution of a BSDE with constrained jumps.\nIn particular, their result implies that (when f is local) the deterministic function v deﬁned through the\nrelation v(t, x) := Y t,x,T\nt\n, with Y t,x,T as in (1.4), is the unique viscosity solution to the PDE obtained by\nsetting h ≡ −∞ in (1.1). Following the seminal work in [14], BSDEs with positive jumps were related\nto fully non-linear Hamilton-Jacobi-Bellman integro-partial diﬀerential equations (HJB-IPDEs) through\na Feynman-Kac representation in [15] while a correspondence between RBSDEs with positive jumps and\nfully non-linear variational inequalities was established in [6].\nThe ensemble of approaches to ﬁnd probabilistic representations of PDEs or solve stochastic optimal\ncontrol problems that utilize BSDEs with constrained jumps is commonly referred to as control random-\nization. A signiﬁcant breakthrough in this ﬁeld was achieved with the seminal work of [10], which directly\n2\nlinked the value function of the randomized control problem to that of the original control problem. This\neliminated the need for a Feynman-Kac representation, thereby expanding the theoretical framework to\nencompass stochastic systems with path-dependencies. Building upon this foundation, subsequent ad-\nvancements extended their approach to the framework of partial information settings in [1] and optimal\nswitching problems in [9]. Recently, [18] further extended the scope of control randomization to zero-\nsum games by (within a non-markovian framework) relating the solution to the above optimal stopping\nproblem (1.3)-(1.5) to the upper and lower value functions in a stochastic diﬀerential game between an\nimpulse controller and a stopper. Notable is that [18] presumes that f only depends on local values of\nY , whereas it may depend on V .\nAn intermediate result in the present work addresses the framework of a local driver and bridges a\ngap left in [18]. Speciﬁcally, we establish a connection between the non-linear Snell envelope examined in\n[18] and viscosity solutions to (1.1). Consequently, we elucidate that, in the Markovian framework, the\nvalue function of the aforementioned zero-sum game indeed constitutes the unique viscosity solution to\n(1.1). Moreover, our primary ﬁndings extend those of [18] in the Markovian framework by proving the\nexistence of the more general non-linear Snell envelope deﬁned through equations (1.3)-(1.5).\nOutline The remainder of the article is organised as follows. In the next section we set the notations\nand state the assumptions that hold throughout. In addition, we give some preliminary results that\nare repeatedly referred in the article. Then, in Section 3 we turn to the local setting before we, in the\nfollowing section, derive the complete result. Uniqueness of solutions to (1.1) when the driver f is local\nappears rudimentary and resembles earlier results deduced in, for example, [12].\nHowever, since our\nsetting is fundamentally diﬀerent and for the sake of completeness, a uniqueness proof through viscosity\ncomparison is included as an appendix.\n2\nPreliminaries\n2.1\nNotation\nWe let (Ω, F, P) be a complete probability space on which lives a d-dimensional Brownian motion W and\nan independent Poisson random measure µ deﬁned on [0, T]×E with intensity λ(de). Here, it is assumed\nthat E is a Borelian subset of Rd endowed with its Borel σ-ﬁeld B(E). We denote by F := (Ft)0≤t≤T\nthe augmented natural ﬁltration generated by W and µ and for t ∈ [0, T] we let Ft := (Ft\ns)t≤s≤T (resp.\nFW,t := (FW,t\ns\n)t≤s≤T ) denote the augmented natural ﬁltration generated by (Ws − Wt : t ≤ s ≤ T) and\nµ(· ∩ [t, T], ·) (resp. (Ws − Wt, t ≤ s ≤ T)).\nThroughout, we will use the following notation, where d ≥ 1 is the dimension of the state-space:\n• We let Πg denote the set of all functions ϕ : [0, T] × Rd → R that are of polynomial growth in x,\ni.e. there are constants C, ρ > 0 such that |ϕ(t, x)| ≤ C(1 + |x|ρ) for all (t, x) ∈ [0, T] × Rd, and let\nΠg\nc be the subset of jointly continuous functions.\n• For each t ∈ [0, T], Pt is the σ-algebra of Ft-predictably measurable subsets of [t, T]×Ω and P := P0.\n• We let T be the set of all [0, T]-valued F-stopping times and for each η ∈ T , we let Tη be the subset\nof stopping times τ such that τ ≥ η, P-a.s. Moreover, we let T t (resp. T t\nη ) be the corresponding\nsubsets of Ft-stopping times, with τ ≥ t (resp. τ ≥ η), P-a.s.\n• For p ≥ 1, t ∈ [0, T] and τ ∈ T t, we let Sp\n[t,τ] be the set of all R-valued, Ft-progressively measurable,\nc`adl`ag processes (Zs : s ∈ [t, τ]) for which ∥Z∥Sp\n[t,τ] := E\n\u0002\nsups∈[t,τ] |Zs|p\u0003\n< ∞.\nMoreover, we\nlet Sp\n[t,τ],i be the subset of Ft-predictably measurable and non-decreasing processes with Zt = 0.\nWhenever τ = T we use the notations Sp\nt and Sp\nt,i, respectively.\n3\n• We let Hp\n[t,τ](W) denote the set of all Rd-valued Ft-progressively measurable processes (Zs : s ∈ [t, τ])\nsuch that ∥Z∥Hp\n[t,τ](W ) := E\n\u0002\u0000 R τ\nt |Zs|2ds\n\u0001p/2\u00031/p < ∞. Furthermore, we set Hp\nt (W) := Hp\n[t,T](W).\n• We let Hp\n[t,τ](µ) denote the set of all R-valued, Pt ⊗B(E)-measurable maps (Zs(e) : s ∈ [t, τ], e ∈ E)\nsuch that ∥Z∥Hp\n[t,τ](µ) := E\n\u0002\u0000 R τ\nt\nR\nE |Zs(e)|2λ(de)ds\n\u0001p/2\u00031/p < ∞ and set Hp\nt (µ) = Hp\n[t,T](µ).\n• For t ∈ [0, T], we let At denote the set of all [−1, 1]d-valued, Ft-progressively measurable processes\n(αs : t ≤ s ≤ T) and set A := A0.\nMoreover, we let AW\nt\nbe the subset of FW,t-progressively\nmeasurable processes (resp. AW := AW\n0 ).\n• For t ∈ [0, T], we deﬁne the composition ⊕t of α1 ∈ A and α2 ∈ At as (α1 ⊕t α2)s :=\n1[0,t)(s)α1\ns +\n1[t,T](s)α2\ns.\n• We let Vt denote the set of all Pt ⊗ B(E)-measurable, bounded maps ν : [t, T] × Ω × E → [0, ∞)\nand for each n ∈ N, we denote by Vn\nt the subset of maps ν : [t, T] × Ω × E → [0, n].\nWe also mention that, unless otherwise speciﬁed, all inequalities between random variables are to be\ninterpreted in the P-a.s. sense.\n2.2\nAssumptions\nWe make the following assumption on the intensity λ of the process µ.\nAssumption 2.1. We assume that λ has full topological support on E and ﬁnite intensity, i.e. λ(E) < ∞.\nThroughout, we make the following assumptions on the parameters, where ρ > 0 is a ﬁxed constant:\nAssumption 2.2.\ni) We assume that f : [0, T]×Rd ×C(Rd → R)×Rd → R ((t, x, g, z) → f(t, x, g, z))\nis such that for any v ∈ Πg\nc, the map (t, x) 7→ f(t, x, v(t, ·), z) is jointly continuous, uniformly in z,\nf is of polynomial growth in x, i.e. there is a Cf > 0 such that\n|f(t, x, 0, 0)| ≤ Cf(1 + |x|ρ)\nand that there are constants kf, KΓ > 0 such that for any t ∈ [0, T], x ∈ Rd, g, ˜g ∈ C(Rd → R) and\nz, ˜z ∈ Rd we have\n|f(t, x, ˜g, ˜z) − f(t, x, g, z)| ≤ kf(\nsup\nx′∈Λf (|x|)\n|˜g(x′) − g(x′)| + |˜z − z|),\nwhere for each α ∈ R+, Λf(α) := {x ∈ Rd : ∥x∥ ≤ α∨KΓ} is the closed ball of radius α∨KΓ centered\nat the origin.\nii) The lower barrier h : [0, T] × Rd → R is jointly continuous and of polynomial growth in x, i.e. there\nis a Ch > 0 such that\n|h(t, x)| ≤ Ch(1 + |x|ρ).\niii) The terminal reward ψ : Rd → R is continuous and satisﬁes the growth condition\n|ψ(x)| ≤ Cψ(1 + |x|ρ)\nfor some Cψ > 0.\n4\niv) The jump-barrier χ : [0, T] × Rd × E → R+ is jointly continuous, of polynomial growth and bounded\nfrom below, i.e.\nχ(t, x, e) ≥ δ > 0,\nv) For each (x, e) ∈ Rd × E we have\nh(T, x) ≤ ψ(x) ≤ ψ(x + γ(T, x, e)) + χ(T, x, e)\nMoreover, we make the following assumptions on the coeﬃcients of the forward SDE:\nAssumption 2.3. For any t, t′ ∈ [0, T], e ∈ E and x, x′ ∈ Rd we have:\ni) The function γ : [0, T] × Rd × E → Rd is jointly continuous and satisﬁes the growth condition\n|x + γ(t, x, e)| ≤ KΓ ∨ |x|\n(2.1)\nMoreover, it is Lipschitz continuous in x uniformly in (t, e), i.e.\n|γ(t, x′, e) − γ(t, x, e)| ≤ kγ|x′ − x|\nfor all (t, x, x′, e) ∈ [0, T] × Rd × Rd × E.\nii) The coeﬃcients a : [0, T] × Rd → Rn and σ : [0, T] × Rd → Rn×d are jointly continuous and satisfy\nthe growth conditions\n|a(t, x)| + |σ(t, x)| ≤ Ca,σ(1 + |x|),\nfor some Ca,σ > 0 and the Lipschitz continuity\n|a(t, x) − a(t, x′)| + |σ(t, x) − σ(t, x′)| ≤ ka,σ|x′ − x|,\nfor some ka,σ > 0.\n2.3\nViscosity solutions\nWe deﬁne the upper, v∗, and lower, v∗ semi-continuous envelope of a function v : [0, T] × Rd → R as\nv∗(t, x) :=\nlim sup\n(t′,x′)→(t,x), t′<T\nv(t′, x′)\nand\nv∗(t, x) :=\nlim inf\n(t′,x′)→(t,x), t′<T v(t′, x′).\nNext, we introduce the limiting parabolic superjet ¯J+v and subjet ¯J−v.\nDeﬁnition 2.4. Subjets and superjets\ni) For a l.s.c. (resp. u.s.c.) function v : [0, T] × Rn → R, the parabolic subjet, denote by J−v(t, x),\n(resp. the parabolic superjet, J+v(t, x)) of v at (t, x) ∈ [0, T] × Rn, is deﬁned as the set of triples\n(p, q, M) ∈ R × Rn × Sn satisfying\nv(t′, x′) ≥ (resp. ≤) v(t, x) + p(t′ − t)+ < q, x′ − x > + 1\n2 < x′ − x, M(x′ − x) > +o(|t′ − t| + |x′ − x|2)\nfor all (t′, x′) ∈ [0, T] × Rn, where Sn is the set of symmetric real matrices of dimension n × n.\n5\nii) For a l.s.c. (resp. u.s.c.) function v : [0, T] × Rn → R we denote by ¯J−v(t, x) the parabolic limiting\nsubjet (resp. ¯J+v(t, x) the parabolic limiting superjet) of v at (t, x) ∈ [0, T] × Rn, deﬁned as the set\nof triples (p, q, M) ∈ R × Rn × Sn such that:\n(p, q, M) = lim\nn→∞(pn, qn, Mn),\n(t, x) = lim\nn→∞(tn, xn)\nfor some sequence (tn, xn, pn, qn, Mn)n≥1 with (pn, qn, Mn) ∈ J−v(tn, xn) (resp.\n(pn, qn, Mn) ∈\nJ+v(tn, xn)) for all n ≥ 1 and v(t, x) = limn→∞ v(tn, xn).\nWe now give the deﬁnition of a viscosity solution for the QVI in (1.1). (see also pp. 9-10 of [7]).\nDeﬁnition 2.5. Let v be a locally bounded function from [0, T] × Rd to R. Then,\na) It is referred to as a viscosity supersolution (resp. subsolution) to (1.1) if it is l.s.c. (resp. u.s.c.) and\nsatisﬁes:\ni) v(T, x) ≥ ψ(x) (resp. v(T, x) ≤ ψ(x))\nii) For any (t, x) ∈ [0, T) × Rd and (p, q, X) ∈ ¯J−v(t, x) (resp. ¯J+v(t, x)) we have\nmin\n\b\nv(t, x) − h(t, x), max{v(t, x) − Mv(t, x), −p − q⊤a(t, x)\n− 1\n2Tr(σσ⊤(t, x)X) − f(t, x, v(t, ·), σ⊤(t, x)q)}\n\t\n≥ 0\n(resp. ≤ 0)\nb) It is called a viscosity solution to (1.1) if v∗ is a supersolution and v∗ is a subsolution.\nWe will sometimes use the following alternative deﬁnition of viscosity supersolutions (resp. subsolu-\ntions):\nDeﬁnition 2.6. A l.s.c. (resp. u.s.c.) function v is a viscosity supersolution (resp. subsolution) to (1.1)\nif v(T, x) ≤ ψ(x) (resp. ≥ ψ(x)) and whenever ϕ ∈ C1,2([0, T] × Rd → R) is such that ϕ(t, x) = v(t, x)\nand ϕ − v has a local maximum (resp. minimum) at (t, x), then\nmin\n\b\nv(t, x) − h(t, x), max{v(t, x) − Mv(t, x), −ϕt(t, x) − Lϕ(t, x)\n− f(t, x, v(t, ·), σ⊤(t, x)∇xϕ(t, x))}\n\t\n≥ 0\n(resp. ≤ 0).\n2.4\nReﬂected BSDEs with jumps and obstacle problems\nWe introduce the local driver ˜f that satisﬁes the following assumption:\nAssumption 2.7.\ni) The driver ˜f : [0, T] × Rd × R × Rd → R is jointly continuous and of polynomial\ngrowth in x, i.e. | ˜f(t, x, 0, 0)| ≤ C(1 + |x|ρ). Moreover, (t, x) 7→ ˜f(t, x, y, z) is continuous, uniformly\nin (y, z), and (y, z) 7→ ˜f(t, x, y, z) is Lipschitz continuous, uniformly in (t, x).\nWe give the following proposition, strategically formulated to streamline subsequent implementation\nprocesses. It is worth noting that comparable ﬁndings are documented in [8, 13], with the latter being\nthe most closely aligned with our own.\nProposition 2.8. For each (t, x) ∈ [0, T]×Rd and n ∈ N, there is a unique quadruple (Y t,x, Zt,x, V t,x, K+,t,x) ∈\nS2\nt × H2\nt (W) × H2\nt (µ) × S2\nt,i such that\n\n\n\n\n\nY t,x\ns\n= ψ(Xt,x\nT ) +\nR T\ns\n˜f n(r, Xt,x\nr , Y t,x\nr\n, Zt,x\nr , V t,x\nr\n)dr −\nR T\ns Zt,x\nr dWr −\nR T\ns\nR\nE V t,x\nr\n(e)µ(dr, de)\n+(K+,t,x\nT\n− K+,t,x\ns\n),\n∀s ∈ [t, T],\nY t,x\ns\n≥ h(s, Xt,x\ns ), ∀s ∈ [t, T]\nand\nR T\nt\n\u0000Y t,x\ns\n− h(s, Xt,x\ns )\n\u0001\ndK+,t,x\ns\n,\n(2.2)\n6\nwhere\n˜f n(t, x, y, z, v) := ˜f(t, x, y, z) − n\nZ\nE\n(v(e) + χ(t, x, e))−λ(de).\nMoreover, Y t,x\ns\n= ess supτ∈T t\ns Y t,x;τ\ns\n, where for each τ ∈ T t, the triple (Y t,x;τ, Zt,x;τ, V t,x;τ) ∈ S2\n[t,τ] ×\nH2\n[t,τ](W) × H2\n[t,τ](µ) satisﬁes\nY t,x;τ\ns\n= Ψ(τ, Xt,x\nτ ) +\nZ τ\ns\n˜f n(r, Xt,x\nr , Y t,x;τ\nr\n, Zt,x;τ\nr\n, V t,x;τ\nr\n)dr −\nZ τ\ns\nZt,x;τ\nr\ndWr −\nZ τ\ns\nZ\nE\nV t,x;τ\nr\n(e)µ(dr, de)\n(2.3)\nand for each η ∈ T t, the stopping time\nτ ∗ := inf{s ≥ η : Y t,x\ns\n= h(r, Xt,x\ns )} ∧ T\nis optimal in the sense that Y t,x\nη\n= Y t,x;τ ∗\nη\n. Finally, there is a function vn ∈ Πg\nc such that vn(s, Xt,x\ns ) = Y t,x\ns\nfor all s ∈ [t, T] and vn is the unique viscosity solution in Πg\nc to\n\n\n\n\n\nmin{vn(t, x) − h(t, x), − ∂\n∂tvn(t, x) − Lvn(t, x) + Knvn(t, x)\n− ˜f(t, x, vn(t, x), σ⊤(t, x)∇xvn(t, x))} = 0,\n∀(t, x) ∈ [0, T) × Rd\nvn(T, x) = ψ(x),\n(2.4)\nwhere Knφ(t, x) := n\nR\nE(φ(t, x + γ(t, x, e)) + χ(t, x, e) − φ(t, x))−λ(de).\nProof. As the parameters of the reﬂected BSDE (2.2) satisfy the conditions for the comparison result of\n[21], everything but the viscosity solution property follows by results presented therein. Existence of a\nunique viscosity solution in Πg\nc to (2.4) can be shown as a special case of the method described in [19].\nWe can now argue as in [13] and let v ∈ Πg\nc be deﬁned as v(t, x) := Y t,x\nt\n. Then, it can be shown (see\nProposition 3.1 in [13]) that V t,x\ns\n(e) = v(s, Xt,x\ns\n+γ(s, Xt,x\ns , e))−v(s, Xt,x\ns ), dP⊗ds⊗λ(de)-a.e. Moreover,\nthe BSDE\n\n\n\n\n\n˜Y t,x\ns\n= ψ(Xt,x\nT ) +\nR T\ns\n˜f n(r, Xt,x\nr , ˜Y t,x\nr\n, ˜Zt,x\nr , v(r, Xt,x\nr\n+ γ(r, Xt,x\nr , ·)) − v(r, Xt,x\nr ))dr\n−\nR T\ns\n˜Zt,x\nr dWr −\nR T\ns\nR\nE ˜V t,x\nr\n(e)µ(dr, de) + ( ˜K+,t,x\nT\n− ˜K+,t,x\ns\n),\n∀s ∈ [t, T],\n˜Y t,x\ns\n≥ h(s, Xt,x\ns ), ∀s ∈ [t, T]\nand\nR T\nt\n\u0000 ˜Y t,x\ns\n− h(s, Xt,x\ns )\n\u0001\ndK+,t,x\ns\n,\n(2.5)\nadmits a unique solution and ˜v(t, x) := ˜Y t,x\nt\nbelongs to Πg\nc and is the unique viscosity solution to\n\n\n\n\n\nmin{˜v(t, x) − h(t, x), −˜vt(t, x) − L˜v(t, x) − Knv(t, x)\n− ˜f(t, x, ˜v(t, x), σ⊤(t, x)∇x˜v(t, x))} = 0,\n∀(t, x) ∈ [0, T) × Rd\n˜v(T, x) = ψ(x).\nOn the other hand, (Y t,x, Zt,x, V t,x, K+,t,x) is the unique solution to (2.5) and we conclude that ˜v = v is\nthe unique solution to (2.4).\nTo emphasize the dependence of the solution to (2.2) on the parameter n, we will henceforth employ\nthe notation (Y t,x,n, Zt,x,n, V t,x,n, K+,t,x,n) for these quadruples.\n7\n2.5\nPreliminary estimates\nFor ν ∈ Vt we let Eν be expectation with respect to the probability measure Pν on (Ω, F) deﬁned by\ndPν := κν\nT dP with\nκν\ns := Es\n\u0010 Z ·\nt\nZ\nE\n(νr(e) − 1)(µ(dr, de) − λ(de))dr\n\u0011\n:= exp\n\u0010 Z s\nt\nZ\nE\n(1 − νr(e))λ(de)dr\n\u0011\nY\nt<ηj≤s\nνηj(βj),\nwhere the sequence (ηj, βj)j≥1 is the one that appears in the Dirac decomposition µ = P\nj≥1 δ(ηj,βj).\nLemma 2.9. Under Assumption 2.3, the SDE (1.5) admits a unique solution for each (t, x) ∈ [0, T]×Rd.\nFurthermore, the solution has moments of all orders, in particular, for each p ≥ 0, there is a constant\nC > 0 such that\nEνh\nsup\ns∈[ζ,T]\n|Xt,x\ns |p\f\f\fFt\nζ\ni\n≤ C(1 + |Xt,x\nζ |p),\n(2.6)\nP-a.s. for all (t, x) ∈ [0, T] × Rn, ν ∈ Vt and ζ ∈ [t, T].\nProof. The proof is rather elementary and follows a similar structure to the proof of Proposition 4.2 in\n[17] (albeit the latter is conﬁned to a Brownian ﬁltration). It is provided in its entirety since some of its\nintermediate results are utilized later on. For each j ∈ N, we let Xj be the unique solution to the SDE\nXj\ns = x +\nZ s\nt\na(r, Xj\nr)dr +\nZ s\nt\nσ(r, Xj\nr )dWr +\nZ s\nt\nZ\nE\n1[µ((0,r),E)<j]γ(s, Xj\ns−, e)µ(dr, de),\n∀s ∈ [t, T],\nand note that Xj → Xt,x, P-a.s., since µ has ﬁnite intensity. By Assumption 2.3.(i) we get for s ∈ [ηj, T],\nusing integration by parts, that\n|Xj\ns|2 = |Xj\nζ∨ηj|2 + 2\nZ s\n(ζ∨ηj)+\nXj\nrdXj\nr +\nZ s\n(ζ∨ηj)+\nd[Xj, Xj]r\n≤ K2\nΓ ∨ |Xj−1\nζ∨ηj|2 + 2\nZ s\n(ζ∨ηj)+\nXj\nrdXj\nr +\nZ s\n(ζ∨ηj)+\nd[Xj, Xj]r.\nNow, either |Xj−1\nηj\n| ≤ KΓ in which case\n|Xj\ns|2 ≤ |Xj\nζ|2 ∨ K2\nΓ + 2\nZ s\n(ζ∨ηj)+\nXj\nrdXj\nr +\nZ s\n(ζ∨ηj)+\nd[Xj, Xj]r.\nor |Xj−1\nηj\n| > KΓ implying that\n|Xj\ns|2 ≤ K2\nΓ ∨ |Xj−2\nζ∨ηj−1|2 + 2\nZ ηj\n(ζ∨ηj−1)+\nXj−1\nr\ndXj−1\nr\n+\nZ ηj\n(ζ∨ηj−1)+\nd[Xj−1, Xj−1]r\n+ 2\nZ s\n(ζ∨ηj)+\nXj\nrdXj\nr +\nZ s\n(ζ∨ηj)+\nd[Xj, Xj]r.\nIn the latter case the same argument can be repeated and we conclude that\n|Xj\ns|2 ≤ |Xj\nζ|2 ∨ K2\nΓ +\nj\nX\ni=j0\nn\n2\nZ s∧˜ηi+1\n(ζ∨˜ηi)+\nXi\nrdXi\nr +\nZ s∧˜ηi+1\n(ζ∨˜ηi)+\nd[Xi, Xi]r\no\n,\n(2.7)\n8\nwhere ˜η0 = −1, ˜ηi = ηi for i = 1, . . . , j and ˜ηj+1 = ∞ and j0 := max{i ∈ {1, . . . , j} : |Xi−1\nηi | ≤ KΓ} ∨ 0.\nNow, since Xi and Xj coincide on [0, ηi+1∧j+1) we have\nj\nX\ni=j0\nZ s∧˜ηi+1\n(ζ∨˜ηi)+\nXi\nrdXi\nr =\nZ s\nζ∨ηj0\nXj\nra(r, Xj\nr)dr +\nZ s\nζ∨ηj0\nXj\nrσ(r, Xj\nr)dWr,\nand\nj\nX\ni=j0\nZ s∧˜ηi+1\n(ζ∨˜ηi)+\nd[Xi, Xi]r =\nZ s\nζ∨ηj0\nσ2(r, Xj\nr)dr.\nInserted in (2.7) this gives that\n|Xj\ns|2 ≤ |Xj\nζ|2 ∨ K2\nΓ +\nZ s\nηj0\n(2Xj\nsa(r, Xj\nr) + σ2(r, Xj\nr))dr + 2\nZ s\nηj0\nXj\nrσ(r, Xj\nr)dWr\n≤ |Xj\nζ|2 + C\n\u0010\n1 +\nZ s\nζ\n|Xj\nr|2dr + sup\nη∈[ζ,s]\n\f\f\f\nZ η\nζ\nXj\nrσ(r, Xj\nr )dWr\n\f\f\f\n\u0011\n(2.8)\nfor all s ∈ [ζ, T]. The Burkholder-Davis-Gundy inequality and the fact that the right-hand side of (2.8)\ndoes not depend on µ now gives that for any ν ∈ Vt and p ≥ 2,\nEνh\nsup\nr∈[ζ,s]\n|Xj\nr|p\f\f\fFt\nζ\ni\n≤ |Xj\nζ|2 + C\n\u00001 + Eνh Z s\nζ\n|Xj\nr|pdr +\n\u0000 Z s\nζ\n|Xj\nr|4dr\n\u0001p/4\f\f\fFt\nζ\ni\u0001\n.\nWe can thus apply Gr¨onwall’s lemma to conclude that for p ≥ 4,\nEνh\nsup\ns∈[ζ,T]\n|Xj\ns|p\f\f\fFt\nζ\ni\n≤ C(1 + |Xj\nζ|p),\nP-a.s., where the constant C = C(T, p) does not depend on ν and j and (2.6) follows by letting j → ∞\non both sides and using Fatou’s lemma. The result for general p ≥ 0 is then a simple consequence of\nJensen’s inequality.\nLemma 2.10. There is a C > 0 such that\n|Y t,x,n\ns\n| ≤ C(1 + |Xt,x\ns |q)\n(2.9)\nfor all (t, x) ∈ [0, T] × Rd and s ∈ [t, T].\nProof. We have\nh(s, Xt,x\ns ) ≤ Y t,x,n\ns\n≤ Y t,x,0\ns\n(2.10)\nand the assertion follows by the polynomial growth assumptions on h and the fact that v0 ∈ Πg\nc (see\nProposition 2.8).\nWe also make use of the following lemma which is given without proof as it follows immediately from\nthe deﬁnitions:\nLemma 2.11. Let u, v : [0, T]×Rn → R be locally bounded functions. M is monotone (if u ≤ v pointwise,\nthen Mu ≤ Mv). Moreover, M(u∗) (resp. M(u∗)) is l.s.c. (resp. u.s.c.).\nIn particular, it follows that Mv is jointly continuous whenever v is.\n9\n3\nThe local setting\nOur approach to obtain existence of a unique viscosity solution to (1.1) goes through a ﬁxed point\nargument. Before we are ready to proceed with this argument we need to solve the problem in the case\nwhere the driver f is a local function. In this regard, we consider the PDE\n\n\n\n\n\nmin{v(t, x) − h(t, x), max{v(t, x) − Mv(t, x), −vt(t, x) − Lv(t, x)\n− ˜f(t, x, v(t, x), σ⊤(t, x)∇xv(t, x))}} = 0,\n∀(t, x) ∈ [0, T) × Rd\nv(T, x) = ψ(x),\n(3.1)\nwhere ˜f satisﬁes Assumption 2.7.\nThe arguments utilized in this section are based on penalization and use the unique viscosity solution,\nvn, to (2.4). By a comparison result for solutions to RBSDEs with jumps (see e.g. Theorem 4.1 in [21]),\nwe ﬁnd that (vn)n∈N is a non-increasing sequence in Πg\nc and by Lemma 2.10 this sequence is bounded from\nbelow in the sense that there is a constant C > 0 such that vn(t, x) ≥ −C(1+|x|ρ) for all (t, x) ∈ [0, T]×Rd\nand n ∈ N. It then immediately follows that there is an upper semi-continuous function v ∈ Πg such that\nvn ց v, pointwisely. We prove that v is the unique viscosity solution to (3.1) within the set of functions\nof polynomial growth.\nWe ﬁrst show that v satisﬁes the requirements for a viscosity solution at time T.\nLemma 3.1. For each x ∈ Rd it holds that v∗(T, x) ≤ ψ(x) and v∗(T, x) ≥ ψ(x).\nProof. First note that\nv∗(T, x) ≤\nlim\n(t′,x′)→(T,x) v0(t′, x′) = ψ(x)\nby continuity of v0, proving the ﬁrst inequality.\nWe turn to the second one which requires more work. In search for a contradiction, we assume that\nthere is an x′\n0 ∈ Rd such that v∗(T, x′\n0) < ψ(x′\n0). The proof is based on the following observation:\na) If v∗(T, x′\n0) < ψ(x′\n0) for some x′\n0 ∈ Rd, then there is a (possible diﬀerent) point x0 ∈ Rd such that\nv∗(T, x0) < ψ(x0) ∧ Mv∗(T, x0).\nTo see this, we note that if a) does not hold, then by lower semi-continuity, there is an e′\n0 ∈ E such that\nv∗(T, x′\n0) ≥ Mv∗(T, x′\n0) = v∗(T, x′\n1) + χ(T, x′\n0, e′\n0),\nwith x′\n1 := x′\n0 + γ(T, x′\n0, e′\n0). Now, by assumption ψ(x′\n0) ≤ ψ(x′\n1) + χ(T, x′\n0, e′\n0) and we ﬁnd that\nv∗(T, x′\n1) − ψ(x′\n1) ≤ v∗(T, x′\n0) − χ(T, x′\n0, e′\n0) − ψ(x′\n1)\n≤ v∗(T, x′\n0) − χ(T, x′\n0, e′\n0) − (ψ(x′\n0) − χ(T, x′\n0, e′\n0))\n< 0\nHence, if a) does not hold, then we must have v∗(T, x′\n1) ≥ Mv∗(T, x′\n1). We can repeat this argument\nindeﬁnitely to ﬁnd that, if a) does not hold, then there is a sequence (x′\nj, e′\nj)∞\nj=1 in Rd × E such that\nx′\nj+1 = x′\nj +γ(T, x′\nj, e′\nj) and v∗(T, x′\nj) ≥ v∗(T, x′\nj+1)+χ(T, x′\nj, e′\nj) for all j ∈ N. We conclude that for each\nk it holds that\nv∗(T, x′\n0) ≥ v∗(T, x′\nk) +\nk−1\nX\nj=0\nχ(T, x′\nj, e′\nj)\n≥ h(T, x′\nk) + kδ,\n10\na contradiction since h is of uniformly bounded from below on [0, T] × Λf(|x′\n0|) and v∗(T, x′\n0) ≤ v0(T, x′\n0).\nWe thus assume that there is a point x0 and an ε > 0 such that\nv∗(T, x0) ≤ ψ(x0) ∧ Mv∗(T, x0) − 3ε.\n(3.2)\nThere is a sequence (tj, xj, nj) in [0, T) × Rd × N such that (tj, xj) → (T, x0) and vnj(tj, xj) → v∗(T, x0).\nIn particular, if (3.2) holds, then there is a j0 such that\nvnj(tj, xj) ≤ ψ(x0) ∧ Mv∗(T, x0) − 2ε\nwhenever j ≥ j0. On the other hand, continuity of ψ and lower semi-continuity of Mv∗ then implies that\nthere is a δ′ > 0 such that\nvnj(tj, xj) ≤ ψ(x) ∧ Mv∗(t, x) − ε\n≤ ψ(x) ∧ Mvnj(t, x) − ε\nwhenever j ≥ j0 and (t, x) ∈ Bδ′(T, x0) ∩ [0, T] × Rd (where Bδ′(T, x0) is the open ball in Rd+1 of radius\nδ′ centered at (T, x0)).\nWe introduce the stopping times\nθj := inf{s ≥ tj : vnj(s, Xtj,xj\ns\n) ≥ ψ(Xtj,xj\ns\n) ∧ Mvnj(s, Xtj,xj\ns\n)}\nand\nϑj := inf{s ≥ tj : (s, Xtj,xj\ns\n) /∈ Bδ′(T, x0) or µ((tj, s], E) ≥ 1}.\nA standard dynamic programming result now gives that\nvnj(tj, xj) = vnj(θj ∧ ϑj, Xtj,xj\nθj∧ϑj) +\nZ θj∧ϑj\ntj\n˜f nj(r, Xtj,xj\nr\n, Y tj,xj,nj\nr\n, Ztj,xj,nj\nr\n, V tj,xj,nj\nr\n)dr\n−\nZ θj∧ϑj\ntj\nZtj,xj,nj\nr\ndWr −\nZ θj∧ϑj\ntj\nZ\nE\nV tj,xj,nj\nr\n(e)µ(dr, de) + K−,tj,xj,nj\nθj∧ϑj\n− K−,tj,xj,nj\ntj\n.\nSince V tj,xj,nj\nr\n(e) = vn(s, Xtj,xj\ns\n+ γ(s, Xtj,xj\ns\n, e)) − vn(s, Xtj,xj\ns\n), dP ⊗ ds ⊗ λ(de)-a.e. (see Proposition 3.1\nin [13]) we get that,\nZ θj\ntj\nZ\nE\n\u0000V tj,xj,nj\nr\n(e) + χ(r, Xtj,xj\nr\n, e)\n\u0001−λ(de)\n=\nZ θj\ntj\nZ\nE\n\u0000vn(s, Xtj,xj\ns\n+ γ(s, Xtj,xj\ns\n, e)) + χ(r, Xtj,xj\nr\n, e) − vn(s, Xtj,xj\ns\n)\n\u0001−λ(de)\n= 0.\nConsequently,\nZ θj∧ϑj\ntj\n˜f nj(r, Xtj,xj\nr\n, Y tj,xj,nj\nr\n, Ztj,xj,nj\nr\n, V tj,xj,nj\nr\n)dr =\nZ θj∧ϑj\ntj\n˜f(r, Xtj,xj\nr\n, Y tj,xj,nj\nr\n, Ztj,xj,nj\nr\n)dr\nand we conclude that\nvnj(tj, xj) = vnj(θj ∧ ϑj, Xtj,xj\nθj∧ϑj) +\nZ θj∧ϑj\ntj\n˜f(r, Xtj,xj\nr\n, Y tj,xj,nj\nr\n, Ztj,xj,nj\nr\n)dr\n−\nZ θj∧ϑj\ntj\nZtj,xj,nj\nr\ndWr −\nZ θj∧ϑj\ntj\nZ\nE\nV tj,xj,nj\nr\n(e)µ(dr, de) + K−,tj,xj,nj\nθj∧ϑj\n− K−,tj,xj,nj\ntj\n.\n11\nStandard arguments now give that there is a C > 0 such that\n∥Y tj,xj,nj∥S2\nt,θj ∧ϑj + ∥Ztj,xj,nj∥H2\nt,θj ∧ϑj (W ) + ∥V tj,xj,nj∥H2\nt,θj ∧ϑj (µ) ≤ C(1 + |xj|ρ)\nfor all j ∈ N, and we ﬁnd that\nvnj(tj, xj) ≥ −C(T − tj)1/2(1 + |xj|ρ) + E\n\u0002\n1[θj<ϑj]vn(θj, Xtj,x0\nθj\n)\n\u0003\n− CE\n\u0002\n1[θj≥ϑj]\n\u00031/2(1 + |xj|ρ),\nwhere the constant C > 0 can be chosen independent of j. Now, since vnj(T, x) = ψ(x), we have θj ≤ T,\nP-a.s. and on the subset of Ω where [θj < ϑj] we have vnj(θj, Xtj,x0\nθj\n) − vnj(tj, xj) ≥ ε. We thus conclude\nthat\nεP[θj < ϑj] ≤ C(T − tj)1/2(1 + |xj|ρ) + CE\n\u0002\n1[θj≥ϑj]\n\u00031/2(1 + |xj|ρ),\nwhenever j ≥ j0. On the other hand, P[θj ≥ ϑj] → 0 as j → ∞ and sending j → ∞ gives the sought\ncontradition.\nTheorem 3.2. The function v is continuous and thus belongs to Πg\nc. Moreover, it is the unique viscosity\nsolution to (3.1) in Πg.\nProof. We prove that v is a viscosity solution to (1.1), then continuity and uniqueness will follow from\nthe comparison principle stated in Proposition A.4 of Appendix A. By continuity of vn, we have (see e.g.\n[2], p. 91),\nv∗(t, x) = lim inf\nn→∞ ∗vn(t, x) :=\nlim inf\n(n,t′,x′)→(∞,t,x) vn(t′, x′),\nv(t, x) = v∗(t, x) = lim sup\nn→∞\n∗vn(t, x) :=\nlim sup\n(n,t′,x′)→(∞,t,x)\nvn(t′, x′).\nSubsolution-property. We ﬁrst show that v = v∗ is a viscosity subsolution. For (t, x) ∈ [0, T) × Rd and\n(p, q, M) ∈ ¯J+v(t, x) there is (by Lemma 6.1 in [7]) a sequence (tj, xj) ∈ [0, T) × Rd and sequences\nnj → ∞ and (pj, qj, Mj) ∈ J+vnj(tj, xj) such that\n(tj, xj, vnj(tj, xj), pj, qj, Mj) → (t, x, v(t, x), p, q, M).\nAs (pj, qj, Mj) ∈ J+vnj(tj, xj) and vnj is a viscosity subsolution to (2.4) with n = nj, it holds that\nmin{vnj(tj, xj) − g(tj, xj), −pj− < a(tj, xj), qj > −1\n2Tr(σσ⊤(tj, xj)Mj)\n+ nj\nZ\nE\n(vnj(tj, xj + γ(tj, xj, e)) + χ(tj, xj, e) − vnj(tj, xj))−λ(de)\n− ˜f(tj, xj, vnj(tj, xj), σ⊤(tj, xj)qj)} ≤ 0.\nNow, whenever v(t, x) > g(t, x) there is a j0 ∈ N, such that vnj(tj, xj) > g(tj, xj) for all j ≥ j0. Hence,\n− pj− < a(tj, xj), qj > −1\n2Tr(σσ⊤(tj, xj)Mj)\n+ nj\nZ\nE\n(vnj(tj, xj + γ(tj, xj, e)) + χ(tj, xj, e) − vnj(tj, xj))−λ(de)\n− ˜f(tj, xj, vnj(tj, xj), σ⊤(tj, xj)qj) ≤ 0\n(3.3)\nwhenever j ≥ j0. Sending j → ∞ gives that\n−p − < a(t, x), q > −1\n2Tr(σσ⊤(t, x)M) − ˜f(t, x, v(t, x), σ⊤(t, x)q) ≤ 0.\n12\nNow, assume that v(t, x) > infe∈E{v(t, x + γ(t, x, e)) + χ(t, x, e)}. Then there exists an e0 ∈ E such that\nv(t, x + γ(t, x, e0)) + χ(t, x, e0) − v(t, x) < 0.\nThis in turn implies the existence of an ε > 0 and an open neighborhood E0 ∈ B(E) of e0 in E such that\nvnj(tj, xj + γ(t, xj, e)) + χ(tj, xj, e) − vnj(tj, xj) ≤ −ε\nfor all e ∈ E0 and all j suﬃciently large. Consequently,\nZ\nE\n(vnj(tj, xj + γ(tj, xj, e)) + χ(tj, xj, e) − vnj(tj, xj))−λ(de) ≥ ελ(E0)\nfor j suﬃciently large. However, since λ has full topological support, λ(E0) > 0 and this contradicts the\nfact that (3.3) holds for all j. We thereby conclude that v(t, x) ≤ infe∈E{v(t, x + γ(t, x, e)) + χ(t, x, e)}.\nSupersolution-property. We turn to the supersolution property of v∗. For (t, x) ∈ [0, T) × Rd and\n(p, q, M) ∈ ¯J−v∗(t, x) there is (again by Lemma 6.1 in [7]) a sequence (tj, xj) ∈ [0, T) × Rd and sequences\nnj → ∞ and (pj, qj, Mj) ∈ J−vnj(tj, xj) such that\n(tj, xj, vnj(tj, xj), pj, qj, Mj) → (t, x, v∗(t, x), p, q, M).\nAs (pj, qj, Mj) ∈ J−vnj(tj, xj) and vnj is a viscosity supersolution to (2.4) with n = nj, it holds that\nmin{vnj(tj, xj) − g(tj, xj), −pj− < a(tj, xj), qj > −1\n2Tr(σσ⊤(tj, xj)Mj)\n+ nj\nZ\nE\n(vnj(tj, xj + γ(tj, xj, e)) + χ(tj, xj, e) − vnj(tj, xj))−λ(de)\n− ˜f(tj, xj, vnj(tj, xj), σ⊤(tj, xj)qj)} ≥ 0\n(3.4)\nIn particular, vnj(tj, xj) ≥ g(tj, xj) and it follows by continuity of g that v∗(t, x) ≥ g(t, x). Suppose now\nthat v∗(t, x) < infe∈E{v∗(t, x + γ(t, x, e)) + χ(t, x, e)} implying the existence of an ε > 0 such that\nv∗(t, x) ≤ v∗(t, x + γ(t, x, e)) + χ(t, x, e) − ε,\n∀e ∈ E.\nSince vnj(tj, xj) → v∗(t, x) and\nlim inf\nj→∞ inf\ne∈E{vnj(tj, xj + γ(tj, xj, e)) + χ(tj, xj, e)}\n≥ lim inf\nj→∞ inf\ne∈E{v∗(tj, xj + γ(tj, xj, e)) + χ(tj, xj, e)}\n≥ inf\ne∈E{v∗(t, x + γ(t, x, e)) + χ(t, x, e)},\nthis implies that\nvnj(t, x) ≤ vnj(tj, xj + γ(tj, xj, e)) + χ(tj, xj, e),\n∀e ∈ E,\nwhenever j is suﬃciently large. In particular, we get that\nZ\nE\n(vnj(tj, xj + γ(tj, xj, e)) + χ(tj, xj, e) − vnj(tj, xj))−λ(de) = 0\nfor j suﬃciently large. Taking the limit in (3.4) we thus ﬁnd that in this situation\n− p − < a(t, x), q > −1\n2Tr(σσ⊤(t, x)M) − ˜f(t, x, v∗(t, x), σ⊤(t, x)q) ≥ 0,\n13\nproving the supersolution property of v∗.\nMuch like the functions vn, for each (t, x) ∈ [0, T] × Rd, the processes (Y t,x,n)n∈N form a non-\nincreasing sequence that is bounded from below by h(·, Xt,x\n·\n) ∈ S2, implying the existence of an Ft-\nprogressively measurable process Y t,x such that Y t,x,n ց Y t,x, pointwisely. Taking the limit on both\nsides of vn(η, Xt,x\nη ) = Y t,x,n\nη\ngives that Y t,x\nη\n= v(η, Xt,x\nη ) for each η ∈ Tt. In particular, Y t,x is c`adl`ag and\nthus belongs to S2\nt .\nIn our pursuit of a related optimal stopping problem, we let for each τ ∈ T t,\nthe process Y t,x,τ be the ﬁrst component in the quadruple of processes (Y t,x,τ, Zt,x,τ, V t,x,τ, K−,t,x,τ) ∈\nS2\n[t,τ] × H2\n[t,τ](W) × H2\n[t,τ](µ) × S2\n[t,τ],i that is the unique maximal solution to the BSDE with constrained\njumps,\n\n\n\n\n\nY t,x,τ\ns\n= Ψ(τ, Xt,x\nτ ) +\nR τ\ns ˜f(r, Xt,x\nr , Y t,x,τ\nr\n, Zt,x,τ\nr\n)dr −\nR τ\ns Zt,x,τ\nr\ndWr −\nR τ\ns\nR\nE V t,x,τ\nr\n(e)µ(dr, de)\n−(K−,t,x,τ\nτ\n− K−,t,x,τ\ns\n),\n∀s ∈ [t, τ],\nV t,x,τ\ns\n(e) ≥ −χ(s, Xt,x\ns−, e),\ndP ⊗ ds ⊗ λ(de) − a.e.\n(3.5)\nTheorem 3.1 of [18] seamlessly transfers to the present context, allowing us to conclude the following:\nProposition 3.3. For each (t, x) ∈ [0, T] × Rd and η ∈ T t, the process Y t,x can be represented as\nY t,x\nη\n= ess sup\nτ∈T t\nη\nY t,x,τ\nη\n= ess inf\nν∈Vt ess sup\nτ∈T t\nη\nP t,x;τ,ν\nη\n,\n(3.6)\nwhere given ν ∈ Vt and τ ∈ T t, the triple (P t,x;τ,ν, Qt,x;τ,ν, St,x;τ,ν) ∈ S2\n[t,τ] × H2\n[t,τ](W) × H2\n[t,τ](µ) is the\nunique solution to the standard BSDE\nP t,x;ν,τ\ns\n= Ψ(τ, Xt,x\nτ ) +\nZ τ\ns\n˜f ν(r, Xt,x\nr , P t,x;ν,τ\nr\n, Qt,x;ν,τ\nr\n, St,x;ν,τ\nr\n)dr\n−\nZ τ\ns\nQt,x;ν,τ\nr\ndWr −\nZ τ\ns\nZ\nE\nSt,x;ν,τ\nr\n(e)µ(dr, de),\n(3.7)\nwith driver\n˜f ν(t, x, y, z, v) := ˜f(t, x, y, z) +\nZ\nE\n(v(e) + χ(t, x, e))νt(e)λ(de).\n4\nThe general setting\nWe now turn to the general setting of a non-local driver. Existence will again follow by an approximation\nroutine and for (t, x) ∈ [0, T] × Rd and k ∈ N, we let Y t,x,k\ns\n:= ess supτ∈T t\ns Y t,x,k;τ\ns\n, where the quadruple\n(Y t,x,k;τ, Zt,x,k;τ, V t,x,k;τ, K−,t,x,k;τ) ∈ S2\n[t,τ] ×H2\n[t,τ](W)×H2\n[t,τ](µ)×S2\n[t,τ],i is the unique maximal solution\nto\n\n\n\n\n\nY t,x,k;τ\ns\n= Ψ(τ, Xt,x\nτ ) +\nR τ\ns f(r, Xt,x\nr , ¯Y k−1(r, ·), Zt,x,k;τ\nr\n)dr −\nR τ\ns Zt,x,k;τ\nr\ndWr\n−\nR τ\ns\nR\nE V t,x,k;τ\nr\n(e)µ(dr, de) − (K−,t,x,k;τ\nτ\n− K−,t,x,k;τ\ns\n),\n∀s ∈ [t, τ]\nV t,x,k;τ\ns\n(e) ≥ −χ(s, Xt,x\ns , e),\ndP ⊗ ds ⊗ λ(de) − a.e.,\n(4.1)\nfor k ≥ 1, with ¯Y k−1(t, x) := Y t,x,k\nt\nand ¯Y 0 ≡ 0.\nProposition 4.1. There is a sequence ( ¯Y k ∈ Πg\nc)k≥0 that satisﬁes the recursion above.\nProof. We need to show that for each k ≥ 1, there is a vk−1 ∈ Πg\nc such that Y t,x,k−1\nt\n= vk−1(t, x) for\nall (t, x) ∈ [0, T] × Rn. However, for k = 1 this is immediate by the deﬁnition. Now, the result follows by\n14\nusing Proposition 3.3, Theorem 3.2 and induction.\nFor (t, ζ) ∈ [0, T]×R+ and α ∈ At, we let (Υt,ζ;α, Θt,ζ;α) ∈ S2\nt ×S2\ni,t solve the one-dimensional reﬂected\nSDE\n\n\n\n\n\nΥt,ζ;α\ns\n= ζ2 ∨ K2\nΓ + (4Ca,σ + 2C2\na,σ)\nR s\nt (1 + Υt,ζ;α\nr\n)dr + 4Ca,σ\nR s\nt (1 + Υt,ζ;α\nr\n)αrdWr + Θt,ζ;α\ns\n,\n∀s ∈ [t, T],\nΥt,ζ;α\ns\n≥ ζ2 ∨ K2\nΓ and\nR T\nt (Υt,ζ;α\ns\n− (ζ2 ∨ K2\nΓ))dΘt,ζ;α\ns\n= 0.\n(4.2)\nWe then set Rt,ζ;α\ns\n:=\nq\nΥt,ζ;α\ns\nand note that classically, we have\nE\nh\nsup\ns∈[t,T]\n|Rt,ζ;α\ns\n|pi\n≤ C(1 + |ζ ∨ KΓ|p),\nfor all p ≥ 2.\nLemma 4.2. For each (t, x) ∈ [0, T] × Rd, there is an α ∈ At such that |Xt,x\ns | ≤ Rt,|x|;α\ns\nfor all s ∈ [t, T],\nP-a.s.\nProof. Since\n|2xa(r, x) + σ2(r, x)| ≤ (4Ca,σ + 2C2\na,σ)(1 + |x|2),\nit follows from (2.8) that we can always choose α ∈ At such that\n2Ca,σ(1 + Υt,|x|,ξ;α\nr\n)αr = Xt,x\nr σ(r, Xt,x\nr ),\n∀r ∈ [t, T],\nand the statement holds by (2.8).\nFor each ϕ ∈ Πg\nc, we let ¯Y ϕ ∈ Πg\nc be deﬁned as ¯Y ϕ(t, x) = ess supτ∈Tt Y t,x,ϕ;τ\nt\n, where the quadruple\n(Y t,x,ϕ;τ, Zt,x,ϕ;τ, V t,x,ϕ;τ, K−,t,x,ϕ;τ) is the unique maximal solution to\n\n\n\n\n\nY t,x,ϕ;τ\ns\n= Ψ(τ, Xt,x\nτ ) +\nR τ\ns f(r, Xt,x\nr , ϕ(r, ·), Zt,x,ϕ;τ\nr\n)dr −\nR τ\ns Zt,x,ϕ;τ\nr\ndWr\n−\nR τ\ns\nR\nE V t,x,ϕ;τ\nr\n(e)µ(dr, de) − (K−,t,x,ϕ;τ\nτ\n− K−,t,x,ϕ;τ\ns\n),\n∀s ∈ [t, τ]\nV t,x,k;τ\ns\n(e) ≥ −χ(s, Xt,x\ns , e), dP ⊗ ds ⊗ λ(de) − a.e.,\n(4.3)\nand note that letting (P t,x,ϕ;ν,τ, Qt,x,ϕ;ν,τ, St,x,ϕ;ν,τ) ∈ S2\nt × H2\nt (W) × H2\nt (µ) solve\nP t,x,ϕ;ν,τ\ns\n= Ψ(τ, Xt,x\nτ ) +\nZ τ\ns\nf ν(r, Xt,x\nr , P t,x,ϕ;ν,τ\nr\n, ϕ(r, ·), Qt,x,ϕ;ν,τ\nr\n, St,x,ϕ;ν,τ\nr\n)dr\n−\nZ τ\ns\nQt,x,ϕ;ν,τ\nr\ndWr −\nZ τ\ns\nZ\nE\nSt,x,ϕ;ν,τ\nr\n(e)µ(dr, de),\n(4.4)\nwhere\nf ν(t, x, g, z, v) := f(t, x, g, z, v) +\nZ\nE\n(v(e) + χ(t, x, e))νt(e)λ(de),\nProposition 3.3 gives that\n¯Y ϕ(t, x) = inf\nν∈Vt sup\nτ∈T t P t,x,ϕ;ν,τ\nt\n.\n(4.5)\nThe above deﬁnitions allow us to present the following result, which extends prior results derived in [19]\n(see Proposition 4.3 therein) and forms the basis for our contraction argument:\n15\nProposition 4.3. There is a κ > 0 such that for all ϕ, ˜ϕ ∈ Πg\nc and ζ > 0, we have\nsup\nα∈AW E\nh Z T\n0\neκt\nsup\nx∈Λf(R0,ζ;α\nt\n)\n| ¯Y ˜ϕ(t, x) − ¯Y ϕ(t, x)|2dt\ni\n≤ 1\n4 sup\nα∈AW E\nh Z T\n0\neκt\nsup\nx∈Λf(R0,ζ;α\nt\n)\n| ˜ϕ(t, x) − ϕ(t, x)|2dt\ni\n.\n(4.6)\nFurthermore, there is a C > 0 such that\nsup\nt∈[0,T]\nsup\nx∈Λf (ζ)\n| ¯Y ˜ϕ(t, x) − ¯Y ϕ(t, x)|2 ≤ C sup\nα∈AW E\nh Z T\n0\nsup\nx∈Λf(R0,ζ;α\nt\n)\n| ˜ϕ(t, x) − ϕ(t, x)|2dt\ni\n(4.7)\nfor each ζ > 0.\nProof. By (4.5) we ﬁnd that\n¯Y ϕ(t, x) − ¯Y ˜ϕ(t, x) ≤ sup\nν∈Vt\nsup\nτ∈T t(P t,x,ϕ;ν,τ\nt\n− P t,x, ˜ϕ;ν,τ\nt\n).\nSince a similar inequality holds in the opposite direction, we get that\n| ¯Y ϕ(t, x) − ¯Y ˜ϕ(t, x)| ≤ sup\nν∈Vt\nsup\nτ∈T t |P t,x,ϕ;ν,τ\nt\n− P t,x, ˜ϕ;ν,τ\nt\n|.\n(4.8)\nFor (ν, τ) ∈ Vt×T t, let (P, Q, S) := (P t,x,ϕ;ν,τ, Qt,x,ϕ;ν,τ, St,x,ϕ;ν,τ) and ( ˜P, ˜Q, ˜S) := (P t,x, ˜ϕ;ν,τ, Qt,x, ˜ϕ;ν,τ, St,x, ˜ϕ;ν,τ)\nand note that for κ > 0, Itˆo’s formula applied to eκ·| ˜P − P|2 gives\neκt| ˜Pt − Pt|2 +\nZ τ\nt\neκs| ˜Qs − Qs|2ds +\nZ τ\nt\nZ\nE\neκs| ˜Ss(e) − Ss(e)|2dµ(ds, de)\n= −2\nZ τ\nt\neκs( ˜Ps − Ps)( ˜Qs − Qs)dWs − 2\nZ τ\nt\nZ\nE\neκs( ˜Ps − Ps)( ˜Ss(e) − Ss(e))dµ(ds, de)\n− κ\nZ τ\nt\neκs| ˜Ps − Ps|2ds + 2\nZ τ\nt\neκs( ˜Ps − Ps)(f(s, Xt,x\ns , ˜ϕ(s, ·), ˜Qs) − f(s, Xt,x\ns , ϕ(s, ·), Qs))ds\n+ 2\nZ τ\nt\nZ\nE\neκs( ˜Ps − Ps)( ˜S(e) − S(e))νt(e)λ(de).\nBy assumption\n|f(s, Xt,x\ns , ϕ(s, ·), Qs) − f(s, Xt,x\ns , ˜ϕ(s, ·), ˜Qs)| ≤ kf(\nsup\nx′∈Λf (|Xt,x\ns\n|)\n| ˜ϕ(s, x′) − ϕ(s, x′)| + | ˜Qs − Qs|).\nHence, taking the expectation w.r.t. the measure Pν and using inequalities 2Cxy ≤ (Cx)2 + y2 and\n2xy ≤ x2/√κ + √κy2 gives\neκt| ˜Pt − Pt|2 ≤ (C2 + C√κ − κ)Eνh Z τ\nt\neκs| ˜Ps − Ps|2ds\ni\n+ C\n√κEνh Z T\nt\neκs\nsup\nx′∈Λf (|Xt,x\ns\n|)\n| ˜ϕ(s, x′) − ϕ(s, x′)|2ds\ni\n.\nNow, pick κ0 > 0 such that κ0 ≥ C2 + C√κ0 and note that for each κ ≥ κ0, we have\neκt|Pt − ˜Pt|2 ≤ C\n√κEνh Z T\nt\neκs\nsup\nx′∈Λf (|Xt,x\ns\n|)\n| ˜ϕ(s, x′) − ϕ(s, x′)|2ds\ni\n≤ C\n√κ sup\nα∈At\nEνh Z T\nt\neκs\nsup\nx′∈Λf (|Rt,|x|;α\ns\n|)\n| ˜ϕ(s, x′) − ϕ(s, x′)|2ds\ni\n≤ C\n√κ sup\nα∈AW\nt\nE\nh Z T\nt\neκs\nsup\nx′∈Λf (|Rt,|x|;α\ns\n|)\n| ˜ϕ(s, x′) − ϕ(s, x′)|2ds\ni\n,\n16\nwhere the ﬁrst inequality follows from Lemma 4.2 while the second one is due to the fact that the SDE\nin (4.2) does not depend on µ (see e.g. Section 4.1 of [1]). Since the right-hand side is non-decreasing in\n|x| and independent of ν and τ, (4.8) now gives that\neκt\nsup\nx∈Λf (ζ)\n| ¯Y ˜ϕ(t, x) − ¯Y ϕ(t, x)|2 ≤ C\n√κ sup\nα∈AW\nt\nE\nh Z T\nt\neκs\nsup\nx′∈Λf (Rt,ζ;α\ns\n)\n| ˜ϕ(s, x′) − ϕ(s, x′)|2ds\ni\n,\n(4.9)\nfor any ζ ≥ 0. In particular, as both sides are continuous in ζ a standard dynamic programming argument\ngives that for any α1 ∈ AW, we have\nE\nh\neκt\nsup\nx∈Λf(R0,ζ;α1\nt\n)\n| ¯Y ˜ϕ(t, x) − ¯Y ϕ(t, x)|2i\n≤ C\n√κ sup\nα∈AW\nt\nE\nh Z T\nt\neκs\nsup\nx′∈Λf (R0,ζ;α1⊕tα\ns\n)\n| ˜ϕ(s, x′) − ϕ(s, x′)|2ds\ni\n.\nTaking the supremum with respect to α1 on the right-hand side and once again relying on a standard\ndynamic programming argument gives that\nE\nh\neκt\nsup\nx∈Λf (R0,ζ;α1\nt\n)\n| ¯Y ˜ϕ(t, x) − ¯Y ϕ(t, x)|2i\n≤ C\n√κ sup\nα∈AW E\nh Z T\n0\neκs\nsup\nx′∈Λf (R0,ζ;α\ns\n)\n| ˜ϕ(s, x′) − ϕ(s, x′)|2ds\ni\n.\nIntegrating with respect to time and using Fubini’s theorem, we ﬁnd that\nE\nh Z T\n0\neκt\nsup\nx∈Λf(R0,ζ;α1\nt\n)\n| ¯Y ˜ϕ(t, x) − ¯Y ϕ(t, x)|2dt\ni\n≤ CT\n√κ sup\nα∈AW E\nh Z T\n0\neκs\nsup\nx′∈Λf (R0,ζ;α\ns\n)\n| ˜ϕ(s, x′) − ϕ(s, x′)|2ds\ni\nafter which taking the supremum with respect to α1 ∈ AW and choosing κ ≥ (4CT)2 ∨ κ0 gives the ﬁrst\ninequality. To get (4.7) we note that comparison gives that R0,ζ;α\ns\n≥ Rt,ζ;α\ns\nfor all s ∈ [t, T] and α ∈ AW.\nFrom (4.9) we thus get that\nsup\nx∈Λf(ζ)\n| ¯Y ˜ϕ(t, x) − ¯Y ϕ(t, x)|2 ≤ C sup\nα∈AW E\nh Z T\n0\nsup\nx′∈Λf (R0,ζ;α\ns\n)\n| ˜ϕ(s, x′) − ϕ(s, x′)|2ds\ni\nfrom which (4.7) is immediate since the right-hand side is independent of t.\nWe now introduce the norm ∥ · ∥ζ on the space of jointly continuous functions of polynomial growth,\nΠg\nc, deﬁned as\n∥ϕ∥ζ := sup\nα∈AW E\nh Z T\n0\neκt\nsup\nx∈Λf (R0,ζ;α\nt\n)\n|ϕ(t, x)|2dt\ni1/2\n,\nwith κ > 0 as in Proposition 4.3 and note that under ∥ · ∥ζ, the map Φ : Πg\nc → Πg\nc that maps ϕ to ¯Y ϕ is\na contraction.\nCorollary 4.4. There are constants C > 0 and p ≥ 0 such that | ¯Y k(t, x)| ≤ C(1 + |x|p) for all (t, x) ∈\n[0, T] × Rd and all k ≥ 0.\nProof. First, we note that (4.6) and the triangle inequality implies that\n∥¯Y k∥ζ ≤ ∥¯Y k − ¯Y k−1∥ζ + ∥¯Y k−1∥ζ ≤ 1\n2∥¯Y k−1 − ¯Y k−2∥ζ + ∥¯Y k−1∥ζ ≤\n1\n2k−1 ∥¯Y 1 − ¯Y 0∥ζ + ∥¯Y k−1∥ζ.\nHowever, as a similar scheme holds for ∥¯Y k−1∥ζ and since ¯Y 0 ≡ 0 we conclude that\n∥¯Y k∥ζ ≤\nk\nX\nj=1\n1\n2j−1 ∥¯Y 1∥ζ ≤ 2∥¯Y 1∥ζ.\n17\nOn the other hand, as ¯Y 1 ∈ Πg\nc there are constants C > 0 and p ≥ 2 such that | ¯Y 1(t, x)| ≤ C(1 + |x|p)\nand we conclude that\n∥¯Y 1∥2\nζ = sup\nα∈AW E\nh Z T\n0\neκt\nsup\nx∈Λf (R0,ζ;α\nt\n)\n| ¯Y 1(t, x)|2dt\ni\n≤ C\n\u0010\n1 + sup\nα∈AW E\nh\nsup\nt∈[0,T]\n|R0,ζ;α\nt\n|2pi\u0011\n≤ C(1 + |ζ|2p)\nimplying the existence of a C > 0 such that ∥¯Y k∥ζ ≤ C(1 + |ζ|p) for all k ≥ 0. Now, (4.7) gives that\nsup\nt∈[0,T]\nsup\nx∈Λf(ζ)\n| ¯Y k(t, x) − ¯Y 1(t, x)|2 ≤ C sup\nα∈AW E\nh Z T\n0\nsup\nx∈Λf(R0,ζ;α\nt\n)\n| ¯Y k−1(t, x)|2dt\ni\n≤ C(1 + |ζ|2p)\nwhere the constants C > 0 and p ≥ 2 do not depend on k and the desired bound follows.\nLetting vk(t, x) := ¯Y k(t, x), Proposition 4.3 and Corollary 4.4 implies that there is a v ∈ Πg such that\nfor each ζ > 0 we have ∥vk − v∥ζ → 0 as k → ∞.\nTheorem 4.5. v is the unique viscosity solution in Πg\nc to (1.1).\nProof. First, (4.7) implies that the convergence is uniform on compact subsets of [0, T] × Rn and since vk\nis jointly continuous for each k ≥ 0 we conclude that v is also jointly continuous. This in turn gives that\nΦ(v) is well deﬁned and we conclude that Φ(v) = v establishing existence of a solution to the optimal\nstopping problem (1.3)-(1.5). Moreover, if ˜Y is another solution, then ˜v(t, x) := ˜Y t,x\nt\nmust also satisfy\nΦ(˜v) = ˜v. However, then repeated use of the contraction property in (4.6) gives that ∥˜v − v∥ζ = 0 and\nby continuity we conclude that ˜v = v implying by uniqueness of the non-linear Snell envelope in (3.6) as\nobtained in Proposition 3.3 that ˜Y t,x = Y t,x. The solution to the optimal stopping problem (1.3)-(1.5)\nis thus unique.\nUtilizing, once more, the connection between the optimal stopping problem (1.3)-(1.5) and PDEs\nwith obstacles we conclude that v is a viscosity solution to (1.1). Suppose now that there exists another\nfunction ˜v ∈ Πg\nc that solves (1.1) and let ¯v = Φ(˜v), then by Theorem 3.2 and Proposition 3.3 we conclude\nthat ¯v ∈ Πg\nc is the unique solution to\n\n\n\n\n\nmin{¯v(t, x) − h(t, x), max{¯v(t, x) − M¯v(t, x), −¯vt(t, x) − L¯v(t, x)\n−f(t, x, ˜v(t, ·), σ⊤(t, x)∇x¯v(t, x))}} = 0,\n∀(t, x) ∈ [0, T) × Rd\n¯v(T, x) = ψ(x),\nBut then ¯v = ˜v implying that ˜v is a ﬁxed point of Φ and since v is the only ﬁxed point of Φ in the set of\njointly continuous functions of polynomial growth we must have ˜v = v.\nCorollary 4.6. Y v is the unique solution to the optimal stopping problem (1.3)-(1.5).\nA\nUniqueness of viscosity solutions in the local framework\nIn this section we prove the critical comparison principle for the PDE with local driver,\n\n\n\n\n\nmin{v(t, x) − h(t, x), max{v(t, x) − Mv(t, x), −vt(t, x) − Lv(t, x)\n− ˜f(t, x, v(t, x), σ⊤(t, x)∇xv(t, x))}} = 0,\n∀(t, x) ∈ [0, T) × Rd\nv(T, x) = ψ(x),\n(A.1)\nthat was treated in Section 3 (see (3.1)). We need the following lemma:\n18\nLemma A.1. Let v be a supersolution to (A.1) satisfying\n∀(t, x) ∈ [0, T] × Rd,\n|v(t, x)| ≤ C(1 + |x|2̺)\nfor some ̺ > 0. Then there is a ̟0 > 0 such that for any ̟ > ̟0 and θ > 0, the function v + θe−̟t(1 +\n((|x| − KΓ)+)2̺+2) is also a supersolution to (A.1).\nProof. With w(t, x) := v(t, x) + θe−̟t(1+ ((|x| − KΓ)+)2̺+2) we note that, since v is a supersolution and\nθe−̟T(1 + ((|x| − KΓ)+)2̺+2) ≥ 0, we have\nw(t, x) ≥ v(t, x) ≥\n1[t<T]h(t, x) +\n1[t=T]ψ(x)\nso that w(t, x) ≥ h(t, x) for all (t, x) ∈ [0, T) × Rd and the terminal condition holds. Assume now that\nv(t, x) − inf\ne∈E{v(t, x + γ(t, x, e)) + χ(t, x, e)} ≥ 0.\nIn this case,\nw(t, x) − inf\ne∈E{w(t, x + γ(t, x, e)) + χ(t, x)}\n= v(t, x) + θe−γt(1 + ((|x| − KΓ)+)2̺+2)\n− inf\ne∈E{v(t, x + γ(t, x, e)) + θe−γt(1 + ((|x + γ(t, x, e)| − KΓ)+)2̺+2) + χ(t, x, e)}\n≥ v(t, x) − inf\ne∈E{v(t, x + γ(t, x, e)) + χ(t, x, e)}\n+ θe−γt{1 + ((|x| − KΓ)+)2̺+2 − sup\ne∈E\nθe−γt(1 + ((|x + γ(t, x, e)| − KΓ)+)2̺+2)}.\nNow, either |x| ≤ KΓ in which case it follows by (2.1) that |x + γ(t, x, e)| ≤ KΓ or |x| > KΓ and (2.1)\ngives that |x + γ(t, x, e)| ≤ |x|. We conclude that\nw(t, x) − inf\ne∈E{w(t, x + γ(t, x, e)) + χ(t, x, e)} ≥ 0.\nConsider instead the case when\nv(t, x) − inf\ne∈E{v(t, x + γ(t, x, e)) + χ(t, x, e)} < 0\nand let ϕ ∈ C1,2([0, T] × Rd → R) be such that ϕ − w has a local maximum of 0 at (t, x) with t < T.\nThen (˜t, ˜x) 7→ ˜ϕ(˜t, ˜x) := ϕ(˜t, ˜x) − θe−̟˜t(1 + ((|˜x| − KΓ)+)2̺+2) ∈ C1,2([0, T] × Rd → R) and ˜ϕ − v has a\nlocal maximum of 0 at (t, x). Since v is a viscosity supersolution, we have\n− ∂t(ϕ(t, x) − θe−̟t(1 + ((|x| − KΓ)+)2̺+2)) − L(ϕ(t, x) − θe−̟t(1 + ((|x| − KΓ)+)2̺+2))\n− ˜f(t, x, ϕ(t, x) − θe−̟t(1 + ((|x| − KΓ)+)2̺+2), σ⊤(t, x)∇x(ϕ(t, x) − θe−̟t(1 + ((|x| − KΓ)+)2̺+2))) ≥ 0.\nConsequently,\n− ∂tϕ(t, x) − Lϕ(t, x) − ˜f(t, x, ϕ(t, x), σ⊤(t, x)∇xϕ(t, x))\n≥ θ̟e−̟t(1 + ((|x| − KΓ)+)2̺+2) − θLe−̟t(1 + ((|x| − KΓ)+)2̺+2)\n˜f(t, x, ϕ(t, x) − θe−̟t(1 + ((|x| − KΓ)+)2̺+2), σ⊤(t, x)∇x(ϕ(t, x) − θe−̟t(1 + ((|x| − KΓ)+)2̺+2)))\n− ˜f(t, x, ϕ(t, x), σ⊤(t, x)∇xϕ(t, x))\n≥ θ̟e−̟t(1 + ((|x| − KΓ)+)2̺+2) − θC(1 + ̺)e−̟t(1 + ((|x| − KΓ)+)2̺+2)\n− kf(1 + ̺)θe−̟t(1 + ((|x| − KΓ)+)2̺+2),\nwhere the right hand side is non-negative for all θ > 0 and all ̟ > ̟0 for some ̟0 > 0.\nWe have the following result, the proof of which we omit since it is classical:\n19\nLemma A.2. For any κ ∈ R, a locally bounded function v : [0, T] × Rd → R is a viscosity superso-\nlution (resp. subsolution) to (A.1) if and only if ˇv(t, x) := eκtv(t, x) is a viscosity supersolution (resp.\nsubsolution) to\n\n\n\n\n\nmin{ˇv(t, x) − eκth(t, x), max{ˇv(t, x) + infe∈E{ˇv(t, x + γ(t, x, e)) + eκtχ(t, x, e)}, −ˇvt(t, x)\n+κˇv(t, x) − Lˇv(t, x) − eκt ˜f(t, x, e−κtˇv(t, x), e−κtσ⊤(t, x)∇xˇv(t, x))} = 0,\n∀(t, x) ∈ [0, T) × Rd\nˇv(T, x) = eκT ψ(x).\n(A.2)\nRemark A.3. Here, it is important to note that ˇh(t, x) := eκth(t, x), ˇχ(t, x, e) := eκtχ(t, x, e), ˇf(t, x, y, z) :=\n−κy + eκt ˜f(t, x, e−κty, e−κtz) and ˇψ(x) := eκT ψ(x) satisfy Assumption 2.2. In particular, this implies\nthat Lemma A.1 holds for supersolutions to (A.2) as well.\nWe have the following comparison result for viscosity solutions in Πg:\nProposition A.4. Let v (resp. u) be a supersolution (resp. subsolution) to (A.1). If u, v ∈ Πg, then\nu ≤ v.\nProof. First, we note that it is suﬃcient to show that the statement holds for solutions to (A.2) for some\nκ ∈ R. We thus assume that v (resp. u) is a viscosity supersolution (resp. subsolution) to (A.2) for κ ∈ R\nspeciﬁed below. Furthermore, we may without loss of generality assume that v is l.s.c. and u is u.s.c.\nBy assumption, u, v ∈ Πg, which implies that there are constants C > 0 and ̺ > 0 such that\n|v(t, x)| + |u(t, x)| ≤ C(1 + |x|2̺).\n(A.3)\nNow, for any ̟ > 0 we only need to show that\nw(t, x) = wθ,̟(t, x) := v(t, x) + θe−̟t(1 + ((|x| − KΓ)+)2̺+2)\n≥ u(t, x)\nfor all (t, x) ∈ [0, T] × Rd and any θ > 0. Then the result follows by taking the limit θ → 0. We know\nfrom Lemma A.1 that there is a ̟0 > 0 such that w is a supersolution to (A.2) for each ̟ ≥ ̟0 and\nθ > 0. We thus assume that ̟ ≥ ̟0.\nWe search for a contradiction and assume that there is a (t0, x0) ∈ [0, T] × Rd such that u(t0, x0) >\nw(t0, x0). By (A.3), there is for each θ > 0 a R > KΓ such that\nw(t, x) > u(t, x),\n∀(t, x) ∈ [0, T] × Rd, |x| > R.\nOur assumption thus implies that there is a point (¯t, ¯x) ∈ [0, T) × BR (the open unit ball of radius R\ncentered at 0) such that\nmax\n(t,x)∈[0,T]×Rd(u(t, x) − w(t, x)) =\nmax\n(t,x)∈[0,T)×BR\n(u(t, x) − w(t, x))\n= u(¯t, ¯x) − w(¯t, ¯x) = η > 0.\nWe ﬁrst show that there is at least one point (t∗, x∗) ∈ [0, T) × BR such that\na) u(t∗, x∗) − w(t∗, x∗) = η,\nb) u(t∗, x∗) > ˇh(t∗, x∗) and\nc) w(t∗, x∗) < infe∈E{v(t∗, x∗ + γ(t∗, x∗, e)) + ˇχ(t∗, x∗, e)}.\n20\nAssume ﬁrst that u(t, x) ≤ ˇh(t, x) for some (t, x) ∈ [0, T] × Rd. Since w is a supersolution, we have\nw(t, x) ≥ ˇh(t, x) and it follows that u(t, x) − w(t, x) ≤ 0 contradicting that u(t, x) − w(t, x) = η. In\nparticular, any point satisfying a) must also satisfy b).\nWe proceed by assuming that w(t, x) ≥ infe∈E{w(t, x + γ(t, x, e)) − ˇχ(t, x, e)} for all (t, x) ∈ A :=\n{(s, y) ∈ [0, T] × Rd : u(s, y) − w(s, y) = η}. Indeed, as w is l.s.c. and γ is continuous, there is an e1 ∈ E\nsuch that\nw(¯t, ¯x) = inf\ne∈E{w(¯t, ¯x + γ(¯t, ¯x, e)) + ˇχ(¯t, ¯x, e)} = w(¯t, ¯x + γ(¯t, ¯x, e1)) + ˇχ(¯t, ¯x, e1).\n(A.4)\nNow, set x1 = ¯x + γ(¯t, ¯x, e1) and note that since\n|x + γ(t, x, e)| < R,\n∀(t, x, e) ∈ [0, T] × BR × E\nit follows that x1 ∈ BR. Moreover, as u is a subsolution with u(¯t, ¯x) > ˇh(¯t, ¯x) it satisﬁes\nu(¯t, ¯x) − (u(¯t, ¯x + γ(¯t, ¯x, e1)) + ˇχ(¯t, ¯x, e1)) ≤ 0,\nthat is\nu(¯t, x1)) ≥ u(¯t, ¯x) − ˇχ(t, ¯x, e1)\nand we conclude from (A.4) that\nu(¯t, x1) − w(¯t, x1) ≥ u(¯t, ¯x) − ˇχ(¯t, ¯x, e1) − (w(¯t, ¯x) − ˇχ(t, ¯x, e1))\n= u(¯t, ¯x) − w(¯t, ¯x) = η.\nHence, (¯t, x1) ∈ A and by our assumption it follows that there is an e2 ∈ E such that\nu(¯t, x1) = u(¯t, x1 + γ(¯t, x1, e2)) + ˇχ(¯t, x1, e2)\nand a corresponding x2 := x1 + γ(¯t, x1, e2) ∈ BR. Now, this process can be repeated indeﬁnitely to ﬁnd\na sequence (xj, ej)j≥1 in BR × E such that for any l ≥ 0 we have\nw(¯t, ¯x) ≥ w(¯t, xl) +\nl\nX\nj=1\nˇχ(¯t, xj−1, ej),\nwith x0 := ¯x.\nHowever, as ˇχ ≥ δ > 0 we get a contradiction by letting l → ∞ while noting that\nw(t, x) ≥ ˇh(t, x) where the latter is bounded on [0, T] × ¯BR. We can thus ﬁnd a (t∗, x∗) ∈ [0, T) × BR\nsuch that a)-c) above holds.\nSince ˜f is Lipschitz in y and z for (t, x) ∈ [0, T] × ¯BR, the remainder of the proof follows along the\nlines of the proof of Proposition 4.1 in [12] (see also Proposition 6.4 in [20]) and is included only for the\nsake of completeness.\nNext, we assume without loss of generality that ̺ ≥ 2 and deﬁne\nΦn(t, x, y) := u(t, x) − w(t, x) − ϕn(t, x, y),\nwhere\nϕn(t, x, y) := n\n2|x − y|2̺ + |x − x∗|2 + |y − x∗|2 + (t − t∗)2.\nSince u is u.s.c. and w is l.s.c. there is a triple (tn, xn, yn) ∈ [0, T] × ¯BR × ¯BR (with ¯BR the closure of BR)\nsuch that\nΦn(tn, xn, yn) =\nmax\n(t,x,y)∈[0,T]× ¯BR× ¯BR\nΦn(t, x, y).\n21\nNow, the inequality 2Φn(tn, xn, yn) ≥ Φn(tn, xn, xn) + Φn(tn, yn, yn) gives\nn|xn − yn|2̺ ≤ u(tn, xn) − u(tn, yn) + w(tn, xn) − w(tn, yn).\nConsequently, n|xn −yn|2̺ is bounded (since u and w are bounded on [0, T]× ¯BR × ¯BR) and |xn −yn| → 0\nas n → ∞. We can, thus, extract subsequences nl such that (tnl, xnl, ynl) → (˜t, ˜x, ˜x) as l → ∞. Since\nu(t∗, x∗) − w(t∗, x∗) ≤ Φn(tn, xn, yn) ≤ u(tn, xn) − w(tn, yn),\nit follows that\nu(t∗, x∗) − w(t∗, x∗) ≤ lim sup\nl→∞\n{u(tnl, xnl) − w(tnl, ynl)}\n≤ u(˜t, ˜x) − w(˜t, ˜x)\nand as the right-hand side is dominated by u(t∗, x∗) − w(t∗, x∗) we conclude that\nu(˜t, ˜x) − w(˜t, ˜x) = u(t∗, x∗) − w(t∗, x∗).\nIn particular, this gives that liml→∞ Φn(tnl, xnl, ynl) = u(˜t, ˜x) − w(˜t, ˜x) which implies that\nlim sup\nl→∞\nnl|xnl − ynl|2̺ = 0\nand\n(tnl, xnl, ynl) → (t∗, x∗, x∗).\nWe can thus extract a subsequence (˜nl)l≥0 of (nl)l≥0 such that t˜nl < T, |x˜nl| < R and\nu(t˜nl, x˜nl) − w(t˜nl, x˜nl) ≥ η\n2\nfor all l ∈ N. Moreover, since (t, x) 7→ infe∈E{w(t, x + γ(t, x, e)) − ˇχ(t, x, e)} is u.s.c. (see Lemma 2.11),\nw(t˜nl, x˜nl) → w(t∗, x∗) and u is u.s.c. while ˇh is continuous, there is an l0 ≥ 0 such that\nw(t˜nl, x˜nl) − inf\ne∈E{w(t˜nl, x˜nl + γ(t˜nl, x˜nl, e)) − ˇχ(t˜nl, e)} < 0,\nand\nu(t˜nl, x˜nl) − ˇh(t˜nl, x˜nl) > 0,\nfor all l ≥ l0. To simplify notation we will, from now on, denote (˜nl)l≥l0 simply by n.\nBy Theorem 8.3 of [7] there are (pu\nn, qu\nn, Mu\nn) ∈ ¯J2,+u(tn, xn) and (pw\nn , qw\nn , Mw\nn ) ∈ ¯J2,+w(tn, yn), where\n¯J2,+ is the limiting superjet, such that\n\n\n\n\n\npu\nn − pw\nn = ∂tϕn(tn, xn, yn) = 2(tn − t∗)\nqu\nn = Dxϕn(tn, xn, yn) = n̺(x − y)|x − y|2̺−2 + 2(x − x∗)\nqw\nn = −Dyϕn(tn, xn, yn) = n̺(x − y)|x − y|2̺−2 + 2(x − x∗)\nand for every ǫ > 0,\n\u0014 Mn\nx\n0\n0\n−Mn\ny\n\u0015\n≤ B(tn, xn, yn) + ǫB2(tn, xn, yn),\n22\nwhere B(tn, xn, yn) := D2\n(x,y)ϕn(tn, xn, yn). Now, we have\nD2\n(x,y)ϕn(t, x, y) =\n\u0014 D2\nxϕn(t, x, y)\nD2\nyxϕn(t, x, y)\nD2\nxyϕn(t, x, y)\nD2\nyϕn(t, x, y)\n\u0015\n=\n\u0014 nξ(x, y) + 2I\n−nξ(x, y)\n−nξ(x, y)\nnξ(x, y) + 2I\n\u0015\nwhere I is the identity-matrix of suitable dimension and\nξ(x, y) := ̺|x − y|2̺−4{|x − y|2I + 2(̺ − 1)(x − y)(x − y)⊤}.\nIn particular, since xn and yn are bounded, choosing ǫ := 1\nn gives that\n˜Bn := B(tn, xn, yn) + ǫB2(tn, xn, yn) ≤ Cn|xn − yn|2̺−2\n\u0014\nI\n−I\n−I\nI\n\u0015\n+ CI.\n(A.5)\nBy the deﬁnition of viscosity supersolutions and subsolutions we have that\n− pu\nn + κu(tn, xn) − a⊤(tn, xn)qu\nn − 1\n2Tr[σ⊤(tn, xn)Mu\nnσ(tn, xn)]\n− eκtn ˜f(tn, xn, e−κtnu(tn, xn), e−κtnσ⊤(tn, xn)qu\nn) ≤ 0\nand\n− pw\nn + κw(tn, yn) − a⊤(tn, yn)qw\nn − 1\n2Tr[σ⊤(tn, yn)Mw\nn σ(tn, yn)]\n− eκtn ˜f(tn, yn, e−κtnw(tn, yn), e−κtnσ⊤(tn, xn)qw\nn ) ≥ 0.\nCombined, this gives that\nκ(u(tn, xn) − w(tn, yn)) ≤ pu\nn + a⊤(tn, xn)qu\nn + 1\n2Tr[σ⊤(tn, xn)Mu\nnσ(tn, xn)]\n+ eκtn ˜f(tn, xn, e−κtnu(tn, xn), e−κtnσ⊤(tn, xn)qu\nn)\n− pw\nn − a⊤(tn, yn)qw\nn − 1\n2Tr[σ⊤(tn, yn)Mw\nn σ(tn, yn)]\n− eκtn ˜f(tn, yn, e−κtnw(tn, yn), e−κtnσ⊤(tn, xn)qw\nn )\nCollecting terms we have that\npu\nn − pw\nn = 2(tn − t∗)\nand since a is Lipschitz continuous in x and bounded on ¯BR, we have\na⊤(tn, xn)qu\nn − a⊤(tn, yn)qw\nn ≤ (a⊤(tn, xn) − a⊤(tn, yn))n̺(xn − yn)|xn − yn|2̺−2\n+ C(|xn − x∗| + |yn − x∗|)\n≤ C(n|xn − yn|2̺ + |xn − x∗| + |yn − x∗|),\nwhere the right-hand side tends to 0 as n → ∞. Let sx denote the ith column of σ(tn, xn) and let sy\ndenote the ith column of σ(tn, yn) then by the Lipschitz continuity of σ and (A.5), we have\ns⊤\nx Mu\nnsx − s⊤\ny Mw\nn sy =\n\u0002 s⊤\nx\ns⊤\ny\n\u0003 \u0014 Mu\nn\n0\n0\n−Mw\nn\n\u0015 \u0014 sx\nsy\n\u0015\n≤\n\u0002 s⊤\nx\ns⊤\ny\n\u0003 ˜Bn\n\u0014 sx\nsy\n\u0015\n≤ C(n|xn − yn|2̺ + |xn − yn|)\n23\nand we conclude that\nlim sup\nn→∞\n1\n2Tr[σ⊤(tn, xn)Mu\nnσ(tn, xn) − σ⊤(tn, yn)Mw\nn σ(tn, yn)] ≤ 0.\nFinally, we have that\neκtn ˜f(tn, xn, e−κtnu(tn, xn), e−κtnσ⊤(tn, xn)qu\nn) − eκtn ˜f(tn, yn, e−κtnw(tn, yn), e−κtnσ⊤(tn, xn)qw\nn )\n≤ kf(u(tn, xn) − w(tn, yn) + |σ⊤(tn, xn)qu\nn − σ⊤(tn, xn)qw\nn |)\n+ eκtn| ˜f(tn, xn, e−κtnu(tn, xn), e−κtnσ⊤(tn, xn)qu\nn) − ˜f(tn, yn, e−κtnu(tn, xn), e−κtnσ⊤(tn, xn)qu\nn)|\nRepeating the above argument and using that ˜f is jointly continuous in (t, x) uniformly in (y, z) we get\nthat the upper limit of the right-hand side when n → ∞ is bounded by kf(u(tn, xn) − w(tn, yn)). Put\ntogether, this gives that\n(κ − kf) lim sup\nn→∞ (u(tn, xn) − w(tn, yn)) ≤ 0\nand choosing κ > kf gives a contradition.\nReferences\n[1] E. Bandini, A. Cosso, M. Fuhrman, and H. Pham. Backward sdes for optimal control of partially\nobserved path-dependent stochastic systems: a control randomization approach. Ann. Appl. Probab.,\n28(3):1634–1678, 2018.\n[2] G. Barles. Solutions de viscosit´e des ´equations de Hamilton-Jacobi, volume 17 of Math´ematiques et\nApplications. Springer, Paris, 1994.\n[3] G. Barles, R. Buckdahn, and E. Pardoux. Backward stochastic diﬀerential equations and integral-\npartial diﬀerential equations. Stoch. Stoch. Rep., 60(1-2):57–83, 1997.\n[4] A. Bensoussan and J.L. Lions. Impulse Control and Quasivariational inequalities. Gauthier-Villars,\nMontrouge, France, 1984.\n[5] B. Bouchard.\nA stochastic target formulation for optimal switching problems inﬁnite horizon.\nStochastics, 81:171–197, 2009.\n[6] S. Choukroun, A. Cosso, and H. Pham. Reﬂected bsdes with nonpositive jumps, and controller-and-\nstopper games. Stochastic Process. Appl., 125:597–633, 2015.\n[7] M. G. Crandall, H. Ishii, and P. L. Lions. Users guide to viscosity solutions of second order partial\ndiﬀerential equations. Bulletin of the American Mathematical Society, 27(1):1–67, 1992.\n[8] R. Dumitrescu, M.-C. Quenez, and A. Sulem. Otimal stopping for dynamic risk measures with jumps\nand obstacle problems. J Optim Theory Appl, 167:219–242, 2015.\n[9] M. Fuhrman and M. Morlais. Optimal switching problems with an inﬁnite set of modes: An approach\nby randomization and constrained backward sdes. Stochastic Process. Appl., 130:5(5):3120–3153,\n2020.\n[10] M. Fuhrman and H. Pham. Randomized and backward sde representation for optimal control of\nnon-markovian sdes. Ann. Appl. Probab., 25(4):2134–2167, 2015.\n24\n[11] S. Hamad`ene, M. Mnif, and S. Neﬀati. Viscosity solution of system of integro-partial diﬀerential\nequations with interconnected obstacles of non-local type without monotonicity conditions. J Dyn\nDiﬀ Equat, 35(2):1151–1173, 2023.\n[12] S. Hamad`ene and M. A. Morlais. Viscosity solutions of systems of pdes with interconnected obstacles\nand switching problem. Appl Math Optim., 67:163–196, 2013.\n[13] S. Hamad`ene and M. A. Morlais. Viscosity solutions for second order integro-diﬀerential equations\nwithout monotonicity condition: the probabilistic approach. Stochastics: An International Journal\nof Probability and Stochastic Processes, 88(4):632–649, 2016.\n[14] I. Kharroubi, J. Ma, H. Pham, and J. Zhang. Backward sdes with constrained jumps and quasi-\nvariational inequalities. Ann. Probab., 38(2):794–840, 2010.\n[15] I. Kharroubi and H. Pham. Feynman-Kac representation for Hamilton-Jacobi-Bellman IPDE. Ann.\nProbab., 43(4):1823–1865, 2015.\n[16] B. Øksendal and A. Sulem. Applied Stochastic Control of Jump Diﬀusions. Springer, 2007.\n[17] M. Perninge. Sequential systems of reﬂected backward stochastic diﬀerential equations with appli-\ncation to impulse control. Appl Math Optim, 86(19), 2022.\n[18] M. Perninge.\nOptimal stopping of bsdes with constrained jumps and related zero-sum games.\narXiv:2308.16504, 2023.\n[19] M. Perninge. Probabilistic representation of viscosity solutions to quasi-variational inequalities with\nnon-local drivers. ESAIM Control Optim. Calc. Var., 25:1–28, 2023.\n[20] M. Perninge. Zero-sum stochastic diﬀerential games of impulse versuscontinuous control by fbsdes.\nJ. Math. Anal. Appl., 527, 2023.\n[21] M-C. Quenez and A. Sulem. Reﬂected bsdes and robust optimal stopping for dynamic risk measures\nwith jumps. Stochastic Process. Appl., 124:3031–3054, 2014.\n25\n"
}