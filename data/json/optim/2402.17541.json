{
    "optim": "arXiv:2402.17541v1  [math.PR]  27 Feb 2024 Optimal Stopping of BSDEs with Constrained Jumps and Related Double Obstacle PDEs Magnus Perninge∗ February 28, 2024 Abstract We consider partial diﬀerential equations (PDEs) characterized by an upper barrier that depends on the solution itself and a ﬁxed lower barrier, while accommodating a non-local driver. First, we show a Feynman-Kac representation for the PDE when the driver is local. Speciﬁcally, we relate the non-linear Snell envelope for an optimal stopping problem, where the underlying process is the ﬁrst component in the solution to a stopped backward stochastic diﬀerential equation (BSDE) with jumps and a constraint on the jumps process, to a viscosity solution for the PDE. Leveraging this Feynman-Kac representation, we subsequently prove existence and uniqueness of viscosity solutions in the non-local setting by employing a contraction argument. In addition, the contraction argument yields existence of a new type of non-linear Snell envelope and extends the theory of probabilistic representation for PDEs. 1 Introduction We consider partial diﬀerential equations (PDEs) of the type      min{v(t, x) − h(t, x), max{v(t, x) − Mv(t, x), −vt(t, x) − Lv(t, x) −f(t, x, v(t, ·), σ⊤(t, x)∇xv(t, x))}} = 0, ∀(t, x) ∈ [0, T) × Rd v(T, x) = ψ(x), (1.1) where for each (t, x, z) ∈ [0, T] × Rd × Rd, the map g 7→ f(t, x, g, z) : C(Rd → R) → R is a functional, Mv(t, x) := infe∈E{v(t, x + γ(t, x, e)) + χ(t, x, e)} and L := d X j=1 aj(t, x) ∂ ∂xj + 1 2 d X i,j=1 (σσ⊤(t, x))i,j ∂2 ∂xi∂xj (1.2) is the inﬁnitesimal generator related to the stochastic diﬀerential equation (SDE) ˇXs = x + Z s 0 a(r, ˇXr)dr + Z s 0 σ(r, ˇ Xr)dWr. We establish existence and uniqueness (within the set of continuous functions of polynomial growth) of viscosity solutions to the above PDE by relating v(t, x) to Y t,x t , where Y t,x s = ess sup τ∈Ts Y t,x,τ s (1.3) ∗M. Perninge is with the Department of Physics and Electrical Engineering, Linnaeus University, V¨axj¨o, Sweden. e-mail: magnus.perninge@lnu.se. 1 and for each stopping time τ ≥ t, the process the Y t,x,τ is the ﬁrst component in the quadruple of processes (Y t,x,τ, Zt,x,τ, V t,x,τ, Kt,x,τ) that is the unique maximal solution to the backward stochastic diﬀerential equation (BSDE), driven by the above mentioned Brownian motion and an independent Poisson random measure µ with intensity λ, that has a constraint on the jump component      Y t,x,τ s = Ψ(τ, Xt,x τ ) + R τ s f(r, Xt,x r , ¯Y (r, ·), Zt,x,τ r )dr − R τ s Zt,x,τ r dWr − R τ s R E V t,x,τ r (e)µ(dr, de) −(K−,t,x,τ τ − K−,t,x,τ s ), ∀s ∈ [t, τ], V t,x,τ s (e) ≥ −χ(s, Xt,x s−, e), dP ⊗ ds ⊗ λ(de) − a.e. (1.4) Here, Ψ(t, x) := 1[t<T]h(t, x) + 1[t=T]ψ(t, x), the process Xt,x is the unique solution to the forward SDE Xt,x s = x + Z s t a(r, Xt,x r )dr + Z s t σ(r, Xt,x r )dWr + Z s t Z E γ(r, Xt,x r−, e)µ(dr, de) (1.5) and the driver at time t ∈ [0, T] depends on the solution to the optimal stopping problem through the map (t, x) 7→ ¯Y (t, x) := Y t,x t . Our contribution is twofold in the sense that our approach implicitly provides existence of a unique solution to the optimal stopping problem (1.3)-(1.5). Related literature Partial diﬀerential equations featuring non-local drivers, wherein the mapping g 7→ f(t, x, g, z) adopts the structure of an integral, are commonly referred to as integro-partial diﬀerential equations (IPDEs). A branch of the literature that relates BSDEs with jumps to IPDEs have focused on the setting where the driver takes the form f(t, x, g, z) = ¯f(t, x, g(x), z, Z E θ(t, x, e)(g(x + ζ(t, x, e)) − g(x))λ(de)), for a Lipschitz function ¯f. In particular, [3] and [8] both assume that ¯f is non-decreasing in the last variable and that θ ≥ 0, the former considering the relation between regular BSDEs with jumps and IPDEs whereas the latter prove a relation between the reﬂected BSDEs with jumps considered in [21] and IPDEs with one-sided obstacles. These results where later extended in [13] to the setting when ¯f is a general Lipschitz function and ζ may be negative. We also mention the work in [11], where a system of IPDEs with interconnected obstacles are treated. When the lower barrier h is absent, the PDE described in (1.1) is termed a quasi-variational inequality (QVI). It is well known that, under suitable conditions on the involved parameters, value functions to impulse control problems are solutions (in viscosity sense) to standard QVIs when the driving noise process is a Brownian motion (see the seminal work in [4]) and to so called quasi-integrovariational inequalities when the driving noise is a general L´evy process [16]. Employing a contraction argument akin to the one delineated in the present study, quasi-variational inequalities (QVIs) featuring general non-local drivers were investigated in [19]. Speciﬁcally, [19] establishes a Feynman-Kac representation of such QVIs by linking their solutions to systems of reﬂected BSDEs (RBSDEs). An alternative Feynman-Kac representation for solutions to standard QVIs was proposed in [14] (see also [5]), where the solution to a QVI is related to the minimal solution of a BSDE with constrained jumps. In particular, their result implies that (when f is local) the deterministic function v deﬁned through the relation v(t, x) := Y t,x,T t , with Y t,x,T as in (1.4), is the unique viscosity solution to the PDE obtained by setting h ≡ −∞ in (1.1). Following the seminal work in [14], BSDEs with positive jumps were related to fully non-linear Hamilton-Jacobi-Bellman integro-partial diﬀerential equations (HJB-IPDEs) through a Feynman-Kac representation in [15] while a correspondence between RBSDEs with positive jumps and fully non-linear variational inequalities was established in [6]. The ensemble of approaches to ﬁnd probabilistic representations of PDEs or solve stochastic optimal control problems that utilize BSDEs with constrained jumps is commonly referred to as control random- ization. A signiﬁcant breakthrough in this ﬁeld was achieved with the seminal work of [10], which directly 2 linked the value function of the randomized control problem to that of the original control problem. This eliminated the need for a Feynman-Kac representation, thereby expanding the theoretical framework to encompass stochastic systems with path-dependencies. Building upon this foundation, subsequent ad- vancements extended their approach to the framework of partial information settings in [1] and optimal switching problems in [9]. Recently, [18] further extended the scope of control randomization to zero- sum games by (within a non-markovian framework) relating the solution to the above optimal stopping problem (1.3)-(1.5) to the upper and lower value functions in a stochastic diﬀerential game between an impulse controller and a stopper. Notable is that [18] presumes that f only depends on local values of Y , whereas it may depend on V . An intermediate result in the present work addresses the framework of a local driver and bridges a gap left in [18]. Speciﬁcally, we establish a connection between the non-linear Snell envelope examined in [18] and viscosity solutions to (1.1). Consequently, we elucidate that, in the Markovian framework, the value function of the aforementioned zero-sum game indeed constitutes the unique viscosity solution to (1.1). Moreover, our primary ﬁndings extend those of [18] in the Markovian framework by proving the existence of the more general non-linear Snell envelope deﬁned through equations (1.3)-(1.5). Outline The remainder of the article is organised as follows. In the next section we set the notations and state the assumptions that hold throughout. In addition, we give some preliminary results that are repeatedly referred in the article. Then, in Section 3 we turn to the local setting before we, in the following section, derive the complete result. Uniqueness of solutions to (1.1) when the driver f is local appears rudimentary and resembles earlier results deduced in, for example, [12]. However, since our setting is fundamentally diﬀerent and for the sake of completeness, a uniqueness proof through viscosity comparison is included as an appendix. 2 Preliminaries 2.1 Notation We let (Ω, F, P) be a complete probability space on which lives a d-dimensional Brownian motion W and an independent Poisson random measure µ deﬁned on [0, T]×E with intensity λ(de). Here, it is assumed that E is a Borelian subset of Rd endowed with its Borel σ-ﬁeld B(E). We denote by F := (Ft)0≤t≤T the augmented natural ﬁltration generated by W and µ and for t ∈ [0, T] we let Ft := (Ft s)t≤s≤T (resp. FW,t := (FW,t s )t≤s≤T ) denote the augmented natural ﬁltration generated by (Ws − Wt : t ≤ s ≤ T) and µ(· ∩ [t, T], ·) (resp. (Ws − Wt, t ≤ s ≤ T)). Throughout, we will use the following notation, where d ≥ 1 is the dimension of the state-space: • We let Πg denote the set of all functions ϕ : [0, T] × Rd → R that are of polynomial growth in x, i.e. there are constants C, ρ > 0 such that |ϕ(t, x)| ≤ C(1 + |x|ρ) for all (t, x) ∈ [0, T] × Rd, and let Πg c be the subset of jointly continuous functions. • For each t ∈ [0, T], Pt is the σ-algebra of Ft-predictably measurable subsets of [t, T]×Ω and P := P0. • We let T be the set of all [0, T]-valued F-stopping times and for each η ∈ T , we let Tη be the subset of stopping times τ such that τ ≥ η, P-a.s. Moreover, we let T t (resp. T t η ) be the corresponding subsets of Ft-stopping times, with τ ≥ t (resp. τ ≥ η), P-a.s. • For p ≥ 1, t ∈ [0, T] and τ ∈ T t, we let Sp [t,τ] be the set of all R-valued, Ft-progressively measurable, c`adl`ag processes (Zs : s ∈ [t, τ]) for which ∥Z∥Sp [t,τ] := E \u0002 sups∈[t,τ] |Zs|p\u0003 < ∞. Moreover, we let Sp [t,τ],i be the subset of Ft-predictably measurable and non-decreasing processes with Zt = 0. Whenever τ = T we use the notations Sp t and Sp t,i, respectively. 3 • We let Hp [t,τ](W) denote the set of all Rd-valued Ft-progressively measurable processes (Zs : s ∈ [t, τ]) such that ∥Z∥Hp [t,τ](W ) := E \u0002\u0000 R τ t |Zs|2ds \u0001p/2\u00031/p < ∞. Furthermore, we set Hp t (W) := Hp [t,T](W). • We let Hp [t,τ](µ) denote the set of all R-valued, Pt ⊗B(E)-measurable maps (Zs(e) : s ∈ [t, τ], e ∈ E) such that ∥Z∥Hp [t,τ](µ) := E \u0002\u0000 R τ t R E |Zs(e)|2λ(de)ds \u0001p/2\u00031/p < ∞ and set Hp t (µ) = Hp [t,T](µ). • For t ∈ [0, T], we let At denote the set of all [−1, 1]d-valued, Ft-progressively measurable processes (αs : t ≤ s ≤ T) and set A := A0. Moreover, we let AW t be the subset of FW,t-progressively measurable processes (resp. AW := AW 0 ). • For t ∈ [0, T], we deﬁne the composition ⊕t of α1 ∈ A and α2 ∈ At as (α1 ⊕t α2)s := 1[0,t)(s)α1 s + 1[t,T](s)α2 s. • We let Vt denote the set of all Pt ⊗ B(E)-measurable, bounded maps ν : [t, T] × Ω × E → [0, ∞) and for each n ∈ N, we denote by Vn t the subset of maps ν : [t, T] × Ω × E → [0, n]. We also mention that, unless otherwise speciﬁed, all inequalities between random variables are to be interpreted in the P-a.s. sense. 2.2 Assumptions We make the following assumption on the intensity λ of the process µ. Assumption 2.1. We assume that λ has full topological support on E and ﬁnite intensity, i.e. λ(E) < ∞. Throughout, we make the following assumptions on the parameters, where ρ > 0 is a ﬁxed constant: Assumption 2.2. i) We assume that f : [0, T]×Rd ×C(Rd → R)×Rd → R ((t, x, g, z) → f(t, x, g, z)) is such that for any v ∈ Πg c, the map (t, x) 7→ f(t, x, v(t, ·), z) is jointly continuous, uniformly in z, f is of polynomial growth in x, i.e. there is a Cf > 0 such that |f(t, x, 0, 0)| ≤ Cf(1 + |x|ρ) and that there are constants kf, KΓ > 0 such that for any t ∈ [0, T], x ∈ Rd, g, ˜g ∈ C(Rd → R) and z, ˜z ∈ Rd we have |f(t, x, ˜g, ˜z) − f(t, x, g, z)| ≤ kf( sup x′∈Λf (|x|) |˜g(x′) − g(x′)| + |˜z − z|), where for each α ∈ R+, Λf(α) := {x ∈ Rd : ∥x∥ ≤ α∨KΓ} is the closed ball of radius α∨KΓ centered at the origin. ii) The lower barrier h : [0, T] × Rd → R is jointly continuous and of polynomial growth in x, i.e. there is a Ch > 0 such that |h(t, x)| ≤ Ch(1 + |x|ρ). iii) The terminal reward ψ : Rd → R is continuous and satisﬁes the growth condition |ψ(x)| ≤ Cψ(1 + |x|ρ) for some Cψ > 0. 4 iv) The jump-barrier χ : [0, T] × Rd × E → R+ is jointly continuous, of polynomial growth and bounded from below, i.e. χ(t, x, e) ≥ δ > 0, v) For each (x, e) ∈ Rd × E we have h(T, x) ≤ ψ(x) ≤ ψ(x + γ(T, x, e)) + χ(T, x, e) Moreover, we make the following assumptions on the coeﬃcients of the forward SDE: Assumption 2.3. For any t, t′ ∈ [0, T], e ∈ E and x, x′ ∈ Rd we have: i) The function γ : [0, T] × Rd × E → Rd is jointly continuous and satisﬁes the growth condition |x + γ(t, x, e)| ≤ KΓ ∨ |x| (2.1) Moreover, it is Lipschitz continuous in x uniformly in (t, e), i.e. |γ(t, x′, e) − γ(t, x, e)| ≤ kγ|x′ − x| for all (t, x, x′, e) ∈ [0, T] × Rd × Rd × E. ii) The coeﬃcients a : [0, T] × Rd → Rn and σ : [0, T] × Rd → Rn×d are jointly continuous and satisfy the growth conditions |a(t, x)| + |σ(t, x)| ≤ Ca,σ(1 + |x|), for some Ca,σ > 0 and the Lipschitz continuity |a(t, x) − a(t, x′)| + |σ(t, x) − σ(t, x′)| ≤ ka,σ|x′ − x|, for some ka,σ > 0. 2.3 Viscosity solutions We deﬁne the upper, v∗, and lower, v∗ semi-continuous envelope of a function v : [0, T] × Rd → R as v∗(t, x) := lim sup (t′,x′)→(t,x), t′<T v(t′, x′) and v∗(t, x) := lim inf (t′,x′)→(t,x), t′<T v(t′, x′). Next, we introduce the limiting parabolic superjet ¯J+v and subjet ¯J−v. Deﬁnition 2.4. Subjets and superjets i) For a l.s.c. (resp. u.s.c.) function v : [0, T] × Rn → R, the parabolic subjet, denote by J−v(t, x), (resp. the parabolic superjet, J+v(t, x)) of v at (t, x) ∈ [0, T] × Rn, is deﬁned as the set of triples (p, q, M) ∈ R × Rn × Sn satisfying v(t′, x′) ≥ (resp. ≤) v(t, x) + p(t′ − t)+ < q, x′ − x > + 1 2 < x′ − x, M(x′ − x) > +o(|t′ − t| + |x′ − x|2) for all (t′, x′) ∈ [0, T] × Rn, where Sn is the set of symmetric real matrices of dimension n × n. 5 ii) For a l.s.c. (resp. u.s.c.) function v : [0, T] × Rn → R we denote by ¯J−v(t, x) the parabolic limiting subjet (resp. ¯J+v(t, x) the parabolic limiting superjet) of v at (t, x) ∈ [0, T] × Rn, deﬁned as the set of triples (p, q, M) ∈ R × Rn × Sn such that: (p, q, M) = lim n→∞(pn, qn, Mn), (t, x) = lim n→∞(tn, xn) for some sequence (tn, xn, pn, qn, Mn)n≥1 with (pn, qn, Mn) ∈ J−v(tn, xn) (resp. (pn, qn, Mn) ∈ J+v(tn, xn)) for all n ≥ 1 and v(t, x) = limn→∞ v(tn, xn). We now give the deﬁnition of a viscosity solution for the QVI in (1.1). (see also pp. 9-10 of [7]). Deﬁnition 2.5. Let v be a locally bounded function from [0, T] × Rd to R. Then, a) It is referred to as a viscosity supersolution (resp. subsolution) to (1.1) if it is l.s.c. (resp. u.s.c.) and satisﬁes: i) v(T, x) ≥ ψ(x) (resp. v(T, x) ≤ ψ(x)) ii) For any (t, x) ∈ [0, T) × Rd and (p, q, X) ∈ ¯J−v(t, x) (resp. ¯J+v(t, x)) we have min \b v(t, x) − h(t, x), max{v(t, x) − Mv(t, x), −p − q⊤a(t, x) − 1 2Tr(σσ⊤(t, x)X) − f(t, x, v(t, ·), σ⊤(t, x)q)} \t ≥ 0 (resp. ≤ 0) b) It is called a viscosity solution to (1.1) if v∗ is a supersolution and v∗ is a subsolution. We will sometimes use the following alternative deﬁnition of viscosity supersolutions (resp. subsolu- tions): Deﬁnition 2.6. A l.s.c. (resp. u.s.c.) function v is a viscosity supersolution (resp. subsolution) to (1.1) if v(T, x) ≤ ψ(x) (resp. ≥ ψ(x)) and whenever ϕ ∈ C1,2([0, T] × Rd → R) is such that ϕ(t, x) = v(t, x) and ϕ − v has a local maximum (resp. minimum) at (t, x), then min \b v(t, x) − h(t, x), max{v(t, x) − Mv(t, x), −ϕt(t, x) − Lϕ(t, x) − f(t, x, v(t, ·), σ⊤(t, x)∇xϕ(t, x))} \t ≥ 0 (resp. ≤ 0). 2.4 Reﬂected BSDEs with jumps and obstacle problems We introduce the local driver ˜f that satisﬁes the following assumption: Assumption 2.7. i) The driver ˜f : [0, T] × Rd × R × Rd → R is jointly continuous and of polynomial growth in x, i.e. | ˜f(t, x, 0, 0)| ≤ C(1 + |x|ρ). Moreover, (t, x) 7→ ˜f(t, x, y, z) is continuous, uniformly in (y, z), and (y, z) 7→ ˜f(t, x, y, z) is Lipschitz continuous, uniformly in (t, x). We give the following proposition, strategically formulated to streamline subsequent implementation processes. It is worth noting that comparable ﬁndings are documented in [8, 13], with the latter being the most closely aligned with our own. Proposition 2.8. For each (t, x) ∈ [0, T]×Rd and n ∈ N, there is a unique quadruple (Y t,x, Zt,x, V t,x, K+,t,x) ∈ S2 t × H2 t (W) × H2 t (µ) × S2 t,i such that      Y t,x s = ψ(Xt,x T ) + R T s ˜f n(r, Xt,x r , Y t,x r , Zt,x r , V t,x r )dr − R T s Zt,x r dWr − R T s R E V t,x r (e)µ(dr, de) +(K+,t,x T − K+,t,x s ), ∀s ∈ [t, T], Y t,x s ≥ h(s, Xt,x s ), ∀s ∈ [t, T] and R T t \u0000Y t,x s − h(s, Xt,x s ) \u0001 dK+,t,x s , (2.2) 6 where ˜f n(t, x, y, z, v) := ˜f(t, x, y, z) − n Z E (v(e) + χ(t, x, e))−λ(de). Moreover, Y t,x s = ess supτ∈T t s Y t,x;τ s , where for each τ ∈ T t, the triple (Y t,x;τ, Zt,x;τ, V t,x;τ) ∈ S2 [t,τ] × H2 [t,τ](W) × H2 [t,τ](µ) satisﬁes Y t,x;τ s = Ψ(τ, Xt,x τ ) + Z τ s ˜f n(r, Xt,x r , Y t,x;τ r , Zt,x;τ r , V t,x;τ r )dr − Z τ s Zt,x;τ r dWr − Z τ s Z E V t,x;τ r (e)µ(dr, de) (2.3) and for each η ∈ T t, the stopping time τ ∗ := inf{s ≥ η : Y t,x s = h(r, Xt,x s )} ∧ T is optimal in the sense that Y t,x η = Y t,x;τ ∗ η . Finally, there is a function vn ∈ Πg c such that vn(s, Xt,x s ) = Y t,x s for all s ∈ [t, T] and vn is the unique viscosity solution in Πg c to      min{vn(t, x) − h(t, x), − ∂ ∂tvn(t, x) − Lvn(t, x) + Knvn(t, x) − ˜f(t, x, vn(t, x), σ⊤(t, x)∇xvn(t, x))} = 0, ∀(t, x) ∈ [0, T) × Rd vn(T, x) = ψ(x), (2.4) where Knφ(t, x) := n R E(φ(t, x + γ(t, x, e)) + χ(t, x, e) − φ(t, x))−λ(de). Proof. As the parameters of the reﬂected BSDE (2.2) satisfy the conditions for the comparison result of [21], everything but the viscosity solution property follows by results presented therein. Existence of a unique viscosity solution in Πg c to (2.4) can be shown as a special case of the method described in [19]. We can now argue as in [13] and let v ∈ Πg c be deﬁned as v(t, x) := Y t,x t . Then, it can be shown (see Proposition 3.1 in [13]) that V t,x s (e) = v(s, Xt,x s +γ(s, Xt,x s , e))−v(s, Xt,x s ), dP⊗ds⊗λ(de)-a.e. Moreover, the BSDE      ˜Y t,x s = ψ(Xt,x T ) + R T s ˜f n(r, Xt,x r , ˜Y t,x r , ˜Zt,x r , v(r, Xt,x r + γ(r, Xt,x r , ·)) − v(r, Xt,x r ))dr − R T s ˜Zt,x r dWr − R T s R E ˜V t,x r (e)µ(dr, de) + ( ˜K+,t,x T − ˜K+,t,x s ), ∀s ∈ [t, T], ˜Y t,x s ≥ h(s, Xt,x s ), ∀s ∈ [t, T] and R T t \u0000 ˜Y t,x s − h(s, Xt,x s ) \u0001 dK+,t,x s , (2.5) admits a unique solution and ˜v(t, x) := ˜Y t,x t belongs to Πg c and is the unique viscosity solution to      min{˜v(t, x) − h(t, x), −˜vt(t, x) − L˜v(t, x) − Knv(t, x) − ˜f(t, x, ˜v(t, x), σ⊤(t, x)∇x˜v(t, x))} = 0, ∀(t, x) ∈ [0, T) × Rd ˜v(T, x) = ψ(x). On the other hand, (Y t,x, Zt,x, V t,x, K+,t,x) is the unique solution to (2.5) and we conclude that ˜v = v is the unique solution to (2.4). To emphasize the dependence of the solution to (2.2) on the parameter n, we will henceforth employ the notation (Y t,x,n, Zt,x,n, V t,x,n, K+,t,x,n) for these quadruples. 7 2.5 Preliminary estimates For ν ∈ Vt we let Eν be expectation with respect to the probability measure Pν on (Ω, F) deﬁned by dPν := κν T dP with κν s := Es \u0010 Z · t Z E (νr(e) − 1)(µ(dr, de) − λ(de))dr \u0011 := exp \u0010 Z s t Z E (1 − νr(e))λ(de)dr \u0011 Y t<ηj≤s νηj(βj), where the sequence (ηj, βj)j≥1 is the one that appears in the Dirac decomposition µ = P j≥1 δ(ηj,βj). Lemma 2.9. Under Assumption 2.3, the SDE (1.5) admits a unique solution for each (t, x) ∈ [0, T]×Rd. Furthermore, the solution has moments of all orders, in particular, for each p ≥ 0, there is a constant C > 0 such that Eνh sup s∈[ζ,T] |Xt,x s |p\f\f\fFt ζ i ≤ C(1 + |Xt,x ζ |p), (2.6) P-a.s. for all (t, x) ∈ [0, T] × Rn, ν ∈ Vt and ζ ∈ [t, T]. Proof. The proof is rather elementary and follows a similar structure to the proof of Proposition 4.2 in [17] (albeit the latter is conﬁned to a Brownian ﬁltration). It is provided in its entirety since some of its intermediate results are utilized later on. For each j ∈ N, we let Xj be the unique solution to the SDE Xj s = x + Z s t a(r, Xj r)dr + Z s t σ(r, Xj r )dWr + Z s t Z E 1[µ((0,r),E)<j]γ(s, Xj s−, e)µ(dr, de), ∀s ∈ [t, T], and note that Xj → Xt,x, P-a.s., since µ has ﬁnite intensity. By Assumption 2.3.(i) we get for s ∈ [ηj, T], using integration by parts, that |Xj s|2 = |Xj ζ∨ηj|2 + 2 Z s (ζ∨ηj)+ Xj rdXj r + Z s (ζ∨ηj)+ d[Xj, Xj]r ≤ K2 Γ ∨ |Xj−1 ζ∨ηj|2 + 2 Z s (ζ∨ηj)+ Xj rdXj r + Z s (ζ∨ηj)+ d[Xj, Xj]r. Now, either |Xj−1 ηj | ≤ KΓ in which case |Xj s|2 ≤ |Xj ζ|2 ∨ K2 Γ + 2 Z s (ζ∨ηj)+ Xj rdXj r + Z s (ζ∨ηj)+ d[Xj, Xj]r. or |Xj−1 ηj | > KΓ implying that |Xj s|2 ≤ K2 Γ ∨ |Xj−2 ζ∨ηj−1|2 + 2 Z ηj (ζ∨ηj−1)+ Xj−1 r dXj−1 r + Z ηj (ζ∨ηj−1)+ d[Xj−1, Xj−1]r + 2 Z s (ζ∨ηj)+ Xj rdXj r + Z s (ζ∨ηj)+ d[Xj, Xj]r. In the latter case the same argument can be repeated and we conclude that |Xj s|2 ≤ |Xj ζ|2 ∨ K2 Γ + j X i=j0 n 2 Z s∧˜ηi+1 (ζ∨˜ηi)+ Xi rdXi r + Z s∧˜ηi+1 (ζ∨˜ηi)+ d[Xi, Xi]r o , (2.7) 8 where ˜η0 = −1, ˜ηi = ηi for i = 1, . . . , j and ˜ηj+1 = ∞ and j0 := max{i ∈ {1, . . . , j} : |Xi−1 ηi | ≤ KΓ} ∨ 0. Now, since Xi and Xj coincide on [0, ηi+1∧j+1) we have j X i=j0 Z s∧˜ηi+1 (ζ∨˜ηi)+ Xi rdXi r = Z s ζ∨ηj0 Xj ra(r, Xj r)dr + Z s ζ∨ηj0 Xj rσ(r, Xj r)dWr, and j X i=j0 Z s∧˜ηi+1 (ζ∨˜ηi)+ d[Xi, Xi]r = Z s ζ∨ηj0 σ2(r, Xj r)dr. Inserted in (2.7) this gives that |Xj s|2 ≤ |Xj ζ|2 ∨ K2 Γ + Z s ηj0 (2Xj sa(r, Xj r) + σ2(r, Xj r))dr + 2 Z s ηj0 Xj rσ(r, Xj r)dWr ≤ |Xj ζ|2 + C \u0010 1 + Z s ζ |Xj r|2dr + sup η∈[ζ,s] \f\f\f Z η ζ Xj rσ(r, Xj r )dWr \f\f\f \u0011 (2.8) for all s ∈ [ζ, T]. The Burkholder-Davis-Gundy inequality and the fact that the right-hand side of (2.8) does not depend on µ now gives that for any ν ∈ Vt and p ≥ 2, Eνh sup r∈[ζ,s] |Xj r|p\f\f\fFt ζ i ≤ |Xj ζ|2 + C \u00001 + Eνh Z s ζ |Xj r|pdr + \u0000 Z s ζ |Xj r|4dr \u0001p/4\f\f\fFt ζ i\u0001 . We can thus apply Gr¨onwall’s lemma to conclude that for p ≥ 4, Eνh sup s∈[ζ,T] |Xj s|p\f\f\fFt ζ i ≤ C(1 + |Xj ζ|p), P-a.s., where the constant C = C(T, p) does not depend on ν and j and (2.6) follows by letting j → ∞ on both sides and using Fatou’s lemma. The result for general p ≥ 0 is then a simple consequence of Jensen’s inequality. Lemma 2.10. There is a C > 0 such that |Y t,x,n s | ≤ C(1 + |Xt,x s |q) (2.9) for all (t, x) ∈ [0, T] × Rd and s ∈ [t, T]. Proof. We have h(s, Xt,x s ) ≤ Y t,x,n s ≤ Y t,x,0 s (2.10) and the assertion follows by the polynomial growth assumptions on h and the fact that v0 ∈ Πg c (see Proposition 2.8). We also make use of the following lemma which is given without proof as it follows immediately from the deﬁnitions: Lemma 2.11. Let u, v : [0, T]×Rn → R be locally bounded functions. M is monotone (if u ≤ v pointwise, then Mu ≤ Mv). Moreover, M(u∗) (resp. M(u∗)) is l.s.c. (resp. u.s.c.). In particular, it follows that Mv is jointly continuous whenever v is. 9 3 The local setting Our approach to obtain existence of a unique viscosity solution to (1.1) goes through a ﬁxed point argument. Before we are ready to proceed with this argument we need to solve the problem in the case where the driver f is a local function. In this regard, we consider the PDE      min{v(t, x) − h(t, x), max{v(t, x) − Mv(t, x), −vt(t, x) − Lv(t, x) − ˜f(t, x, v(t, x), σ⊤(t, x)∇xv(t, x))}} = 0, ∀(t, x) ∈ [0, T) × Rd v(T, x) = ψ(x), (3.1) where ˜f satisﬁes Assumption 2.7. The arguments utilized in this section are based on penalization and use the unique viscosity solution, vn, to (2.4). By a comparison result for solutions to RBSDEs with jumps (see e.g. Theorem 4.1 in [21]), we ﬁnd that (vn)n∈N is a non-increasing sequence in Πg c and by Lemma 2.10 this sequence is bounded from below in the sense that there is a constant C > 0 such that vn(t, x) ≥ −C(1+|x|ρ) for all (t, x) ∈ [0, T]×Rd and n ∈ N. It then immediately follows that there is an upper semi-continuous function v ∈ Πg such that vn ց v, pointwisely. We prove that v is the unique viscosity solution to (3.1) within the set of functions of polynomial growth. We ﬁrst show that v satisﬁes the requirements for a viscosity solution at time T. Lemma 3.1. For each x ∈ Rd it holds that v∗(T, x) ≤ ψ(x) and v∗(T, x) ≥ ψ(x). Proof. First note that v∗(T, x) ≤ lim (t′,x′)→(T,x) v0(t′, x′) = ψ(x) by continuity of v0, proving the ﬁrst inequality. We turn to the second one which requires more work. In search for a contradiction, we assume that there is an x′ 0 ∈ Rd such that v∗(T, x′ 0) < ψ(x′ 0). The proof is based on the following observation: a) If v∗(T, x′ 0) < ψ(x′ 0) for some x′ 0 ∈ Rd, then there is a (possible diﬀerent) point x0 ∈ Rd such that v∗(T, x0) < ψ(x0) ∧ Mv∗(T, x0). To see this, we note that if a) does not hold, then by lower semi-continuity, there is an e′ 0 ∈ E such that v∗(T, x′ 0) ≥ Mv∗(T, x′ 0) = v∗(T, x′ 1) + χ(T, x′ 0, e′ 0), with x′ 1 := x′ 0 + γ(T, x′ 0, e′ 0). Now, by assumption ψ(x′ 0) ≤ ψ(x′ 1) + χ(T, x′ 0, e′ 0) and we ﬁnd that v∗(T, x′ 1) − ψ(x′ 1) ≤ v∗(T, x′ 0) − χ(T, x′ 0, e′ 0) − ψ(x′ 1) ≤ v∗(T, x′ 0) − χ(T, x′ 0, e′ 0) − (ψ(x′ 0) − χ(T, x′ 0, e′ 0)) < 0 Hence, if a) does not hold, then we must have v∗(T, x′ 1) ≥ Mv∗(T, x′ 1). We can repeat this argument indeﬁnitely to ﬁnd that, if a) does not hold, then there is a sequence (x′ j, e′ j)∞ j=1 in Rd × E such that x′ j+1 = x′ j +γ(T, x′ j, e′ j) and v∗(T, x′ j) ≥ v∗(T, x′ j+1)+χ(T, x′ j, e′ j) for all j ∈ N. We conclude that for each k it holds that v∗(T, x′ 0) ≥ v∗(T, x′ k) + k−1 X j=0 χ(T, x′ j, e′ j) ≥ h(T, x′ k) + kδ, 10 a contradiction since h is of uniformly bounded from below on [0, T] × Λf(|x′ 0|) and v∗(T, x′ 0) ≤ v0(T, x′ 0). We thus assume that there is a point x0 and an ε > 0 such that v∗(T, x0) ≤ ψ(x0) ∧ Mv∗(T, x0) − 3ε. (3.2) There is a sequence (tj, xj, nj) in [0, T) × Rd × N such that (tj, xj) → (T, x0) and vnj(tj, xj) → v∗(T, x0). In particular, if (3.2) holds, then there is a j0 such that vnj(tj, xj) ≤ ψ(x0) ∧ Mv∗(T, x0) − 2ε whenever j ≥ j0. On the other hand, continuity of ψ and lower semi-continuity of Mv∗ then implies that there is a δ′ > 0 such that vnj(tj, xj) ≤ ψ(x) ∧ Mv∗(t, x) − ε ≤ ψ(x) ∧ Mvnj(t, x) − ε whenever j ≥ j0 and (t, x) ∈ Bδ′(T, x0) ∩ [0, T] × Rd (where Bδ′(T, x0) is the open ball in Rd+1 of radius δ′ centered at (T, x0)). We introduce the stopping times θj := inf{s ≥ tj : vnj(s, Xtj,xj s ) ≥ ψ(Xtj,xj s ) ∧ Mvnj(s, Xtj,xj s )} and ϑj := inf{s ≥ tj : (s, Xtj,xj s ) /∈ Bδ′(T, x0) or µ((tj, s], E) ≥ 1}. A standard dynamic programming result now gives that vnj(tj, xj) = vnj(θj ∧ ϑj, Xtj,xj θj∧ϑj) + Z θj∧ϑj tj ˜f nj(r, Xtj,xj r , Y tj,xj,nj r , Ztj,xj,nj r , V tj,xj,nj r )dr − Z θj∧ϑj tj Ztj,xj,nj r dWr − Z θj∧ϑj tj Z E V tj,xj,nj r (e)µ(dr, de) + K−,tj,xj,nj θj∧ϑj − K−,tj,xj,nj tj . Since V tj,xj,nj r (e) = vn(s, Xtj,xj s + γ(s, Xtj,xj s , e)) − vn(s, Xtj,xj s ), dP ⊗ ds ⊗ λ(de)-a.e. (see Proposition 3.1 in [13]) we get that, Z θj tj Z E \u0000V tj,xj,nj r (e) + χ(r, Xtj,xj r , e) \u0001−λ(de) = Z θj tj Z E \u0000vn(s, Xtj,xj s + γ(s, Xtj,xj s , e)) + χ(r, Xtj,xj r , e) − vn(s, Xtj,xj s ) \u0001−λ(de) = 0. Consequently, Z θj∧ϑj tj ˜f nj(r, Xtj,xj r , Y tj,xj,nj r , Ztj,xj,nj r , V tj,xj,nj r )dr = Z θj∧ϑj tj ˜f(r, Xtj,xj r , Y tj,xj,nj r , Ztj,xj,nj r )dr and we conclude that vnj(tj, xj) = vnj(θj ∧ ϑj, Xtj,xj θj∧ϑj) + Z θj∧ϑj tj ˜f(r, Xtj,xj r , Y tj,xj,nj r , Ztj,xj,nj r )dr − Z θj∧ϑj tj Ztj,xj,nj r dWr − Z θj∧ϑj tj Z E V tj,xj,nj r (e)µ(dr, de) + K−,tj,xj,nj θj∧ϑj − K−,tj,xj,nj tj . 11 Standard arguments now give that there is a C > 0 such that ∥Y tj,xj,nj∥S2 t,θj ∧ϑj + ∥Ztj,xj,nj∥H2 t,θj ∧ϑj (W ) + ∥V tj,xj,nj∥H2 t,θj ∧ϑj (µ) ≤ C(1 + |xj|ρ) for all j ∈ N, and we ﬁnd that vnj(tj, xj) ≥ −C(T − tj)1/2(1 + |xj|ρ) + E \u0002 1[θj<ϑj]vn(θj, Xtj,x0 θj ) \u0003 − CE \u0002 1[θj≥ϑj] \u00031/2(1 + |xj|ρ), where the constant C > 0 can be chosen independent of j. Now, since vnj(T, x) = ψ(x), we have θj ≤ T, P-a.s. and on the subset of Ω where [θj < ϑj] we have vnj(θj, Xtj,x0 θj ) − vnj(tj, xj) ≥ ε. We thus conclude that εP[θj < ϑj] ≤ C(T − tj)1/2(1 + |xj|ρ) + CE \u0002 1[θj≥ϑj] \u00031/2(1 + |xj|ρ), whenever j ≥ j0. On the other hand, P[θj ≥ ϑj] → 0 as j → ∞ and sending j → ∞ gives the sought contradition. Theorem 3.2. The function v is continuous and thus belongs to Πg c. Moreover, it is the unique viscosity solution to (3.1) in Πg. Proof. We prove that v is a viscosity solution to (1.1), then continuity and uniqueness will follow from the comparison principle stated in Proposition A.4 of Appendix A. By continuity of vn, we have (see e.g. [2], p. 91), v∗(t, x) = lim inf n→∞ ∗vn(t, x) := lim inf (n,t′,x′)→(∞,t,x) vn(t′, x′), v(t, x) = v∗(t, x) = lim sup n→∞ ∗vn(t, x) := lim sup (n,t′,x′)→(∞,t,x) vn(t′, x′). Subsolution-property. We ﬁrst show that v = v∗ is a viscosity subsolution. For (t, x) ∈ [0, T) × Rd and (p, q, M) ∈ ¯J+v(t, x) there is (by Lemma 6.1 in [7]) a sequence (tj, xj) ∈ [0, T) × Rd and sequences nj → ∞ and (pj, qj, Mj) ∈ J+vnj(tj, xj) such that (tj, xj, vnj(tj, xj), pj, qj, Mj) → (t, x, v(t, x), p, q, M). As (pj, qj, Mj) ∈ J+vnj(tj, xj) and vnj is a viscosity subsolution to (2.4) with n = nj, it holds that min{vnj(tj, xj) − g(tj, xj), −pj− < a(tj, xj), qj > −1 2Tr(σσ⊤(tj, xj)Mj) + nj Z E (vnj(tj, xj + γ(tj, xj, e)) + χ(tj, xj, e) − vnj(tj, xj))−λ(de) − ˜f(tj, xj, vnj(tj, xj), σ⊤(tj, xj)qj)} ≤ 0. Now, whenever v(t, x) > g(t, x) there is a j0 ∈ N, such that vnj(tj, xj) > g(tj, xj) for all j ≥ j0. Hence, − pj− < a(tj, xj), qj > −1 2Tr(σσ⊤(tj, xj)Mj) + nj Z E (vnj(tj, xj + γ(tj, xj, e)) + χ(tj, xj, e) − vnj(tj, xj))−λ(de) − ˜f(tj, xj, vnj(tj, xj), σ⊤(tj, xj)qj) ≤ 0 (3.3) whenever j ≥ j0. Sending j → ∞ gives that −p − < a(t, x), q > −1 2Tr(σσ⊤(t, x)M) − ˜f(t, x, v(t, x), σ⊤(t, x)q) ≤ 0. 12 Now, assume that v(t, x) > infe∈E{v(t, x + γ(t, x, e)) + χ(t, x, e)}. Then there exists an e0 ∈ E such that v(t, x + γ(t, x, e0)) + χ(t, x, e0) − v(t, x) < 0. This in turn implies the existence of an ε > 0 and an open neighborhood E0 ∈ B(E) of e0 in E such that vnj(tj, xj + γ(t, xj, e)) + χ(tj, xj, e) − vnj(tj, xj) ≤ −ε for all e ∈ E0 and all j suﬃciently large. Consequently, Z E (vnj(tj, xj + γ(tj, xj, e)) + χ(tj, xj, e) − vnj(tj, xj))−λ(de) ≥ ελ(E0) for j suﬃciently large. However, since λ has full topological support, λ(E0) > 0 and this contradicts the fact that (3.3) holds for all j. We thereby conclude that v(t, x) ≤ infe∈E{v(t, x + γ(t, x, e)) + χ(t, x, e)}. Supersolution-property. We turn to the supersolution property of v∗. For (t, x) ∈ [0, T) × Rd and (p, q, M) ∈ ¯J−v∗(t, x) there is (again by Lemma 6.1 in [7]) a sequence (tj, xj) ∈ [0, T) × Rd and sequences nj → ∞ and (pj, qj, Mj) ∈ J−vnj(tj, xj) such that (tj, xj, vnj(tj, xj), pj, qj, Mj) → (t, x, v∗(t, x), p, q, M). As (pj, qj, Mj) ∈ J−vnj(tj, xj) and vnj is a viscosity supersolution to (2.4) with n = nj, it holds that min{vnj(tj, xj) − g(tj, xj), −pj− < a(tj, xj), qj > −1 2Tr(σσ⊤(tj, xj)Mj) + nj Z E (vnj(tj, xj + γ(tj, xj, e)) + χ(tj, xj, e) − vnj(tj, xj))−λ(de) − ˜f(tj, xj, vnj(tj, xj), σ⊤(tj, xj)qj)} ≥ 0 (3.4) In particular, vnj(tj, xj) ≥ g(tj, xj) and it follows by continuity of g that v∗(t, x) ≥ g(t, x). Suppose now that v∗(t, x) < infe∈E{v∗(t, x + γ(t, x, e)) + χ(t, x, e)} implying the existence of an ε > 0 such that v∗(t, x) ≤ v∗(t, x + γ(t, x, e)) + χ(t, x, e) − ε, ∀e ∈ E. Since vnj(tj, xj) → v∗(t, x) and lim inf j→∞ inf e∈E{vnj(tj, xj + γ(tj, xj, e)) + χ(tj, xj, e)} ≥ lim inf j→∞ inf e∈E{v∗(tj, xj + γ(tj, xj, e)) + χ(tj, xj, e)} ≥ inf e∈E{v∗(t, x + γ(t, x, e)) + χ(t, x, e)}, this implies that vnj(t, x) ≤ vnj(tj, xj + γ(tj, xj, e)) + χ(tj, xj, e), ∀e ∈ E, whenever j is suﬃciently large. In particular, we get that Z E (vnj(tj, xj + γ(tj, xj, e)) + χ(tj, xj, e) − vnj(tj, xj))−λ(de) = 0 for j suﬃciently large. Taking the limit in (3.4) we thus ﬁnd that in this situation − p − < a(t, x), q > −1 2Tr(σσ⊤(t, x)M) − ˜f(t, x, v∗(t, x), σ⊤(t, x)q) ≥ 0, 13 proving the supersolution property of v∗. Much like the functions vn, for each (t, x) ∈ [0, T] × Rd, the processes (Y t,x,n)n∈N form a non- increasing sequence that is bounded from below by h(·, Xt,x · ) ∈ S2, implying the existence of an Ft- progressively measurable process Y t,x such that Y t,x,n ց Y t,x, pointwisely. Taking the limit on both sides of vn(η, Xt,x η ) = Y t,x,n η gives that Y t,x η = v(η, Xt,x η ) for each η ∈ Tt. In particular, Y t,x is c`adl`ag and thus belongs to S2 t . In our pursuit of a related optimal stopping problem, we let for each τ ∈ T t, the process Y t,x,τ be the ﬁrst component in the quadruple of processes (Y t,x,τ, Zt,x,τ, V t,x,τ, K−,t,x,τ) ∈ S2 [t,τ] × H2 [t,τ](W) × H2 [t,τ](µ) × S2 [t,τ],i that is the unique maximal solution to the BSDE with constrained jumps,      Y t,x,τ s = Ψ(τ, Xt,x τ ) + R τ s ˜f(r, Xt,x r , Y t,x,τ r , Zt,x,τ r )dr − R τ s Zt,x,τ r dWr − R τ s R E V t,x,τ r (e)µ(dr, de) −(K−,t,x,τ τ − K−,t,x,τ s ), ∀s ∈ [t, τ], V t,x,τ s (e) ≥ −χ(s, Xt,x s−, e), dP ⊗ ds ⊗ λ(de) − a.e. (3.5) Theorem 3.1 of [18] seamlessly transfers to the present context, allowing us to conclude the following: Proposition 3.3. For each (t, x) ∈ [0, T] × Rd and η ∈ T t, the process Y t,x can be represented as Y t,x η = ess sup τ∈T t η Y t,x,τ η = ess inf ν∈Vt ess sup τ∈T t η P t,x;τ,ν η , (3.6) where given ν ∈ Vt and τ ∈ T t, the triple (P t,x;τ,ν, Qt,x;τ,ν, St,x;τ,ν) ∈ S2 [t,τ] × H2 [t,τ](W) × H2 [t,τ](µ) is the unique solution to the standard BSDE P t,x;ν,τ s = Ψ(τ, Xt,x τ ) + Z τ s ˜f ν(r, Xt,x r , P t,x;ν,τ r , Qt,x;ν,τ r , St,x;ν,τ r )dr − Z τ s Qt,x;ν,τ r dWr − Z τ s Z E St,x;ν,τ r (e)µ(dr, de), (3.7) with driver ˜f ν(t, x, y, z, v) := ˜f(t, x, y, z) + Z E (v(e) + χ(t, x, e))νt(e)λ(de). 4 The general setting We now turn to the general setting of a non-local driver. Existence will again follow by an approximation routine and for (t, x) ∈ [0, T] × Rd and k ∈ N, we let Y t,x,k s := ess supτ∈T t s Y t,x,k;τ s , where the quadruple (Y t,x,k;τ, Zt,x,k;τ, V t,x,k;τ, K−,t,x,k;τ) ∈ S2 [t,τ] ×H2 [t,τ](W)×H2 [t,τ](µ)×S2 [t,τ],i is the unique maximal solution to      Y t,x,k;τ s = Ψ(τ, Xt,x τ ) + R τ s f(r, Xt,x r , ¯Y k−1(r, ·), Zt,x,k;τ r )dr − R τ s Zt,x,k;τ r dWr − R τ s R E V t,x,k;τ r (e)µ(dr, de) − (K−,t,x,k;τ τ − K−,t,x,k;τ s ), ∀s ∈ [t, τ] V t,x,k;τ s (e) ≥ −χ(s, Xt,x s , e), dP ⊗ ds ⊗ λ(de) − a.e., (4.1) for k ≥ 1, with ¯Y k−1(t, x) := Y t,x,k t and ¯Y 0 ≡ 0. Proposition 4.1. There is a sequence ( ¯Y k ∈ Πg c)k≥0 that satisﬁes the recursion above. Proof. We need to show that for each k ≥ 1, there is a vk−1 ∈ Πg c such that Y t,x,k−1 t = vk−1(t, x) for all (t, x) ∈ [0, T] × Rn. However, for k = 1 this is immediate by the deﬁnition. Now, the result follows by 14 using Proposition 3.3, Theorem 3.2 and induction. For (t, ζ) ∈ [0, T]×R+ and α ∈ At, we let (Υt,ζ;α, Θt,ζ;α) ∈ S2 t ×S2 i,t solve the one-dimensional reﬂected SDE      Υt,ζ;α s = ζ2 ∨ K2 Γ + (4Ca,σ + 2C2 a,σ) R s t (1 + Υt,ζ;α r )dr + 4Ca,σ R s t (1 + Υt,ζ;α r )αrdWr + Θt,ζ;α s , ∀s ∈ [t, T], Υt,ζ;α s ≥ ζ2 ∨ K2 Γ and R T t (Υt,ζ;α s − (ζ2 ∨ K2 Γ))dΘt,ζ;α s = 0. (4.2) We then set Rt,ζ;α s := q Υt,ζ;α s and note that classically, we have E h sup s∈[t,T] |Rt,ζ;α s |pi ≤ C(1 + |ζ ∨ KΓ|p), for all p ≥ 2. Lemma 4.2. For each (t, x) ∈ [0, T] × Rd, there is an α ∈ At such that |Xt,x s | ≤ Rt,|x|;α s for all s ∈ [t, T], P-a.s. Proof. Since |2xa(r, x) + σ2(r, x)| ≤ (4Ca,σ + 2C2 a,σ)(1 + |x|2), it follows from (2.8) that we can always choose α ∈ At such that 2Ca,σ(1 + Υt,|x|,ξ;α r )αr = Xt,x r σ(r, Xt,x r ), ∀r ∈ [t, T], and the statement holds by (2.8). For each ϕ ∈ Πg c, we let ¯Y ϕ ∈ Πg c be deﬁned as ¯Y ϕ(t, x) = ess supτ∈Tt Y t,x,ϕ;τ t , where the quadruple (Y t,x,ϕ;τ, Zt,x,ϕ;τ, V t,x,ϕ;τ, K−,t,x,ϕ;τ) is the unique maximal solution to      Y t,x,ϕ;τ s = Ψ(τ, Xt,x τ ) + R τ s f(r, Xt,x r , ϕ(r, ·), Zt,x,ϕ;τ r )dr − R τ s Zt,x,ϕ;τ r dWr − R τ s R E V t,x,ϕ;τ r (e)µ(dr, de) − (K−,t,x,ϕ;τ τ − K−,t,x,ϕ;τ s ), ∀s ∈ [t, τ] V t,x,k;τ s (e) ≥ −χ(s, Xt,x s , e), dP ⊗ ds ⊗ λ(de) − a.e., (4.3) and note that letting (P t,x,ϕ;ν,τ, Qt,x,ϕ;ν,τ, St,x,ϕ;ν,τ) ∈ S2 t × H2 t (W) × H2 t (µ) solve P t,x,ϕ;ν,τ s = Ψ(τ, Xt,x τ ) + Z τ s f ν(r, Xt,x r , P t,x,ϕ;ν,τ r , ϕ(r, ·), Qt,x,ϕ;ν,τ r , St,x,ϕ;ν,τ r )dr − Z τ s Qt,x,ϕ;ν,τ r dWr − Z τ s Z E St,x,ϕ;ν,τ r (e)µ(dr, de), (4.4) where f ν(t, x, g, z, v) := f(t, x, g, z, v) + Z E (v(e) + χ(t, x, e))νt(e)λ(de), Proposition 3.3 gives that ¯Y ϕ(t, x) = inf ν∈Vt sup τ∈T t P t,x,ϕ;ν,τ t . (4.5) The above deﬁnitions allow us to present the following result, which extends prior results derived in [19] (see Proposition 4.3 therein) and forms the basis for our contraction argument: 15 Proposition 4.3. There is a κ > 0 such that for all ϕ, ˜ϕ ∈ Πg c and ζ > 0, we have sup α∈AW E h Z T 0 eκt sup x∈Λf(R0,ζ;α t ) | ¯Y ˜ϕ(t, x) − ¯Y ϕ(t, x)|2dt i ≤ 1 4 sup α∈AW E h Z T 0 eκt sup x∈Λf(R0,ζ;α t ) | ˜ϕ(t, x) − ϕ(t, x)|2dt i . (4.6) Furthermore, there is a C > 0 such that sup t∈[0,T] sup x∈Λf (ζ) | ¯Y ˜ϕ(t, x) − ¯Y ϕ(t, x)|2 ≤ C sup α∈AW E h Z T 0 sup x∈Λf(R0,ζ;α t ) | ˜ϕ(t, x) − ϕ(t, x)|2dt i (4.7) for each ζ > 0. Proof. By (4.5) we ﬁnd that ¯Y ϕ(t, x) − ¯Y ˜ϕ(t, x) ≤ sup ν∈Vt sup τ∈T t(P t,x,ϕ;ν,τ t − P t,x, ˜ϕ;ν,τ t ). Since a similar inequality holds in the opposite direction, we get that | ¯Y ϕ(t, x) − ¯Y ˜ϕ(t, x)| ≤ sup ν∈Vt sup τ∈T t |P t,x,ϕ;ν,τ t − P t,x, ˜ϕ;ν,τ t |. (4.8) For (ν, τ) ∈ Vt×T t, let (P, Q, S) := (P t,x,ϕ;ν,τ, Qt,x,ϕ;ν,τ, St,x,ϕ;ν,τ) and ( ˜P, ˜Q, ˜S) := (P t,x, ˜ϕ;ν,τ, Qt,x, ˜ϕ;ν,τ, St,x, ˜ϕ;ν,τ) and note that for κ > 0, Itˆo’s formula applied to eκ·| ˜P − P|2 gives eκt| ˜Pt − Pt|2 + Z τ t eκs| ˜Qs − Qs|2ds + Z τ t Z E eκs| ˜Ss(e) − Ss(e)|2dµ(ds, de) = −2 Z τ t eκs( ˜Ps − Ps)( ˜Qs − Qs)dWs − 2 Z τ t Z E eκs( ˜Ps − Ps)( ˜Ss(e) − Ss(e))dµ(ds, de) − κ Z τ t eκs| ˜Ps − Ps|2ds + 2 Z τ t eκs( ˜Ps − Ps)(f(s, Xt,x s , ˜ϕ(s, ·), ˜Qs) − f(s, Xt,x s , ϕ(s, ·), Qs))ds + 2 Z τ t Z E eκs( ˜Ps − Ps)( ˜S(e) − S(e))νt(e)λ(de). By assumption |f(s, Xt,x s , ϕ(s, ·), Qs) − f(s, Xt,x s , ˜ϕ(s, ·), ˜Qs)| ≤ kf( sup x′∈Λf (|Xt,x s |) | ˜ϕ(s, x′) − ϕ(s, x′)| + | ˜Qs − Qs|). Hence, taking the expectation w.r.t. the measure Pν and using inequalities 2Cxy ≤ (Cx)2 + y2 and 2xy ≤ x2/√κ + √κy2 gives eκt| ˜Pt − Pt|2 ≤ (C2 + C√κ − κ)Eνh Z τ t eκs| ˜Ps − Ps|2ds i + C √κEνh Z T t eκs sup x′∈Λf (|Xt,x s |) | ˜ϕ(s, x′) − ϕ(s, x′)|2ds i . Now, pick κ0 > 0 such that κ0 ≥ C2 + C√κ0 and note that for each κ ≥ κ0, we have eκt|Pt − ˜Pt|2 ≤ C √κEνh Z T t eκs sup x′∈Λf (|Xt,x s |) | ˜ϕ(s, x′) − ϕ(s, x′)|2ds i ≤ C √κ sup α∈At Eνh Z T t eκs sup x′∈Λf (|Rt,|x|;α s |) | ˜ϕ(s, x′) − ϕ(s, x′)|2ds i ≤ C √κ sup α∈AW t E h Z T t eκs sup x′∈Λf (|Rt,|x|;α s |) | ˜ϕ(s, x′) − ϕ(s, x′)|2ds i , 16 where the ﬁrst inequality follows from Lemma 4.2 while the second one is due to the fact that the SDE in (4.2) does not depend on µ (see e.g. Section 4.1 of [1]). Since the right-hand side is non-decreasing in |x| and independent of ν and τ, (4.8) now gives that eκt sup x∈Λf (ζ) | ¯Y ˜ϕ(t, x) − ¯Y ϕ(t, x)|2 ≤ C √κ sup α∈AW t E h Z T t eκs sup x′∈Λf (Rt,ζ;α s ) | ˜ϕ(s, x′) − ϕ(s, x′)|2ds i , (4.9) for any ζ ≥ 0. In particular, as both sides are continuous in ζ a standard dynamic programming argument gives that for any α1 ∈ AW, we have E h eκt sup x∈Λf(R0,ζ;α1 t ) | ¯Y ˜ϕ(t, x) − ¯Y ϕ(t, x)|2i ≤ C √κ sup α∈AW t E h Z T t eκs sup x′∈Λf (R0,ζ;α1⊕tα s ) | ˜ϕ(s, x′) − ϕ(s, x′)|2ds i . Taking the supremum with respect to α1 on the right-hand side and once again relying on a standard dynamic programming argument gives that E h eκt sup x∈Λf (R0,ζ;α1 t ) | ¯Y ˜ϕ(t, x) − ¯Y ϕ(t, x)|2i ≤ C √κ sup α∈AW E h Z T 0 eκs sup x′∈Λf (R0,ζ;α s ) | ˜ϕ(s, x′) − ϕ(s, x′)|2ds i . Integrating with respect to time and using Fubini’s theorem, we ﬁnd that E h Z T 0 eκt sup x∈Λf(R0,ζ;α1 t ) | ¯Y ˜ϕ(t, x) − ¯Y ϕ(t, x)|2dt i ≤ CT √κ sup α∈AW E h Z T 0 eκs sup x′∈Λf (R0,ζ;α s ) | ˜ϕ(s, x′) − ϕ(s, x′)|2ds i after which taking the supremum with respect to α1 ∈ AW and choosing κ ≥ (4CT)2 ∨ κ0 gives the ﬁrst inequality. To get (4.7) we note that comparison gives that R0,ζ;α s ≥ Rt,ζ;α s for all s ∈ [t, T] and α ∈ AW. From (4.9) we thus get that sup x∈Λf(ζ) | ¯Y ˜ϕ(t, x) − ¯Y ϕ(t, x)|2 ≤ C sup α∈AW E h Z T 0 sup x′∈Λf (R0,ζ;α s ) | ˜ϕ(s, x′) − ϕ(s, x′)|2ds i from which (4.7) is immediate since the right-hand side is independent of t. We now introduce the norm ∥ · ∥ζ on the space of jointly continuous functions of polynomial growth, Πg c, deﬁned as ∥ϕ∥ζ := sup α∈AW E h Z T 0 eκt sup x∈Λf (R0,ζ;α t ) |ϕ(t, x)|2dt i1/2 , with κ > 0 as in Proposition 4.3 and note that under ∥ · ∥ζ, the map Φ : Πg c → Πg c that maps ϕ to ¯Y ϕ is a contraction. Corollary 4.4. There are constants C > 0 and p ≥ 0 such that | ¯Y k(t, x)| ≤ C(1 + |x|p) for all (t, x) ∈ [0, T] × Rd and all k ≥ 0. Proof. First, we note that (4.6) and the triangle inequality implies that ∥¯Y k∥ζ ≤ ∥¯Y k − ¯Y k−1∥ζ + ∥¯Y k−1∥ζ ≤ 1 2∥¯Y k−1 − ¯Y k−2∥ζ + ∥¯Y k−1∥ζ ≤ 1 2k−1 ∥¯Y 1 − ¯Y 0∥ζ + ∥¯Y k−1∥ζ. However, as a similar scheme holds for ∥¯Y k−1∥ζ and since ¯Y 0 ≡ 0 we conclude that ∥¯Y k∥ζ ≤ k X j=1 1 2j−1 ∥¯Y 1∥ζ ≤ 2∥¯Y 1∥ζ. 17 On the other hand, as ¯Y 1 ∈ Πg c there are constants C > 0 and p ≥ 2 such that | ¯Y 1(t, x)| ≤ C(1 + |x|p) and we conclude that ∥¯Y 1∥2 ζ = sup α∈AW E h Z T 0 eκt sup x∈Λf (R0,ζ;α t ) | ¯Y 1(t, x)|2dt i ≤ C \u0010 1 + sup α∈AW E h sup t∈[0,T] |R0,ζ;α t |2pi\u0011 ≤ C(1 + |ζ|2p) implying the existence of a C > 0 such that ∥¯Y k∥ζ ≤ C(1 + |ζ|p) for all k ≥ 0. Now, (4.7) gives that sup t∈[0,T] sup x∈Λf(ζ) | ¯Y k(t, x) − ¯Y 1(t, x)|2 ≤ C sup α∈AW E h Z T 0 sup x∈Λf(R0,ζ;α t ) | ¯Y k−1(t, x)|2dt i ≤ C(1 + |ζ|2p) where the constants C > 0 and p ≥ 2 do not depend on k and the desired bound follows. Letting vk(t, x) := ¯Y k(t, x), Proposition 4.3 and Corollary 4.4 implies that there is a v ∈ Πg such that for each ζ > 0 we have ∥vk − v∥ζ → 0 as k → ∞. Theorem 4.5. v is the unique viscosity solution in Πg c to (1.1). Proof. First, (4.7) implies that the convergence is uniform on compact subsets of [0, T] × Rn and since vk is jointly continuous for each k ≥ 0 we conclude that v is also jointly continuous. This in turn gives that Φ(v) is well deﬁned and we conclude that Φ(v) = v establishing existence of a solution to the optimal stopping problem (1.3)-(1.5). Moreover, if ˜Y is another solution, then ˜v(t, x) := ˜Y t,x t must also satisfy Φ(˜v) = ˜v. However, then repeated use of the contraction property in (4.6) gives that ∥˜v − v∥ζ = 0 and by continuity we conclude that ˜v = v implying by uniqueness of the non-linear Snell envelope in (3.6) as obtained in Proposition 3.3 that ˜Y t,x = Y t,x. The solution to the optimal stopping problem (1.3)-(1.5) is thus unique. Utilizing, once more, the connection between the optimal stopping problem (1.3)-(1.5) and PDEs with obstacles we conclude that v is a viscosity solution to (1.1). Suppose now that there exists another function ˜v ∈ Πg c that solves (1.1) and let ¯v = Φ(˜v), then by Theorem 3.2 and Proposition 3.3 we conclude that ¯v ∈ Πg c is the unique solution to      min{¯v(t, x) − h(t, x), max{¯v(t, x) − M¯v(t, x), −¯vt(t, x) − L¯v(t, x) −f(t, x, ˜v(t, ·), σ⊤(t, x)∇x¯v(t, x))}} = 0, ∀(t, x) ∈ [0, T) × Rd ¯v(T, x) = ψ(x), But then ¯v = ˜v implying that ˜v is a ﬁxed point of Φ and since v is the only ﬁxed point of Φ in the set of jointly continuous functions of polynomial growth we must have ˜v = v. Corollary 4.6. Y v is the unique solution to the optimal stopping problem (1.3)-(1.5). A Uniqueness of viscosity solutions in the local framework In this section we prove the critical comparison principle for the PDE with local driver,      min{v(t, x) − h(t, x), max{v(t, x) − Mv(t, x), −vt(t, x) − Lv(t, x) − ˜f(t, x, v(t, x), σ⊤(t, x)∇xv(t, x))}} = 0, ∀(t, x) ∈ [0, T) × Rd v(T, x) = ψ(x), (A.1) that was treated in Section 3 (see (3.1)). We need the following lemma: 18 Lemma A.1. Let v be a supersolution to (A.1) satisfying ∀(t, x) ∈ [0, T] × Rd, |v(t, x)| ≤ C(1 + |x|2̺) for some ̺ > 0. Then there is a ̟0 > 0 such that for any ̟ > ̟0 and θ > 0, the function v + θe−̟t(1 + ((|x| − KΓ)+)2̺+2) is also a supersolution to (A.1). Proof. With w(t, x) := v(t, x) + θe−̟t(1+ ((|x| − KΓ)+)2̺+2) we note that, since v is a supersolution and θe−̟T(1 + ((|x| − KΓ)+)2̺+2) ≥ 0, we have w(t, x) ≥ v(t, x) ≥ 1[t<T]h(t, x) + 1[t=T]ψ(x) so that w(t, x) ≥ h(t, x) for all (t, x) ∈ [0, T) × Rd and the terminal condition holds. Assume now that v(t, x) − inf e∈E{v(t, x + γ(t, x, e)) + χ(t, x, e)} ≥ 0. In this case, w(t, x) − inf e∈E{w(t, x + γ(t, x, e)) + χ(t, x)} = v(t, x) + θe−γt(1 + ((|x| − KΓ)+)2̺+2) − inf e∈E{v(t, x + γ(t, x, e)) + θe−γt(1 + ((|x + γ(t, x, e)| − KΓ)+)2̺+2) + χ(t, x, e)} ≥ v(t, x) − inf e∈E{v(t, x + γ(t, x, e)) + χ(t, x, e)} + θe−γt{1 + ((|x| − KΓ)+)2̺+2 − sup e∈E θe−γt(1 + ((|x + γ(t, x, e)| − KΓ)+)2̺+2)}. Now, either |x| ≤ KΓ in which case it follows by (2.1) that |x + γ(t, x, e)| ≤ KΓ or |x| > KΓ and (2.1) gives that |x + γ(t, x, e)| ≤ |x|. We conclude that w(t, x) − inf e∈E{w(t, x + γ(t, x, e)) + χ(t, x, e)} ≥ 0. Consider instead the case when v(t, x) − inf e∈E{v(t, x + γ(t, x, e)) + χ(t, x, e)} < 0 and let ϕ ∈ C1,2([0, T] × Rd → R) be such that ϕ − w has a local maximum of 0 at (t, x) with t < T. Then (˜t, ˜x) 7→ ˜ϕ(˜t, ˜x) := ϕ(˜t, ˜x) − θe−̟˜t(1 + ((|˜x| − KΓ)+)2̺+2) ∈ C1,2([0, T] × Rd → R) and ˜ϕ − v has a local maximum of 0 at (t, x). Since v is a viscosity supersolution, we have − ∂t(ϕ(t, x) − θe−̟t(1 + ((|x| − KΓ)+)2̺+2)) − L(ϕ(t, x) − θe−̟t(1 + ((|x| − KΓ)+)2̺+2)) − ˜f(t, x, ϕ(t, x) − θe−̟t(1 + ((|x| − KΓ)+)2̺+2), σ⊤(t, x)∇x(ϕ(t, x) − θe−̟t(1 + ((|x| − KΓ)+)2̺+2))) ≥ 0. Consequently, − ∂tϕ(t, x) − Lϕ(t, x) − ˜f(t, x, ϕ(t, x), σ⊤(t, x)∇xϕ(t, x)) ≥ θ̟e−̟t(1 + ((|x| − KΓ)+)2̺+2) − θLe−̟t(1 + ((|x| − KΓ)+)2̺+2) ˜f(t, x, ϕ(t, x) − θe−̟t(1 + ((|x| − KΓ)+)2̺+2), σ⊤(t, x)∇x(ϕ(t, x) − θe−̟t(1 + ((|x| − KΓ)+)2̺+2))) − ˜f(t, x, ϕ(t, x), σ⊤(t, x)∇xϕ(t, x)) ≥ θ̟e−̟t(1 + ((|x| − KΓ)+)2̺+2) − θC(1 + ̺)e−̟t(1 + ((|x| − KΓ)+)2̺+2) − kf(1 + ̺)θe−̟t(1 + ((|x| − KΓ)+)2̺+2), where the right hand side is non-negative for all θ > 0 and all ̟ > ̟0 for some ̟0 > 0. We have the following result, the proof of which we omit since it is classical: 19 Lemma A.2. For any κ ∈ R, a locally bounded function v : [0, T] × Rd → R is a viscosity superso- lution (resp. subsolution) to (A.1) if and only if ˇv(t, x) := eκtv(t, x) is a viscosity supersolution (resp. subsolution) to      min{ˇv(t, x) − eκth(t, x), max{ˇv(t, x) + infe∈E{ˇv(t, x + γ(t, x, e)) + eκtχ(t, x, e)}, −ˇvt(t, x) +κˇv(t, x) − Lˇv(t, x) − eκt ˜f(t, x, e−κtˇv(t, x), e−κtσ⊤(t, x)∇xˇv(t, x))} = 0, ∀(t, x) ∈ [0, T) × Rd ˇv(T, x) = eκT ψ(x). (A.2) Remark A.3. Here, it is important to note that ˇh(t, x) := eκth(t, x), ˇχ(t, x, e) := eκtχ(t, x, e), ˇf(t, x, y, z) := −κy + eκt ˜f(t, x, e−κty, e−κtz) and ˇψ(x) := eκT ψ(x) satisfy Assumption 2.2. In particular, this implies that Lemma A.1 holds for supersolutions to (A.2) as well. We have the following comparison result for viscosity solutions in Πg: Proposition A.4. Let v (resp. u) be a supersolution (resp. subsolution) to (A.1). If u, v ∈ Πg, then u ≤ v. Proof. First, we note that it is suﬃcient to show that the statement holds for solutions to (A.2) for some κ ∈ R. We thus assume that v (resp. u) is a viscosity supersolution (resp. subsolution) to (A.2) for κ ∈ R speciﬁed below. Furthermore, we may without loss of generality assume that v is l.s.c. and u is u.s.c. By assumption, u, v ∈ Πg, which implies that there are constants C > 0 and ̺ > 0 such that |v(t, x)| + |u(t, x)| ≤ C(1 + |x|2̺). (A.3) Now, for any ̟ > 0 we only need to show that w(t, x) = wθ,̟(t, x) := v(t, x) + θe−̟t(1 + ((|x| − KΓ)+)2̺+2) ≥ u(t, x) for all (t, x) ∈ [0, T] × Rd and any θ > 0. Then the result follows by taking the limit θ → 0. We know from Lemma A.1 that there is a ̟0 > 0 such that w is a supersolution to (A.2) for each ̟ ≥ ̟0 and θ > 0. We thus assume that ̟ ≥ ̟0. We search for a contradiction and assume that there is a (t0, x0) ∈ [0, T] × Rd such that u(t0, x0) > w(t0, x0). By (A.3), there is for each θ > 0 a R > KΓ such that w(t, x) > u(t, x), ∀(t, x) ∈ [0, T] × Rd, |x| > R. Our assumption thus implies that there is a point (¯t, ¯x) ∈ [0, T) × BR (the open unit ball of radius R centered at 0) such that max (t,x)∈[0,T]×Rd(u(t, x) − w(t, x)) = max (t,x)∈[0,T)×BR (u(t, x) − w(t, x)) = u(¯t, ¯x) − w(¯t, ¯x) = η > 0. We ﬁrst show that there is at least one point (t∗, x∗) ∈ [0, T) × BR such that a) u(t∗, x∗) − w(t∗, x∗) = η, b) u(t∗, x∗) > ˇh(t∗, x∗) and c) w(t∗, x∗) < infe∈E{v(t∗, x∗ + γ(t∗, x∗, e)) + ˇχ(t∗, x∗, e)}. 20 Assume ﬁrst that u(t, x) ≤ ˇh(t, x) for some (t, x) ∈ [0, T] × Rd. Since w is a supersolution, we have w(t, x) ≥ ˇh(t, x) and it follows that u(t, x) − w(t, x) ≤ 0 contradicting that u(t, x) − w(t, x) = η. In particular, any point satisfying a) must also satisfy b). We proceed by assuming that w(t, x) ≥ infe∈E{w(t, x + γ(t, x, e)) − ˇχ(t, x, e)} for all (t, x) ∈ A := {(s, y) ∈ [0, T] × Rd : u(s, y) − w(s, y) = η}. Indeed, as w is l.s.c. and γ is continuous, there is an e1 ∈ E such that w(¯t, ¯x) = inf e∈E{w(¯t, ¯x + γ(¯t, ¯x, e)) + ˇχ(¯t, ¯x, e)} = w(¯t, ¯x + γ(¯t, ¯x, e1)) + ˇχ(¯t, ¯x, e1). (A.4) Now, set x1 = ¯x + γ(¯t, ¯x, e1) and note that since |x + γ(t, x, e)| < R, ∀(t, x, e) ∈ [0, T] × BR × E it follows that x1 ∈ BR. Moreover, as u is a subsolution with u(¯t, ¯x) > ˇh(¯t, ¯x) it satisﬁes u(¯t, ¯x) − (u(¯t, ¯x + γ(¯t, ¯x, e1)) + ˇχ(¯t, ¯x, e1)) ≤ 0, that is u(¯t, x1)) ≥ u(¯t, ¯x) − ˇχ(t, ¯x, e1) and we conclude from (A.4) that u(¯t, x1) − w(¯t, x1) ≥ u(¯t, ¯x) − ˇχ(¯t, ¯x, e1) − (w(¯t, ¯x) − ˇχ(t, ¯x, e1)) = u(¯t, ¯x) − w(¯t, ¯x) = η. Hence, (¯t, x1) ∈ A and by our assumption it follows that there is an e2 ∈ E such that u(¯t, x1) = u(¯t, x1 + γ(¯t, x1, e2)) + ˇχ(¯t, x1, e2) and a corresponding x2 := x1 + γ(¯t, x1, e2) ∈ BR. Now, this process can be repeated indeﬁnitely to ﬁnd a sequence (xj, ej)j≥1 in BR × E such that for any l ≥ 0 we have w(¯t, ¯x) ≥ w(¯t, xl) + l X j=1 ˇχ(¯t, xj−1, ej), with x0 := ¯x. However, as ˇχ ≥ δ > 0 we get a contradiction by letting l → ∞ while noting that w(t, x) ≥ ˇh(t, x) where the latter is bounded on [0, T] × ¯BR. We can thus ﬁnd a (t∗, x∗) ∈ [0, T) × BR such that a)-c) above holds. Since ˜f is Lipschitz in y and z for (t, x) ∈ [0, T] × ¯BR, the remainder of the proof follows along the lines of the proof of Proposition 4.1 in [12] (see also Proposition 6.4 in [20]) and is included only for the sake of completeness. Next, we assume without loss of generality that ̺ ≥ 2 and deﬁne Φn(t, x, y) := u(t, x) − w(t, x) − ϕn(t, x, y), where ϕn(t, x, y) := n 2|x − y|2̺ + |x − x∗|2 + |y − x∗|2 + (t − t∗)2. Since u is u.s.c. and w is l.s.c. there is a triple (tn, xn, yn) ∈ [0, T] × ¯BR × ¯BR (with ¯BR the closure of BR) such that Φn(tn, xn, yn) = max (t,x,y)∈[0,T]× ¯BR× ¯BR Φn(t, x, y). 21 Now, the inequality 2Φn(tn, xn, yn) ≥ Φn(tn, xn, xn) + Φn(tn, yn, yn) gives n|xn − yn|2̺ ≤ u(tn, xn) − u(tn, yn) + w(tn, xn) − w(tn, yn). Consequently, n|xn −yn|2̺ is bounded (since u and w are bounded on [0, T]× ¯BR × ¯BR) and |xn −yn| → 0 as n → ∞. We can, thus, extract subsequences nl such that (tnl, xnl, ynl) → (˜t, ˜x, ˜x) as l → ∞. Since u(t∗, x∗) − w(t∗, x∗) ≤ Φn(tn, xn, yn) ≤ u(tn, xn) − w(tn, yn), it follows that u(t∗, x∗) − w(t∗, x∗) ≤ lim sup l→∞ {u(tnl, xnl) − w(tnl, ynl)} ≤ u(˜t, ˜x) − w(˜t, ˜x) and as the right-hand side is dominated by u(t∗, x∗) − w(t∗, x∗) we conclude that u(˜t, ˜x) − w(˜t, ˜x) = u(t∗, x∗) − w(t∗, x∗). In particular, this gives that liml→∞ Φn(tnl, xnl, ynl) = u(˜t, ˜x) − w(˜t, ˜x) which implies that lim sup l→∞ nl|xnl − ynl|2̺ = 0 and (tnl, xnl, ynl) → (t∗, x∗, x∗). We can thus extract a subsequence (˜nl)l≥0 of (nl)l≥0 such that t˜nl < T, |x˜nl| < R and u(t˜nl, x˜nl) − w(t˜nl, x˜nl) ≥ η 2 for all l ∈ N. Moreover, since (t, x) 7→ infe∈E{w(t, x + γ(t, x, e)) − ˇχ(t, x, e)} is u.s.c. (see Lemma 2.11), w(t˜nl, x˜nl) → w(t∗, x∗) and u is u.s.c. while ˇh is continuous, there is an l0 ≥ 0 such that w(t˜nl, x˜nl) − inf e∈E{w(t˜nl, x˜nl + γ(t˜nl, x˜nl, e)) − ˇχ(t˜nl, e)} < 0, and u(t˜nl, x˜nl) − ˇh(t˜nl, x˜nl) > 0, for all l ≥ l0. To simplify notation we will, from now on, denote (˜nl)l≥l0 simply by n. By Theorem 8.3 of [7] there are (pu n, qu n, Mu n) ∈ ¯J2,+u(tn, xn) and (pw n , qw n , Mw n ) ∈ ¯J2,+w(tn, yn), where ¯J2,+ is the limiting superjet, such that      pu n − pw n = ∂tϕn(tn, xn, yn) = 2(tn − t∗) qu n = Dxϕn(tn, xn, yn) = n̺(x − y)|x − y|2̺−2 + 2(x − x∗) qw n = −Dyϕn(tn, xn, yn) = n̺(x − y)|x − y|2̺−2 + 2(x − x∗) and for every ǫ > 0, \u0014 Mn x 0 0 −Mn y \u0015 ≤ B(tn, xn, yn) + ǫB2(tn, xn, yn), 22 where B(tn, xn, yn) := D2 (x,y)ϕn(tn, xn, yn). Now, we have D2 (x,y)ϕn(t, x, y) = \u0014 D2 xϕn(t, x, y) D2 yxϕn(t, x, y) D2 xyϕn(t, x, y) D2 yϕn(t, x, y) \u0015 = \u0014 nξ(x, y) + 2I −nξ(x, y) −nξ(x, y) nξ(x, y) + 2I \u0015 where I is the identity-matrix of suitable dimension and ξ(x, y) := ̺|x − y|2̺−4{|x − y|2I + 2(̺ − 1)(x − y)(x − y)⊤}. In particular, since xn and yn are bounded, choosing ǫ := 1 n gives that ˜Bn := B(tn, xn, yn) + ǫB2(tn, xn, yn) ≤ Cn|xn − yn|2̺−2 \u0014 I −I −I I \u0015 + CI. (A.5) By the deﬁnition of viscosity supersolutions and subsolutions we have that − pu n + κu(tn, xn) − a⊤(tn, xn)qu n − 1 2Tr[σ⊤(tn, xn)Mu nσ(tn, xn)] − eκtn ˜f(tn, xn, e−κtnu(tn, xn), e−κtnσ⊤(tn, xn)qu n) ≤ 0 and − pw n + κw(tn, yn) − a⊤(tn, yn)qw n − 1 2Tr[σ⊤(tn, yn)Mw n σ(tn, yn)] − eκtn ˜f(tn, yn, e−κtnw(tn, yn), e−κtnσ⊤(tn, xn)qw n ) ≥ 0. Combined, this gives that κ(u(tn, xn) − w(tn, yn)) ≤ pu n + a⊤(tn, xn)qu n + 1 2Tr[σ⊤(tn, xn)Mu nσ(tn, xn)] + eκtn ˜f(tn, xn, e−κtnu(tn, xn), e−κtnσ⊤(tn, xn)qu n) − pw n − a⊤(tn, yn)qw n − 1 2Tr[σ⊤(tn, yn)Mw n σ(tn, yn)] − eκtn ˜f(tn, yn, e−κtnw(tn, yn), e−κtnσ⊤(tn, xn)qw n ) Collecting terms we have that pu n − pw n = 2(tn − t∗) and since a is Lipschitz continuous in x and bounded on ¯BR, we have a⊤(tn, xn)qu n − a⊤(tn, yn)qw n ≤ (a⊤(tn, xn) − a⊤(tn, yn))n̺(xn − yn)|xn − yn|2̺−2 + C(|xn − x∗| + |yn − x∗|) ≤ C(n|xn − yn|2̺ + |xn − x∗| + |yn − x∗|), where the right-hand side tends to 0 as n → ∞. Let sx denote the ith column of σ(tn, xn) and let sy denote the ith column of σ(tn, yn) then by the Lipschitz continuity of σ and (A.5), we have s⊤ x Mu nsx − s⊤ y Mw n sy = \u0002 s⊤ x s⊤ y \u0003 \u0014 Mu n 0 0 −Mw n \u0015 \u0014 sx sy \u0015 ≤ \u0002 s⊤ x s⊤ y \u0003 ˜Bn \u0014 sx sy \u0015 ≤ C(n|xn − yn|2̺ + |xn − yn|) 23 and we conclude that lim sup n→∞ 1 2Tr[σ⊤(tn, xn)Mu nσ(tn, xn) − σ⊤(tn, yn)Mw n σ(tn, yn)] ≤ 0. Finally, we have that eκtn ˜f(tn, xn, e−κtnu(tn, xn), e−κtnσ⊤(tn, xn)qu n) − eκtn ˜f(tn, yn, e−κtnw(tn, yn), e−κtnσ⊤(tn, xn)qw n ) ≤ kf(u(tn, xn) − w(tn, yn) + |σ⊤(tn, xn)qu n − σ⊤(tn, xn)qw n |) + eκtn| ˜f(tn, xn, e−κtnu(tn, xn), e−κtnσ⊤(tn, xn)qu n) − ˜f(tn, yn, e−κtnu(tn, xn), e−κtnσ⊤(tn, xn)qu n)| Repeating the above argument and using that ˜f is jointly continuous in (t, x) uniformly in (y, z) we get that the upper limit of the right-hand side when n → ∞ is bounded by kf(u(tn, xn) − w(tn, yn)). Put together, this gives that (κ − kf) lim sup n→∞ (u(tn, xn) − w(tn, yn)) ≤ 0 and choosing κ > kf gives a contradition. References [1] E. Bandini, A. Cosso, M. Fuhrman, and H. Pham. Backward sdes for optimal control of partially observed path-dependent stochastic systems: a control randomization approach. Ann. Appl. Probab., 28(3):1634–1678, 2018. [2] G. Barles. Solutions de viscosit´e des ´equations de Hamilton-Jacobi, volume 17 of Math´ematiques et Applications. Springer, Paris, 1994. [3] G. Barles, R. Buckdahn, and E. Pardoux. Backward stochastic diﬀerential equations and integral- partial diﬀerential equations. Stoch. Stoch. Rep., 60(1-2):57–83, 1997. [4] A. Bensoussan and J.L. Lions. Impulse Control and Quasivariational inequalities. Gauthier-Villars, Montrouge, France, 1984. [5] B. Bouchard. A stochastic target formulation for optimal switching problems inﬁnite horizon. Stochastics, 81:171–197, 2009. [6] S. Choukroun, A. Cosso, and H. Pham. Reﬂected bsdes with nonpositive jumps, and controller-and- stopper games. Stochastic Process. Appl., 125:597–633, 2015. [7] M. G. Crandall, H. Ishii, and P. L. Lions. Users guide to viscosity solutions of second order partial diﬀerential equations. Bulletin of the American Mathematical Society, 27(1):1–67, 1992. [8] R. Dumitrescu, M.-C. Quenez, and A. Sulem. Otimal stopping for dynamic risk measures with jumps and obstacle problems. J Optim Theory Appl, 167:219–242, 2015. [9] M. Fuhrman and M. Morlais. Optimal switching problems with an inﬁnite set of modes: An approach by randomization and constrained backward sdes. Stochastic Process. Appl., 130:5(5):3120–3153, 2020. [10] M. Fuhrman and H. Pham. Randomized and backward sde representation for optimal control of non-markovian sdes. Ann. Appl. Probab., 25(4):2134–2167, 2015. 24 [11] S. Hamad`ene, M. Mnif, and S. Neﬀati. Viscosity solution of system of integro-partial diﬀerential equations with interconnected obstacles of non-local type without monotonicity conditions. J Dyn Diﬀ Equat, 35(2):1151–1173, 2023. [12] S. Hamad`ene and M. A. Morlais. Viscosity solutions of systems of pdes with interconnected obstacles and switching problem. Appl Math Optim., 67:163–196, 2013. [13] S. Hamad`ene and M. A. Morlais. Viscosity solutions for second order integro-diﬀerential equations without monotonicity condition: the probabilistic approach. Stochastics: An International Journal of Probability and Stochastic Processes, 88(4):632–649, 2016. [14] I. Kharroubi, J. Ma, H. Pham, and J. Zhang. Backward sdes with constrained jumps and quasi- variational inequalities. Ann. Probab., 38(2):794–840, 2010. [15] I. Kharroubi and H. Pham. Feynman-Kac representation for Hamilton-Jacobi-Bellman IPDE. Ann. Probab., 43(4):1823–1865, 2015. [16] B. Øksendal and A. Sulem. Applied Stochastic Control of Jump Diﬀusions. Springer, 2007. [17] M. Perninge. Sequential systems of reﬂected backward stochastic diﬀerential equations with appli- cation to impulse control. Appl Math Optim, 86(19), 2022. [18] M. Perninge. Optimal stopping of bsdes with constrained jumps and related zero-sum games. arXiv:2308.16504, 2023. [19] M. Perninge. Probabilistic representation of viscosity solutions to quasi-variational inequalities with non-local drivers. ESAIM Control Optim. Calc. Var., 25:1–28, 2023. [20] M. Perninge. Zero-sum stochastic diﬀerential games of impulse versuscontinuous control by fbsdes. J. Math. Anal. Appl., 527, 2023. [21] M-C. Quenez and A. Sulem. Reﬂected bsdes and robust optimal stopping for dynamic risk measures with jumps. Stochastic Process. Appl., 124:3031–3054, 2014. 25 "
}