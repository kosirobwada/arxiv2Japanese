{
    "optim": "Learning-Based Algorithms for Graph Searching Problems Adela Frances DePavia adepavia@uchicago.edu University of Chicago Erasmo Tani etani@uchicago.edu University of Chicago Ali Vakilian vakilian@ttic.edu TTIC February 28, 2024 Abstract We consider the problem of graph searching with prediction recently introduced by Banerjee et al. (2023). In this problem, an agent, starting at some vertex r has to traverse a (potentially unknown) graph G to find a hidden goal node g while minimizing the total distance travelled. We study a setting in which at any node v, the agent receives a noisy estimate of the distance from v to g. We design algorithms for this search task on unknown graphs. We establish the first formal guarantees on unknown weighted graphs and provide lower bounds showing that the algorithms we propose have optimal or nearly-optimal dependence on the prediction error. Further, we perform numerical experiments demonstrating that in addition to being robust to adversarial error, our algorithms perform well in typical instances in which the error is stochastic. Finally, we provide alternative simpler performance bounds on the algorithms of Banerjee et al. (2023) for the case of searching on a known graph, and establish new lower bounds for this setting. 1 Introduction Searching on graphs is a fundamental problem which models many real-world applications in autonomous navigation. In a graph searching problem instance, an agent is initialized at some vertex r ∈ V (referred to as the root) in some (potentially weighted, directed) graph G = (V, E). The agent’s task is to find a goal node g ∈ V . The agent searches for g by sequentially visiting adjacent nodes in the graph. The graph searching problem terminates when the agent reaches the goal node, and the cost incurred by the agent is the total amount of distance they travelled. There are two main settings of interest. In the exploration setting, as the agent moves through the graph, it only learns the structure of G by observing the vertices and edges adjacent to the nodes it has visited, a model sometimes referred to as the fixed graph scenario (Komm et al., 2015; Kalyanasundaram and Pruhs, 1994). In the strictly-easier planning setting, the agent is given the entire graph G ahead of time, but does not know the identity of the goal node g. Without additional information, in the worst-case the agent must resort to visiting the entire graph, a task which amounts to finding an efficient tour in an unknown graph1(Berman, 2005; Dobrev et al., 2012; Megow et al., 2012; Eberle et al., 2022). Recently, Banerjee et al. (2023) consider the setting when an algorithm for graph searching also receives some prediction function, f : V → R, representing some (noisy) estimate of the distance to the goal node g at any given node v ∈ V . This setup models applications in which the searcher receives advice from some machine-learning model designed to predict the distance to the goal; this problem fits into the broader framework of learning-based algorithms, which exploit (potentially noisy) advice from a machine learning model to enhance their performance. In the case of planning, Banerjee et al. (2023) propose an intuitive strategy that can be deployed in weighted and unweighted graphs and analyze its performance in terms of structural properties of the instance graph, such as its maximum-degree and its doubling-dimension. They establish formal guarantees on the cost incurred by their algorithm under different notions of prediction error. In contrast, their results in the exploration setting are limited: they propose an algorithm for exploration in unweighted trees. Their 1We note that historically the task of finding an efficient tour in an unknown graph has been referred to as graph exploration, but following the conventions of Banerjee et al. (2023) we reserve this name for the graph search problem on an unknown graph. 1 arXiv:2402.17736v1  [cs.DS]  27 Feb 2024 algorithm is tailored to this restricted class of graphs and their guarantees are parameterized by the number of incorrect predictions, which could in general be a poor measure of the accuracy of the prediction model. In particular, this parameterization is not well suited for settings in which the prediction function incurs some small error at every node. This paper seeks to expand the understanding of graph exploration problems with predictions. We design algorithms which can be deployed on a variety of weighted graphs and prove worst-case guarantees on their performance. We also complement this analysis by providing lower-bounds for these problems, showing that the algorithms studied in this work are optimal or nearly optimal. In particular, we focus on two different error models. In the absolute error model, the magnitude of the error at a node is independent of that node’s true distance to the goal, and guarantees are given in terms of the total magnitude of the error incurred at every node. In the relative error model, nodes further from the goal may have larger deviation between the prediction and the truth, and algorithmic guarantees are parameterized by the maximum ratio of the error to the true distance at any vertex. Related Works Online graph searching problems have long been used as basic models for problems in autonomous navigation Berman (2005). Searching with access to predictions, also referred to as “advice” or “heuristics” in different communities, is a commonly studied variant (Pelc, 2002; Dobrev et al., 2012; Eberle et al., 2022; Banerjee et al., 2023). The problem and prediction settings considered in this work most closely correspond to those considered by Banerjee et al. (2023). This setup models applications in which predictions are the output of some machine-learning model. Recent years have seen a marked increase in the integration of machine learning techniques to enhance traditional algorithmic challenges (Angelopoulos et al., 2020; Gupta et al., 2022; Mitzenmacher and Vassilvitskii, 2022; Antoniadis et al., 2023). More generic forms of advice and the advice-complexity of exploration tasks are long-standing subjects of study. Komm et al. (2015) study the case when the the searcher receives generic advice, which can take the form of any bit string, and prove results about the advice complexity of this task. For a more detailed survey of related works, we direct the reader to Section A. Organization In Section 1.1 we formally state the main results of the paper. In Section 2 we present technical preliminaries and define relevant notation. Sections 3 and 4 contain algorithms and analysis for exploration under absolute and relative error models respectively. In Section 5 we derive new bounds in the planning setting via metric embeddings. Finally, in Section 6 we complement these results with numerical experiments. All missing proofs are in Section B of the supplementary material. 1.1 Summary Of Results We begin by formally describing the exploration and planning settings: The Exploration Problem In this setting, both the graph G and the predictions f are initially unknown to the agent: the agent is initialized with access to the root node r, the neighbors of r, and the predictions at all of these nodes. As the algorithm proceeds, on each iteration i it has access in memory to a subgraph Gi ⊆ G containing the nodes it has visited, the neighbors of those nodes, and any edges between visited nodes and neighbors. The searcher can only query predictions from nodes in the subgraph Gi. This problem models exploration of an unknown environment. The Planning Problem In this setting, both the graph G and the predictions f are fully known to the searcher upon initialization. For any algorithm which visits an ordered sequence of vertices v1, . . . , vT , we denote the algorithmic cost ALG def = P i∈T dGi(vi, vi+1). The guarantees in this paper compare ALG to the optimal cost a posteriori, denoted by OPT def = dG(r, g). Exploration Under Absolute Error A natural way of measuring the error of some predictions is the magnitude of the difference between the true distance-to-goal and prediction value at each node. In Section 3 we propose an algorithm for the exploration problem on weighted graphs and prove performance guarantees parameterized by these error measures. In particular, we prove the following theorem: 2 Theorem 1. There is an algorithm for searching arbitrary (potentially directed) graphs which finds the goal g by traveling a distance of at most OPT + E− 1 + n · E+ ∞, where E− 1 def = P v∈V max {0, d(v, g) − f(v)} and E+ ∞ def = maxv∈V max {0, f(v) − d(v, g)}. This algorithm enjoys several advantages over the most recent results on the exploration problem by Banerjee et al. (2023). Their work introduces an involved combinatorial algorithm for exploration on un- weighted trees whose performance is parametrized by the ℓ0 norm of the vector of errors. In particular, the guarantees of their algorithm are trivial when most or all nodes contain some (possibly very small) error, and they do not apply when the graph being searched is not an unweighted tree. In contrast, the algorithm proposed in the present work is intuitive and easily implementable, and the guarantees obtained hold in a wide variety of settings, e.g. when the graph is weighted and/or directed. The performance of the algorithm is parameterized by the natural absolute deviation (ℓ1) error measure. We also establish that under the above parameterization, the proposed algorithm is in some sense optimal (see Theorem 6). Further our analysis highlights that the same algorithm performs particularly well when (erroneous) predictions only underestimate distance to the true goal. Prediction functions with this property are referred to as admissible. They are key objects of study in path-finding literature and are well-motivated by applications (Dechter and Pearl, 1985; Eden et al., 2022; Ferguson et al., 2005; Pohl, 1969). Relative Errors One realistic setting for applications is one in which the error is proportionate to the magnitude of the distance to the goal. In order to capture this behavior, we consider a different error model in which the ratio of the error to true distance-to-goal at every vertex is assumed to be bounded by some value ε ∈ (0, 1): (1 − ε)d(v, g) ≤ f(v) ≤ (1 + ε)d(v, g). (1) We do not place any restriction on the total amount of error in the graph beyond this condition. We consider two regimes of multiplicative error. In the first setting, ε is assumed to be known to the searcher a priori. We propose an algorithm and show that it achieves the following competitive ratio: Theorem 2. Consider the exploration problem on a weighted tree where predictions satisfy (1) with respect to ε ∈ (0, 1), and ε is known. Then there exists an algorithm which succeeds in finding the goal g and incurs competitive ratio at most ALG OPT ≤ 1 1 − ε + nε · 4 (1 − ε)2 . In particular, if the predictions are admissible, then the same algorithm incurs competitive ratio ALG OPT ≤ 1 + nε · 2 1 − ε. In the second regime ε is assumed to be small (ε < 1/3) but its exact value is not assumed to be known. For this setting, we design a different algorithm which allows us to prove the following result: Theorem 3. Given G a weighted tree with predictions f satisfying Equation (1) for some unknown ε < 1/3, then Algorithm 3 with β = 2/3 incurs competitive ratio at most ALG OPT ≤ 2 + O \u0012 nε 5 + 3ε (1 − 3ε)2 \u0013 . In Section 4, we describe our algorithms for these problems, prove the above theorems, and complement these algorithmic guarantees with lowerbounds that show these algorithms are nearly optimal. Planning Problems Banerjee et al. (2023) consider problems in which both the full graph and all predic- tions are available to the algorithm upon initialization. This setting is referred to as the planning problem. They construct algorithms for this version of the problem under different error models and the guaran- tees they obtained are outlined in Table 1. In many regimes (e.g. planning on unweighted trees under error parametrized by the ℓ0-norm of the vector of errors, denoted E0, and planning on graphs under error parametrized by the ℓ1-norm of the vector of errors, denoted E1) matching lowerbounds for their algorithms 3 E0, unweighted E1, positive weights Trees with maximum degree ∆ upper bound OPT + O(∆E0) (†) OPT + O(∆E2 1) (integer distances) lower bound max {OPT, Ω(∆E0)} (†) max \b OPT, Ω(∆E2 1) \t Graphs with doubling dimension α upper bound OPT + 2O(α)O(E2 0) (†) OPT + 2O(α)O(E1) (†) lower bound Unknown max {OPT, Ω(2αE1)} Graphs with path- embedding distortion ρ upper bound OPT + O(ρE0) OPT + O(ρE1) lower bound Unknown max {OPT, Ω(ρE1)} Table 1: Known results for planning problem in different settings. (†) denotes results from Banerjee et al. (2023). ∆ denotes the maximum degree of any vertex in the graph, α denotes the doubling-dimension of the graph, and ρ denotes the distortion of the path-embedding on G. Banerjee et al. (2023) in their work note the absence of a matching lowerbound in the graph planning problem. This gap motivates this work’s study of planning bounds parameterized by metric embeddings, which yields a reduced asymptotic dependency on E0. For full discussions of lowerbounds for E1 parametrized by ∆, α, and ρ, see Lemmas 11 and 13, and Lemma 20 in Section B of the supplementary material. can be established, as shown in the table. A notable exception is the case of planning on unweighted graphs under E0 parametrization: they establish an upperbound of OPT + 2O(α)O(E2 0) where α is the doubling dimension of the graph. In particular, the lowerbounds they provide fail to match the depedence on the quadratic term E2 0 in their upperbound. We provide an alternative analysis of their algorithm based on metric properties of the instance graph which shows that in some classes of graphs one can reduce the asymptotic dependence on E0 from a quadratic to a linear factor. In particular, we consider the distortion of embedding the instance graph into a weighted path or cycle graph, and establish the following guarantee: Theorem 4. Consider G an unweighted graph such that G admits an embedding into a weighted path or a weighted cycle of distortion at most ρ. Then on G, the E0 planning algorithm of Banerjee et al. (2023) incurs cost at most OPT + O(ρE0). We note that the results present in Table 1 which were not proved by Banerjee et al. (2023) are established in this paper in Section 5 and the proved in the supplementary material. 2 Technical Preliminaries and Notation Graphs are assumed to be weighted and directed, unless otherwise specified. (Weighted) shortest-path distances in a graph G are denoted by dG(·, ·). Given a set S ⊆ V , let ∂S be its external vertex boundary: ∂S def = {v ∈ G \\ S | ∃u ∈ S : v ∼ u}. For a vertex set S ⊆ V , we denote by tourG(S) the (weighted) length of the shortest walk that visits all nodes in S: tourG(S) def = max v∈S min W ∈W(v,S) lengthG(W), (2) where W(v, S) is the set of walks in G starting at vertex v and visiting every vertex in S. Given a metric space (X, dX) its doubling constant is the minimum number λ such that, for every r > 0, every ball of radius r can be covered by at most λ balls of radius r/2 (Gupta et al., 2003). The doubling constant of a graph G is the doubling constant of (G, d) where d is the shortest path distance on G. The doubling dimension of the space, denoted α, is defined as α def = log2 λ. 4 Notation For Exploration Algorithms Recall that in exploration problems, the true graph G is initially unknown to the searcher. Thus in the setting of exploration, one needs to distinguish between the shortest known path distance between two vertices and the true shortest path distance. To this end, let Vi−1 be the set of vertices visited by iteration i and let Gi be the subgraph of G containing: all of the vertices in Vi−1 ∪ ∂Vi−1, and all of the edges adjacent to Vi−1. Throughout this paper, we emphasize the distinction between dGi and dG. In general, we have dGi ≥ dG. When analyzing performance, we denote the progress made on the ith iteration as ∆i def = dG(vi, g) − dG(vi+1, g). (3) Observe that, under the assumption that v0, v1, . . . , vT are nodes visited by some algorithm which originates at r and terminates at g (i.e. v0 = r and vT = g) we have: T −1 X i=0 ∆i = dG(r, g) − 0 = OPT. Metric Embeddings When analyzing the planning algorithms of Banerjee et al. (2023), we consider metric embeddings on graphs, and parametrize results in terms of the distortion of the relevant embedding: Definition 1 (Distortion). Given a function τ : X → Y between two finite metric spaces (X, dX) and (Y, dY ), we define the distortion dist(τ) of τ as the minimum value ρ satisfying the following: there exists a constant c > 0 such that for all x1, x2 ∈ X, c · dX(x1, x2) ≤ dY (τ(x1), τ(x2)) ≤ c · ρ · dX(x1, x2). 3 Exploration Under Absolute Error In this section we study the absolute error regime, in which the ℓ1 norm of the vector of errors is bounded by some constant E1, not necessarily known to the searcher. We consider the following natural rule: on the ith iteration, choose the next vertex to visit by picking the node vi ∈ ∂Vi−1 minimizing the sum of dGi(vi−1, vi) and f(vi) (See Algorithm 1). This iterative step can be interpreted as visiting the vertex that would be on the shortest path to the goal if all the predictions f(v) were correct. Algorithm 1 ℓ1-Greedy_Search(G, r) v0 ← r i ← 0 V0 ← {r} while vi ̸= g do i ← i + 1 vi ∈ argminv∈∂Vi−1 dGi(vi−1, v) + f(v) Vi ← {v0, ..., vi} end while We remark that because we are working in the exploration setting, Algorithm 1 does not have access to the true distances dG(·, ·) and must instead make use of dGi(·, ·) the distances in the subgraph of observed vertices at iteration i. Theorem 1 parametrizes the worst-case guarantees for Algorithm 1 in terms of the total negative error E− and the maximum-occurring positive error E+ ∞. This asymmetry corresponds to the intuition that positive errors can obstruct the search task more dramatically than negative errors by obscuring shortest paths to the goal. Indeed, an immediate corollary of Theorem 1 is the following result about the performance of Algorithm 1 in the setting in which the prediction function is admissible (i.e. error is only negative): 5 Corollary 5. Consider the problem of searching a weighted (possibly directed) graph with predictions f satisfying f(v) ≤ dG(v, g) ∀v ∈ V Then there exists an algorithm which finds the goal g with cost at most OPT + E1, where E1 is the total ℓ1 error in the predictions, i.e. E1 def = P v∈V |f(v) − d(v, g)|. The dependency on E− and E+ ∞ in Theorem 1 is optimal in the following sense: Theorem 6. For every E− > 0, there exist graph search instances with total negative error E− such that any algorithm for the exploration problem on these instances must incur cost at least OPT+E− in the worst case. Additionally, for any n > 3 and any E+ ∞, there exist graph search instances on n nodes with maximum positive error E+ ∞ such that any algorithm for the exploration problem on these instances must incur cost at least OPT + E+ ∞(n − 2) in the worst case. We note that the lower bound in Theorem 6 also holds for the expected distance travelled of randomized search strategies, up to constant factors, as per the following result. Proposition 7. For every E− > 0 there exists a graph search instance with total negative error E− such that any randomized algorithm incurs expected costs at least OPT+ 1 2E− on this instance. Moreover, for any n > 3 and any E+ ∞ there exists a graph search instance on n nodes with maximum positive error E+ ∞ such that any randomized algorithm must incur expected cost at least OPT + (n − 2)E+ ∞/2 on this instance. The full proof of Theorem 1 and the proof of Corollary 5, given in Section B, rely on a charging argument which shows that distance travelled away from the goal can be directly attributed to errors in the predictions of observed nodes. The proof of Theorem 6 and Proposition 7 are constructive and can also be found in Section B. For completeness we now sketch the proof of Theorem 1. The proof considers the progress ∆i as in Equation (3), which measures how much closer the agent is to the goal after the ith iteration of the algorithm. The cost of the algorithm is given by ALG = P i∈[T ] dGi(vi−1, vi). At each step i ∈ [T], one can show that the distance travelled dGi(vi−1, vi) in the observed subgraph Gi is bounded above by the sum of three terms: dGi(vi−1, vi) ≤ ∆i + E−(vi) + E+(wi), (4) where E−(vi) is the negative error at vi, and E+(wi) is the positive error at some vertex wi on a shortest path from vi−1 to g. In particular, all three terms in this upper bound are independent of the observed subgraph Gi. The statement of the theorem then follows by summing both sides of Equation (4) over all i ∈ [T]. 4 Exploration Under Relative Error In this section, we consider the setting when the prediction function satisfies Equation (1) for every v ∈ V . We assume that ε ∈ (0, 1): in particular, if ε ≥ 1, then f(v) = 0 is a valid prediction at every vertex and no exploration algorithm can avoid visiting the entire graph in the worst case. If ε is known to the searcher a priori then given access to the prediction at a node, the searcher can construct an upper bound on the true distance-to-goal. On trees this allows one to limit exploration to a ball of some radius R (dependent on ε and OPT) around the initial vertex, effectively “pruning” distant nodes from the vertex set. In particular, one could limit their search to the set: Sε,r def = \u001a v ∈ V | dG(v, r) ≤ 1 1 − εf(r) \u001b . (5) We couple this observation with the algorithm in the previous section and obtain the following algorithm. 6 Algorithm 2 ε-Known_Search(G, r, ε) v0 ← r i ← 0 V0 ← {r} while vi ̸= g do i ← i + 1 vi ∈ argminv∈∂Vi−1∩Sε,r dGi(vi−1, v) + f(v) Vi ← {v0, ..., vi} end while In Section B we leverage favorable properties of the set Sε,r to show that Algorithm 2 satisfies the guarantees of Theorem 2. We observe that in particular, Theorem 2 implies that for any n the competitive ratio incurred by Algorithm 2 tends to 1 as ε → 0. The combination of the truncation with the shortest-path rule in Algorithm 2 was necessary to secure this property: for example, a simple scheme such as running breadth-first-search on the truncated set Sε,r would not enjoy such a guarantee in the worst case. We note that Algorithm 2 crucially relies on the fact that the searcher knows the value of ε and so it cannot be deployed in the setting where ε is unknown. For the latter regime we propose an alternative algorithm, also based on Algorithm 1, which provably succeeds for unknown values of ε under the assumption that ε is small, e.g. ε < 1/3. Algorithm 3 ε-Unknown_Weighted_Search(G, r, β) v0 ← r i ← 0 V0 ← {r} while vi ̸= g do i ← i + 1 vi ∈ argminv∈∂Vi−1 βdGi(vi−1, v) + f(v) Vi ← {v0, ..., vi} end while In Section B we show that on trees this reweighting scheme ensures that Algorithm 3 never explores nodes which are far from the goal and use this property to establish the guarantees in Theorem 3 under the setting where β = 2/3. We give a lower bound to establish that Algorithm 2 is almost optimal. Specifically, we show that even when ε is known a-priori, the asymptotic dependence on n · ε is tight up to factors of 1/(1 − ε): Theorem 8. For all n sufficiently large (n ≥ 6) and for any ε ∈ (0, 1), there exists an instance I of the exploration on weighted trees G with predictions (1), such that any algorithm for the exploration problem on G must incur cost ALG ≥ (1 + nε)OPT on I. Note that this lower bound also applies to the regime addressed by Algorithm 3. Moreover, one can prove an analogous lower bound for the case of potentially randomized exploration strategies, as per the following result. Proposition 9. For all n sufficiently large (n ≥ 6) and for any ε ∈ (0, 1), there exists an instance I of the exploration on weighted trees G with predictions (1), such that any randomized algorithm for the exploration problem on G must incur cost ALG ≥ (1 + nε 2 )OPT on I. 4.1 Planning With Relative Error Under the model of relative error described by Equation (1), planning problems become either trivial or impossible, with no intermediate regimes. In the context of predictions f(v) = (1 + εv)dG(v, g) for some εv ∈ [−ε, ε], we observe that it must be that f(g) = 0, independent of the value of ε. For the planning problem to be nontrivial, there must also occur vertices v ̸= g such that f(v) = 0. Thus, for nontrivial instances of the planning problem in this regime, ε ≥ 1. However, instances with such (large) values of ε are 7 hopeless in the worst case: such a setting allows for the prediction of every node to be set equal to 0, a case which forces the searcher to visit every node in the worst case. 5 Planning 5.1 Planning Bounds Via Metric Embeddings In this section, we analyze the performance of the algorithm by Banerjee et al. (2023) for the planning problem, as a function of how similar the target graph is to some graph G′ admitting inexpensive tours. In the planning problem, the full graph G as well as all predictions f are made available to the algorithm upon initialization. Banerjee et al. (2023) study the implied error functions ϕ0 : V → R and ϕ1 : V → R, defined as ϕ0(v) def = |{u ∈ V : f(u) ̸= dG(u, v)}| and ϕ1(v) def = X u∈V |f(u) − dG(u, v)|. Banerjee et al. (2023) consider an algorithm that iteratively visits sublevel sets of ϕ0 or ϕ1 respectively, for geometrically increasing thresholds (see Algorithm 4). Their algorithm is very simple: for every threshold, it visits every node in the sublevel set before increasing to the next threshold value. Algorithmically, Banerjee et al. (2023) accomplish this by computing a minimum length Steiner tree of the sublevel set, which is in general not computationally efficient. However, one can replace this computationally expensive procedure with a polynomial-time constant factor approximation (see e.g. (Karlin et al., 2021)), which preserves the asymptotic upper bound on the algorithms’ performance. Algorithm 4 FullInfoX (G, r, ϕ) from Banerjee et al. (2023) Vi ← r λ ← 0 while g ̸∈ Vi do Vi ← Vi ∪ L− ϕ (2λ) Compute a minimum length Steiner tree of Vi and perform an Euler tour of the tree λ ← λ + 1 end while This definition of Algorithm 4 motivates our analysis, which focuses on the distortion of embedding the instance graph into some graph G′ which admits inexpensive tours. Recall the definition of tourG(S) as in Equation (2). Definition 2 (Easily-tourable). A graph G′ = (V ′, E′) is c-easily-tourable for some c > 0 if for any S′ ⊆ V ′, tourG′ ≤ c · diam(S′). In Section B, we establish that in easily-tourable graphs the algorithm of Banerjee et al. enjoys good performance. We then show that if a graph G can be embedded into an easily-tourable graph G′ with distortion ρ, then G itself must be easily-tourable with tour costs that scale with ρ. This culminates in the following result: Lemma 10. Given G an unweighted graph, if G admits an embedding τ : G → G′ of distortion ρ for G′ some cG′-easily-tourable graph, then Algorithm 4 with objective ϕ = ϕ0 from Banerjee et al. (2023) incurs cost at most OPT+O(ρ·cG′ ·E0). If G has integer-valued distances and admits an embedding of distortion ρ into G′ some easily-tourable graph, then Algorithm 4 with objective ϕ = ϕ1 incurs cost at most OPT + O(ρ · cG′ · E1). In particular, (weighted) paths and cycles are easily-tourable with respect to constant c, resulting in the guarantees in Theorem 4. In Section C we give results suggesting that our analysis of planning problems via metric embeddings is a refinement of the analysis of Banerjee et al. (2023). 8 1 1 r 1 1 1 1 ... ... ... ... ... ... W W W W W W W W W W W W 1 1 1 1 1 1 1 1 1 1 1 1 g Figure 1: The lower bound construction for the proof of Lemmas 11 and 13. 5.2 Lowerbounds For Planning In this section, we provide lowerbounds that extend the results in Banerjee et al. (2023). Consider the planning problem on some weighted graph G with integer weights2 where prediction error is parameterized by E1. Banerjee et al. (2023) propose an algorithm which provably incurs cost at most OPT+O(E1poly(λ)), where λ is the doubling constant of the input graph. We provide complementary lower bounds by establishing the following result: Lemma 11. Let A be any algorithm for the planning problem which is guaranteed to incur cost: OPT + O(Ea 1 λb) for some a, b ∈ R when run on a weighted graph G with doubling constant λ, and with a error vector ⃗e such that ∥e∥1 = E1. Then it must be the case that a ≥ 1. Moreover, if a = 1, then b ≥ 1. Our lowerbounds are constructive, and consider a family of graphs illustrated in Figure 1. A full proof can be found in Section B. It is known that the doubling constant is always at least as large as the maximum degree but we note that in general it may be much larger even if one restricts themselves to trees. We analyze the algorithm of Banerjee et al. (2023) and prove that in trees with integer weights performance of their algorithm can be bounded in terms of maximum degree, at the cost of paying a higher asymptotic dependence on E1: Lemma 12. Given G a tree with integer-valued distances and maximum degree ∆, consider the planning problem on G with predictions satisfying E1 ≥ 1. Then on this problem instance Algorithm 4 with objective ϕ = ϕ1 from Banerjee et al. (2023) incurs cost at most OPT + O(∆E2 1). We establish corresponding lowerbounds via a similar construction to that in Lemma 11: Lemma 13. Let A be any algorithm for the planning problem on trees with integer weights which is guar- anteed to incur cost: OPT + O(Ea 1 ∆b) for some a, b ∈ R when run on a tree G with maximum degree ∆ and with a prediction vector ⃗e such that ∥e∥1 = E1. Then it must be the case that a ≥ 1 and b ≥ 1. Moreover, it must be that a + b ≥ 3. 2We note that the analysis of Banerjee et al. for the above setting also appears to go through for the case non-integer weights, and that the lowerbound provided by Lemma 11 would then hold for that setting too. 9 6 Numerical Experiments: Impact of Random Errors Throughout this paper we have focused on worst-case theoretical guarantees. In this section, we provide numerical results exploring the effectiveness of Algorithms 1 and 3 on exploration problems beyond the worst-case setting, particularly under random errors. The experiments show that in addition to being robust to adversarial error, the algorithms considered perform well in instances with stochastic error. Moreover, we find that although the guarantees for Algorithm 3 were shown only for trees, empirically the algorithm also succeeds on general (cyclic) graphs. These results suggest that Algorithms 1 and 3 could be deployed effectively for exploration problems in practice. We study the performance of Algorithm 1 in the absolute regime and Algorithm 3 in the relative regime. In the left subfigure of Figure 2 we plot the performance of Algorithm 1 for different graph topologies when the error is sampled at random in an absolute fashion. We plot the performance against the total ℓ1-norm of the error vector. In the right subfigure of Figure 2 we explore the performance of Algorithm 3 against relative error. Once again, we find that the algorithm enjoys empirical performance superior to that predicted by the worst-case upper bound. In particular, the gap between the worst-case bound and the average empirical performance is consistent over families of graphs with very different topologies. In Table 2 we report the average ratio of algorithmic cost incurred to value of the upper-bound in Theorem 1 (given as a percentage). We compute this percentage for different classes of graphs over 100 runs of these experiments when the error, initial node and goal node, and graph structure (when applicable) have been sampled at random. Figure 2: Performance of Algorithms 1 and 3 against random errors. Experimental procedures are detailed in Section D. The number of nodes is fixed over all graph topologies and error settings. LEFT: Average and standard deviation of ALG − OPT incurred by Algorithm 1 over 2000 independent random trials for varying values of E1. RIGHT: Average and standard deviation of ALG/OPT incurred by Algorithm 3 over 2000 independent random trials for varying values of ε. We also empirically compare the performance of Algorithm 1 to another natural heuristic, which we call Smallest Prediction. In Smallest Prediction, the agent always travels to the vertex v in ∂Vi−1 with the smallest value of the prediction function f(v). While our theoretical results already show that Algorithm 1 achieves optimal performance in the worst-case, we show that our algorithm performs better than Smallest Prediction in the presence of random error across a variety of graph topologies. In Figure 3, we plot the average performance of Algorithm 1 against the performance of Smallest Prediction (measured as the distance travelled by the agent, minus OPT, as a fraction of of OPT) in random trees with 100 vertices for a growing value of the magnitude E1 of the error vector. More details on this comparison can be found in the supplementary material. Further details of our experiments, including details on the error models and the graph families being used in the experiments can be found in Section D in the supplementary material. 10 Algorithm 1 Smallest Prediction (ALG-OPT)/OPT Figure 3: A comparison of the performance of Algorithm 1 with the Smallest Prediction heuristic. We plot the average and the standard deviation of the performance of Algorithm 1 and that of the Smallest Prediction heuristic against the magnitude of the error vector E1. Experiments in this figure were conducted on random trees; for analogous results on other graph topologies, see Figure 9 in Appendix D. GRAPH FAMILY Random Lobster Erdös Rényi Random Tree Circular Ladder COST(%) 2.4 ± 2.5 3.1 ± 4.3 1.7 ± 2.3 0.7 ± 0.5 Table 2: Average empirical cost of running Algorithm 1 as a percentage of the upperbound in Theorem 1 for different family of graphs. Experiments performed on graphs with 300 nodes. These results demonstrate that when run with randomly-generated errors, the actual cost incurred by the algorithm is a very small fraction of the upperbound. 7 Conclusions and Future Directions In this work we have introduced new general algorithms for the problem of searching in an unknown graph. Under the absolute error model we design algorithms which succeed in a broad class of graphs and prove that these algorithms are optimal (Section 3). We then move beyond the absolute error regime and consider relative error; to the best of the authors’ knowledge, this work is the first to address the exploration problem under this natural error model. Within this setting we propose algorithms for the exploration problem on weighted trees and show that their performance is nearly-optimal (Section 4). We complement our advances in the exploration setting by expanding the landscape of results for the planning problem. We extend the work of Banerjee et al. (2023) by providing alternative performance guarantees which establish a linear–rather than quadratic–dependency on the error parameter E0 in some graph families, and which suggests that such a lower asymptotic dependency may be attainable in general (Theorem 4). We also complete the results of Banerjee et al. in the planning setting on integer-distance graphs by proving one cannot improve the factor of E1 in their upperbound and that achieving this linear dependence on the error requires cost linear in the doubling constant λ of the instance graph (Lemma 11). The work in this paper directly suggests several avenues for further study. While our lowerbounds demonstrate the impossibility of uniformly improving the results in Theorem 1, it is possible the bound may be overly pessimistic in certain classes of graphs; it would be interesting to consider whether making stronger structural assumptions about the instance graph would yield better guarantees. In the setting of relative error, an immediate open problem is whether the guarantees on Algorithms 2 and 3 can be extended to more general graphs. In order to improve understanding of the planning problem, a complete characterization of easily-tourable graphs would better contextualize Lemma 10. Finally, while the numerical results suggest the algorithms proposed in this paper perform well under random errors, formal guarantees studying this 11 setting would be a valuable addition. References A. Aamand, J. Y. Chen, and P. Indyk. (Optimal) Online Bipartite Matching with Degree Information. In Advances in Neural Information Processing Systems, volume 35, 2022. S. Alpern and S. Gal. The theory of search games and rendezvous, volume 55. Springer Science & Business Media, 2006. K. Anand, R. Ge, and D. Panigrahi. Customizing ml predictions for online algorithms. In International Conference on Machine Learning, pages 303–313, 2020. S. Angelopoulos, C. Dürr, S. Jin, S. Kamali, and M. Renault. Online computation with untrusted advice. In 11th Innovations in Theoretical Computer Science Conference (ITCS 2020). Schloss Dagstuhl-Leibniz- Zentrum für Informatik, 2020. A. Antoniadis, C. Coester, M. Eliáš, A. Polak, and B. Simon. Online metric algorithms with untrusted predictions. ACM Transactions on Algorithms, 19(2):1–34, 2023. E. Bamas, A. Maggiori, and O. Svensson. The primal-dual method for learning augmented algorithms. Advances in Neural Information Processing Systems, 33:20083–20094, 2020. S. Banerjee, V. Cohen-Addad, A. Gupta, and Z. Li. Graph searching with predictions. In 14th Innovations in Theoretical Computer Science Conference, ITCS, volume 251 of LIPIcs, pages 12:1–12:24, 2023. P. Berman. On-line searching and navigation. Online Algorithms: The State of the Art, pages 232–241, 2005. A. Bhattacharya, B. Gorain, and P. S. Mandal. Treasure hunt in graph using pebbles. In International Symposium on Stabilizing, Safety, and Security of Distributed Systems, pages 99–113. Springer, 2022. S. Bouchard, Y. Dieudonne, A. Labourel, and A. Pelc. Almost-optimal deterministic treasure hunt in arbitrary graphs. In International Colloquium on Automata, Languages and Programming (ICALP) 2021, 2021. J. Y. Chen, T. Eden, P. Indyk, H. Lin, S. Narayanan, R. Rubinfeld, S. Silwal, T. Wagner, D. P. Woodruff, and M. Zhang. Triangle and four cycle counting with predictions in graph streams. In 10th International Conference on Learning Representations, ICLR, 2022. E. Cohen, O. Geri, and R. Pagh. Composable sketches for functions of frequencies: Beyond the worst case. In Proceedings of the 37th International Conference on Machine Learning, 2020. R. Dechter and J. Pearl. Generalized best-first search strategies and the optimality of A*. Journal of the ACM (JACM), 32(3):505–536, 1985. I. Diakonikolas, V. Kontonis, C. Tzamos, A. Vakilian, and N. Zarifis. Learning online algorithms with distributional advice. In International Conference on Machine Learning, pages 2687–2696, 2021. S. Dobrev, R. Královič, and E. Markou. Online graph exploration with advice. In International Colloquium on Structural Information and Communication Complexity, pages 267–278. Springer, 2012. E. Du, F. Wang, and M. Mitzenmacher. Putting the “learning\" into learning-augmented algorithms for frequency estimation. In Proceedings of the 38th International Conference on Machine Learning, pages 2860–2869, 2021. F. Eberle, A. Lindermayr, N. Megow, L. Nölke, and J. Schlöter. Robustification of online graph exploration methods. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 9732–9740, 2022. 12 T. Eden, P. Indyk, S. Narayanan, R. Rubinfeld, S. Silwal, and T. Wagner. Learning-based support estimation in sublinear time. In 9th International Conference on Learning Representations, ICLR, 2021. T. Eden, P. Indyk, and H. Xu. Embeddings and labeling schemes for a. In 13th Innovations in Theoretical Computer Science Conference (ITCS 2022). Schloss Dagstuhl-Leibniz-Zentrum für Informatik, 2022. P. Erdős, A. Rényi, et al. On the evolution of random graphs. Publ. math. inst. hung. acad. sci, 5(1):17–60, 1960. D. Ferguson, M. Likhachev, and A. Stentz. A guide to heuristic-based path planning. In Proceedings of the international workshop on planning under uncertainty for autonomous systems, international conference on automated planning and scheduling (ICAPS), pages 9–18, 2005. P. Ferragina and G. Vinciguerra. Learned data structures. In Recent Trends in Learning From Data: Tutorials from the INNS Big Data and Deep Learning Conference (INNSBDDL2019), pages 5–41. Springer, 2020. D. Foead, A. Ghifari, M. B. Kusuma, N. Hanafiah, and E. Gunawan. A systematic literature review of A* pathfinding. Procedia Computer Science, 179:507–514, 2021. B. Gorain, K. Mondal, H. Nayak, and S. Pandit. Pebble guided optimal treasure hunt in anonymous graphs. Theoretical Computer Science, 922:61–80, 2022. A. Gupta, R. Krauthgamer, and J. R. Lee. Bounded geometries, fractals, and low-distortion embeddings. In 44th Annual IEEE Symposium on Foundations of Computer Science, 2003. Proceedings., pages 534–543. IEEE, 2003. A. Gupta, D. Panigrahi, B. Subercaseaux, and K. Sun. Augmenting online algorithms with ε-accurate predictions. Advances in Neural Information Processing Systems, 35:2115–2127, 2022. C. Hsu, P. Indyk, D. Katabi, and A. Vakilian. Learning-based frequency estimation algorithms. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019, 2019. P. Indyk, A. Vakilian, and Y. Yuan. Learning-based low-rank approximations. In Advances in Neural Information Processing Systems, pages 7400–7410, 2019. T. Jiang, Y. Li, H. Lin, Y. Ruan, and D. P. Woodruff. Learning-augmented data stream algorithms. In International Conference on Learning Representations, 2020. B. Kalyanasundaram and K. R. Pruhs. Constructing competitive tours from local information. Theoretical Computer Science, 130(1):125–138, 1994. A. R. Karlin, N. Klein, and S. O. Gharan. A (slightly) improved approximation algorithm for metric tsp. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, pages 32–45, 2021. D. Komm, R. Královič, R. Královič, and J. Smula. Treasure hunt with advice. In Structural Information and Communication Complexity: 22nd International Colloquium, SIROCCO 2015, Montserrat, Spain, July 14-16, 2015. Post-Proceedings 22, pages 328–341. Springer, 2015. T. Kraska, A. Beutel, E. H. Chi, J. Dean, and N. Polyzotis. The case for learned index structures. In Proceedings of the 2018 International Conference on Management of Data, pages 489–504, 2018. Y. Li, H. Lin, S. Liu, A. Vakilian, and D. Woodruff. Learning the positions in countsketch. In The Eleventh International Conference on Learning Representations, 2023. H. Lin, T. Luo, and D. Woodruff. Learning augmented binary search trees. In International Conference on Machine Learning, pages 13431–13440. PMLR, 2022. T. Lykouris and S. Vassilvitskii. Competitive caching with machine learned advice. In International Con- ference on Machine Learning, pages 3302–3311, 2018. 13 N. Megow, K. Mehlhorn, and P. Schweitzer. Online graph exploration: New results on old and new algo- rithms. Theoretical Computer Science, 463:62–72, 2012. M. Mitzenmacher. A model for learned bloom filters and optimizing by sandwiching. In Advances in Neural Information Processing Systems, pages 464–473, 2018. M. Mitzenmacher and S. Vassilvitskii. Algorithms with predictions. Communications of the ACM, 65(7): 33–35, 2022. P. Paliwal. A survey of a-star algorithm family for motion planning of autonomous vehicles. In 2023 IEEE International Students’ Conference on Electrical, Electronics and Computer Science (SCEECS), pages 1–6. IEEE, 2023. A. Pelc. Searching games with errors—fifty years of coping with liars. Theoretical Computer Science, 270 (1-2):71–109, 2002. I. Pohl. Bi-directional and heuristic search in path problems. Technical report, Stanford Linear Accelerator Center, Calif., 1969. M. Purohit, Z. Svitkina, and R. Kumar. Improving online algorithms via ml predictions. In Advances in Neural Information Processing Systems, pages 9661–9670, 2018. L. H. O. Rios and L. Chaimowicz. A survey and classification of A* based best-first heuristic search algo- rithms. In Brazilian Symposium on Artificial Intelligence, pages 253–262. Springer, 2010. A. Wei and F. Zhang. Optimal robustness-consistency trade-offs for learning-augmented online algorithms. Advances in Neural Information Processing Systems, 33:8042–8053, 2020. A. C.-C. Yao. Probabilistic computations: Toward a unified measure of complexity. In 18th Annual Sympo- sium on Foundations of Computer Science (sfcs 1977), pages 222–227. IEEE Computer Society, 1977. A Survey of Related Works Graph search with distance-to-goal predictions The problem and prediction settings considered in this work most closely correspond to those considered by Banerjee et al. (2023). Banerjee et al. (2023) study exploration and planning under absolute error models. They consider two parametrizations of prediction error: the first in terms of the number of nodes at which predictions are not equal to true distance-to-goal, denoted E0, and the second in terms of the ℓ1 norm of the vector of errors, denoted E1 as in this work. They develop an algorithm for exploration on unweighted trees, and prove guarantees on its performance in terms of E0. They also develop algorithms for planning on graphs: on unweighted graphs, they establish guarantees parameterized by E0, while in graphs with integer-valued distances their performance bounds are parameterized by E1. Treasure Hunt In the treasure hunt problem, a mobile agent must traverse some unknown environment, continuous or discrete, to locate a stationary hidden goal (Alpern and Gal, 2006). When the search en- vironment is a graph, this problem shares many features with the exploration problem considered in this paper. Bouchard et al. (2021) study the graph treasure hunt problem when the searcher receives no addi- tional information. They establish lower bounds on the total cost incurred by any algorithm in terms of the number of edges in the ball of radius OPT around the root node, and give algorithms with performance guarantees which asymptotically exceed these lower bounds by at most a factor of log(OPT). Graph treasure hunt problems have also been considered when the agent receives help with the task. Komm et al. (2015) study the case when the the searcher receives generic advice, which can take the form of any bit string. They consider the advice complexity of the treasure hunt task; they prove that there is an algorithm which achieves competitive ratio r by receiving O(n/r) bits of advice along the search and moreover they establish that any algorithm achieving a competitive ratio of r must receive Ω(n/r) bits of advice (see Theorems 4 and 5 in Komm et al. (2015)). In the setting where graph vertices are anonymized, i.e. the searcher has no 14 Figure 4: Comparing Algorithm 1 versus A∗ search on a random tree with randomly generated errors. The same set of predictions is provided to both algorithms. While the set of nodes visited by the two algorithms is comparable, the computational model in A∗ places no penalty on traversal distance so that algorithm has a tendency to double-back on itself, leading to a more expensive tour. Nodes are colored by prediction value and labeled with the order in which they are first visited by the relevant algorithm. Tour cost is taken to be P d(vi, vi+1) for indices i ordered according to when a node is first visited: the tour cost for A∗ omits costs incurred by re-expanding a node within the execution of the algorithm. way to recognize whether a vertex has or has not previously been visited, recent work has studied the task of graph treasure hunt with access to advice from an omniscient oracle which marks vertices with binary labels (Bhattacharya et al., 2022; Gorain et al., 2022). The exploration model studied in this paper can be viewed as a graph treasure hunt problem with specific kinds of advice (predictions of distance-to-goal). One main contrast with this work is that the advice considered can contain adversarial errors, and indeed the impact that different error models have on the graph exploration task is a core topic investigated in this work. Path-Planning and A∗ Search Distance-to-goal predictions have been the subject of study in many path-planning and graph-traversal settings. Initialized with a root node and some known target node, path- planning problems seek to learn a shortest path between the root and goal and common problem models assume access to a set of distance-to-goal predictions, referred to as “heuristics” within this literature Pohl (1969); Ferguson et al. (2005). A∗ search is a celebrated algorithm for the problem of path-finding and graph-traversal, designed for cases when the entire graph G and all predictions f are accessible in memory, and has spawned many algorithmic variants (Rios and Chaimowicz, 2010; Foead et al., 2021; Paliwal, 2023). Much of the theory of A∗ search focuses on cases when predictions have particular structural properties: a prediction function f : V → R is called admissible if the prediction at every node v is never greater than the actual distance to the goal from v. A prediction function f : V → R is consistent (or monotone) if for every node v and every neighbor u of v, f(v) ≤ f(u)+d(v, u) and f(g) = 0. Consistency is studied so heavily in part because it implies admissibility. Admissible heuristics are well-motivated and occur in various other problems. For example, Eden et al. (2022) consider access to an oracle that provides an underestimate for the probabilities of any element in some discrete probability distribution. In addition to being well-motivated by applications, admissibility is a focus of literature because A∗ search with admissible heuristics enjoys optimality properties (Dechter and Pearl, 1985). While many of the problems and algorithms within path-planning may appear closely related to this work at first-glance, we emphasize that the goals and cost models differentiate the graph searching problems considered in this work from those in path-planning. In particular, the design and algorithmic guarantees on path-planning algorithms like A∗ search implicitly assume that the full graph and predictions are available in memory upon initialization of the algorithm. Performance guarantees and notions of optimality are proven in terms of computational procedures, rather than traversal distance. For example, when predictions are 15 admissible A∗ is optimal in the sense that the set of nodes expanded (an operation analogous to visiting a node) is minimal (Dechter and Pearl, 1985). However, the sequence in which these nodes are expanded can incur high traversal distance, as illustrated in Figure 4. More generally, the goals of algorithms for path-planning differ substantially from that in the graph search problem: the path-finding problem seeks to learn and return a shortest path even if the process required to find such a path is expensive in the sense of graph traversal, whereas the aim of a graph searching problem is finding the goal node in an inexpensive manner and makes no demand that a shortest path from the root node to the goal be in the set of visited nodes upon termination of the algorithm. These differences in goals and algorithmic guarantees mean that in cases when the environment is unknown, i.e. when the graph and predictions are not available in memory but must instead by accessed by traversal, path-planning algorithms may incur much higher traversal cost than the graph search algorithms proposed in this paper. Learning-Based Algorithms. Recent years have seen a marked increase in the integration of machine learning techniques to enhance traditional algorithmic challenges. Such algorithms have been developed for various topics including online algorithms Lykouris and Vassilvitskii (2018); Purohit et al. (2018); An- gelopoulos et al. (2020); Wei and Zhang (2020); Bamas et al. (2020); Aamand et al. (2022); Antoniadis et al. (2023); Anand et al. (2020); Diakonikolas et al. (2021); Gupta et al. (2022), data structures Kraska et al. (2018); Mitzenmacher (2018); Ferragina and Vinciguerra (2020); Lin et al. (2022), and streaming models Hsu et al. (2019); Indyk et al. (2019); Jiang et al. (2020); Cohen et al. (2020); Du et al. (2021); Eden et al. (2021); Chen et al. (2022); Li et al. (2023). For an extensive collection of learning-based algorithms, refer to the repository at https://algorithms-with-predictions.github.io/. B Missing Proofs In this section, we present detailed proofs of the results in the main body of the paper. B.1 Proofs For Section 3 Proof of Theorem 1 and Corollary 5. Algorithm 1 follows a shortest path in Gi from vi−1 to vi. A simple consequence of this is that: ALG = X i∈[T ] dGi(vi−1, vi). Let ∆i def = dG(vi−1, g) − dG(vi, g), and let T be the number of iterations of the while loop executed, so that vT = g. We then have: X i∈[T ] ∆i = dG(v0, g) − dG(vT , g) = dG(v0, g) − dG(g, g) = OPT . Consider any iteration i ∈ [T]. Let wi be the first vertex outside of Vi−1 encountered when traversing a shortest path from vi−1 to g. Note that wi ∈ ∂Vi−1, and hence, by the update rule in Algorithm 1 we have: f(vi) + dGi(vi−1, vi) ≤ f(wi) + dGi(vi−1, wi). (6) Furthermore, by the definition of wi, we have: dGi(vi−1, wi) = dG(vi−1, wi). (7) The above follows from a simple contradiction argument, for the existence of a shorter path from vi−1 to wi in G which is not in Gi, would contradict the definition of wi. We also have: dG(vi−i, g) = dG(vi−1, wi) + dG(wi, g). (8) We then have, for any i ∈ [T]: dG(vi, g) − f(vi) (6) ≥ dG(vi, g) + dGi(vi−1, vi) − dGi(vi−1, wi) − f(wi) 16 (7) = dG(vi, g) + dGi(vi−1, vi) − dG(vi−1, wi) − f(wi) = dG(vi−1, g) − ∆i + dGi(vi−1, vi) − dG(vi−1, wi) − f(wi) (8) = dGi(vi−1, vi) − ∆i + dG(wi, g) − f(wi). Note that the vertices in the sequence {vi}i∈[T ]∪{0} are always distinct, while the vertices in the sequence {wi}i∈[T ] might not be. This also implies that T ≤ n. The above then implies: ALG = X i∈[T ] dGi(vi−1, vi) ≤ X i∈[T ] ∆i + dG(vi, g) − f(vi) + f(wi) − dG(wi, g) = X i∈[T ] ∆i + X i∈[T ] dG(vi, g) − f(vi) + X i∈[T ] f(wi) − dG(wi, g) ≤ OPT + E− 1 + T · E+ ∞ ≤ OPT + E− 1 + n · E+ ∞. This completes the proof of Theorem 1. When predictions are admissible, E− 1 = E1 and E+ ∞ = 0 so Corollary 5 follows. Proof of Theorem 6. We begin by proving the first half of the theorem. Given E− 1 > 0 one considers the three-vertex graph path P3 where the two edges are weighted with weight w = E−/2, the start vertex / root is chosen to be the middle vertex and the goal is one of the other two vertices (see left side of Figure 5). Note that the value of OPT is dG(r, g) = w. When the predictions on the vertices are given by: f(v1) = 0 , f(v2) = w and f(v3) = 0, the error is equal to E− and the graph looks completely symmetric to the searcher, and hence in the worst case to find the goal, the searcher has to incur a cost of 3w = w + 2w = OPT + E− as needed. For the second part of the theorem, we construct a star on n vertices, where each edge has weight w = E+ ∞/2, the starting vertex is at the center of the star, and the goal is chosen arbitrarily among the other vertices. The prediction at the goal is then picked to equal E+ ∞ so that it equals the prediction in all other vertices, i.e. we set the predictions to f(r) = w and f(v) = 2w for all w ̸= r. Every algorithm will then have to visit the entire star in the worst case, incurring a cost of E+ ∞/2 + E+ ∞(n − 2) = OPT + E+ ∞(n − 2) as needed (See the right side of Figure 5). Proof of Proposition 7. We apply Yao’s minimax principle (Yao, 1977) to the same constructions used in the proof of Theorem 6. For both constructions, we consider the distribution over instances produced by choosing the goal node uniformly at random among the leaf nodes. In particular, for the first statement, we consider the performance of any deterministic algorithm on the distribution of instances given by taking the three-node path graph on the left-hand side of Figure 5, and placing the goal g at either v1 or v3 with equal probability. We fix predictions f(v1) = f(v3) = 0 and f(v2) = w as in the proof of Theorem 6. The expected cost incurred by any deterministic algorithm over this distribution of instances is 2w = OPT + w = OPT + 1/2E−. Yao’s minimax principle then implies the stated lower bound for all randomized algorithms. The proof of the second result follows analogously by considering the second construction in the proof of Theorem 6. B.2 Proofs For Section 4 B.2.1 Algorithmic Guarantees Under Relative Error We begin the analysis of Algorithm 2 by establishing the following properties of the set Sε,r defined in Equation (5). For G a tree, let PG(u, v) denote the (unique) shortest path between nodes u and v in G. Lemma 14. For Sε,r as defined in (5) and G a weighted tree, then the following hold: 17 w w v1 v2 v3 r g w w v1 v2 v3 r g w w v4 w v5 w v(n−1) vn · · · Figure 5: The construction in the proof of Theorem 6. (i) ∀v ̸∈ Sε,r, dG(v, r) > OPT, (ii) ∀v ∈ Sε,r, dG(v, r) ≤ 1+ε 1−ε · OPT, (iii) ∀v ∈ Sε,r, dG(v, g) ≤ 2 1−ε · OPT, (iv) PG(r, g) ⊆ Sε,r, (v) For any v ∈ Sε,r, PG(v, g) ⊆ Sε,r. Proof. The properties follow immediately from the definition of the relative error model in Equation (1) and the definition of Sε,r in Equation (5). (i) ∀v ̸∈ Sε,r, f(v) > 1 1−εf(r) and by Equation (1), f(r) ≥ (1 − ε)dG(r, g) = (1 − ε)OPT. (ii) ∀v ∈ Sε,r, dG(v, r) ≤ 1 1−εf(r), and by Equation (1), f(r) ≤ (1 + ε)OPT. (iii) By triangle inequality, for any v ∈ G dG(v, g) ≤ dG(v, r) + dG(r, g) = dG(v, r) + OPT and so by property (ii) above, for any v ∈ Sε,r the result follows. (iv) ∀v ∈ PG(r, g), dG(r, v) ≤ dG(r, g) = OPT. Thus property (i) above implies ∀v ∈ PG(r, g), v ∈ Sε,r. (v) Consider v ∈ Sε,r, and let u def = argmin{dG(u, g) | u ∈ PG(v, r)}. Because G is a tree, PG(v, g) = PG(v, u) ∪ PG(u, g). In particular, PG(v, u) ⊆ PG(v, r); observe that because v ∈ Sε,r, ∀w ∈ PG(v, r), dG(w, r) ≤ dG(v, r) ≤ 1 1−εf(r) and thus by the definition of Sε,r, PG(v, r) ⊆ Sε,r. We’ve thus concluded that PG(v, u) ⊆ Sε,r. For the second portion of the path, PG(u, g), observe that by the definition of u = argmin{dG(u, g) | u ∈ PG(v, r)}, it must be that u ∈ PG(r, g). Thus PG(u, g) ⊆ PG(r, g) and so by property (iv), PG(u, g) ⊆ Sε,r. With these properties, we now bound the distance travelled on the ith step of the algorithm: Lemma 15. Let G be a weighted tree, with predictions satisfying Equation (1) with respect to parameter ε < 1. Then, the distance travelled by Algorithm 2 on the ith iteration satisfies (1 − ε)dGi(vi−1, vi) ≤ ∆i + 2εdG(vi, g). (9) Additionally, if the predictions on G are multiplicative and decremental, dGi(vi−1, vi) ≤ ∆i + εdG(vi, g). (10) 18 Proof of Lemma 15. We observe that, by definition of Algorithm 2, for all iterations i, Vi−1 ⊂ Sε,r. Consider wi the first vertex outside of Vi−1 encountered when traversing P(vi−1, g), the shortest path from vi−1 to g. Note that wi ∈ ∂Vi−1, and that by property (v) of Lemma 14, wi ∈ Sϵ,r. Thus, on iteration i, ∃wi ∈ ∂Vi−1 ∩ Sε,r ∩ P(vi−1, g), so by the definition of Algorithm 2 such wi satisfies f(vi) + dGi(vi−1, vi) ≤ f(wi) + dGi(vi−1, wi). In particular, because wi ∈ P(vi−1, g) ∩ ∂Vi−1 and by the tree properties of G, we have dGi(vi−1, wi) = dG(vi−1, wi) = dG(vi−1, g) − dG(wi, g). We can thus upper bound dGi(vi−1, vi) ≤ dG(vi−1, g) − dG(wi, g) + f(wi) − f(vi) = dG(vi−1, g) − dG(vi, g) + \u0000dG(vi, g) − f(vi) \u0001 + \u0000f(wi) − dG(wi, g) \u0001 = ∆i − εvidG(vi, g) + εwidG(wi, g) where εvi, εwi ∈ [−ε, ε] are the constants whose existence is implied by Equation (1) such that f(v) = (1 + εv)dG(v, g). (11) Consider two cases: first, consider the case when εwi > 0. Because wi ∈ P(vi−1, g), dG(wi, g) ≤ dG(vi−1, g) ≤ dG(vi−1, vi) + dG(vi, g). Combining this bound and the fact that εvi, εwi ∈ [−ε, ε] yields: −εvidG(vi, g) + εwidG(wi, g) ≤ 2εdG(vi, g) + εdG(vi−1, vi). Thus in this case, the desired bound in (9) is satisfied. In the second case, when εwi ≤ 0, −εvidG(vi, g) + εwidG(wi, g) ≤ −εvidG(vi, g) ≤ εdG(vi, g) which is trivially upper bounded by 2εdG(vi, g) + εdG(vi−1, vi). Thus, in both cases, the desired bound in (9) is satisfied. In the case of decremental errors, εv ≤ 0 ∀v ∈ V . Thus the latter case always applies, so we can bound dGi(vi−1, vi) ≤ ∆i − εvidG(vi, g) + εwidG(wi, g) ≤ ∆i + εdG(vi, g) thus establishing the bound in (10). We are now equipped to prove Theorem 2. Proof of Theorem 2. We will show that Algorithm 2 achieves the desired competitive ratio. We begin by establishing that the algorithm will terminate at the goal node g: by Property (iv) in Lemma 14, P(r, g) ⊆ Sε,r, and further by definition P(r, g) is connected, so Algorithm 2 initialized at r will explore a connected subgraph of G that contains g, and will thus terminate at g. We now bound the total distance travelled by Algorithm 2. Consider the general case, when errors can be incremental or decremental. Then, by Lemma 15, ALG = X i∈[T ] dGi(vi−1, vi) = X i∈[T ] (1 − ε)dGi(vi−1, vi) + εdGi(vi−1, vi) ≤ X i∈[T ] ∆i + X i∈[T ] 2εdG(vi, g) + X i∈[T ] εdG(vi−1, vi) = OPT + 2ε   X i∈[T ] dG(vi, g)   + εALG. 19 Because Vi ⊆ Sε,r for all iterations i, and by property (iii) in Lemma 14, 2ε X i∈[T ] dG(vi, g) ≤ 2ε|Sε,r| · 2 1 − εOPT. Thus, re-arranging, (1 − ε)ALG ≤ OPT \u0012 1 + |Sε,r|ε · 4 1 − ε \u0013 , yielding the claimed competitive ratio from the trivial upper bound |Sε,r| ≤ n. In the case of decremental errors, Lemma 15 and a similar argument give ALG = X i∈[T ] dGi(vi−1, vi) ≤ X i∈[T ] ∆i + X i∈[T ] εdG(vi, g) ≤ OPT \u0012 1 + |Sε,r|ε · 2 1 − ε \u0013 , yielding the claimed competitive ratio. To prove Theorem 3, we’ll use the following lemmas: the first (Lemma 16) establishes that certain algorithms never explore nodes too far from g. We emphasize that the below lemma makes use of distances in the full G, not Gi. In the case of weighted trees, these two distances are always identical: on a tree, for all iterations i and for any u, v ∈ Vi ∪ ∂Vi, dGi(u, v) = dG(u, v). The second lemma (Lemma 17) bounds the distance travelled by these algorithms on any given iteration. Lemma 16. Consider the exploration problem on G a weighted, undirected graph with predictions f satisfying Equation (1). Consider the update rule used in Algorithm 3: vi = argmin v∈∂Vi−1 {βdG(vi−1, v) + f(v)} , (12) and assume β > 0 satisfies β < 1 − ε. Then, for every iteration i ∈ [T], the node vi visited by the algorithm on the ith iteration satisfies dG(vi, g) ≤ 1 + ε + β 1 − (ε + β)OPT. Proof of Lemma 16. Let ri be the first vertex outside of Vi−1 encountered when traversing PG(r, g) a shortest path from the root r to g. Note that ri ∈ ∂Vi−1, and thus by Equation (12), βdG(vi−1, vi) + f(vi) ≤ βdG(vi−1, ri) + f(ri). In particular, by the triangle inequality we can bound f(vi) ≤ β (dG(vi−1, ri) − dG(vi−1, vi)) + f(ri) ≤ βdG(ri, vi) + f(ri) ≤ β (dG(ri, g) + dG(vi, g)) + f(ri). Given ri ∈ PG(r, g), dG(ri, g) ≤ dG(r, g) = OPT. Moreover, recalling that the predictions f must satisfy Equation (1), let εvi and εri be the relative errors at vertex vi and ri respectively (defined as in Equation (11)). Then we can rewrite the bound above as (1 + εvi)dG(vi, g) ≤ β (dG(ri, g) + dG(vi, g)) + (1 + εri)dG(ri, g), and hence: (1 + εvi − β)dG(vi, g) ≤ (β + 1 + εri)OPT. Using the fact that εvi, εri ∈ [−ε, ε] and the assumption that β satisfies β < 1 − ε, we can use the above bound to conclude dG(vi, g) ≤ 1 + ε + β 1 − (ε + β)OPT. In particular, this holds on any iteration independently of i, so we obtain the desired result. 20 Lemma 17. Consider the exploration problem on G a weighted, undirected graph with predictions f satisfying Equation (1). Assume β > 0 satisfies 1 + ε 2 < β < 1 − ε. (13) Then the distance traversed by Algorithm 3 on the ith iteration is bounded by dGi(vi−1, vi) ≤ β 2β − 1 − ε∆i + 2ε 2β − 1 − εdG(vi, g). Proof of Lemma 17. Let PG(u, v) denote an (arbitrary) shortest path between nodes u and v in G. Algo- rithm 3 follows a shortest path in Gi from vi−1 to vi. Let wi be the first vertex outside of Vi−1 encountered when traversing PG(vi−1, g). Note that as a consequence, wi ∈ ∂Vi−1, and hence by (12) we have βdGi(vi−1, vi) + f(vi) ≤ βdGi(vi−1, wi) + f(wi). Since wi ∈ PG(vi−1, g), dGi(vi−1, wi) = dG(vi−1, wi) = dG(vi−1, g) − dG(wi, g). Re-arranging and using the above fact, we obtain βdGi(vi−1, vi) ≤ βdGi(vi−1, wi) + f(wi) − f(vi) = β \u0000dG(vi−1, g) − dG(wi, g) \u0001 + f(wi) − f(vi) = β \u0000dG(vi−1, g) − dG(vi, g) \u0001 + \u0000βdG(vi, g) − f(vi) \u0001 + \u0000f(wi) − βdG(wi, g) \u0001 . Let εvi, εwi be the relative prediction errors at vi and wi respectively (defined as in Equation (11)), and recall the definition of ∆i in (3). Then we can rewrite the above as βdGi(vi−1, vi) ≤ β∆i + (β − 1 − εvi)dG(vi, g) + (1 + εwi − β)dG(wi, g). Because wi ∈ PG(vi−1, g), we have that dG(vi−1, wi) + dG(wi, g) = dG(vi−1, g) ≤ dG(vi−1, vi) + dG(vi, g). Moreover, by upper bound on β in (13), (1 + εwi − β) ≥ 0, so we can revise our upper bound: βdGi(vi−1, vi) ≤ β∆i + (β − 1 − εvi)dG(vi, g) + (1 + εwi − β) \u0000dG(vi−1, vi) + dG(vi, g) \u0001 . Re-arranging and recalling εvi−1, εwi ∈ [−ε, ε] yields (2β − 1 − ε)dGi(vi−1, vi) ≤ β∆i + 2εdG(vi, g) Leveraging the lower bound on β in (13), we can divide to obtain the desired result. Theorem 3 follows immediately from Lemmas 16 and 17: Proof of Theorem 3. Observe that for ε ∈ (0, 1/3), β = 2/3 always satisfies Equation (13), independently of the value of ε. Thus for this setting, Lemma 17 implies that the update cost on a single iteration of Algorithm 3 is bounded as dGi(vi−1, vi) ≤ 2 1 − 3ε∆i + 6ε 1 − 3εdG(vi, g). (14) In particular, for G a weighted tree, on all iterations i, for all u, v ∈ Vi ∪ ∂Vi, dGi(u, v) = dG(u, v). This, in combination with the choice of β = 2/3 implies that Lemma 16 applies, so for all vertices vi visited by the algorithm, we have dG(vi, g) ≤ 5 + 3ε 1 − 3εOPT. (15) 21 We can then upper bound the last term in Equation (14) and obtain: dGi(vi−1, vi) ≤ 2 1 − 3ε∆i + 6ε 1 − 3ε · 5 + 3ε 1 − 3εOPT Thus, letting T denote the total number of iterations made by Algorithm 3, summing over all iterations yields ALG = X i∈[T ] dGi(vi−1, vi) ≤ 2 1 − 3ε X i∈[T ] ∆i + 6ε 1 − 3ε · 5 + 3ε 1 − 3εOPT · T. In particular, P i∈[T ] ∆i = OPT, and as every iteration i must end at some distinct vi satisfying (15), T ≤ \f\f\f\fB \u0012 g, 5 + 3ε 1 − 3εOPT \u0013\f\f\f\f ≤ n. We then have: ALG ≤ 2 1 − 3εOPT + 6ε 1 − 3ε · 5 + 3ε 1 − 3εOPT · T ≤ OPT \u0012 2 + 6ε 1 − 3ε + 6ε 1 − 3ε · 5 + 3ε 1 − 3ε · n \u0013 . Giving the result in the statement of the theorem. B.2.2 Lower bounds For Exploration With Relative Error Proof of Theorem 8. We consider a star in which every edge has weight w1, to this, we add a new vertex g connected to one of the outside vertices by an edge of weight w2. We consider the case when the initial position r is the central node of the star. In this case, the optimal algorithmic cost is OPT = dG(r, g) = w1 + w2. For the given ε ∈ (0, 1), consider choice of w1 and w2 such that ε = w1 w1 + w2 . Note that in particular, such a setting of weights allows for the following predictions: every node except for the root and the goal can have prediction f(v) = (1 − ε)(2w1 + w2). For the above setting of w1 and w2, this satisfies Equation 1 with respect to ε. In particular, for a searcher starting at the root, all neighbors of the root appear identical. In this error regime, every algorithm for the exploration problem has to explore all branches of the star before finding g in the worst-case. Thus any algorithm has to incur cost at least ALG = 2w1 · (n − 3) + (w1 + w2) = w1(2(n − 3) + 1) + w2. The competitive ratio in this instance is thus ALG OPT = (2(n − 3) + 1) w1 w1 + w2 + w2 w1 + w2 = (2(n − 3) + 1) ε + (1 − ε) = Θ(1 + nε). Proof of Proposition 9. Consider a distribution over instances obtained by taking the instance defined in the proof of Theorem 8, selecting a neighbor v of the root vertex r uniformly at random, and replacing the edge incident to the goal vertex g with an edge gv of weight w2. Any deterministic algorithm for the exploration problem running on an instance sampled from this distributions incurs expected cost at least: ALG = (n − 3) · 1 22w2 + OPT = ((n − 3)ε + 1) OPT ≥ \u0010 1 + nε 2 \u0011 OPT. The lower bound for randomized algorithms then follows from applying Yao’s minimax principle (Yao, 1977). 22 B.3 Proofs For Section 5 Throughout this subsection, we will use the following properties of ϕ0 and ϕ1 established by Banerjee et al. (2023): Lemma 18. Corollary 5.4 and Lemma 5.10 in Banerjee et al. (2023). Given G an unweighted graph, for any u, v ∈ G, ϕ0(u) + ϕ0(v) ≥ dG(u, v). For G weighted, ϕ1(u) + ϕ1(v) ≥ 2dG(u, v). B.3.1 Planning Bounds Via Metric Embeddings The distortion of an embedding can be related to its Lipschitz constant and that of its inverse: the Lipschitz constant of τ is defined as: ∥τ∥Lip def = max x1,x2∈X dY (τ(x1), τ(x2)) dX(x1, x2) . Note that any map with non-trivial distortion must be injective, and thus considering τ −1 : Y → X, dist(τ) = ∥τ∥Lip · ∥τ −1∥Lip. To prove Lemma 10, we’ll use the following fact to relate tours in G to tours in some embedding. Lemma 19. Consider an embedding τ : G → G′ for G = (V, E) and G′ = (V ′, E′). Then for any S ⊆ V , tourG(S) ≤ ∥τ −1∥Lip · tourG′(τ(S)). Proof of Lemma 19. Recall the definition of tourG(S) given in Equation (2): tourG(S) def = max v∈S min W ∈W(v,S) lengthG(W), where W(v, S) is the set of walks in G starting at vertex v and visiting every vertex in S. Consider any walk W = (u1, ..., uk) in G′ starting at some u1 ∈ τ(S) and visiting all of τ(S). Let W ′ = (u′ 1, ..., u′ k′) be the subsequence of W containing only the points in τ(S). Note that W ′ contains all of the points in τ(S). We have: lengthG′(W) = k−1 X i=1 dG′(ui, ui+1) ≥ k′−1 X i=1 dG′(u′ i, u′ i+1) (16) ≥ k′−1 X i=1 1 ∥τ −1∥Lip · dG(τ −1(u′ i), τ −1(u′ i+1)). (17) So, letting W ′′ be the walk visiting the vertices (τ −1(u′ i))k′ i=1 in order while walking the shortest path in G between them. We then have: lengthG′(W) ≥ k′−1 X i=1 1 ∥τ −1∥Lip · dG(τ −1(u′ i), τ −1(u′ i+1)) = 1 ∥τ −1∥Lip · lengthG(W ′′). In particular, for any starting point v ∈ S and any walk in W ∈ W(τ(v), τ(S)) there exists some walk W ′′ ∈ W(v, S) such that: lengthG(W ′′) ≤ ∥τ −1∥Lip · lengthG′(W), so that, for every v ∈ S: min W ∈W(v,S) lengthG(W) ≤ ∥τ −1∥Lip min W ∈W(τ(v),τ(S)) lengthG′(W) ≤ ∥τ −1∥Lip max u∈τ(S) min W ∈W(u,τ(S)) lengthG′(W), and hence: max v∈S min W ∈W(v,S) lengthG(W) ≤ ∥τ −1∥Lip max u∈τ(S) min W ∈W(u,τ(S)) lengthG′(W), completing the proof. 23 We now use Lemma 19 to establish Lemma 10. Proof of Lemma 10. Given a real-valued function f : V → R, we denote the sublevel set of f about threshold c as L− f (c) def = {v ∈ V : f(v) ≤ c}. For the first part of the result, let G be an unweighted graph and consider the sublevel set L− ϕ0(λ). By definition of the Lipschitz constant of τ : G → G′, for all u, v ∈ G dG′(τ(u), τ(v)) ≤ ∥τ∥LipdG(u, v). Thus by Lemma 18, the embedding of the sublevel set has bounded diameter: let u, v ∈ L− ϕ0(λ) such that diam \u0000τ(L− ϕ0(λ)) \u0001 = dG′(τ(u), τ(v)). Then diam \u0000τ(L− ϕ0(λ)) \u0001 = dG′(τ(u), τ(v)) ≤ ∥τ∥LipdG(u, v) ≤ ∥τ∥Lip(ϕ0(u) + ϕ0(v)) ≤ ∥τ∥Lip · 2λ. Using this result along with the bound from Lemma 19 and the assumption that G′ is cG′ easily-tourable, we can bound tourG(L− ϕ0)(λ) ≤ ∥τ −1∥Lip · tourG′\u0000τ(L− ϕ0(λ) \u0001 ≤ ∥τ −1∥Lip · cG′diam \u0000τ(L− ϕ0(λ)) \u0001 ≤ ∥τ −1∥Lip · cG′ · 2λ∥τ∥Lip = 2ρcG′λ. We now use this bound to analyze the cost of Algorithm 4. Algorithm 4 sequentially visits sublevel sets of ϕ0. On an iteration k corresponding to threshold λk, the algorithm visits each node in L− ϕ0(λk) ⊆ V by computing a constant-factor approximation to the following problem: for {v1, . . . , v|L− ϕ0(λk)|} the nodes of L− ϕ0(λk) and Π(n) the set of permutations on integers 1, . . . , n, the algorithm computes σ∗ λk def = argmin σ∈Π(|L− ϕ0(λk)|) |L− ϕ0(λk)| X i=1 dG(vσ(i), vσ(i+1)). The total distance travelled on the iteration k is thus |L− ϕ0(λk)| X i=1 dG(vσ∗(i), vσ∗(i+1)) ≤ max v∈L− ϕ0(λk) min W ∈W(v,L− ϕ0(λk)) lengthG(W) = tourG(L− ϕ0(λk)). Algorithm 4 begins with λ0 = 1 and doubles the threshold on each iteration, such that λk = 2k. In particular, ϕ0(g) = E0, so the algorithm is guaranteed to terminate by the time it has visited every node of L− ϕ0(λk) for the first sufficiently large threshold λk ≥ E0. The algorithmic cost can thus be bounded as ALG ≤ dG(r, L− ϕ0(1)) + ⌈log2(E0)⌉ X k=0 tourG(L− ϕ0(2k)) ≤ dG(r, L− ϕ0(1)) + 2ρcG′ ⌈log2(E0)⌉ X k=0 2k ≤ dG(r, L− ϕ0(1)) + 2ρcG′(4E0 − 1). Using Lemma 18, we can bound the transition cost from r to the first sublevel set as dG(r, L− ϕ0(1)) ≤ dG(r, g) + dG(g, L− ϕ0(1)) ≤ OPT + (ϕ0(g) + 1) = OPT + E0 + 1. 24 Combining these yields ALG ≤ OPT + E0(8ρcG′ + 1) − 2ρcG′ + 1 = OPT + O(ρcG′E0), as desired. For the second part of the result, let G be an graph with integer-valued distances consider the sublevel set L− ϕ1(λ), and note that Lemma 19 holds for both weighted and unweighted graphs. The proof then follows analogously to the above argument, using the appropriate bound relating ϕ1 to distances in G from Lemma 18. B.3.2 Lower Bounds For Planning Problems 1 1 r 1 1 1 1 ... ... ... ... ... ... W W W W W W W W W W W W 1 1 1 1 1 1 1 1 1 1 1 1 g Figure 6: Reproduction of Figure 1. The lower bound construction for the proof of Lemma 11 Proof of Lemma 11. We construct a family of graphs with uniform predictions and analyze the worst-case cost incurred by any algorithm for the planning problem. For a given ∆ and W ∈ N let G∆,W be following graph: consider a root node r with ∆ child nodes v1, . . . , v∆. Let every edge (r, vi) have edge weight 1. Each child node vi then has ∆ − 1 descendants ui 1, . . . , ui ∆−1 with edge weights 1 for each edge (vi, ui j). Each of these descendants has a single child node wi j to which ui j is attached with edge weight W. This construction is illustrated in Figure 1. We consider the planning problem when the searcher is initialized at the root node r described above, and the goal is the leaf node w1 1. We consider the case when error in the predictions is such that each subtree rooted at vi appears to have the same predictions. In this construction, predictions are equal to true distance-to-goal for all nodes which are descendents of v1 for i ̸= 1, and error is allocated only over descendents of v1. We first calculate the total error in such predictions: E1 = |f(v1) − dG(v1, g)| + |f(g)| + ∆−1 X j=2 |f(u1 j) − dG(u1 j, g)| + |f(w1 j) − dG(w1 j, g)| = 2W + 6∆ + 4. Under these predictions, all nodes on a given level from the root appear identical to the searcher. As a result, in the worst-case any algorithm for this problem must visit every node and incur cost ALG at least 25 as large as the shortest tour of the graph starting at r and ending at g. Hence: ALG ≥ W(2∆2 − 2∆ − 1) + 2(∆2 − 1). On the other hand, we have OPT = dG(r, g) = W + 2. This gives: ALG − OPT ≥ 2W(∆2 − ∆ − 1) + 2(∆2 − 2). In order to understand how this cost scales with our parameters of interest, we now establish bounds on the doubling constant of G that show that λ = Θ(∆2). Recall that the doubling constant is defined to be the minimum value of λ such that for any radius R, any ball of radius R can be covered with at most λ many balls of radius R/2. Observe that the number of nodes n always upper bounds the doubling constant, so λ ≤ 2∆2 + ∆ + 1. To lower bound the doubling constant, consider the ball of radius W + 2 centered at the root node r, and note that this ball contains the entire graph. For W large (W ≥ 4), ∆2 + 1 many balls of radius W/2 + 1 are required to cover the nodes of the graph, hence ∆2 − 1 ≤ λ. The fact that a ≥ 1 then follows from observing that λ is independent of W while ALG−OPT = Ω(W∆2). The fact that if a = 1, b ≥ 1 similarly follows from the above along with E1 = Θ(W + ∆). Proof of Lemma 13. To establish that a ≥ 1 and that a + b ≥ 3, we consider the same construction outlined in the proof of Lemma 11 above. The same argument implies a ≥ 1. Setting W = ∆ yields a family of problem instances on integer-weighted trees for which ALG − OPT = Ω(∆3) where E1 = Θ(∆). Thus on this family of instances any algorithm which is guaranteed to incur cost ALG − OPT = O(Ea 1 ∆b) must have a + b ≥ 3. To establish that b ≥ 1, we consider a construction in which E1 scales independently of ∆. Consider the weighted star with edge weights w, and assume the searcher is initialized at the central root node r and the goal node g is a leaf node as illustrated on the right side of Figure 5. We consider the same predictions constructed in the proof of Theorem 6: all nodes except for g have f(v) = dG(v, g), and f(g) = 2w so that predictions at all leaf nodes appear uniform. Then in the worst case, the searcher must visit every node in the graph, incurring traversal cost ALG = w(2∆ − 1). However, the total ℓ1 norm of the vector of errors is E1 = 2w independent of ∆, and OPT = w, so the result follows. Lemma 20. Let A be any algorithm for the planning problem on weighted trees which is guaranteed to incur cost: OPT + O(Ea 1 ρb) on graph searching instance I, where ρ is the minimum distortion of embedding the instance graph into the path. Then a ≥ 1 and b ≥ 1. Proof. The proof is entirely analogous to that of the second part of Lemma 13. For any value of E1, one can make use of the same construction (the weighted star, with r the central node and g a leaf) with weights w = E1/2 on each edge. The result then follows from observing that for the family of constructed graphs, ρ = ∆ and the analogous calculations. B.4 Planning On Trees With Integer-Valued Distances In this section, we prove Lemma 12. The result follows from arguments analogous to those outlined in Banerjee et al. (2023) Section 5.1: we first state and prove three necessary lemmas. Lemma 21 (Analogous to Lemma 5.3 in Banerjee et al. (2023)). Given G with positive integer distances d : V × V → Z≥0, for any U ⊆ V |S \\ M(U)| ≤ X u∈U φ1(u), where M(U) def = {v ∈ V : d(v, u) = d(v, u′) ∀u, u′ ∈ U}. 26 Proof Lemma 21. Given d : V × V → Z≥0, for any U ⊆ V , ∀w ̸∈ M(U) let uw, vw denote elements of U such that dG(w, uw) ̸= dG(w, vw). In particular, because d(·, ·) is integer-valued, ∀w ̸∈ M(U) |dG(w, uw) − dG(w, vw)| ≥ 1. In particular, for any S ⊆ V X u∈U φ1(u) = X u∈U X w∈V |f(w) − dG(w, u)| ≥ X u∈U X w∈S\\M(U) |f(w) − dG(w, u)| ≥ X w∈S\\M(U) |f(w) − dG(w, uw)| + |f(w) − dG(w, vw)| ≥ X w∈S\\M(U) |dG(w, uw) − dG(w, vw)| ≥ |S \\ M(U)|. Lemma 22 (Generalization of Lemma 5.10 in Banerjee et al. (2023)). For any u, v ∈ V , we have: φ1(u) + φ1(v) ≥ 2d(u, v) + X w∈V \\{u,v} |d(u, w) − d(v, w)| . Proof of Lemma 22. The proof is a straight-forward application of the triangle inequality: φ1(u) + φ1(v) = X w∈V |d(u, w) − f(w)| + |d(v, w) − f(w)| ≥ X w∈V |d(u, w) − f(w) − d(v, w) + f(w)| = X w∈V |d(u, w) − d(v, w)| = 2d(u, v) + X w∈V \\{u,v} |d(u, w) − d(v, w)| . We also utilize the following bound on the size of the minimum Steiner tree of any sublevel set of ϕ1: recall that for a real-valued function f : V → R, we denote the sublevel set of f about threshold c as L− f (c) def = {v ∈ V : f(v) ≤ c}. Lemma 23. For G a connected tree with at least three nodes, integer edge weights, and maximum degree ∆, let Cλ denote the set of vertices in the minimum Steiner tree containing all vertices in L− ϕ1(λ). Then |Cλ| ≤ λ∆. Proof of Lemma 23. By definition, L− ϕ1(λ) ⊆ Cλ. Let u1, u2 ∈ L− ϕ1(λ) such that d(u1, u2) = diam(L− ϕ1(λ)) If ̸ ∃w ∈ Cλ such that d(u1, w) = d(u2, w), then Lemma 21 implies |Cλ| = |Cλ \\ M(u1, u2)| ≤ φ1(u1) + φ1(u2) ≤ 2λ. 27 Tj qj w u1 u2 x uj ... Figure 7: Visual aid for proof of Lemma 23, for the case when ∃w ∈ Cλ such that d(u1, w) = d(u2, w). In particular, for G connected with at least three nodes, ∆ ≥ 2, so the desired bound holds. We now consider the case when ∃w ∈ Cλ such that d(u1, w) = d(u2, w). Let q1, . . . , qk denote the neighbors of w and let Ti ⊆ Cλ denote the subtree of descendants of w that contains qi. Assume without loss of generality that T1 ∋ u1 and T2 ∋ u2. Note that, because Cλ is defined to be minimal, ∀i ∈ [k] L− ϕ1(λ) ∩ Ti ̸= ∅. Let u3, ..., uk be points such that ui ∈ L− ϕ1(λ) ∩ Ti. Consider any x ∈ Cλ \\ {w}. Then ∃j ∈ [k] such that x ∈ Tj. This case is illustrated in Figure 7. Assume without loss of generality that j ̸= 1 (this can be assumed WLOG because if x ∈ T1, then the below argument can be carried out with respect to u2). Because G is a tree and x ̸∈ T1, d(u1, x) = d(u1, w) + d(w, x) By choice of u1, u2, diam(L− ϕ1(λ)) = 2d(u1, w) so in particular d(u1, w) ≥ d(uj, w) ∀uj ∈ L− ϕ1(λ). Thus d(u1, x) = d(u1, w) + d(w, x) ≥ d(uj, w) + d(w, x). Moreover, for all v ∈ Tj, d(v, w) = d(v, qj) + d(qj, w) by definition of subtree Tj, so for non-zero weights, d(uj, w) + d(w, x) > d(uj, qj) + d(x, qj) ≥ d(uj, x) We thus conclude d(u1, x) > d(uj, x), which in particular implies x ̸∈ M({u1, . . . , uk}). Thus for all (Cλ \\ {w}) ∩ M({u1, . . . , uk}) = ∅, so |Cλ| − 1 = |Cλ \\ M({u1, ..., uk}) ≤ k X i=1 φ1(ui) ≤ λ∆. We have thus established the result in both cases (i.e. when Cλ ∩ M({u1, . . . , uk}) = ∅ and when Cλ ∩ M({u1, . . . , uk}) ̸= ∅). Proof of Lemma 12. Consider the cost of visiting every node in Cλ, a minimum Steiner tree containing the sublevel set L− ϕ1(λ). Because Cλ is minimal, diam(Cλ) = diam(L− ϕ1(λ)) ≤ λ where the last inequality follows from Lemma 22. In particular, traversing Cλ to visit every node incurs travel cost at most diam(Cλ) · |Cλ|. Combining the above bound and Lemma 23 implies diam(Cλ) · |Cλ| ≤ λ2∆. Algorithm 4 with objective ϕ1 proceeds by iteratively visiting every node in the sublevel set L− ϕ1(λ) by computing and traversing a minimum Steiner tree Cλ that contains the sublevel set. Algorithm 4 begins with λ0 = 1 and doubles the threshold on each iteration, such that λk = 2k. In particular, ϕ1(g) = E1, so the algorithm is guaranteed to terminate by the time it has visited every node of L− ϕ1(λk) for the first sufficiently large threshold λk ≥ E1. The algorithmic cost of Algorithm 4 with objective ϕ1 is thus bounded by ALG = d(r, L− ϕ1(1)) + ⌈log2(E1)⌉ X k=0 diam(C2k) · |C2k| 28 ≤ d(r, L− ϕ1(1)) + ∆ ⌈log2(E1)⌉ X k=0 (2k)2 ≤ d(r, L− ϕ1(1)) + ∆ 3 (16E2 1 − 1) Additionally, leveraging Lemma 22 and the fact that ϕ1(g) ≤ cE1, d(r, L− ϕ1(1)) ≤ d(r, g) + d(g, L− ϕ1(1)) ≤ OPT + 1 2 (E1 + 1) . Combining these bounds yields the desired result in the regime E1 ≥ 1. C Relation Between Embedding Distortion and Doubling Dimen- sion We show that that every graph with a low-distortion embedding into the path also has small doubling dimension / doubling constant, as per the following lemma. Recall that the doubling constant of a metric space is the smallest value λ such that, for any choice of radius R ∈ R, every ball of radius R can be covered with the union of λ balls of radius R/2, and that the doubling dimension is given by log2 λ. Lemma 24. Let G be an undirected graph on n vertices admitting an embedding into a path on n vertices with distortion ρ and let λ be the doubling constant of G. Then: λ ≤ ⌈8ρ⌉. In contrast there exist graphs with constant doubling dimension that admit no embeddings into the unweighted path of distortion independent of n. For example, the 2D planar grid graph on n vertices has constant doubling dimension / doubling constant, but a simple argument shows that every embedding of the 2D planar grid into the path has distortion Ω(√n). Proof of Lemma 24. Let G = (V, E) be an undirected graph which embeds into [n] with distortion ρ. Let τ be an embedding which achieves this distortion. For any R > 0, let BG(u, R) ⊆ V denote the ball in G centered at u of radius R, and let B[n](τ(u), R) denote the ball of radius R in [n] centered at τ(u). Let τ(S) ⊆ [n] denote the image of S ⊆ V under τ. For any radius R and any u ∈ V , by the definition of the Lipschitz constant we can bound d[n](τ(u), τ(v)) ≤ ∥τ∥LipdG(u, v) ≤ ∥τ∥LipR ∀v ∈ BG(u, R) so τ(BG(u, R)) ⊆ B[n](τ(u), ∥τ∥LipR). In particular, for S1 ⊆ V , τ(S1) ⊆ S2 implies S1 ⊆ τ −1(S2), so we conclude BG(u, R) ⊆ τ −1(B[n](τ(u), ∥τ∥LipR)). Consider B[n](τ(u), ∥τ∥LipR). Fix ϵ and let kϵ denote the cardinality of an ϵ-covering of B[n](τ(u), ∥τ∥LipR). Observe that for any c, ϵ > 0 and any v ∈ [n], B[n](v, c) admits an ϵ-covering of cardinality at most ⌈2c/ϵ⌉, so kϵ ≤ ⌈2∥τ∥LipR/ϵ⌉. Let {x1, . . . , xkϵ} ⊆ [n] denote the centers of the covering balls. Given BG(u, R) ⊆ τ −1(B[n](τ(u), ∥τ∥LipR)), we observe that BG(u, R) ⊆ kε [ i=1 τ −1 \u0000B[n](xi, ϵ) \u0001 . In particular, ∀i ∈ [kϵ], for any x, y ∈ B[n](xi, ϵ), the definition of the Lipschitz constant implies dG(τ −1(x), τ −1(y)) ≤ ∥τ −1∥Lipd[n](x, y) ≤ ∥τ −1∥Lip · 2ϵ. Thus diam \u0000τ −1 \u0000B[n](xi, ϵ) \u0001\u0001 ≤ 2ϵ∥τ −1∥Lip. In particular, this implies that ∀i ∈ [kϵ] such that τ −1 \u0000B[n](xi, ϵ) \u0001 ̸= ∅, ∃vi ∈ V such that τ −1 \u0000B[n](xi, ϵ) \u0001 ⊆ BG(vi, 2ϵ∥τ −1∥Lip). Thus BG(u, R) ⊆ kε [ i=1 τ −1 \u0000B[n](xi, ϵ) \u0001 ⊆ kε [ i=1 BG(vi, 2ϵ∥τ −1∥Lip). 29 We have thus produced a covering of BG(u, R) using kϵ balls of radius 2ϵ∥τ −1∥Lip. We now choose ϵ so that 2ϵ∥τ −1∥Lip = R/2, namely let ϵ = R/(4∥τ −1∥Lip). The cardinality of the covering is then kϵ ≤ & 2∥τ∥LipR ϵ ' = & 2∥τ∥LipR · 4∥τ −1∥Lip R ' = ⌈8∥τ∥Lip∥τ −1∥Lip⌉ Using the fact that ρ = ∥τ∥Lip∥τ −1∥Lip we conclude that the doubling constant of G is at most ⌈8ρ⌉. D Experimental Details In this section, we provide a detailed descriptions of the experiments discussed in Section 6 of the main body of the paper. We outline two sets of experiments: the first set of experiments is used to evaluate the performance of Algorithm 1 in the presence of absolute error, the second set is used to evaluate the performance of Algorithm 2 in the presence of relative error. Both these sets of experiments focus on stochastic error. All experiments in this section were run on a 2019 MacBook Pro with a 1.4 GHz Quad-Core Intel Core i5 Processor with 16 GB of RAM. No GPUs were used for this experiment. Figure 8: A larger rendering of the left subfigure in Figure 2 in the main body of the paper. Absolute Error The first set of experiments corresponds to the left side of Figure 2 (replicated above as Figure 8). Here, we generate an error vector ⃗e ∈ Rn according to the following procedure: we fixed a value E1 representing the total desired ℓ1-norm of the vector of errors, and then we sampled a vector ⃗eunsigned uniformly at random from the scaled simplex with ℓ1-norm equal to E1, i.e.: ⃗eunsigned ∼ E1 · ∆n def = {⃗x ∈ Rn | ⃗x ≥ 0, ∥⃗x∥1 = E1}. We then assign a random sign to each entry of ⃗eunsigned to obtain ⃗e, this is done by multiplying each ⃗eunsigned[v] by a Rademacher random variable σv. Fixing a graph G, the predictions at each vertex v ∈ V are then given by f(v) = dG(v, g) + σv · ⃗eunsigned[v]. This is repeated over many instance graphs selected from four classes: Random Tree, Random Lobster, Erdos-Rényi and Circular Ladder (See paragraph Graph 30 Families below). Whenever the family of graphs chosen is stochastic, as it is the case for all classes except for Circular Ladder, the graph is also resampled from its family at each iteration, so that the expectation is taken over the sampling of the graph topology as well as the random error. For each of these problem instances, we run Algorithm 1 and record the difference between the total distance ALG travelled by the algorithm to find g, and the true shortest-path distance OPT from the starting point to g, and we plot E1 against it. We report mean and standard deviation of ALG − OPT over 2000 independent trials. (ALG-OPT)/OPT Erdos-Renyi Algorithm 1 Smallest Prediction (ALG-OPT)/OPT Random Lobster Algorithm 1 Smallest Prediction (ALG-OPT)/OPT Circular Ladder Algorithm 1 Smallest Prediction Figure 9: A comparison of the performance of Algorithm 1 with the Smallest Prediction heuristic. Each subfigure represents one family of graphs: the top-left corresponds to random Erdös-Rényi graphs, the top- right corresponds to Random Lobster, and the middle one at the bottom corresponds to circular ladder (See Graph Families at the end of this section). In each figure, we plot the average and the standard deviation of the performance of Algorithm 1 and that of the Smallest Prediction heuristic against the magnitude of the error vector E1. Comparison to Smallest Prediction Heuristic We then compare the performance of Algorithm 1 to the Smallest Prediction heuristic defined in Section 6 (Figure 9). Recall that in Smallest Prediction, at each iteration i, the agent travels to the an arbitrary vertex vi ∈ argminv∈Vi−1 f(v). We consider the same families of graphs as in the previous section. For each family, we compare the performance of our algorithm with that of Smallest Prediction for different values of the error magnitude E1. The instances, including the errors, are generated like in the previous set of experiments. Performance is measured as the total distance travelled by the agent, minus the true distance OPT from r to g, as a fraction of OPT. Just like in the previous experiments, we run 2000 trials for every value of E1 and report the average and standard deviation of the performance across those trials. 31 Figure 10: A larger rendering of the right subfigure of Figure 2 in the main body of the paper. Relative Error In the right subfigure of Figure 2, for each value of ε the predictions are generated by setting f(v) = (1 + εv) · dG(v, g) where εv is sampled from a Gaussian distribution with mean 0 and standard deviation ε/2 conditioned on the event: εv ∈ [−ε, ε]. We run Algorithm 3 and plot the value of the competitive ratio ALG/OPT against the value of ε for ε ∈ [0, 0.3], and report the mean and standard deviation incurred over 2000 independent trials. Scaling with Number of Nodes Finally, we plot the performance of Algorithm 3 as a function of n (Figure 11). For this experiment we generate instances with different numbers of vertices and plot report the average and standard deviation of the respective empirical competitive ratios (ALG/OPT). We run 2000 trials for each family of graphs and for each number n ∈ {50, 100, 500, 1000} of nodes. The error is generated as in the previous section with ε = 0.2. Graph Families In the above experiments we consider the four graph families described below. All the graphs considered are undirected and unweighted. In Figure 2, we sample the below graphs on n = 100 nodes, and in Table 2, we sample them on n = 300 nodes. • Erdös-Renyi Random Graphs: Erdös-Rényi Gn,p graphs (Erdős et al., 1960) are a popular random graph model in the literature. We sample from the distribution of Erdös-Rényi graphs with n nodes and edge probability p = 0.1, conditioned on the graph being connected; • Random Trees: Trees are just connected acyclic graphs. We sample trees on n vertices uniformly at random; • Random Lobster Graphs: A lobster graph is a tree which becomes a caterpillar graph when its leaves are removed, we sample random lobster graphs on n vertices; • Circular Ladder Graphs: A circular ladder graph is a graph obtained by gluing the endpoints of a ladder graph, i.e. it’s a graph on vertices {1, ..., 2k} where the edges are of the form (i, i + 1) for i = 1, ..., k−1 and i = k+1, ..., 2k, and (i, k+i) for i = 1, ..., k as well as (1, k), (k+1, 2k). We consider the circular ladder graph on n vertices. 32 ALG/OPT Number of Nodes Figure 11: The empirical competitive ratio of Algorithm 3 for different graph families and for different values of n. On the x-axis: the number of vertices n in the instance graphs considered. We consider n = 50, 100, 500, 1000. On the y-axis: the ratio between the distance travelled by the agent, and the true distance OPT from r to g in G. 33 "
}